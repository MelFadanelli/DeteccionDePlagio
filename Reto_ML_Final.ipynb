{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "becf9cb2c5754546b0fa900ff580a819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4608f3a3882e49f791b763eb47893756",
              "IPY_MODEL_ee2e595ac7fb4fefbdd58a1d62f94bd8",
              "IPY_MODEL_72d3b027e63e4af6bf9eb0b8567bb6c4"
            ],
            "layout": "IPY_MODEL_b0c67d63413c42e6a1aef8bb58530b4e"
          }
        },
        "4608f3a3882e49f791b763eb47893756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00d62c647251424fb15a02b0e82a617d",
            "placeholder": "​",
            "style": "IPY_MODEL_5718c718555b4f759948d5a16df08d28",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "ee2e595ac7fb4fefbdd58a1d62f94bd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7e73e24f2984f1899ef809ad4df24b5",
            "max": 399,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f138efd040b44532a48568b0129bee01",
            "value": 399
          }
        },
        "72d3b027e63e4af6bf9eb0b8567bb6c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00a2b19bea5d48c9b34ed3b39c9ac756",
            "placeholder": "​",
            "style": "IPY_MODEL_06a71d1357f2475591b110ad834ca77e",
            "value": " 399/399 [00:00&lt;00:00, 16.6kB/s]"
          }
        },
        "b0c67d63413c42e6a1aef8bb58530b4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00d62c647251424fb15a02b0e82a617d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5718c718555b4f759948d5a16df08d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7e73e24f2984f1899ef809ad4df24b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f138efd040b44532a48568b0129bee01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "00a2b19bea5d48c9b34ed3b39c9ac756": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06a71d1357f2475591b110ad834ca77e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0256c88da6e479b918c48c81bd57234": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04f6322a6f3647589dbca6d45bdf365d",
              "IPY_MODEL_f9e710eed9ef404991a7587f3d7ff036",
              "IPY_MODEL_661249516d424aeda83c4833a049a98e"
            ],
            "layout": "IPY_MODEL_511673328b90460faaf5d7b0d3bb59b4"
          }
        },
        "04f6322a6f3647589dbca6d45bdf365d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4ffa7bfadab435b88b022649c4df664",
            "placeholder": "​",
            "style": "IPY_MODEL_43d78f1ebda7489db3fe9965099be540",
            "value": "config.json: 100%"
          }
        },
        "f9e710eed9ef404991a7587f3d7ff036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc194a1cba924045a3bb8ed3d956f882",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5f5b1b3aa9747e3b4edd0742190f10f",
            "value": 625
          }
        },
        "661249516d424aeda83c4833a049a98e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e368a1c05ea64fe6b2ef40cf03df9cdf",
            "placeholder": "​",
            "style": "IPY_MODEL_a9096c8bfbbc43f6ae710401161f7752",
            "value": " 625/625 [00:00&lt;00:00, 42.9kB/s]"
          }
        },
        "511673328b90460faaf5d7b0d3bb59b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4ffa7bfadab435b88b022649c4df664": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43d78f1ebda7489db3fe9965099be540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc194a1cba924045a3bb8ed3d956f882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5f5b1b3aa9747e3b4edd0742190f10f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e368a1c05ea64fe6b2ef40cf03df9cdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9096c8bfbbc43f6ae710401161f7752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8915e34474834f31a7404fdcbaf5e9c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc4d5af457114a59a699bc3e0edb2496",
              "IPY_MODEL_f829504d5e76454ca895c511496db3a3",
              "IPY_MODEL_6dbf0f0e5fe440cc8146d5c0013a8c3d"
            ],
            "layout": "IPY_MODEL_73b49df047304ac4ba46489ea6f08fdd"
          }
        },
        "cc4d5af457114a59a699bc3e0edb2496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3029520d55a4204aed288400b8e2644",
            "placeholder": "​",
            "style": "IPY_MODEL_f50ac11dfa544a14a85900c167d04799",
            "value": "vocab.txt: 100%"
          }
        },
        "f829504d5e76454ca895c511496db3a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1bd133a42944f468b538de12195ecde",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01d300a5f2a742fb95d2c748edb96c57",
            "value": 231508
          }
        },
        "6dbf0f0e5fe440cc8146d5c0013a8c3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73a80f0a5a0d46428b1e35eb1822f5ae",
            "placeholder": "​",
            "style": "IPY_MODEL_2e11319d330941cfa875df36a7d22bc5",
            "value": " 232k/232k [00:00&lt;00:00, 3.79MB/s]"
          }
        },
        "73b49df047304ac4ba46489ea6f08fdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3029520d55a4204aed288400b8e2644": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f50ac11dfa544a14a85900c167d04799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1bd133a42944f468b538de12195ecde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01d300a5f2a742fb95d2c748edb96c57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73a80f0a5a0d46428b1e35eb1822f5ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e11319d330941cfa875df36a7d22bc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "583fbbe9ea234d959f27b94b0524194b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0cc3c47b067a4b61859875f1209459d6",
              "IPY_MODEL_4983eb02ae8e469cb0f3c98603940d78",
              "IPY_MODEL_796b5e65106d4444b1dd1cf06d112e33"
            ],
            "layout": "IPY_MODEL_5f51a345d1ae494292f28b72354c8f63"
          }
        },
        "0cc3c47b067a4b61859875f1209459d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cec6e2a321914cc9bbc2399394b642ee",
            "placeholder": "​",
            "style": "IPY_MODEL_cc60b6fcc7d54f46bd4759674b4abc96",
            "value": "tokenizer.json: 100%"
          }
        },
        "4983eb02ae8e469cb0f3c98603940d78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4892d9a3c054143a7f0836567aebe67",
            "max": 466081,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8560bdfa1e5429498cce1f035d5c2f0",
            "value": 466081
          }
        },
        "796b5e65106d4444b1dd1cf06d112e33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db742631eb4b4e01a31b8c6c1bdf31a0",
            "placeholder": "​",
            "style": "IPY_MODEL_6aa5583962c44d92a13dd822be728ddd",
            "value": " 466k/466k [00:00&lt;00:00, 23.6MB/s]"
          }
        },
        "5f51a345d1ae494292f28b72354c8f63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cec6e2a321914cc9bbc2399394b642ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc60b6fcc7d54f46bd4759674b4abc96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4892d9a3c054143a7f0836567aebe67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8560bdfa1e5429498cce1f035d5c2f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db742631eb4b4e01a31b8c6c1bdf31a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6aa5583962c44d92a13dd822be728ddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "213a6ec454414648ab6c1aa23b15a52e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec2df851495a477b8490ff1f433c619c",
              "IPY_MODEL_331b5775cf21489fb80ad5360105c35b",
              "IPY_MODEL_787f9bb1077a4fdb87d96392c6cf92f5"
            ],
            "layout": "IPY_MODEL_e45a2469f7024399af87810046e51f82"
          }
        },
        "ec2df851495a477b8490ff1f433c619c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0285c8c0cc0e47539f612d534b954cf6",
            "placeholder": "​",
            "style": "IPY_MODEL_894a73471d904da8b4cf4a6c4ad857f1",
            "value": "added_tokens.json: 100%"
          }
        },
        "331b5775cf21489fb80ad5360105c35b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41bd2c2c1bbc4a8ca760cb6ebcc18d45",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5b684acf033453f9d3a25f5fd8a323d",
            "value": 2
          }
        },
        "787f9bb1077a4fdb87d96392c6cf92f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e43933bc4f554a18bb3d3f0c70ea48bb",
            "placeholder": "​",
            "style": "IPY_MODEL_79e47dee4448483a86f9a0f78f6fbe7b",
            "value": " 2.00/2.00 [00:00&lt;00:00, 106B/s]"
          }
        },
        "e45a2469f7024399af87810046e51f82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0285c8c0cc0e47539f612d534b954cf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "894a73471d904da8b4cf4a6c4ad857f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41bd2c2c1bbc4a8ca760cb6ebcc18d45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5b684acf033453f9d3a25f5fd8a323d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e43933bc4f554a18bb3d3f0c70ea48bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79e47dee4448483a86f9a0f78f6fbe7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd849ec76e684cb9b95b6457b84ddfff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_492ac077a38a4a5e97dad533eecca5f8",
              "IPY_MODEL_619c94803f1747ae9885b74ea5781a2f",
              "IPY_MODEL_927d2265d8784a42aa30c1a37994ec92"
            ],
            "layout": "IPY_MODEL_0db70a48e9ee4601b170192f08405176"
          }
        },
        "492ac077a38a4a5e97dad533eecca5f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5d030bff0174a869686c2f9adf139c0",
            "placeholder": "​",
            "style": "IPY_MODEL_8b93e65299dc4255882e3671fc33ba06",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "619c94803f1747ae9885b74ea5781a2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_518c514f8ff240c883542398591a393d",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_317c24cce19d4c428241307e55d31cbf",
            "value": 112
          }
        },
        "927d2265d8784a42aa30c1a37994ec92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bf749a005b246c79e6b277d953ed4a4",
            "placeholder": "​",
            "style": "IPY_MODEL_57998c7274fe49bda45a572a33792259",
            "value": " 112/112 [00:00&lt;00:00, 7.64kB/s]"
          }
        },
        "0db70a48e9ee4601b170192f08405176": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5d030bff0174a869686c2f9adf139c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b93e65299dc4255882e3671fc33ba06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "518c514f8ff240c883542398591a393d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "317c24cce19d4c428241307e55d31cbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8bf749a005b246c79e6b277d953ed4a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57998c7274fe49bda45a572a33792259": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76a1d7dc6d8c4c358a6c2076aa4ad2aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_685643db42064159837a624143f978e8",
              "IPY_MODEL_c9bd701b93e84c56a35bed76a47de8a4",
              "IPY_MODEL_4347f16cb9e544e5a4065ba30ad7fed3"
            ],
            "layout": "IPY_MODEL_69aff2388a7849eaa0a524b87d5bdb03"
          }
        },
        "685643db42064159837a624143f978e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73a3a759b4d840549a9251c6a9037282",
            "placeholder": "​",
            "style": "IPY_MODEL_635bcd5be8764af6864d8ee291fc448a",
            "value": "model.safetensors: 100%"
          }
        },
        "c9bd701b93e84c56a35bed76a47de8a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44c44f69faee41f09f9e376bf7716293",
            "max": 437955512,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45aa48e2755f4f34a9f7868148dd3203",
            "value": 437955512
          }
        },
        "4347f16cb9e544e5a4065ba30ad7fed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ca37055e6b34022ab6758bd897759d1",
            "placeholder": "​",
            "style": "IPY_MODEL_c448dc59120c4fcd93ba6b1b1b1b78c5",
            "value": " 438M/438M [00:02&lt;00:00, 192MB/s]"
          }
        },
        "69aff2388a7849eaa0a524b87d5bdb03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73a3a759b4d840549a9251c6a9037282": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "635bcd5be8764af6864d8ee291fc448a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44c44f69faee41f09f9e376bf7716293": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45aa48e2755f4f34a9f7868148dd3203": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ca37055e6b34022ab6758bd897759d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c448dc59120c4fcd93ba6b1b1b1b78c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preparación del entorno y los datos"
      ],
      "metadata": {
        "id": "gYN5w3A_vsuc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparación del entorno"
      ],
      "metadata": {
        "id": "wUZdFkyu2IA4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKxSKG_c40Hd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06589dba-3882-4499-ed68-75316ab1c191"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.41.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.23.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence_transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 sentence_transformers-3.0.1\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "# Instalar las bibliotecas necesarias\n",
        "!pip install transformers\n",
        "!pip install sentence_transformers\n",
        "!pip install torch\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importación de bibliotecas"
      ],
      "metadata": {
        "id": "t-F8zauswPlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar bibliotecas de manipulación de datos y visualización\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "\n",
        "# Importar bibliotecas de procesamiento del lenguaje natural (NLP)\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Importar bibliotecas de machine learning y procesamiento de texto\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Importar bibliotecas de transformers y pytorch\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertModel, AdamW, AutoTokenizer, AutoModel\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Importar biblioteca para trabajar con Google Drive\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "px7WQUDRv6mo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuración de Google Drive"
      ],
      "metadata": {
        "id": "mTwrd091wZPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NjprKqJMwcuS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55f1ca0b-cbc7-4c25-fc42-05cea3baac96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definición de rutas a los datos"
      ],
      "metadata": {
        "id": "_tHhFBDFwuGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir rutas a la carpeta de datos\n",
        "#data_dir = '/Documents/escuela/tecMonterrey/semestre8/Ciencias/Reto'\n",
        "data_dir = '/content/drive/MyDrive/RetoDesarrollo/dataset/'\n",
        "# Ruta a datos que nosotros creamos\n",
        "# clasification_data_dir = os.path.join(data_dir, 'plagiarism')\n",
        "\n",
        "# Ruta a datos otorgados por los profesores\n",
        "construction_data_dir = os.path.join(data_dir, 'train')\n",
        "test_data_dir = os.path.join(data_dir, 'test')\n",
        "clasification_data_dir = os.path.join(data_dir, 'plagiarism')\n",
        "\n",
        "#clasification_data_dir = 'C:\\\\Users\\\\nadia\\\\Documents\\\\escuela\\\\tecMonterrey\\\\semestre8\\\\Ciencias\\\\Reto\\\\plagiarism'\n",
        "#construction_data_dir = 'C:\\\\Users\\\\nadia\\\\Documents\\\\escuela\\\\tecMonterrey\\\\semestre8\\\\Ciencias\\\\Reto\\\\train'\n",
        "#test_data_dir = 'C:\\\\Users\\\\nadia\\\\Documents\\\\escuela\\\\tecMonterrey\\\\semestre8\\\\Ciencias\\\\Reto\\\\test'"
      ],
      "metadata": {
        "id": "PsEdCX3IxDZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Listar archivos de plagio\n",
        "plagiarism_files = sorted([os.path.join(clasification_data_dir, f) for f in os.listdir(clasification_data_dir)])\n",
        "\n",
        "# Listar archivos de construcción y prueba\n",
        "construction_files = sorted([os.path.join(construction_data_dir, f) for f in os.listdir(construction_data_dir)])\n",
        "test_files = sorted([os.path.join(test_data_dir, f) for f in os.listdir(test_data_dir)])"
      ],
      "metadata": {
        "id": "5lDR_MuaxiMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lectura de archivos"
      ],
      "metadata": {
        "id": "aVBsfSNbxv-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para leer archivos\n",
        "def read_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        return file.read()\n",
        "\n",
        "# Leer todos los archivos de construcción plagiados\n",
        "plagiarism_texts = [read_file(f) for f in plagiarism_files]\n",
        "\n",
        "# Leer todos los archivos de construcción\n",
        "construction_texts = [read_file(f) for f in construction_files]\n",
        "\n",
        "# Leer todos los archivos de prueba\n",
        "test_texts = [read_file(f) for f in test_files]\n",
        "\n",
        "# Impresion de los datos contenidos\n",
        "print(f'Plagiarism: {plagiarism_texts}')\n",
        "print(f'Construction: {construction_texts}')\n",
        "print(f'Test: {test_texts}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mN0qX09GxsR2",
        "outputId": "19134483-6545-4d66-df64-38a05ee5d377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plagiarism: ['Recent developments in Artificial Intelligence (AI) have generated great expectations for the future impact of AI in education and learning (AIED). Often these expectations have been influenced by misconceptions about current technical capabilities, insufficient awareness of the latest advancements in AI for education, and overly limited perspectives on the roles of education in society. In this article, we provide a review of existing AI systems in education and their pedagogic and educational assumptions. We create a classification of AIED systems and outline various approaches to incorporating AI in education and learning, demonstrating how these are based on different understandings of what AI and education are or could become, and highlight some potential challenges on the path to AIED implementation.', \"Artificial intelligence (AI) is evolving and its application is expanding rapidly, becoming an integral part of our daily lives. In fact, AI has transformed the way people learn. However, its integration into the educational sector has faced numerous challenges and ethical concerns. The purpose of this study is to examine the opportunities, benefits, and obstacles of AI in education. A comprehensive review of relevant literature was conducted using the systematic review method to identify current research trends and provide a thorough understanding of AI technology in education for educators and future research directions. Findings revealed that AI's implementation in education has progressed significantly in developed countries, and most research gained prominence during the Industry 4.0 era. Additional challenges and recommendations are also discussed in the study.\", \"This study conducted a content analysis of research focused on uncovering how artificial intelligence (AI) has been utilized in the education sector and identifying potential research trends and challenges in AI for education. A total of 100 papers, including 63 empirical papers (74 studies) and 37 analytical papers, were selected from the education and educational research category of the Social Sciences Citation Index database from 2010 to 2020. The content analysis revealed that the research questions could be categorized into the development layer (classification, matching, recommendation, and deep learning), application layer (feedback, reasoning, and adaptive learning), and integration layer (affective computing, role-playing, immersive learning, and gamification). Additionally, four research trends—Internet of Things, swarm intelligence, deep learning, and neuroscience—along with an evaluation of AI in education, were recommended for further exploration. However, we also identified challenges in education that may arise from AI, including the improper application of AI techniques, evolving roles of teachers and students, and social and ethical concerns. The findings offer a comprehensive overview of AI's role in the education domain, which aids in reinforcing the theoretical foundation of AI in education and presents a promising avenue for educators and AI engineers to pursue further collaborative research.\", 'As of 2021, more than 30 countries have released national artificial intelligence (AI) policy strategies. These documents outline plans and expectations regarding how AI will influence various policy sectors, including education, and typically address the social and ethical implications of AI. This article performs a thematic analysis of 24 such national AI policy strategies, examining the role of education in global AI policy discussions. It finds that the application of AI in education (AIED) is largely missing from policy dialogues, while the instrumental value of education in preparing an AI-ready workforce and training more AI experts is heavily emphasized. Additionally, the ethical considerations of AIED receive minimal attention despite the general prominence of AI ethics discussions in these documents. This suggests that AIED and its broader policy and ethical implications—positive or negative—have yet to achieve mainstream recognition and inclusion in the agendas of key decision-makers, a concern given that effective policy and careful ethical consideration are closely intertwined, as this article argues. In light of these findings, the article applies a framework of five AI ethics principles to propose ways in which policymakers can better integrate AIED’s implications. Finally, the article offers recommendations for AIED scholars on strategies for engaging with the policymaking process and conducting ethics and policy-oriented AIED research, in order to shape policy deliberations for the public good.', 'Artificial Intelligence (AI) is transforming the world in significant ways; while some of its impacts are undeniably positive, widespread and enduring harms can also result from the technology. The incorporation of AI into various facets of human life is ongoing, and the complex ethical issues arising from the design, deployment, and use of the technology underscore the need to reevaluate what future developers and designers, along with professionals, are learning about AI. It is crucial to train future members of the AI community, and other stakeholders, to consider how AI might affect people’s lives and to embrace their responsibilities to maximize its benefits while minimizing its potential harms. This can be achieved in part through the comprehensive and systematic inclusion of AI ethics in the curriculum. In this paper, we briefly outline different approaches to AI ethics and provide a set of recommendations related to AI ethics education.', 'While Artificial Intelligence in Education (AIED) research aims to support student learning, experience from other AI domains indicates that ethical intentions alone are insufficient. It is also necessary to explicitly consider issues such as fairness, accountability, transparency, bias, autonomy, agency, and inclusion. More generally, there is a need to differentiate between acting ethically and making ethical decisions, to understand and make pedagogical choices that are ethical, and to account for the constant possibility of unintended consequences. However, addressing these and related questions is far from straightforward. As an initial step towards addressing this critical gap, we invited 60 of the AIED community’s leading researchers to respond to a survey about ethics and the application of AI in educational contexts. In this paper, we first introduce issues surrounding the ethics of AI in education. Next, we summarize the contributions of the 17 respondents and discuss the complex issues they raised. Specific outcomes include the recognition that most AIED researchers are not equipped to address emerging ethical questions. A well-designed framework for engaging with the ethics of AIED, combining a multidisciplinary approach and a set of robust guidelines, seems essential in this context.', \"The educational applications of AI are a blend of what Pasteur's Quadrant refers to as use-inspired basic and purely applied research. This article provides an overview of the traditional and emerging frameworks for AI in education. Early researchers concentrated on developing personalized teaching systems for individual learners, whereas recent work considers social interactions and the learning environment. Various Grand Challenges highlight the issues still confronting AI in education.\", 'The evolving needs of the engineering industry require continuous evolution in engineering education to keep pace with the latest technological advancements. One exciting development in this realm is the utilization of generative artificial intelligence (AI) technology, exemplified by the ChatGPT conversational agent. ChatGPT has the potential to offer tailored and effective learning experiences by providing personalized feedback and explanations to students, as well as creating realistic virtual simulations for hands-on learning. However, it is crucial to acknowledge the limitations of this technology. ChatGPT and similar generative AI systems are only as effective as their training data and may perpetuate biases or inadvertently generate and spread misinformation. Furthermore, the integration of generative AI in education raises ethical concerns, such as the possibility of unethical or dishonest use by students and the potential displacement of human workers rendered obsolete by technology. While the current state of generative AI technology, as exemplified by ChatGPT, is impressive yet imperfect, it serves as a glimpse of future possibilities. It is imperative for engineering educators to comprehend the implications of this technology and explore ways to adapt the engineering education ecosystem to ensure that the next generation of engineers can leverage the advantages offered by generative AI while mitigating any negative repercussions.', \"The purpose of this article is to analyze the advantages and drawbacks of artificial intelligence (AI) in education with a focus on fundamental human rights. The article is based on an EU scoping study [Berendt, B., A. Littlejohn, P. Kern, P. Mitros, X. Shacklock, and M. Blakemore. 2017. Big Data for Monitoring Educational Systems. Luxembourg: Publications Office of the European Union. https://publications.europa.eu/en/publication-detail/-/publication/94cb5fc8-473e-11e7-aea8-01aa75ed71a1/]. In the study, AI and 'Big Data' are considered as potential solutions to monitor the education system more efficiently in real-time, but also considers the implications for fundamental human rights and freedoms of both teachers and learners. The analysis highlights a need to balance the benefits and risks as AI tools are developed, marketed and deployed. We conclude with a call to embed consideration of the benefits and risks of AI in education as technology tools into the development, marketing and deployment of these tools. There are questions around who – which body or organisation – should take responsibility for regulating AI in education, particularly since AI impacts not only data protection and privacy, but on fundamental rights in general. Given AI’s global impact, it should be regulated at a trans-national level, with a global organisation such as the UN taking on this role.\", \"A defining characteristic of our modern era is our steadfast belief in technology across all aspects of life, including education. It could be argued that this fascination with technology, or 'techno-philia,' in education has profoundly influenced the classroom dynamic, altering the relationship between teacher and student, as well as among students. These relationships have increasingly shifted towards being more I–It (transactional) than I–Thou (relational) based, as the ability to form bonds and the level of connectedness between teacher and students, and among students, has either decreased or been affected by the growing technologization of education. Running parallel to this and possibly exacerbating the issue is the concept of 'learnification,' which views teachers as mere facilitators of the learning process rather than individuals with expertise who have valuable knowledge to impart to others. In this article, I first evaluate the current technologization of education and its impact on classroom relationships; second, I explore Buber’s concepts of I–It and I–Thou relationships and their implications for education; finally, I speculate through a thought experiment on whether the advancement of AI could one day successfully replace human teachers in the classroom.\", 'Thus, recognition of plant disease is essential. Agriculture is the ultimate imperative and primary source of origin to furnish domestic income for multifarious countries. The disease caused in plants due to various pathogens like viruses, fungi, and bacteria is liable for considerable monetary losses in the agriculture corporation across the world. The security of crops concerning quality and quantity is crucial to monitor disease in plants. Computer vision, deep learning, few-shot learning, and soft computing techniques are utilized by various investigators to automatically identify the disease in plants via leaf images. These techniques also benefit farmers in achieving expeditious and appropriate actions to avoid a reduction in the quality and quantity of crops. The application of these techniques in the recognition of disease can avert the disadvantage of origin by a factious selection of disease features, extraction of features, and boost the speed of technology and efficiency of research. The plant disease syndrome is noticeable in distinct parts of plants. Also, certain molecular techniques have been established to prevent and mitigate the pathogenic threat. Nonetheless, commonly the infection is detected in distinct leaves of plants. Hence, this review helps the investigator to automatically detect disease in plants using machine learning, deep learning, and few shot learning and provide certain diagnosis techniques to prevent disease. Moreover, some of the future works in the classification of disease are also discussed.', 'Many Artificial Intelligence based foundation models have been proposed for smart sensing to recognize the known object classes in the new but similar scenarios. There are a large number of functional sensors installed on the modern intelligent vehicles. We first summarize the current widely-used foundation models and the foundation intelligence needed for smart sensing of intelligent vehicles. This letter aims at pushing the boundary of smart sensing research for intelligent vehicles. Several representative case studies are discussed to show the potential usages of Sora-based Parallel Vision, followed by its future research direction. However, it is still challenging for the foundation models of smart sensing to detect all the object classes in both seen and unseen scenarios. We then explain Sora-based Parallel Vision to boost the foundation models of smart sensing from basic intelligence (1.0) to enhanced intelligence (2.0) and final generalized intelligence (3.0).', 'Solutions must also advance with technology to ensure that individuals can effectively navigate their surroundings and assist them in real-time navigation. The study conducts surveys on visually challenged individuals in the community and aims to assist them by providing smart gadgets to identify faces, colours, and objects. Artificial Intelligence has become a significant tool in modern technology, enabling people to interact with machines through various methods. Moreover, this study emphasizes more on different technologies and methods that are used earlier to help visually impaired people in their day-to-day life. Individuals with visual impairments have trouble doing tasks because they are either blind or have poor vision. BVI stands for Blind and Visually Impaired.', 'This multifunctional blind assistance device is designed to empower users by enhancing their spatial awareness and providing them the tools they need to navigate travel securely and on their own. In a world where a major portion of the populace suffer with daily challenges of blindness, this pioneering project introduces a comprehensive smart support system designed to aid the needs of people who are visually impaired. Its primary goals encompass recognizing objects, accurately estimating distances between objects and users, deciphering captured signs and indications, and offering real-time location-based navigation and directions. This advanced system is ingeniously integrated into a pair of headphones, combining various state-of-the-art technologies such as cameras, ultrasonic sensors, and cutting-edge machine learning algorithms. It represents a remarkable leap forward in refining the overall quality of life and mobility for the blind people.', \"An emerging control technique is visual servoing utilizing the onboard camera systems for inspecting the UAV's environment and autonomously controlling the UAV's operation. Despite the increasing research in the field of AI-based visual control of UAV systems, comprehensive review articles that showcase the general trends and future directions in this field of research are limited. Unmanned aerial vehicles (UAVs) have attracted massive attention in many engineering and practical applications in the last years for their characteristics and operation flexibility. The paper first reviews the application of intelligent visual servoing systems for autonomously executing various UAV control tasks, including 3D UAV positioning, aerial and ground object following, obstacle avoidance, and autonomous landing. Artificial intelligence (AI) techniques are widely deployed in the visual servoing of autonomous UAV applications. This work comprehensively examines the application and advancements of AI-enhanced visual servoing in autonomous UAV systems, covering critical control tasks and offering insights into future research directions for enhancing performance and applicability which is limited in the current literature. Second, the research progresses in applying AI techniques in the visual servoing of autonomous UAV systems are discussed and analyzed. For the UAV system, suitable control systems are required to operate appropriately and efficiently. Finally, future directions and critical research gaps for further improving the performance and applicability of intelligent visual servoing systems are included.\\nKeywords: Unmanned aerial vehicles; Visual servoing; Artificial intelligence; Artificial neural networks; Fuzzy logic; Reinforcement learning\\n\", 'In mammography, computer vision and artificial intelligence techniques have been used successfully to detect or to characterize abnormalities on digital images. Radiologists supplied with this information often perform better at mammographic detection or characterization tasks in observer studies than do unaided radiologists. The revolution in digital computer technology that has made possible new and sophisticated imaging techniques may next influence the interpretation of radiologic images. This technology therefore could decrease errors in mammographic interpretation that continue to plague human observers.', 'In this context, this work presents a systematic review that aims to identify the applicability of computer vision in precision agriculture for the production of the five most produced grains in the world: maize, rice, wheat, soybean, and barley. Among the available tools, we highlight computer vision solutions combined with artificial intelligence algorithms that achieved important results in the detection of patterns in images. In this sense, we present 25 papers selected in the last five years with different approaches to treat aspects related to disease detection, grain quality, and phenotyping. Grain production plays an important role in the global economy. Information Technology is one of the tools to that end. From the results of the systematic review, it is possible to identify great opportunities, such as the exploitation of GPU (Graphics Processing Unit) and advanced artificial intelligence techniques, such as DBN (Deep Belief Networks) in the construction of robust methods of computer vision applied to precision agriculture. In this sense, the demand for efficient and safe methods of food production is increasing.', 'Computer vision (CV) is the field of study that deals with how computers can understand digital images or videos and seeks to automate tasks that can be performed by the human visual system. Among these surgery-related technologies, the amount of information extracted from a surgical video captured by an endoscope is especially great. It has led to an increase in the number of technologies in the operating room. Technology has advanced surgery, especially minimally invasive surgery (MIS), including laparoscopic surgery and robotic surgery. They can provide further information about a surgical procedure, e.g. instrument usage and trajectories. Therefore, the automation of data analysis is essential in surgery to reduce the complexity of the data while maximizing its utility to enable new opportunities for research and development. Because this field deals with all the processes of real-world information acquisition by computers, the terminology “CV” is extensive, and ranges from hardware for image sensing to AI-based image recognition. AI-based image recognition for simple tasks, such as recognizing snapshots, has advanced and is comparable to humans in recent years. Although surgical video recognition is a more complex and challenging task, if we can effectively apply it to MIS, it leads to future surgical advancements, such as intraoperative decision-making support and image navigation surgery. Ultimately, automated surgery might be realized. In this article, we summarize the recent advances and future perspectives of AI-related research and development in the field of surgery.', 'Both aids achieved greater than 95% accuracy in text recognition for flat, plain word documents and ranged from 13 to 57% accuracy for formatted text on curved surfaces. Individuals successfully completed 71% and 55% (p = .114) of tasks while using Orcam MyEye 1 and Seeing AI, respectively. There was no significant difference in time to completion of tasks (p = .775). To evaluate human performance, we asked the participants to use the devices to attempt 12 reading tasks similar to activities of daily living. We assessed the ranges of text attributes for which reading was possible, such as print size, contrast, and light level. We also assessed if individuals could complete tasks with the devices and measured accuracy and completion time. Participants also completed a survey concerning the two aids. Introduction: We compared the print-to-speech properties and human performance characteristics of two artificial intelligence vision aids, Orcam MyEye 1 (a portable device) and Seeing AI (an iPhone and iPad application). Implications for Practitioners: Selection of a reading device or aid should be based on individual preferences and prior familiarity with the platform, since we found no clear superiority of one solution over the other. Both aids could read print sizes as small as 0.8M (20/40 Snellen equivalent, 40 cm viewing distance). Individuals believed both aids would be helpful for daily activities. Discussion: Orcam MyEye 1 and Seeing AI had similar text-reading capability and usability. Both aids were useful to users with severe visual impairments in performing reading tasks. Methods: There were seven participants with visual impairments who had no experience with the two reading aids. Four participants had no light perception. Two individuals with measurable acuity and one with light perception were tested while blindfolded. We also tested performance with text of varying appearance in varying viewing conditions.', 'The current research on the application of artificial intelligence deep learning models in medical imaging generally pays more attention to accuracy rather than explain ability, resulting in the lack of explain ability, and thus hindering the practical clinical application of deep learning models. Based on the general lack of explain ability caused by the unknown data processing process in the deep model, the existing solutions mainly include the establishment of internal explain ability, attention mechanism interpretation of specific models, and the interpretation of unknowable models represented by LIME. Its advantage is that it does not rely on human annotation, and the computer can recognize and process the feature information omitted by human beings during the model training process, so as to achieve or even exceed the accuracy of human processing. As one of the branches of machine learning, the deep learning model combined with artificial intelligence is widely used in the field of computer vision technology, and the image recognition field represented by medical image analysis is also developing. Therefore, the need to analyze the development of medical image analysis in the field of artificial intelligence and computer vision technology, and how to balance accuracy and interpretability to develop deep learning models that both doctors and patients can trust will become the research focus of the industry in the future. The way to quantitatively assess interpretability is still being explored, especially in the interpretative assessment of both doctors and patients in medical decision-related models, several scales have been proposed for reference.', 'This paper mainly discussed the asymmetric face recognition problem where the number of names in a name list and the number of faces in the photo might not be equal, but each face should be automatically labeled with a name. The motivation for this issue was that there had been many meetings in the past. After each meeting, the participant took group photos. The meeting provided only a corresponding name list of participants without one-to-one labels. In the worst case, the group photo might mix with the faces that were not participating in the meeting. Another reason for asymmetric face recognition was that some meeting personnel did not appear in photos because they assisted in taking pictures. This paper proposed an asymmetric face recognition mechanism, called AFRM in short. Initially, the proposed AFRM adopted the histogram of oriented gradients (HOG) and support vector machine (SVM) to detect and extract all faces from photos. Next, AFRM extracted the features from each face using the convolution feature map (Conv_FF) and adopted the features to partition the faces into different classes. Then, the AFRM applied the statistic-based mechanism to map each name in the name list to each face class. According to this mapping, each face would be associated with one name. To quickly identify a face during the meeting, the AFRM applied the K-nearest neighbors (KNN) to represent the features of each face. During the new meeting, the proposed AFRM could extract the feature of one face and then adopted KNN to derive the features. Experimental results showed that the proposed mechanism achieved more than 97% accuracy without one-to-one name and face labeling.\\n', 'The face will be the most essential part of the human body, and because of its distinctive traits, it will be crucial for recognizing people. Facial recognition technology (FRT) will be one of the most successful and fascinating technologies of the modern times. The world will be moving towards contactless FRT after the COVID-19 pandemic. Due to its contactless biometric characteristics, FRT will be becoming quite popular worldwide. Businesses will be replacing conventional fingerprint scanners with artificial intelligence—based FRT, opening up enormous commercial prospects. Security and surveillance, authentication/access control systems, digital healthcare, photo retrieval, etc., will be some sectors where its use will become essential. In the present communication, we will present the global adoption of FRT, its rising trend in the market, utilization of the technology in various sectors, its challenges and rising concerns with special reference to India and worldwide.', 'Measures of success for facial feminization surgery (FFS) have previously included improved rates of external gender perception as female and patient-reported outcome measures. In this study, we have used artificial intelligence facial recognition software to objectively evaluate the effects of FFS on both perceived gender and age among male-to-female transgender patients, as well as their relationship with patient facial satisfaction. Standardized frontal preoperative and postoperative images of 27 transgender women undergoing FFS have been analyzed by Amazon’s AI facial recognition software to determine gender, femininity confidence score, and perceived age. Female gender-typing, improvement in gender-typing (preoperatively to postoperatively), and femininity confidence scores have been analyzed. To assess patient satisfaction, FACE-Q modules have been completed postoperatively. Preoperatively, FFS images have been perceived as female 48.1% of the time, and postoperatively, this has improved to 74.1% (P=0.05). Femininity confidence scores have improved from a mean score of 0.04 preoperatively to 0.39 postoperatively (P=0.003). FFS has been associated with a decrease in perceived age relative to the patient’s true age (−2.4 y, P<0.001), with older patients experiencing greater reductions. Pearson correlation matrix has found no significant relationship between improved female gender typing and patient facial satisfaction. Undergoing surgery at a younger age has been associated with higher overall facial satisfaction (r=−0.6, P=0.01). Transfeminine patients have experienced improvements in satisfaction with facial appearance, perceived gender, and decreases in perceived age following FFS. Notably, patient satisfaction has not been directly associated with improved AI-gender typing, suggesting that other factors may influence patient satisfaction.', 'Surprisingly, the high accuracies previously reported, exceeding 95%, had dropped significantly when faced with the more demanding conditions of the forensic scenario, plummeting to as low as 65%. In essence, while facial recognition systems had shown impressive performance in ideal conditions, our study indicated a substantial decrease in accuracy when faced with the complexities and challenges typical of real-world forensic scenarios, highlighting the need for further advancements to bridge this gap. Recent advancements in machine learning and computer vision had shown facial recognition systems achieving accuracies that surpassed human performance in controlled settings, but fingerprint analysis had proved more accurate in all aspects. To investigate this, we had created a large-scale synthetic facial dataset and designed a controlled facial lineup that mimicked conditions encountered in real forensic situations. This approach had allowed us to systematically assess facial recognition under various challenging real-world conditions. Using both our synthetic dataset and a well-known dataset of actual faces, we had tested the accuracy of two widely used neural-based facial recognition systems. Comparative and Analytical method had been applied for present Research. Artificial intelligence could help humans in accuracy and speeding up the process of investigation.', 'Facial recognition will have been a well-established and popular field in Computer Vision, especially with advancements in deep learning and data sets. Deep facial recognition will have made significant progress and will be widely applied in real-world scenarios. A complete facial recognition system will have involved three main components: facial recognition, orientation, and representation. This system will have detected faces, aligned them to a standard view, and extracted features for recognition using deep convolutional neural networks. This article will have provided a detailed overview of the latest advancements in these areas, showing how deep learning will have greatly enhanced their abilities. Object detection in machine vision will have been a challenging area that will have required significant improvements. While image classification accuracy will have been nearing 2.25%, surpassing human performance, object detection algorithms will have still been in the early stages. Current algorithms will have achieved only 40.8 MAPS on modern objects, so careful dataset selection will have been crucial for optimal results.', 'Face recognition gained significant attention as one of the most useful image analysis applications. By leveraging their unique but incredible identification skills, these systems were capable of recognizing users. Face recognition systems were extensively studied. The system, however, had a number of drawbacks. Existing face recognition methods might have resulted in a longer histogram, which slowed down for a large-scale database. To address the challenges with face recognition, we proposed a hybrid descriptor using MultiBlock Local Ternary Pattern (LTP)—Gray Level Co-occurrence Matrix (GLCM). In this study, we employed the LTP, GLCM, and Speeded Up Robust Features (SURF) methods to extract the illumination, rotation, and scale-invariant features of the face database images. These features were then trained using Artificial Neural Network. The layer neurons were optimally selected by Crow Search Optimization (CSO) method which yielded an accuracy of 95%. The proposed approach was implemented in the Matlab software, and the experimental data was analyzed to show that the developed texture descriptor had a higher recognition rate than existing methods.', 'With the rise of deep neural networks, the performance of biometric systems will increase tremendously. Biometric systems for face recognition will be used in everyday life, e.g., border control, crime prevention, or personal device access control. Although the accuracy of face recognition systems will be generally high, they will not be without flaws. Many biometric systems will be found to exhibit demographic bias, resulting in different demographic groups not being recognized with the same accuracy. This will be especially true for facial recognition due to demographic factors, e.g., gender and skin color. While many previous works will already have reported demographic bias, this work will aim to reduce demographic bias for biometric face recognition applications. In this regard, 12 face recognition systems will be benchmarked regarding biometric recognition performance as well as demographic differentials, i.e., fairness. Subsequently, multiple fusion techniques will be applied with the goal to improve the fairness in contrast to single systems. The experimental results will show that it will be possible to improve the fairness regarding single demographics, e.g., skin color or gender, while improving fairness for demographic subgroups will turn out to be more challenging.', \"In Nigeria, there have been many different security concerns, and thus, crimes have increased despite the fact that there are stringent laws and punishments in place to deter them, making it appear as though the authorities are unable to stop it. In order to identify criminals and conduct investigations, it has been imperative that a facial recognition system be connected to a constantly updated digital library. The focus of this paper has been to develop an automatic criminal investigation system that can identify criminals based on their faces and produce real-time digital archives about them. However, as an object detection method and facial recognition model, the new system has been built on the Haar Cascades Classifier technique in the OpenCV package. Additionally, appropriate programming languages that may provide the needed results have been investigated. Python 3.6 has been used with the Django 4.2 framework, OpenCV-Python, and Dlib for language execution. Due to Django's ORM, support for numerous databases, and usage of the SQLite3 database, a straightforward database has been employed for lightweight applications. The 12 factor app idea has been used to construct the DICA-FR system's essential skills. Face detection has been applied to the image using the Haar method during processing, and during post-processing, the discovered face has been compared with well-known criminal face encodings for matching purposes. Results have demonstrated that DICA-FRS could effectively replace human systems since it can recover faces from the furthest distances, display the name of the offender, and sound an alert on the DICA web app's output screen. The DICA system has been a working prototype of a system that might be used in the criminal investigative process in Nigeria.\", 'Facial Expression Recognition (FER) has been utilized in various fields, such as education, gaming, robotics, healthcare, and others. Facial expression techniques, for instance, an interactive robot with Artificial Intelligence, have recognized human faces, detected the emotions of the person it was conversing with, and then used these emotions to choose appropriate answers. One use case for face emotion detection has been playing music based on the user’s mood. To do this, we have analyzed the user’s facial expression to deduce their feelings. As a result, new emotion models have required more investigation as existing ones have struggled to correctly measure music’s connection with facial emotion. In this paper, we have implemented this kind of job using Convolution Neural Network (CNN) based deep learning approach. Deep learning has been able to more effectively analyze unstructured data, movies, and other forms of media than machine learning. In our research, we have created a real-time system that could recognize human faces, assess human emotions, and even recommend music to users. The OAHEGA and FER-2013 datasets have been utilized for experimental study. We have created and trained two emotion recognition models using various combinations of these datasets. The proposed model’s accuracy has been 73.02%. Using our CNN model, we have been able to predict six emotions: anger, fear, joy, neutral, sadness, and surprise. The proposed system could be utilized in different places where real-time facial recognition has played an important role.', 'Facial Expression Recognition (FER) will have been utilized in various fields, such as education, gaming, robotics, healthcare, and others. Facial expression techniques, for instance, an interactive robot with Artificial Intelligence, will have recognized human faces, detected the emotions of the person it is conversing with, and then used these emotions to choose appropriate answers. One use case for face emotion detection will have been playing music based on the user’s mood. To do this, we can analyze the user’s facial expression to deduce their feelings. As a result, new emotion models will require more investigation as existing ones struggle to correctly measure music’s connection with facial emotion. In this paper, we will have implemented this kind of job using Convolution Neural Network (CNN) based deep learning approach. Deep learning will have more effectively analyzed unstructured data, movies, and other forms of media than machine learning. In our research, we will have created a real-time system that can recognize human faces, assess human emotions, and even recommend music to users. The OAHEGA and FER-2013 datasets will have been utilized for experimental study. We will have created and trained two emotion recognition models using various combinations of these datasets. The proposed model’s accuracy will be 73.02%. Using our CNN model, we will be able to predict six emotions: anger, fear, joy, neutral, sadness, and surprise. The proposed system will be able to be utilized in different places where real-time facial recognition plays an important role.', 'Future transportation systems are expected to be reshaped by autonomous vehicles (AVs), and decision making is considered one of the critical modules toward high-level automated driving. To overcome those complicated scenarios that rule-based methods could not cope with well, more focus has been placed on data-driven decision-making approaches. The performance of decision making is dramatically influenced by the datasets used in developing data-driven methods; hence, it is necessary to have a comprehensive insight into the existing datasets. From the aspects of collection sources, driving data can be divided into vehicle-, environment-, and driver-related data. The state-of-the-art datasets of these three categories are compared in this study, and their features, including sensors used, annotation, and driving scenarios, are summarized. Based on the characteristics of the datasets, potential applications of datasets on various aspects of AV decision making are discussed in this survey, assisting researchers in finding appropriate ones to support their own research. The future trends of AV dataset development are also summarized.', 'In this paper, a safe and reliable motion planning and control framework is proposed to handle the tracking errors caused by inaccurate tracking by coordinating the motion planning layer and controller. Specifically, motion space is divided into safe regions and risky regions by designing the movement restraint size dependent on tracking error to construct the repulsive potential field. The collision-free waypoint set can then be obtained by combining global search and the proposed waypoint set filtering method. The planned trajectory is fitted by an optimization-based approach which minimizes the acceleration of the reference trajectory. Then, the planned trajectory is checked and modified by the designed anti-collision modification to ensure safety. Using invertible transformation and adaptive compensation allows the transient trajectory tracking errors to be limited within the designed region even with actuator faults. Because tracking error is considered and margined at the planning level, safety and reliability can be guaranteed by the coordination between the planning and control levels under inaccurate tracking and actuator faults. The advantages and effectiveness of the proposed motion planning and control method are verified by simulation and experimental results. Accurate trajectory tracking is unrealistic in real-world scenarios, however, which is commonly assumed to facilitate motion planning algorithm design.', 'How would risks of autonomous vehicles (AVs) in everyday road traffic be distributed by people? The rich literature on the ethics of autonomous vehicles (AVs) revolves around moral judgments in unavoidable collision scenarios. It is argued that the debate should be extended to driving behaviors in everyday road traffic where ubiquitous ethical questions arise due to the permanent redistribution of risk among road users. This distribution of risks raises ethically relevant questions that cannot be evaded by simple heuristics such as “hitting the brakes.” Using an interactive, graphical representation of different traffic situations, participants’ preferences on driving maneuvers of AVs were measured in a representative survey in Germany. Participants’ preferences deviated significantly from mere collision avoidance. Interestingly, participants were willing to take risks themselves for the benefit of other road users, suggesting that the social dilemma of AVs may be mitigated in risky environments. This research might build a bridge between engineers and philosophers to discuss the ethics of AVs more constructively.', 'Artificial intelligence powers emerging technologies that simulate human intelligence in machines, enabling them to think like human beings and mimic their actions. Autonomous vehicles can function and carry out necessary functions without human involvement. This innovative technology may provide increased passenger safety, less congested roads, congestion reduction, optimum traffic, lower fuel consumption, less pollution, and better travel experiences. Autonomous vehicles play a vital role in industry, agriculture, transportation, and military applications. The activities of autonomous vehicles rely on sensor data and a few artificial intelligence systems. Artificial intelligence involves the collection of data, path planning, and execution in autonomous vehicles that require some machine learning techniques that are part of artificial intelligence. However, this also raises some privacy issues and security concerns. Security is an important concern for autonomous vehicles. This article will cover the issues of cybersecurity while incorporating artificial intelligence in autonomous vehicles, along with the growing technology of self-driving automobiles.', \"Throughout the last decades, the number of vehicles on the road has steadily increased due to the rising demand for urban mobility and contemporary logistics. Two of the many detrimental effects of more vehicles on the road, which also impede economic development, are increased traffic congestion and traffic accidents. The issues mentioned above can be significantly resolved by making vehicles smarter by reducing their reliance on humans. Over the past century, extensive research has been conducted by various nations that has fueled the automation of road vehicles. The development of autonomous vehicle (AV) technologies is currently being pursued by all significant motor manufacturers worldwide. Undoubtedly, the widespread use of autonomous cars is more imminent than we realize given the development of artificial intelligence (AI). In order for AVs to perceive their surroundings and make the right decisions in real time, AI has emerged as a crucial component. This development of AI is being driven by the growth of big data from numerous sensing devices and cutting-edge computing resources. AI's development and history must first be examined in order to comprehend its functions in AV systems.\", 'The future sustainability of the global automotive industry will be greatly affected by the fourth industrial revolution and the evolution of artificial intelligence (AI). The “new normal” is projected to be driven by new industry standards including an increasingly autonomous self-driving technology, amended safety standards, more complex insurance regulations, adaptive social resistance to technological change, city infrastructure requirements with a digital divide, and disruptive business innovation based on strategic input supply partnerships with open-source AI. In this chapter, the key factors of the autonomous vehicles (AVs) are analyzed using AI developments in radar and laser technology, commercial risk factors, self-driving consumer behavior, city infrastructure constraints, and social adaptations to new technology. The future trajectory of the AV industry is expected to be an interplay between commercial, social, risk, infrastructure, and regulatory mechanisms with various impacts on the industry’s stakeholders. This study predicts that the most likely sustainable scenario for the AV industry is that it will be driven by: (1) AI’s pulsed laser LiDAR (Light Detection and Ranging) with a sufficient loop frequency and GPS bi-directional cloud technology requirement, (2) pooled insurance in contrast to individual liability, (3) smart city infrastructure with expected sharp digital divide across transport regions leading to more regional inequality, and (4) customers who strongly prefer a human controlled semi-autonomous vehicle rather than complete machine autonomy.', \"The convergence of human-centric design and advanced AI capabilities is where the future of autonomous vehicles lies. In the future, autonomous vehicles will not only transport passengers but also be interacted with and adapted to their desires, making the journey comfortable, efficient, and pleasant. In this paper, a novel framework is presented that leverages Large Language Models (LLMs) to enhance autonomous vehicles' decision-making processes. By integrating LLMs' natural language capabilities and contextual understanding, specialized tools usage, synergizing reasoning, and acting with various modules on autonomous vehicles, this framework aims to seamlessly integrate the advanced language and reasoning capabilities of LLMs into autonomous vehicles. The proposed framework holds the potential to revolutionize the way autonomous vehicles operate, offering personalized assistance, continuous learning, and transparent decision-making, ultimately contributing to safer and more efficient autonomous driving technologies.\", \"The potential for connected automated vehicles is multifaceted, and automated advancement is driven by more of Internet of Things (IoTs) development enabling artificial intelligence (AI). Early advancements in engineering, electronics, and many other fields have been inspired by AI. There are several technologies used in automated vehicles. Automated vehicles greatly contribute toward traffic optimization and casualty reduction. In studying vehicle autonomy, two categories of development are available: high-level system integrations like new-energy vehicles and intelligent transportation systems, and the other involves backward subsystem advancement like sensor and information processing systems. The Advanced Driver Assistance System shows results that meet the expectations of real-world problems in vehicle autonomy. Situational intelligence that collects enormous amounts of data is considered for high-definition creation of city maps, land surveying, and quality checking of roads as well. The infotainment system of the transport covers the driver's gesture recognition, language transaction, and perception of the surroundings with the assistance of a camera, Light Detection and Ranging (LiDAR), and Radio Detection And Ranging (RADAR) along with localization of the objects in the scene. This chapter discusses the history of autonomous vehicles (AV), trending research areas of artificial intelligence technology in AV, state-of-the-art datasets used for AV research, and several Machine Learning (ML)/Deep Learning (DL) algorithms constituting the functioning of AV as a system, concluding with the challenges and opportunities of AI in AV.\", 'In recent years, artificial intelligence has become a necessary component for both production and service systems, as technology has become a vital aspect of daily life. Autonomous driving vehicles are operated autonomously, also known as driverless cars that can operate without a human driver. Research on autonomous vehicles has substantially advanced in recent years. Artificially intelligent autonomous vehicles are the current need of society. Although some people might be apprehensive to give a computer control of their vehicle, automated driving technologies have the potential to make roads safer. Environmental issues as well as safety-related ones can be addressed by self-driving automobiles. Unlike humans, computers do not really have difficulty keeping attention when driving. Additionally, by responding appropriately, an automated car can prevent accidents from potentially dangerous events on the road. Self-driving technology has many advantages, one of which will make more easily accessible means of transport to people who are unable to drive. For a variety of reasons, such as inexperience, incapacity, or age, many people are unable to operate a vehicle. These individuals can travel considerably more safely and independently. Therefore, in this chapter, the architectures of both software and hardware of autonomous cars will be explored, as well as their parts, benefits, and future developments.', 'The transformative era in transportation has been heralded by the advent of autonomous vehicles, reshaping the landscape of mobility through cutting-edge technologies. Integration of Artificial Intelligence (AI) and learning algorithms is central to this evolution, propelling vehicles into realms of unprecedented autonomy. A comprehensive exploration of the evolutionary trajectory of AI within autonomous vehicles is provided in this paper, tracing the journey from foundational principles to the most recent advancements. Commencing with a current landscape overview, the fundamental role of AI in shaping the autonomous decision-making capabilities of vehicles is delved into. The steps involved in the AI-powered development life cycle in vehicles are elucidated, addressing ethical considerations and bias in AI-driven software development for autonomous vehicles. Statistical insights into the usage and types of AI/learning algorithms over the years are presented, showcasing the evolving research landscape within the automotive industry. Furthermore, the pivotal role of parameters in refining algorithms for both trucks and cars is highlighted, facilitating vehicles to adapt, learn, and improve performance over time. Different levels of autonomy are outlined, elucidating the nuanced usage of AI and learning algorithms, and automating key tasks at each level. Additionally, the variation in software package sizes across different autonomy levels is discussed.', 'In the hospitality industry, service failures involving artificial intelligence (AI) are common. Therefore, understanding how AI service recovery can retain customers is crucial. This article examines AI service recovery from a different perspective, shifting away from the traditional focus on \"intelligence quotient\" and instead looking at the impact of empathy responses, which are linked to emotional intelligence. Through four experimental scenarios, the research shows that a high-empathy AI response during service recovery can increase customers\\' intention to continue using the service. It also finds that psychological distance and trust play sequential roles in mediating this process. Furthermore, the study suggests that using multisensory stimulus interactions (such as text and voice) in high-empathy responses enhances the effectiveness of AI service recovery compared to mono-sensory interactions (text only). This research expands the understanding of AI service recovery by focusing on the ongoing use of AI after a service failure, rather than just the immediate response. It also highlights the importance of emotional intelligence in AI, showing how it can evoke emotional responses from customers during service recovery. Ultimately, this research offers valuable insights for developing autonomous solutions to AI service failures, benefiting both research and hospitality operators seeking to improve AI services.', \"Charitable organizations worldwide are facing a shortage of manpower. To address this, artificial intelligence (AI) chatbots are being utilized, but their exact capabilities and limitations remain unclear, warranting further investigation. This study aimed to enhance our understanding of AI fundraisers by involving 654 adults from an online crowdsourcing platform. Six chatbot agents were developed with varying characteristics (emotional vs. factual, and with different images - no image, machinelike image, human image). The study used an independent samples t-test to analyze the impact of chatbots' conversational styles on the willingness to donate to Ukraine war victims. Additionally, a serial multiple mediation analysis was conducted to examine the mediating roles of perceived humanness and empathy toward victims in the relationship between chatbots' emotional expression and willingness to donate. The study also tested the moderating effect of visual cues (no image, machinelike image, human image) using a moderated serial multiple mediation analysis. The findings indicated that emotional chatbots led to a higher willingness to donate, with perceived humanness and empathy mediating this relationship both independently and serially. However, visual cues did not significantly moderate the relationship between chatbot agents' emotional expression and willingness to donate.\", \"Integrating empathy into healthcare chatbots is seen as a promising approach to evoke a sense of human connection. However, current research often overlooks the complexity of empathy, leading to a limited understanding of whether artificial empathy is perceived similarly to human empathy. This study argues that incorporating experiential forms of empathy could have unintended negative effects, as they may come across as inauthentic. Instead, providing instrumental support might be more effective in modeling artificial empathy, as it aligns better with the typical expectations of interactions with chatbots. Two experimental studies using healthcare chatbots investigated the impact of empathetic (feeling with), sympathetic (feeling for), and behavioral-empathetic (empathetic helping) responses compared to non-empathetic responses on perceived warmth, perceived authenticity, and their effects on trust and intentions to use. The results showed that any form of empathy (compared to no empathy) increased perceived warmth, leading to higher levels of trust and intentions to use the chatbot. As hypothesized, empathetic and sympathetic responses reduced the perceived authenticity of the chatbot, which counteracted the positive effects in both studies. However, a third study did not replicate this negative effect in human-human interactions. This research highlights that empathy does not translate equally to interactions between humans and bots. It also introduces the concept of 'perceived authenticity' and demonstrates that attributes typically associated with humans may backfire by feeling inauthentic in interactions with chatbots.\", \"Interactive software agents, like chatbots, are increasingly used in health and well-being contexts, engaging users in conversations for coaching, comfort, or behavior-change interventions. However, there is a lack of tools to understand these agents' empathic abilities. To address this, we need a clear understanding of empathy. Despite various definitions in the literature, there is no consensus on a formal definition. Through a systematic literature review and qualitative analysis of recent approaches to empathy in interactive agents for health and well-being, we have developed a formal definition—an ontology—of empathy. This definition was applied in a controlled user study to assess empathy in two state-of-the-art health and well-being chatbots, Replika and Wysa. Our results indicate that our definition captures essential aspects for assessing empathy in interactive agents and can elucidate trends in changing perceptions of empathy over time. Implemented in Web Ontology Language (OWL), this definition could serve as an automated tool for systems to recognize empathy in interactions, whether it's an interactive agent evaluating its own empathic performance or an intelligent system assessing the empathic capability of its users.\", \"This paper introduces a groundbreaking framework designed to transform chatbot systems by incorporating real-time face and emotion recognition with natural language processing. The framework is currently in development and demonstrates proficiency in various tasks, including generating captions, object counting, and answering queries. Using parameter-efficient fine-tuning from OpenFlamingo and the Low-rank Adapter (LoRA), the framework prioritizes versatility and efficiency. Central to this approach are instruction templates that merge vision and language data, enhancing the chatbot's adaptability. Emphasizing the importance of high-quality training data, this research lays a foundation for creating a versatile conversational agent with applications in customer service and mental health support.\", 'Background:\\nThere is a lack of studies examining the practicality of using large language models (LLMs) to respond to queries from autistic individuals in a Chinese-language setting. While Chinese is spoken by a large population worldwide, most research on using these models in healthcare has centered on English-speaking communities.\\n\\nObjective:\\nThis research seeks to evaluate how well LLM chatbots, including ChatGPT-4 from OpenAI and ERNIE Bot (version 2.2.3) from Baidu, Inc., perform in responding to queries from autistic individuals in a Chinese context.\\n\\nMethods:\\nFor this research, we collected data from DXY, a well-known web-based medical consultation platform in China with a user base exceeding 100 million individuals. We meticulously selected 100 patient consultation samples from January 2018 to August 2023, comprising 239 questions extracted from publicly available documents related to autism on the platform. To ensure impartiality, both the original questions and responses were anonymized and randomized. An evaluation team consisting of 3 chief physicians assessed the responses based on 4 criteria: relevance, accuracy, usefulness, and empathy. In total, the team conducted 717 evaluations. Initially, the team identified the best response and then used a Likert scale with 5 response categories to rate the responses, each representing a different level of quality. Finally, we compared the responses collected from various sources.', \"In this initial installment of the series on Artificial Intelligence in Cancer Clinical Research, it is crucial to delve into the definition of intelligence and its key attributes linked with human intelligence. Intelligence is a concept primarily associated with humans, encompassing perception, cognition, thought, conceptualization, pattern recognition, symbolic processing, creativity, and problem-solving. While intelligence-like traits are observed in other living beings, human intelligence is often seen as a product of our conscious awareness, ability to form concepts, capacity for symbolic processing, language development, and our faculty for reasoning, decision-making, and judgment in navigating our surroundings. Despite acknowledging the existence of intelligence-like features in other species, consciousness and self-awareness remain enigmatic and profound aspects of human experience. The question arises: how does the intricate interplay of atoms and molecules adhering to physical laws, coupled with the complex neural network in the central nervous system, give rise to our conscious experience, thoughts, reasoning, and emotional experiences such as joy, sadness, love, and beauty? While machine learning (ML) can handle conceptual processes to some extent, human intellect has the unique ability to generate novel abstract concepts that further structure our environment and lead to the discovery of abstract ideas. These processes offer insights beyond the tangible world, shaping our individual symbolic systems that reflect an active curiosity and pursuit of meaning and genuine comprehension of the world around us. Whereas a sign represents an observable aspect of the external world, which can be analyzed algorithmically and replicated, a symbol elicits an abstract internal response detached from any specific concrete event. Human symbolic systems not only facilitate the communication of cognitive information, enabling language, but also the conveyance of emotional information. Many of humanity's significant and noble qualities stem from the development and creative use of symbolic systems, contributing to the formation of culture, myth, idealism, and empathy. While a sign can be seen as an objective characteristic of an object or situation, a symbol resonates with our internal experiences, gaining significance within the context of emotions and interests influenced by our past experiences and memories, as well as the current situation. This interplay results in the generation of feelings or emotions within us, portraying us as active contributors to the construction of our world.\", 'Human-AI interaction has become a focal point in creating technology that is more responsive and empathetic. Artificial empathy strategies are particularly intriguing in this context, as they have the potential to enhance customer experiences both affectively and socially. This study seeks to investigate how artificial empathy strategies can optimize human-AI interactions to improve customer experiences. The research methodology employed is qualitative, involving a review of various studies and relevant literature. Data sources include journals, articles, and books related to the research topic. The findings indicate that implementing artificial empathy strategies in human-AI interactions can significantly enhance the quality of interactions and customer experiences. Technologies such as natural language processing, emotion recognition, and sentiment analysis enable AI to respond more accurately and sensitively to user needs and emotions.', \"From ELIZA to Alexa, Conversational Agents (CAs) have been intentionally designed to express or evoke empathy. While empathy can enhance technology's ability to meet human needs, it can also be misleading and potentially exploitative. This study focuses on understanding empathy in interactions with CAs, emphasizing the need to differentiate between empathetic interactions between two humans and those involving a human and a CA. We conducted systematic interactions with CAs powered by large language models (LLMs), prompting them to demonstrate empathy while conversing with or about 65 different human identities. We also compared how various LLMs express or model empathy. Our findings reveal that CAs tend to make value judgments about certain identities and can inadvertently promote identities associated with harmful ideologies (e.g., Nazism and xenophobia). Furthermore, a computational analysis of empathy indicates that despite their ability to exhibit empathy, CAs struggle to accurately interpret and explore a user's experiences, a skill at which human counterparts excel.\", \"Empathy computing is an emerging field that blends artificial intelligence (AI) and big data technologies to predict, identify, simulate, and generate human empathy. It draws from psychological studies on empathy concepts, measurements, neural foundations, and applications, while employing innovative computing methods for analyzing and simulating empathy. This article critically reviews current research in empathy computing and discusses its future directions from a psychological perspective to advance foundational research and practical applications.\\n\\nResearch in empathy computing can be categorized into four themes based on different purposes and methods. First, there is a focus on analyzing and understanding empathy using computers, which includes individual empathy assessment and empathetic content classification in texts. Second, there is research on simulating and expressing empathy through computing, which involves designing empathetic response systems and developing generative empathetic dialogue systems. These research streams are relatively independent yet complementary. As the field progresses, new directions may emerge, such as enhancing computer empathic capabilities through brain-computer interface technology.\\n\\nAlthough empathy computing is in its early stages, it shows promise for innovative applications in mental health, education, business services, and public management. In mental health, it can help evaluate and enhance therapists' empathetic abilities and provide personalized empathetic support through AI-driven chatbots. In education, it can facilitate learning with empathetic AI tutors. In business, it enables tailored customer experiences through empathic dialogues. In public management, it can generate empathetic discourse and help policymakers respond empathetically to citizen needs. These scenarios highlight the potential of empathy computing, but complete reliance on computers for empathetic tasks is currently impractical due to safety and ethical concerns. A collaboration between humans and computers is necessary.\\n\\nEmpathy computing represents a transformative frontier, enriching the theoretical landscape of empathy research and exploring empathy in emerging human-AI relationships. It raises questions about the universality of empathy and its evolution in human-computer interaction. Empathy computing could serve as a cornerstone for a unified theory of empathy that encompasses diverse relationship dynamics, from human-human to human-machine interactions. Collaboration between psychologists and computer scientists is crucial for effective and ethical AI learning of empathy, promoting wellbeing in an intelligent society.\\n\\nFuture research should focus on developing integrated theoretical models of empathy computing, establishing reliable datasets of empathy-related characteristics, and validating empathy computing research through a human-centered approach. Psychologists' involvement is essential for guiding and optimizing research and practice in empathy computing. Collaborative efforts between psychology and computer science are key to ensuring AI learns empathy effectively and ethically, benefiting society in an intelligent future.\", \"Advanced computational techniques, such as knowledge-based systems (KBS), soft computing methods (SCM), machine learning models (MLM), evolutionary algorithms (EA), swarm intelligence (SI), and nature-inspired algorithms (NIA), have recently been widely applied in power electronics and motor control systems. Each computational method has its own distinct features and attributes. Recently, researchers have developed a model of emotional processing in the mammalian brain, known as the brain emotional learning based intelligent controller (BELBIC). The findings demonstrate BELBIC's capability to manage unknown non-linear dynamic systems. Consequently, BELBIC can be readily integrated into specialized mechatronics and industrial applications.\", 'Purpose of Review: Emotion artificial intelligence (AI) is technology for emotion detection and recognition. Emotion AI is expanding rapidly in commercial and government settings outside of healthcare, and will increasingly become a routine part of daily life. The goal of this narrative review is to increase awareness both of the widespread use of emotion AI, and of the concerns with commercial use of emotion AI in relation to people with mental health conditions. Recent Findings: This paper discusses emotion AI fundamentals, a general overview of commercial emotion AI outside of healthcare, and examples of the use of emotion AI in employee recruitment and workplace surveillance. Summary: The successful re-integration of individuals with mental health conditions into society must recognize the increasing commercial use of emotion AI. There are concerns that commercial use of emotion AI will increase stigma and discrimination, and have negative consequences in daily life for people with mental health conditions. Commercial emotion AI algorithm predictions about mental health conditions should not be treated as medical fact.', 'Brain-Computer Interaction (BCI) system intelligence has become more reliant on electroencephalogram (EEG)-based emotion detection due to the various applications of emotion classification, such as recommendation systems, cognitive load monitoring, etc. Emotion classification has recently gained significant attention in Artificial Intelligence (AI)-driven research. In this article, we presented a systematic review of automated emotion detection from EEG signals using AI. The review process follows the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. Subsequently, EEG datasets, and EEG preprocessing techniques are included in this study. Also covered are feature extraction and feature selection methods. Additionally, the included studies were categorized into two types: i) deep learning (DL)-based emotion detection systems and ii) machine learning (ML)-based emotion classification models. The examined systems are analyzed based on their features, classification methodologies, classifiers, types of classified emotions, accuracy, and the datasets they utilized. There is also an interesting comparison, a look at emerging research trends, and suggestions for future study areas.', 'Humans possess certain social and emotional skills that enable them to interact effectively with others, one of which is the ability to recognize emotions. This ability significantly enhances human interactions. As we progress towards an era of increasing Human-Machine Interaction systems, it is essential to develop algorithms that endow machines with similar social and emotional skills. A primary area of research in emotion detection involves recognizing emotions through facial images. The ability to identify human emotions allows machines to adapt and respond to human needs and comfort levels. Emotion detection can be performed using various modalities such as video, audio, images, text, biometric data, etc. This study explores the emerging trends in emotion recognition using facial images. Automated recognition of human emotions has the potential to predict psychiatric conditions or other underlying mental health issues.', \"Artificial intelligence chatbots have proliferated in the tourism industry due to their cost-effectiveness and high efficiency. However, the impact of chatbots' emotional expressions on service outcomes has not been extensively studied by researchers. Drawing on expectancy violations theory, we investigated how chatbots' emotional expressions influence customer satisfaction through three experiments in the context of tourist attraction recommendations. Chatbots expressing concern for customers can enhance customer satisfaction by mitigating expectancy violations. Specifically, customer goal orientation, the human-likeness of chatbot avatars, and the type of relationship between customers and chatbots can moderate the negative relationship between emotional expression and expectancy violation. These findings contribute to research on chatbots' emotional expressions and offer valuable insights for implementing chatbots in customer service within the tourism industry.\", 'This paper first investigates English text emotion expression and information communication, categorizes these aspects based on the human emotion-value relationship, and summarizes their characteristics. Secondly, using artificial intelligence technology, it proposes constructing an analysis model for English text emotion and information communication using the BiLSTM neural network. To process the characteristics of English text quickly and efficiently, it is necessary to encode the emotional information in English text. Based on this encoding, the BiLSTM neural network is applied to extract the emotional features of English text and address the issue of emotional feature loss through the loss function. Then, a web scraper is used to obtain the dataset from the Chinese English module under the MOOC of Chinese universities, and evaluation metrics are set according to the model’s performance, followed by experimental analysis of English text emotion expression and information conveyance. The results show that compared with the original CNN, LSTM, and T-LSTM, the BiLSTM-based neural network performs better in the task of text emotion expression and information conveyance, with the accuracy rate staying above 0.925, and the effect on the English dataset is slightly better than on the Chinese dataset. This study aims to enhance English teaching and communication between Chinese and foreign cultures.', 'Automated dialogue systems are significant applications of artificial intelligence, yet traditional systems struggle to comprehend user emotions and offer empathetic responses. This study integrates emotional intelligence technology into automated dialogue systems, creating a dialogue generation model imbued with emotional intelligence using deep learning and natural language processing techniques. This model can real-time detect and understand a broad spectrum of emotions and specific pain signals, enabling the system to provide empathetic interactions. By incorporating findings from the study \"Can artificial intelligence detect pain and express pain empathy?\", the model\\'s capacity to grasp subtle aspects of pain empathy has been augmented, establishing higher benchmarks for emotional intelligence in dialogue systems. The project aims to provide theoretical insights and practical recommendations for integrating advanced emotional intelligence capabilities into dialogue systems, thereby enhancing user experience and interaction quality.', 'Research suggests that machines capable of simulating empathy and responding emotionally can increase user acceptance, as the sense of affinity towards the machine reduces negative perceptual feedback. To imbue a robot with emotional intelligence, it must be equipped with sensors capable of detecting users’ emotions (sense), process captured emotions to regulate its internal state (compute), and ultimately perform tasks where actions are influenced by the computed “emotional” state (act). Despite significant progress in artificial intelligence, speech recognition and synthesis, computer vision, and many other disciplines related to artificial emotional recognition and behavior, we are still far from equipping robots with the empathic capabilities of humans. This article aims to provide an overview of the implications of introducing emotional intelligence in robotic systems by discussing recent advances in emotional intelligence in robotics.', 'Emotion recognition involves accurately inferring human emotions from various sources and modalities, including questionnaires, physical signals, and physiological signals. Recently, there has been a growing interest in emotion recognition due to its wide-ranging applications, such as affective computing, healthcare, human-robot interactions, and market research. This paper presents a comprehensive and systematic review of emotion recognition techniques from the current decade, focusing on physical and physiological signals. Physical signals include speech and facial expressions, while physiological signals encompass electroencephalogram (EEG), electrocardiogram (ECG), galvanic skin response (GSR), and eye tracking. The paper introduces various emotion models, stimuli used for emotion elicitation, and the background of existing automated emotion recognition systems. It covers a thorough search and review of well-known datasets, following the design criteria for the review. After an in-depth analysis and discussion, 142 journal articles were selected using PRISMA guidelines. The review offers a detailed analysis of existing studies and available datasets for emotion recognition, along with potential challenges in the existing literature and directions for future research.', \"This paper explores the utilization of artificial intelligence for emotion detection in neuromarketing, aiming to identify user emotions through a webcam using convolutional neural networks (CNNs). The initial section provides an overview of neural networks, including basic types and distinctions, with a focus on convolutional neural networks. CNNs are adept at processing grid-like data, such as images. Emotion recognition is facilitated through the use of the face-api.js library, which implements models like SSD Mobilenet V1, Tiny Face Detector, and MTCNN. The Tiny Face Detector model, utilized in the application, offers real-time face detection with a small size, speed, and moderate resource consumption, compatible with web and mobile platforms. \\n\\nThe second part of the paper details the development of an application utilizing the face-api.js library for emotion detection, designed to support neuromarketing research. This application enables marketers to analyze advertising material by displaying content and collecting data during viewing, storing and graphically presenting this data for analysis. The section provides an in-depth explanation of the emotion detection process. \\n\\nLastly, the paper evaluates the developed solution through experimentation, demonstrating the system's ability to recognize user emotions with a satisfactory level of precision. The advertising content is pre-assigned parameters representing desired results, which are compared with the obtained results to determine the advertisement's success.\", 'With AI, deep learning and prediction of user behavior can be achieved to anticipate and address potential barriers to use in UI design. This cost can be quantified through \"experience metrics\", which reveal the problems users encounter when using the interface (UI), and make targeted optimization. At a time when artificial intelligence is widely used in all walks of life, the way users interact with the digital world also needs to incorporate intelligent elements to reduce the cost of connectivity. Through accurate analysis of experience indicators and combined with AI technology to optimize design, the gap between users and the digital world can be greatly reduced, making digital products more suitable for user needs and achieving seamless interactive experience. This will not only improve the user experience, but also promote the development of UI design in a more user-friendly and intelligent direction.', 'Art is known to pave the way to exploring and conveying new possibilities. Nowadays, interdisciplinary fields between Artificial Life, artificial intelligence, computational biology, and synthetic biology are increasingly emerging into public view. It is necessary to reconsider the relations between the material body, identity, the natural world, and the concept of life. This survey provides a literature review on recent works of Artificial Life in visual art during the past 40 years, specifically in the computational and software domain. We aim to provide a systematic overview of how artists are understanding nature and creating new life with modern technology. Having proposed a set of criteria and a taxonomy, we briefly analyze representative artworks of different categories.\\n', 'We survey the general trajectory of artificial intelligence (AI) over the last century, in the context of influences from Artificial Life. The risks may be blamed exclusively on human users—the robots could not care less. There is a similar divide, regrettably unrecognized, over the very way that such AI problems have been framed. The latter approach has enabled advances in deep learning and the astonishing AI advances we see today—bringing immense benefits but also societal risks. To date, this has been overwhelmingly GOFAIstic, meaning that tools for humans to use have been developed; they have no agency or motivations of their own. With a broad brush, we can divide technical approaches to solving AI problems into two camps: GOFAIstic (or computationally inspired) or cybernetic (or ALife inspired). We explore the implications of this for concerns about existential risk for humans of the “robots taking over.”\\n', 'Artificial Intelligence (AI) is having a revolutionary impact on our societies. Traditionally, AI is developed in software or through neuromorphic engineering in hardware. In this work, two promising approaches for boosting CAI are described. One regards designing and implementing neural surrogates that can communicate through optical or chemical signals and give rise to networks for computational purposes and to develop micro/nanorobotics. More recently, a brand-new strategy has been proposed. It is the so-called Chemical AI (CAI), which exploits molecular, supramolecular, and systems chemistry in wetware to mimic human intelligence. Both topics are presented at a basic level, mainly to inform the broader audience of non-specialists, and so favour the rise of interest in these frontier subjects. It is helping humans in facing the global challenges of this century. The other approach concerns “bottom-up synthetic cells” that can be exploited for applications in various scenarios, including future nano-medicine.', 'Recent innovations in Human-Centric Functional Modeling (HCFM) seek to represent natural phenomena in terms of graphs called “functional state spaces” or FSS that consist of discrete states of functionality separated by the interactions through which regions of matter and/or antimatter transition from one state of functionality to another. These approaches are called “human-centric” because it is hypothesized that the human organism is constrained by the laws of thermodynamics to perceive the observable world in terms of FSS, where in each FSS all processes consist of a minimally reducible set of reversible operations or functions. The goal of this monograph is to encourage exploration of how components of these theories might align with emerging or established scientific concepts. In simulating physical processes, or processes in any other domain in which the abstract functionality of systems can be represented in terms of FSS, it is hypothesized that network effects create the potential to significantly or even exponentially increase the general problem-solving ability of human groups. These hypothetical FSS are networks.', 'After reviewing discussions about and examples of artificial intelligence use in education, particularly primary school contexts, I will focus on the real implications of this key educational challenge. Obviously, with the advent of these technological transformations, there is the risk of generating or reinforcing inequalities between social groups if equal access is not guaranteed. Artificial intelligence and robotics pose a range of social, pedagogical, practical, ethical and also social justice issues and challenges in dealing with changes in educational processes. Lastly, using an analogy with the development of classical literacy (reading/writing), I will discuss the need to propose artificial intelligence and robotics literacy courses for teachers so that these technologies can be used more widely among different age groups and grades. One of the elements sure to characterise the future of education is artificial intelligence used as a tool to improve teaching and learning processes as well as the work of teachers and administrators. I will focus on the possibility of personalising learning pathways by describing primary school initiatives aimed at fostering effective and collaborative communication skills in order to recognise and identify, but also prevent, the factors impacting learning disorders.', 'While on the one hand the development of artificial intelligence is having an increasingly important impact not only on the economic system, but also on people’s lives, opening up new scenarios, imposing new constraints, and giving rise to new opportunities, at the same time it is emerging as a further potential threat to humanity. Artificial intelligence is a tool that must be used with care and caution, also taking into account the possible risks involved, risks that will become all the greater the more powerful the calculation tools are. We need to abandon an approach based on an optimistic prejudice towards artificial intelligence, which is often presented as a panacea for all evils, with thaumaturgic properties that can be extended to all problems and situations. This is why the issue of ‘Machine Ethics’ is being forcefully raised at the scientific level.\\n\\n\\n', 'The author calls for a total ban on AI and suggests that it could prompt a reevaluation of neoliberal capitalism and the need to address other existential threats. The article explores various risks associated with AI, including extreme genetic engineering, threats to the financial system, lethal autonomous weapons, economic inequality, environmental impact, and the erosion of human relationships. While AI offers many benefits, such as improving energy solutions and accessibility to information, the negative consequences outweigh the short-term advantages. The author highlights missed opportunities in the past to prevent the negative impacts of technologies like automobiles and toxic chemicals. This article discusses the potential dangers of artificial intelligence (AI) and argues that it must be stopped.\\n\\n', 'Evolutionary computation is a sub-field of artificial intelligence and artificial life that uses biologically inspired methods to solve optimization problems, using iterative refinements of a set of solutions via change and selection. Its successful applications are counted in multiple domains, including, but not limited to, optimization, machine learning, robotics, and various areas that study living systems. This approach, which began in the 1950s, constitutes a growing set of algorithms capable of solving a wide range of problems, divided into various types that differ in selection, mutation, and representation of candidate solutions. It has a unique potential to generate endless innovations and lead to a paradigm shift in the development of artificial intelligence and artificial life. Evolutionary computation has recently seen a revival, particularly in the study of open-ended evolution, with important implications for the future of AI.\\n\\n', 'The purpose of the study is to study the possibilities of multigenerational optimization of behavior control systems for agents of general artificial intelligence capable of independently solving a universal range of tasks in a real environment. A software package for simulating the processes of ontophylogenetic synthesis of multi-agent neurocognitive architectures has been developed and experiments have been carried out to create phenotypes of intelligent agents based on them. The main principles of ontophylogenetic synthesis of control systems for agents of general artificial intelligence based on multi-agent neurocognitive architectures have been developed. It is shown that multigenerational optimization of the multi-agent neurocognitive architecture of intelligent agents can contribute to the achievement of adaptive resistance to the operating conditions of a general artificial intelligence agent, provide the synthesis of its suboptimal structural and functional scheme, accelerate learning and algorithms for finding solutions to a universal range of problems solved by this agent in its ecological niche. Methods and algorithms for synthesizing the phenotypes of control systems of intelligent agents according to their genotypes are proposed. A complex genome of an intelligent agent has been developed, the features of a multichromosome genetic algorithm for organizing calculations in the paradigm of multigenerational optimization of multiagent neurocognitive architectures have been established and substantiated.\\n\\n', \"\\ufeffThis article explored the fusion of Fuzzy Logic (FL) and Group Theory within the realm of Artificial Intelligence (AI), uncovering a transformative synergy that promised to enhance the adaptability and robustness of intelligent systems.\\nBeginning with an individual examination of Fuzzy Logic and Group Theory, the paper established the theoretical foundations for their integration. Fuzzy Logic's capacity to handle uncertainty harmonized with Group Theory's prowess in revealing structural insights, leading to a unified framework. The integration was validated through a series of compelling case studies and experiments across diverse domains, ranging from adaptive robotics control to healthcare decision support. These practical applications showcased the collective impact of FL and Group Theory, demonstrating improved adaptability, precision, and resilience in complex scenarios. The results not only reaffirmed the theoretical foundations but also provided tangible evidence of the integrated approach's potential. Looking toward the future, the paper outlined key directions for further research, including the refinement of theoretical foundations, integration with machine learning, and addressing challenges of scalability and explainability. Ethical considerations, cross-disciplinary collaboration, and continuous validation were emphasized as crucial elements in shaping the trajectory of this interdisciplinary exploration.\", '\\ufeffIn this study, we will explore the dynamic field of fuzzy logic and artificial intelligence (AI) in financial analysis from 1990 to 2023. Utilizing the bibliometrix package in RStudio and data from the Web of Science, we will focus on identifying mathematical models and the evolving role of fuzzy information granulation in this domain. The research addresses the urgent need to understand the development and impact of fuzzy logic and AI within the broader scope of evolving technological and analytical methodologies, particularly concentrating on their application in financial and banking contexts. The bibliometric analysis will involve an extensive review of the literature published during this period. We will examine key metrics such as the annual growth rate, international collaboration, and average citations per document, which will highlight the field’s expansion and collaborative nature. The results will reveal a significant annual growth rate, international collaboration, and an average citation per document. Major journals such as IEEE Transactions on Fuzzy Systems, Fuzzy Sets and Systems, the Journal of Intelligent & Fuzzy Systems, and Information Sciences will emerge as significant contributors, aligning with Bradford’s Law’s Zone 1. Notably, post-2020, IEEE Transactions on Fuzzy Systems will show a substantial increase in publications. A significant finding will be the high citation rate of seminal research on fuzzy information granulation, emphasizing its mathematical importance and practical relevance in financial analysis. Keywords like “design”, “model”, “algorithm”, “optimization”, “stabilization”, and terms such as “fuzzy logic controller”, “adaptive fuzzy controller”, and “fuzzy logic approach” will be prevalent. The Countries’ Collaboration World Map will indicate a strong pattern of global interconnections, suggesting a robust framework of international collaboration. Our study will highlight the escalating influence of fuzzy logic and AI in financial analysis, marked by a growth in research outputs and global collaborations. It will underscore the crucial role of fuzzy information granulation as a mathematical model and set the stage for further investigation into how fuzzy logic and AI-driven models are transforming financial and banking analysis practices worldwide.', '\\ufeffThis paper presented a method for providing explainability in the integration of artificial intelligence (AI) and data mining techniques when dealing with meteorological prediction. Explainable artificial intelligence (XAI) refers to the transparency of AI systems in providing explanations for their predictions and decision-making processes, and contributes to improving prediction accuracy and enhancing trust in AI systems. The focus of this paper relied on the interpretability challenges in ordinal classification problems within weather forecasting. Ordinal classification involves predicting weather phenomena with ordered classes, such as temperature ranges, wind speed, precipitation levels, and others. To address this challenge, a novel and general explicable forecasting framework, that combined inductive rules and fuzzy logic, was proposed in this work. Inductive rules, derived from historical weather data, provided a logical and interpretable basis for forecasting; while fuzzy logic handled the uncertainty and imprecision in the weather data. The system predicted a set of probabilities that the incoming sample belonged to each considered class. Moreover, it allowed the expert decision-making process to be strengthened by relying on the transparency and physical explainability of the model, and not only on the output of a black-box algorithm. The proposed framework was evaluated using two real-world weather databases related to wind speed and low-visibility events due to fog. The results were compared to both ML classifiers and specific methods for ordinal classification problems, achieving very competitive results in terms of ordinal performance metrics while offering a higher level of explainability and transparency compared to existing approaches.', '\\ufeffInterpretable artificial intelligence (AI), also known as explainable AI, will be indispensable in establishing trustable AI for bench-to-bedside translation, with substantial implications for human well-being. However, the majority of existing research in this area is centering on designing complex and sophisticated methods, regardless of their interpretability. Consequently, the main prerequisite for implementing trustworthy AI in medical domains will not be met. Scientists are developing various explanation methods for interpretable AI. Among these methods, fuzzy rules embedded in a fuzzy inference system (FIS) are emerging as a novel and powerful tool to bridge the communication gap between humans and advanced AI machines. However, there are few reviews of the use of FISs in medical diagnosis. In addition, the application of fuzzy rules to different kinds of multimodal medical data is receiving insufficient attention, despite the potential use of fuzzy rules in designing appropriate methodologies for available datasets. This review will provide a fundamental understanding of interpretability and fuzzy rules, conduct comparative analyses of the use of fuzzy rules and other explanation methods in handling three major types of multimodal data (i.e., sequence signals, medical images, and tabular data), and offer insights into appropriate fuzzy rule application scenarios and recommendations for future research.', '\\ufeffDue to the advancement and complexity of modern automobiles, fault detection will have gone beyond manual or trial by error methods. The fault detection technologies in the automotive industry will have been used to identify any potential or existing faults in automobiles. Faults in automobiles are usually mechanical or electrical, including airbag control unit malfunctions, radiator issues, gearbox problems, transmission control unit errors, tire pressure abnormalities, brake failures, air conditioner malfunctions, cylinder casket issues, alternator faults, hub malfunctions, etc. Each fault will have specific or related signs and symptoms. There will be several methods of fault detection in automobiles, such as the binary logic technique, the fuzzy logic method, and artificial intelligence technique with different algorithms. In this research work, we will have employed a fuzzy logic-based technique that uses a Mamdani Algorithm, which will have presented a better fault detection mechanism. Mamdani’s algorithm will have been proposed by Ebrahim Mamdani as a fuzzy inference method that has rule-bases that are more intuitive and easier to analyze and implement. Mamdani’s algorithm will produce fuzzy sets that originate from the fuzzy inference system’s output membership function for decision-making. This research work will be a web-based technology that will have been implemented using JavaScript, JQuery, SQL Server, ASP.Net, Bootstrap 3.5, and CSS. The output of the system will have shown a greater improvement from other existing methods of fault detection in automobiles.', '\\ufeffA wireless sensor network (WSN) will be a distributed collection of tiny, low-power, wireless devices deployed in a physical environment to monitor various environmental conditions. The data collected by the positioned sensor nodes will be transmitted through the destination nodes using multi-hop communications. WSNs will offer numerous advantages over other networks, including enhanced flexibility, low cost, and simplified deployment. Due to the resource-constrained nature of WSNs, they will face various challenges and issues that will need to be addressed to ensure reliable and secure data transmission. The nodes of WSNs will be highly vulnerable to various types of security attacks, namely black hole attacks, Denial of Service (DoS) attacks, and node compromise attacks. Among these attacks, the black hole attack will pose a serious threat to the nodes in the network. This attack will be carried out by malicious nodes that intentionally drop all data packets and control packets without forwarding them to the intended destination. To ensure the security of the network against black hole attacks, it will be necessary to design an efficient Intrusion Detection Technique (IDT) for detecting malicious nodes. In this work, a novel Fuzzy Logic-based Intrusion Detection System with Hidden Markov Model (FIDS-HMM) will be proposed to identify malicious nodes and mitigate black hole attacks. Moreover, an HMM will be employed in the proposed protocol to monitor the energy levels of the nodes to detect malicious nodes effectively. The implementation of the proposed protocol will be carried out using the NS2 simulator. Simulation results will justify the proposed protocol, namely FIDS-HMM, providing an efficient detection mechanism for black hole attacks in the network. Moreover, the proposed protocol will improve the Quality of Service (QoS) parameters, namely packet delivery ratio, delay, and throughput in the network with efficiency.', '\\ufeffIn this article, we presented a model of adjustable moisture control for historical buildings. The proposed system was developed in the form of a flexible IoT infrastructure, in which a complex system of sensors was set up to measure inside conditions of humidity and compare the results to levels of groundwaters, rain, and wind speed to manage the drying system. The developed control model used type-2 fuzzy logic reasoning to flexibly adjust decisions to the intensity of water absorption. In this way, the proposed model made an innovative intelligent system for controlling interior conditions in historical buildings. The developed system was installed and examined in an old brewery building, showing efficiency in dehumidification at the lowest cost.', '\\ufeffSemantic features will play a pivotal role in natural language processing, providing a deeper understanding of the meaning and context within textual data. In the realm of machine learning and artificial intelligence, semantic feature extraction will involve translating linguistic elements into numerical representations, often utilizing advanced techniques like word embeddings and deep learning models. The integration of semantic features will enhance the precision and context-awareness of language models, enabling applications such as sentiment analysis, document categorization, and information retrieval to operate with greater accuracy and relevance. The paper will introduce a novel approach, Hierarchical Mandhami Optimized Semantic Feature Extraction (HMOSFE), designed to enhance semantic feature extraction from English sentences. The proposed HMOSFE model will comprise fusion of hierarchical clustering and fuzzy-based feature extraction. HMOSFE will aim to capture intricate semantic relationships within sentences, providing nuanced insights into the underlying meaning of textual content. The model will employ pre-trained word embeddings for term representation, calculate a similarity matrix using cosine similarity, and utilize hierarchical clustering for document grouping. Fuzzy logic will contribute to assigning weights to features, enabling a more refined understanding of semantic significance. The paper will present comprehensive results, including semantic similarity estimations, clustering distances, and fuzzy memberships, demonstrating the effectiveness of HMOSFE across diverse documents.', '\\ufeffAn intelligent lighting system was a public lighting system that used artificial intelligence technology to optimize energy management and improve the quality of lighting in public areas. This paper presented the use of two prominent artificial intelligence methods, namely fuzzy logic and neural networks, for intelligent power control in public lighting networks. The primary objective of this study was to evaluate the performance of these approaches in optimizing power consumption and achieving efficient lighting, taking into consideration two parameters, namely road flow and weather conditions. To achieve this, the lighting system was modeled using the state flow tool in MATLAB/Simulink. Various algorithms based on fuzzy logic and artificial neural networks were subsequently developed. Real data on traffic flow and cloud cover were utilized to train these algorithms. Upon analysis of the simulation results, it was observed that, overall, results closer to the algorithm based on fuzzy logic were yielded by algorithms based on neural networks.', \"\\ufeffIn the 21st century, global waste challenges are expected to worsen in developing nations that rely on manual sorting. Improper waste disposal will pose significant threats to human health and the environment, necessitating the adoption of Artificial Intelligence-Based Solid Waste Segregation Technology (AIBSWST). In this context, the advanced Frank t-norm will capture nuanced relationships in fuzzy logic, which will be crucial in scenarios where the order of fuzzy sets matters. Building on these principles, the complex q-rung picture fuzzy set (Cq-RPFS) will become instrumental in representing decision-makers' preferences in a two-dimensional manner, enhancing the handling of vague information in real-world scenarios. Expanding on these foundational principles, the paper will introduce innovative Frank operations grounded in Frank t-norms within the context of Cq-RPFS. Leveraging these operations, the paper will propose four robust aggregation operators (AOs) under Cq-RPFS: complex q-rung picture fuzzy Frank weighted average (Cq-PFFWA), complex q-rung picture fuzzy Frank weighted geometric (Cq-PFFWG), complex q-rung picture fuzzy Frank ordered weighted average (Cq-PFFWOA), and complex q-rung picture fuzzy Frank ordered weighted geometric (Cq-PFFWOG). These AOs will exhibit essential properties such as idempotency, monotonicity, and boundedness. A Multi-Criteria Decision-Making (MCDM) method based on the proposed AOs will be suggested to validate these strategies. A real-life case study on India’s adoption of AIBSWST will serve as a practical application, with thorough analyses, including sensitivity, comparative, and superiority assessments, evaluating the performance of the approaches. A thoughtful discussion of the pros and cons of the proposed AOs will accompany the analysis, emphasizing the significance of the approach in ensuring the cleanliness and health of developing nations.\", 'Information overload and a plethora of options have been brought about by easy internet access and technological advancements, making decision-making extremely difficult. Recommender System (RS) is seen as a potential solution for assisting users in making decisions by recommending or predicting product ratings. Collaborative, content-based, and hybrid filtering are three fundamental forms of RS that use implicit or explicit feedback for recommendation. While ratings are the most common form of feedback, product descriptions, reviews, images, audios, and videos are also important and can help improve the performance of the traditional RS. These additional variables can have a significant impact on RS’s performance. Approaches based on the nearest neighbor or other machine learning models were used by traditional RSs, but recent advances in artificial intelligence and deep learning have led to the development of RSs using Convolutional Neural Networks (CNN), which can efficiently exploit auxiliary information. In addition to comparing CNN-based RSs on common grounds, this article provides a full examination of CNN-based RSs and how they might use various types of auxiliary information. The study also discusses data characteristics, data statistics, and auxiliary information in a variety of publicly available datasets. Different evaluation measures for RSs are also discussed, and readers are provided with interesting challenges and open research issues.', \"In recent years, with the continuous progress and development of science and technology, especially the continuous development of artificial intelligence, machine algorithm, and other technologies, more personalized content has begun to be implemented in the education system, moving away from traditional functions. Traditional education systems are often characterized by adopting a one-size-fits-all approach to teaching that does not consider the unique needs and learning styles of each student. An education system personalized and optimized by machine learning algorithms can provide customized learning materials and recommendations based on each student's learning history, interests, and abilities to improve learning outcomes. Real-time feedback on student performance can be provided by machine learning algorithms and learning plans can be adjusted based on this feedback, making the learning process more dynamic and personalized. Therefore, it can be applied to all types of education, including language learning, mathematics, science, etc. However, improving the efficiency of machine learning algorithms depends more on the improvement of numerical optimization algorithms, so it is necessary to summarize the optimization algorithms in large-scale machine learning. This paper tries to make a detailed overview of the existing machine learning algorithms in optimizing personalized education recommendation systems and introduces the algorithm optimization process.\", 'A comprehensive literature review of the research and application of machine learning (ML) algorithms in recommender systems (RS) is presented in this paper. The study aims to identify recent trends, explore real-life applications, and guide researchers in positioning their research activities in this domain published in 2023 (Jan-June). The findings are categorized into different domains including education, healthcare, ML algorithms (auto-encoders and reinforcement learning), e-commerce, and digital journalism. The review highlights the enhanced recommendation accuracy, increased scalability, personalization and context awareness, diverse ML techniques, and strategies for handling cold start and data sparsity, and the foundation for future advancements in ML algorithms for RSs considering the application in manufacturing enterprises.', 'The convergence of information and communication technologies (ICT) with urban management to improve the quality of life of city dwellers characterizes smart cities. In this context, recommender systems, tools that offer personalized suggestions to city dwellers, have emerged as key contributors to this convergence. Their successful application in various areas of city life and their ability to process massive amounts of data generated in urban environments have expedited their status as a crucial technology in the evolution of city planning. Our methodology included reviewing the Web of Science database, resulting in 130 articles that, filtered for relevancy, were reduced to 86. The first stage consisted of carrying out a bibliometric analysis with the objective of analyzing structural aspects with the SciMAT tool. Secondly, we undertook a systematic literature review using the PRISMA 2020 statement. The results illustrated the different processes by which recommendations are filtered in areas such as tourism, health, mobility, and transport. This research is seen as a significant breakthrough that can drive the evolution and efficiency of smart cities, establishing a solid framework for future research in this dynamic field.\\n', \"Remote healthcare applications based on the Internet of Things (IoT) provide fast and preventative medical services to patients at risk. However, predicting heart disease is a complex task, and diagnosis results are rarely accurate. To address this issue, a novel Recommendation System for Cardiovascular Disease Prediction Using IoT Network (DEEP-CARDIO) has been proposed to provide prior diagnosis, treatment, and dietary recommendations for cardiac diseases. Initially, physiological data are collected from the patients remotely using four biosensors such as an ECG sensor, pressure sensor, pulse sensor, and glucose sensor. The collected data are received by an Arduino controller from the IoT sensors to predict and diagnose the disease. A cardiovascular disease prediction model is implemented using a BiGRU (Bidirectional-Gated Recurrent Unit) attention model, which diagnoses the cardiovascular disease and classifies it into five available cardiovascular classes. The recommendation system provides physical and dietary recommendations to cardiac patients based on the classified data, via a user mobile application. The performance of DEEP-CARDIO is validated by Cloud Simulator (CloudSim) using the real-time Framingham's and Statlog heart disease dataset. The proposed DEEP CARDIO method achieves an overall accuracy of 99.90%, whereas the MABC-SVM, HCBDA, and MLbPM method achieves 86.91%, 88.65%, and 93.63%, respectively.\", 'The latest effort in delivering computing resources as a service to managers and consumers represents a shift away from computing as a product that is purchased, to computing as a service that is delivered to users over the internet from large-scale data centers. However, with the advent of cloud-based IoT and artificial intelligence (AI), which are advancing customer experience automations in many application areas, such as recommender systems (RS), a need has arisen for various modifications to support the IoT devices that are at the center of the automation world, including recent language models like ChatGPT and Bard and technologies like nanotechnology. This paper introduces the marketing community to a recent computing development: IoT-driven fog computing (FC). Although numerous research studies have been published on FC “smart” applications, none hitherto have been conducted on fog-based smart marketing domains such as recommender systems. FC is considered a novel computational system, which can mitigate latency and improve bandwidth utilization for autonomous consumer behavior applications requiring real-time data-driven decision-making. A conceptual framework is provided by this paper for studying the effects of fog computing on consumer behavior, with the goal of stimulating future research by using, as an example, the intersection of FC and RS. Indeed, our conceptualization of the “fog-based recommender systems” opens many novel and challenging avenues for academic research, some of which are highlighted in the later part of this paper. Keywords: fog computing; recommender system; internet of things (IoT); edge computing; artificial intelligence (AI); software-defined networks (SDNs)', \"Purpose: The general purpose of the study was to investigate the effectiveness of recommender systems in knowledge discovery.\\n\\nMethodology: A desktop research methodology was adopted for the study. Desk research refers to secondary data or that which can be collected without fieldwork. Desk research is basically involved in collecting data from existing resources hence it is often considered a low-cost technique as compared to field research, as the main cost is involved in executive’s time, telephone charges, and directories. Thus, the study relied on already published studies, reports, and statistics. This secondary data was easily accessed through online journals and the library.\\n\\nFindings: It was revealed by the findings that there exists a contextual and methodological gap relating to recommender systems in knowledge discovery. The study on the effectiveness of recommender systems in knowledge discovery found that such systems played a pivotal role in facilitating users' exploration of vast information repositories, enabling them to uncover relevant resources and expand their knowledge. It was found that recommender systems employing advanced algorithms and personalized techniques demonstrated higher effectiveness in generating relevant recommendations tailored to users' preferences and needs. Additionally, the positive correlation between user engagement metrics and knowledge discovery outcomes was highlighted, emphasizing the importance of fostering active user participation in the recommendation process. Contextual information was also identified as a crucial factor influencing recommendation effectiveness. Overall, the study underscored the significance of continuous refinement and optimization of recommender system algorithms to enhance knowledge discovery outcomes for users.\\n\\nUnique Contribution to Theory, Practice, and Policy: The Social Learning theory, Information Foraging theory, and Cognitive Load theory may be used to anchor future studies on recommender systems in knowledge discovery. Recommendations to enhance the efficacy of such systems were provided by the study. It suggested adopting hybrid recommender systems that combine collaborative and content-based filtering techniques to offer more accurate and diverse recommendations. Additionally, the importance of integrating contextual information into recommendation algorithms to dynamically adjust recommendations based on situational context was emphasized. Furthermore, the use of explainable AI techniques to improve transparency and user understanding of recommendation processes was recommended. Maximizing user engagement through active participation and feedback was also highlighted as crucial, along with prioritizing recommendation diversity to foster exploration and serendipitous discovery of new knowledge resources.\", 'The application of Artificial Intelligence (AI) is being significantly increased in many Human Resources (HR) functions. This research aims to understand how the potential of artificial intelligence-based recommender systems to match job profiles with employee profiles is perceived by diverse experts from distinct organisations, such as Project Managers, Managers, Supervisors, and Human Resource Managers. This study employs a Delphi study-based methodology, specifically organising an expert panel that provides their opinions through their ratings and comments on a set of propositions. Based on the online Delphi study results and participant opinions, this research aims to identify the challenges related to employee-job profile matching through artificial intelligence and machine learning tools in the form of recommender systems. In this study, the various challenges of matching employee profiles to job profiles and the current problems faced by executives, human resource personnel, or supervisors such as project managers in an organisation are delved into. The study also sheds light on the potential or feasibility solutions of artificial intelligence in the form of recommender systems where a couple of propositions that focus on potential solutions and various challenges for matching employee profiles to job profiles in an organisation are also tested.\\n\\n', 'Facial Expression Recognition (FER) is utilized in various fields, such as education, gaming, robotics, healthcare, and others. Facial expression techniques, for instance, an interactive robot with Artificial Intelligence, recognize human faces, detect the emotions of the person it is conversing with, and then use these emotions to choose appropriate answers. One use case for face emotion detection is playing music based on the user’s mood. To do this, the user’s facial expression can be analyzed to deduce their feelings. As a result, more investigation is required for new emotion models as existing ones struggle to correctly measure music’s connection with facial emotion. In this paper, this kind of job is implemented using a Convolution Neural Network (CNN) based deep learning approach. Deep learning can more effectively analyze unstructured data, movies, and other forms of media than machine learning. In this research, a real-time system has been created that can recognize human faces, assess human emotions, and even recommend music to users. The OAHEGA and FER-2013 datasets were utilized for the experimental study. Two emotion recognition models were created and trained using various combinations of these datasets. The accuracy of the proposed model is 73.02%. Using the CNN model, six emotions can be predicted: anger, fear, joy, neutral, sadness, and surprise. The proposed system can be utilized in different places where real-time facial recognition plays an important role.', 'Given the challenges of inter-domain information fusion and data sparsity in collaborative filtering algorithms, a cross-domain information fusion matrix decomposition algorithm is proposed in this paper to enhance the accuracy of personalized recommendations in artificial intelligence recommendation systems. The study begins by collecting Douban movie rating data and social network information. To ensure data integrity, Levenshtein distance detection is employed to remove duplicate scores, while natural language processing technology is utilized to extract keywords and topic information from social texts. Additionally, graph convolutional networks are utilized to convert user relationships into feature vectors, and a unique thermal coding method is used to convert discrete user and movie information into binary matrices. To prevent overfitting, the Ridge regularization method is introduced to gradually optimize potential feature vectors. Weighted average and feature connection techniques are then applied to integrate features from different fields. Moreover, the item-based collaborative filtering algorithm is combined with merged user characteristics to generate personalized recommendation lists. In the experimental stage, cross-domain information fusion optimization is conducted on four mainstream mathematical matrix decomposition algorithms: alternating least squares method, non-negative matrix decomposition, singular value decomposition, and latent factor model (LFM). These algorithms are compared with the non-fused approach. The results indicate a significant improvement in score accuracy, with mean absolute error and root mean squared error reduced by 12.8% and 13.2% respectively across the four algorithms. Additionally, when k\\u2009=\\u200910, the average F1 score reaches 0.97, and the ranking accuracy coverage of the LFM algorithm increases by 54.2%. Overall, the mathematical matrix decomposition algorithm combined with cross-domain information fusion demonstrates clear advantages in accuracy, prediction performance, recommendation diversity, and ranking quality, and improves the accuracy and diversity of the recommendation system. By effectively addressing collaborative filtering challenges through the integration of diverse techniques, traditional models in recommendation accuracy and variety are significantly surpassed.', \"The Metaverse, a digital environment where users can interact with each other and virtual objects, is quickly becoming a reality. Artificial Intelligence (AI) is increasingly shaping its development, opening up new immersive experiences. This study examines how AI is combined with technologies like the Internet of Things, blockchain, Natural Language Processing, virtual reality, Augmented Reality, Mixed Reality, and Extended Reality within the Metaverse. One advantage of AI in the Metaverse is its ability to tailor experiences to individual users based on their behavior and preferences. Additionally, AI can automate mundane tasks, allowing more time for creative endeavors. However, challenges such as privacy, bias, and discrimination must be addressed. By exploring these aspects, including ethical concerns, we can better prepare for the future of VR. This study provides a thorough overview of AI's integration with emerging Metaverse technologies, emphasizing the importance of staying updated in this rapidly evolving field.\", 'The realm of artificial intelligence has undergone significant transformation in the last decade, particularly with the emergence of deep learning, which has led to notable advancements across various industries and creative fields. However, what advantages does this hold for the video game sector? Game artificial intelligence (AI) has been a longstanding discipline for over three decades, addressing specific challenges such as strategic adversaries, non-player characters, gameplay pacing, and procedural content generation. This chapter emphasizes the fundamental areas where traditional, rule-based AI continues to excel and how machine learning is offering novel alternatives to these conventional methods. Additionally, it explores the new possibilities arising from AI that are reshaping game development, including player behavior analysis, enhanced graphics, animation control, and automated quality assurance testing.', 'Artificial General Intelligence (AGI) is a concept suggesting that artificial intelligence (AI) advancements could lead to the creation of an entity surpassing even the most intelligent humans. This concept has been present since the early stages of AI development and has sparked various discussions on how such AI might interact with humans, both in fictional works and research studies. This paper examines the current progress in AI and discusses the ongoing AI competition, which is rapidly introducing new and impressive AI techniques capable of surpassing human performance in previously unimaginable tasks and disrupting the job market. These advancements have raised concerns that AGI might become a reality sooner than anticipated. However, the paper argues that deep neural networks, which currently form the foundation of most AI methods, are unlikely to lead to AGI due to their inherent limitations. Instead, it suggests that any threats stemming from the current AI race are more related to the limitations, applications, and lack of regulation surrounding existing models and algorithms rather than the emergence of AGI.', \"Predicting winners in E-sports through real-time analytics has the potential to enhance viewer engagement during major tournament events. However, this task is challenging due to the game's unpredictable variables, such as diverse player strategies and decision-making. Our research aims to increase audience engagement in video game tournaments by introducing a real-time prediction method for determining wins. We utilize a Long Short Term Memory Network (LSTMs) based approach, which efficiently predicts win-lose outcomes using only the health indicator of each player as a time series. To demonstrate our approach, we evaluate its performance in the classic two-player arcade game, Super Street Fighter II Turbo. Additionally, we compare our method with state-of-the-art time series forecasting methods, such as Transformer models found in large language models (LLMs). Lastly, we provide our dataset and code as open-source resources to encourage further development in predictive analysis for arcade games.\", 'This project draws inspiration from turn-based strategy games like Final Fantasy Tactics, X-Com 2, and more recent titles in the genre. It aims to leverage artificial intelligence to enhance storytelling in strategy games. Specifically, the project focuses on using AI to develop a quest generation system for storytelling purposes. This system generates new quests dynamically by interacting with an AI, enabling players to potentially enjoy an ever-expanding story through these quests.', \"The chapter examines how digital technology can be utilized to advance peacebuilding through education, considering both its potential benefits and risks. It proposes an approach grounded in human-centered design (HCD), which prioritizes the needs and perspectives of learners. Through three case studies, the chapter showcases the potential of digital storytelling, artificial intelligence (AI), and gaming in supporting peacebuilding efforts. The first case study illustrates the use of digital storytelling for teaching about genocide, while the second highlights AI's role in safeguarding victims of violence. The third case study explores how gaming can be employed to raise awareness of war. The authors recognize that each technology presents a multifaceted area of study and suggest imaginative exercises to envision the possibilities of liberatory design. In conclusion, the chapter underscores the significance of recognizing technology's dual nature and its capacity for both contributing to conflict and fostering peacebuilding.\", \"Dynamic Virtual Reality (VR) has transformed gaming and entertainment by offering immersive experiences that transport users to new realms. This study introduces an innovative concept: virtual reality horror sports, blending horror with sports in VR. We propose an adaptive approach to developing VR horror games, combining player modeling with an adaptive means-based system that learns each player's fears and adjusts game content accordingly. This research presents two key advancements: a unique method for identifying player fears through game data and machine learning, and an adaptive game system using agents to monitor player terror and limit exposure to distressing elements. Additional evidence from user studies and statistical testing suggests our approach heightens stress and anxiety for gamers, enhancing their experience. Combining VR, horror, and sports creates a compelling and immersive entertainment experience. Players are immersed in a lifelike and thrilling virtual environment. This dynamic VR horror sports experience, enhanced by Artificial Intelligence (AI) and player modeling, offers a comprehensive form of entertainment blending physical activity, customization, and immersion. Such an endeavor could advance VR and AI in gaming while providing gamers with exciting adventures.\", \"Utilizing gamification and video games is a contemporary method for enhancing cognitive abilities and managerial competencies, particularly in strategic thinking skills. Many organizations apply video games across various sectors, such as education, marketing, business, and entrepreneurship, to achieve these ends. This study aimed to explore the impact of video games on enhancing strategic thinking among managers and their potential in developing cognitive capabilities. The study involved 30 students actively engaged in the innovation and entrepreneurship ecosystem. To assess the participants' strategic thinking, Pisapia’s strategic thinking questionnaire was utilized, while their cognitive capabilities were measured using the CANTAB test. Indicators of micro-management, planning, plan recognition, predictions, resource gathering, partial observability, and damage avoidance were designed to identify individuals' game-playing styles. Results showed that 53.3 percent of participants demonstrated reflective thinking, 30 percent exhibited systems thinking, and the remainder displayed a reframing thinking style as their dominant strategic thinking dimension. Moreover, a correlation was identified between the criteria of damage avoidance with reflective thinking style, and an inverse and significant correlation between the criteria of gathering resources with PRM test results. This suggests that strategic games have the potential to influence and enhance certain cognitive functions like attention, reaction, and memory, making them valuable tools for improving cognitive abilities. Consequently, these games can be leveraged to create tasks that enhance managerial cognitive abilities, thereby promoting strategic thinking and decision-making skills.\", \"This research explores the potential enhancement of business simulation games (BSG) through automated adaptable learning (BSG). Given the rapid expansion of information and the complexity of contemporary business environments, traditional BSG education methods often fall short in adequately preparing students for real-world challenges. To address this, the study proposes an innovative framework that continuously adapts learning paths, responses, and testing scenarios based on individual student progress and preferences. This is achieved through the application of modern artificial intelligence techniques, including machine learning, with the aim of optimizing users' retention of knowledge, decision-making abilities, and creative thinking skills by personalizing their learning experience. In conclusion, our research contributes to the ongoing discourse on the intersection of AI, education, and corporate strategies, offering prospects for enhanced and more engaging educational approaches in the modern era.\", 'A growing number of people are incorporating video games into their life. They can arouse a variety of feelings in players, from happiness and excitement to terror and empathy, resulting in a profound level of immersion and lasting memories. Is it feasible to use the feelings directly in the game itself, and how do they handle it?\\n\\nThe idea of creating a dynamic procedural content generation (PCG) system with emotional game dynamics for interaction is presented in this paper. The approach is built on affective computing techniques. The paper created an emotion recognition system based on fuzzy logic in order to accomplish this goal. and Artificial Neural Networks handled PCG.\\n\\nAffective computing techniques, including interacting with emotional expression, have a lot to offer the video game business because player emotional investment is crucial. This will add something fresh to the variety of interactions between humans and computers.\\n\\n\\n']\n",
            "Construction: ['Recent developments in Artificial Intelligence (AI) have generated great expectations for the future impact of AI in education and learning (AIED). Often these expectations have been based on misunderstanding current technical possibilities, lack of knowledge about state-of-the-art AI in education, and exceedingly narrow views on the functions of education in society. In this article, we provide a review of existing AI systems in education and their pedagogic and educational assumptions. We develop a typology of AIED systems and describe different ways of using AI in education and learning, show how these are grounded in different interpretations of what AI and education is or could be, and discuss some potential roadblocks on the AIED highway.', \"Artificial intelligence (AI) is developing and its application is spreading at an alarming rate, and AI has become part of our daily lives. As a matter of fact, AI has changed the way people learn. However, its adoption in the educational sector has been saddled with challenges and ethical issues. The purpose of this study is to analyze the opportunities, benefits, and challenges of AI in education. A review of available and relevant literature was done using the systematic review method to identify the current research focus and provide an in-depth understanding of AI technology in education for educators and future research directions. Findings showed that AI's adoption in education has advanced in the developed countries and most research became popular within the Industry 4.0 era. Other challenges, as well as recommendations, are discussed in the study.\", 'This study provided a content analysis of studies aiming to disclose how artificial intelligence (AI) has been applied to the education sector and explore the potential research trends and challenges of AI in education. A total of 100 papers including 63 empirical papers (74 studies) and 37 analytic papers were selected from the education and educational research category of Social Sciences Citation Index database from 2010 to 2020. The content analysis showed that the research questions could be classified into development layer (classification, matching, recommendation, and deep learning), application layer (feedback, reasoning, and adaptive learning), and integration layer (affection computing, role-playing, immersive learning, and gamification). Moreover, four research trends, including Internet of Things, swarm intelligence, deep learning, and neuroscience, as well as an assessment of AI in education, were suggested for further investigation. However, we also proposed the challenges in education may be caused by AI with regard to inappropriate use of AI techniques, changing roles of teachers and students, as well as social and ethical issues. The results provide insights into an overview of the AI used for education domain, which helps to strengthen the theoretical foundation of AI in education and provides a promising channel for educators and AI engineers to carry out further collaborative research.', 'As of 2021, more than 30 countries have released national artificial intelligence (AI) policy strategies. These documents articulate plans and expectations regarding how AI will impact policy sectors, including education, and typically discuss the social and ethical implications of AI. This article engages in thematic analysis of 24 such national AI policy strategies, reviewing the role of education in global AI policy discourse. It finds that the use of AI in education (AIED) is largely absent from policy conversations, while the instrumental value of education in supporting an AI-ready workforce and training more AI experts is overwhelmingly prioritized. Further, the ethical implications of AIED receive scant attention despite the prominence of AI ethics discussion generally in these documents. This suggests that AIED and its broader policy and ethical implications—good or bad—have failed to reach mainstream awareness and the agendas of key decision-makers, a concern given that effective policy and careful consideration of ethics are inextricably linked, as this article argues. In light of these findings, the article applies a framework of five AI ethics principles to consider ways in which policymakers can better incorporate AIED’s implications. Finally, the article offers recommendations for AIED scholars on strategies for engagement with the policymaking process, and for performing ethics and policy-oriented AIED research to that end, in order to shape policy deliberations on behalf of the public good.', 'Artificial Intelligence (AI) is reshaping the world in profound ways; some of its impacts are certainly beneficial but widespread and lasting harms can result from the technology as well. The integration of AI into various aspects of human life is underway, and the complex ethical concerns emerging from the design, deployment, and use of the technology serves as a reminder that it is time to revisit what future developers and designers, along with professionals, are learning when it comes to AI. It is of paramount importance to train future members of the AI community, and other stakeholders as well, to reflect on the ways in which AI might impact people’s lives and to embrace their responsibilities to enhance its benefits while mitigating its potential harms. This could occur in part through the fuller and more systematic inclusion of AI ethics into the curriculum. In this paper, we briefly describe different approaches to AI ethics and offer a set of recommendations related to AI ethics pedagogy.', 'While Artificial Intelligence in Education (AIED) research has at its core the desire to support student learning, experience from other AI domains suggest that such ethical intentions are not by themselves sufficient. There is also the need to consider explicitly issues such as fairness, accountability, transparency, bias, autonomy, agency, and inclusion. At a more general level, there is also a need to differentiate between doing ethical things and doing things ethically, to understand and to make pedagogical choices that are ethical, and to account for the ever-present possibility of unintended consequences. However, addressing these and related questions is far from trivial. As a first step towards addressing this critical gap, we invited 60 of the AIED community’s leading researchers to respond to a survey of questions about ethics and the application of AI in educational contexts. In this paper, we first introduce issues around the ethics of AI in education. Next, we summarise the contributions of the 17 respondents, and discuss the complex issues that they raised. Specific outcomes include the recognition that most AIED researchers are not trained to tackle the emerging ethical questions. A well-designed framework for engaging with ethics of AIED that combined a multidisciplinary approach and a set of robust guidelines seems vital in this context.', \"The educational applications of AI are a combination of what Pasteur's Quadrant describes as use-inspired basic and pure applied research. This article gives an overview of the classical and emerging architectures for AI in education. Early researchers focused on creating personalized teaching systems based on solitary learners, whereas recent work takes account of other people and the learning context. Various Grand Challenges illustrate the issues still facing AI in education.\", 'Engineering education is constantly evolving to keep up with the latest technological developments and meet the changing needs of the engineering industry. One promising development in this field is the use of generative artificial intelligence technology, such as the ChatGPT conversational agent. ChatGPT has the potential to offer personalized and effective learning experiences by providing students with customized feedback and explanations, as well as creating realistic virtual simulations for hands-on learning. However, it is important to also consider the limitations of this technology. ChatGPT and other generative AI systems are only as good as their training data and may perpetuate biases or even generate and spread misinformation. Additionally, the use of generative AI in education raises ethical concerns such as the potential for unethical or dishonest use by students and the potential unemployment of humans who are made redundant by technology. While the current state of generative AI technology represented by ChatGPT is impressive but flawed, it is only a preview of what is to come. It is important for engineering educators to understand the implications of this technology and study how to adapt the engineering education ecosystem to ensure that the next generation of engineers can take advantage of the benefits offered by generative AI while minimizing any negative consequences.', 'This article examines benefits and risks of Artificial Intelligence (AI) in education in relation to fundamental human rights. The article is based on an EU scoping study [Berendt, B., A. Littlejohn, P. Kern, P. Mitros, X. Shacklock, and M. Blakemore. 2017. Big Data for Monitoring Educational Systems. Luxembourg: Publications Office of the European Union. https://publications.europa.eu/en/publication-detail/-/publication/94cb5fc8-473e-11e7-aea8-01aa75ed71a1/]. The study takes into account the potential for AI and ‘Big Data’ to provide more effective monitoring of the education system in real-time, but also considers the implications for fundamental human rights and freedoms of both teachers and learners. The analysis highlights a need to balance the benefits and risks as AI tools are developed, marketed and deployed. We conclude with a call to embed consideration of the benefits and risks of AI in education as technology tools into the development, marketing and deployment of these tools. There are questions around who – which body or organisation – should take responsibility for regulating AI in education, particularly since AI impacts not only data protection and privacy, but on fundamental rights in general. Given AI’s global impact, it should be regulated at a trans-national level, with a global organisation such as the UN taking on this role.', 'A defining aspect of our modern age is our tenacious belief in technology in all walks of life, not least in education. It could be argued that this infatuation with technology or ‘techno-philia’ in education has had a deep impact in the classroom changing the relationship between teacher and student, as well as between students; that is, these relations have become increasingly more I–It than I–Thou based because the capacity to form bonds, the level of connectedness between teacher and students, and between students has either decreased or become impaired by the increasing technologisation of education. Running parallel to this and perhaps exacerbating the problem is the so-called process of ‘learnification’, which understands that teachers are mere facilitators of the learning process, rather than someone with an expertise who has something to teach others. In this article, I first assess the current technologisation of education and the impact it has had in relations within the classroom; second, I characterise Buber’s I–It and I–Thou relations and its implications for education; finally, I investigate through a thought experiment if the development of AI could 1 day successfully replace human teachers in the classroom.', 'Agriculture is the ultimate imperative and primary source of origin to furnish domestic income for multifarious countries. The disease caused in plants due to various pathogens like viruses, fungi, and bacteria is liable for considerable monetary losses in the agriculture corporation across the world. The security of crops concerning quality and quantity is crucial to monitor disease in plants. Thus, recognition of plant disease is essential. The plant disease syndrome is noticeable in distinct parts of plants. Nonetheless, commonly the infection is detected in distinct leaves of plants. Computer vision, deep learning, few-shot learning, and soft computing techniques are utilized by various investigators to automatically identify the disease in plants via leaf images. These techniques also benefit farmers in achieving expeditious and appropriate actions to avoid a reduction in the quality and quantity of crops. The application of these techniques in the recognition of disease can avert the disadvantage of origin by a factious selection of disease features, extraction of features, and boost the speed of technology and efficiency of research. Also, certain molecular techniques have been established to prevent and mitigate the pathogenic threat. Hence, this review helps the investigator to automatically detect disease in plants using machine learning, deep learning and few shot learning and provide certain diagnosis techniques to prevent disease. Moreover, some of the future works in the classification of disease are also discussed.\\n', 'There are a large number of functional sensors installed on the modern intelligent vehicles. Many Artificial Intelligence based foundation models have been proposed for smart sensing to recognize the known object classes in the new but similar scenarios. However, it is still challenging for the foundation models of smart sensing to detect all the object classes in both seen and unseen scenarios. This letter aims at pushing the boundary of smart sensing research for intelligent vehicles. We first summarize the current widely-used foundation models and the foundation intelligence needed for smart sensing of intelligent vehicles. We then explain Sora-based Parallel Vision to boost the foundation models of smart sensing from basic intelligence (1.0) to enhanced intelligence (2.0) and final generalized intelligence (3.0). Several representative case studies are discussed to show the potential usages of Sora-based Parallel Vision, followed by its future research direction.', 'Artificial Intelligence has become a significant tool in modern technology, enabling people to interact with machines through various methods. Individuals with visual impairments have trouble doing tasks because they are either blind or have poor vision. BVI stands for Blind and Visually Impaired. Solutions must also advance with technology to ensure that individuals can effectively navigate their surroundings and assist them in real-time navigation. The study conducts surveys on visually challenged individuals in the community and aims to assist them by providing smart gadgets to identify faces, colours, and objects. Moreover, this study emphasizes more on different technologies and methods that are used earlier to help visually impaired people in their day-to-day life.', 'In a world where a major portion of the populace suffer with daily challenges of blindness, this pioneering project introduces a comprehensive smart support system designed to aid the needs of people who are visually impaired. This advanced system is ingeniously integrated into a pair of headphones, combining various state-of-the-art technologies such as cameras, ultrasonic sensors, and cutting-edge machine learning algorithms. Its primary goals encompass recognizing objects, accurately estimating distances between objects and users, deciphering captured signs and indications, and offering real-time location-based navigation and directions. This multifunctional blind assistance device is designed to empower users by enhancing their spatial awareness and providing them the tools they need to navigate travel securely and on their own. It represents a remarkable leap forward in refining the overall quality of life and mobility for the blind people.', \"Unmanned aerial vehicles (UAVs) have attracted massive attention in many engineering and practical applications in the last years for their characteristics and operation flexibility. For the UAV system, suitable control systems are required to operate appropriately and efficiently. An emerging control technique is visual servoing utilizing the onboard camera systems for inspecting the UAV's environment and autonomously controlling the UAV's operation. Artificial intelligence (AI) techniques are widely deployed in the visual servoing of autonomous UAV applications. Despite the increasing research in the field of AI-based visual control of UAV systems, comprehensive review articles that showcase the general trends and future directions in this field of research are limited. This work comprehensively examines the application and advancements of AI-enhanced visual servoing in autonomous UAV systems, covering critical control tasks and offering insights into future research directions for enhancing performance and applicability which is limited in the current literature. The paper first reviews the application of intelligent visual servoing systems for autonomously executing various UAV control tasks, including 3D UAV positioning, aerial and ground object following, obstacle avoidance, and autonomous landing. Second, the research progresses in applying AI techniques in the visual servoing of autonomous UAV systems are discussed and analyzed. Finally, future directions and critical research gaps for further improving the performance and applicability of intelligent visual servoing systems are included.\\nKeywords: Unmanned aerial vehicles; Visual servoing; Artificial intelligence; Artificial neural networks; Fuzzy logic; Reinforcement learning\\n\", 'The revolution in digital computer technology that has made possible new and sophisticated imaging techniques may next influence the interpretation of radiologic images. In mammography, computer vision and artificial intelligence techniques have been used successfully to detect or to characterize abnormalities on digital images. Radiologists supplied with this information often perform better at mammographic detection or characterization tasks in observer studies than do unaided radiologists. This technology therefore could decrease errors in mammographic interpretation that continue to plague human observers.', 'Grain production plays an important role in the global economy. In this sense, the demand for efficient and safe methods of food production is increasing. Information Technology is one of the tools to that end. Among the available tools, we highlight computer vision solutions combined with artificial intelligence algorithms that achieved important results in the detection of patterns in images. In this context, this work presents a systematic review that aims to identify the applicability of computer vision in precision agriculture for the production of the five most produced grains in the world: maize, rice, wheat, soybean, and barley. In this sense, we present 25 papers selected in the last five years with different approaches to treat aspects related to disease detection, grain quality, and phenotyping. From the results of the systematic review, it is possible to identify great opportunities, such as the exploitation of GPU (Graphics Processing Unit) and advanced artificial intelligence techniques, such as DBN (Deep Belief Networks) in the construction of robust methods of computer vision applied to precision agriculture.\\n\\n', 'Technology has advanced surgery, especially minimally invasive surgery (MIS), including laparoscopic surgery and robotic surgery. It has led to an increase in the number of technologies in the operating room. They can provide further information about a surgical procedure, e.g. instrument usage and trajectories. Among these surgery-related technologies, the amount of information extracted from a surgical video captured by an endoscope is especially great. Therefore, the automation of data analysis is essential in surgery to reduce the complexity of the data while maximizing its utility to enable new opportunities for research and development. Computer vision (CV) is the field of study that deals with how computers can understand digital images or videos and seeks to automate tasks that can be performed by the human visual system. Because this field deals with all the processes of real-world information acquisition by computers, the terminology “CV” is extensive, and ranges from hardware for image sensing to AI-based image recognition. AI-based image recognition for simple tasks, such as recognizing snapshots, has advanced and is comparable to humans in recent years. Although surgical video recognition is a more complex and challenging task, if we can effectively apply it to MIS, it leads to future surgical advancements, such as intraoperative decision-making support and image navigation surgery. Ultimately, automated surgery might be realized. In this article, we summarize the recent advances and future perspectives of AI-related research and development in the field of surgery.', 'Introduction: We compared the print-to-speech properties and human performance characteristics of two artificial intelligence vision aids, Orcam MyEye 1 (a portable device) and Seeing AI (an iPhone and iPad application). Methods: There were seven participants with visual impairments who had no experience with the two reading aids. Four participants had no light perception. Two individuals with measurable acuity and one with light perception were tested while blindfolded. We also tested performance with text of varying appearance in varying viewing conditions. To evaluate human performance, we asked the participants to use the devices to attempt 12 reading tasks similar to activities of daily living. We assessed the ranges of text attributes for which reading was possible, such as print size, contrast, and light level. We also assessed if individuals could complete tasks with the devices and measured accuracy and completion time. Participants also completed a survey concerning the two aids. Results: Both aids achieved greater than 95% accuracy in text recognition for flat, plain word documents and ranged from 13 to 57% accuracy for formatted text on curved surfaces. Both aids could read print sizes as small as 0.8M (20/40 Snellen equivalent, 40 cm viewing distance). Individuals successfully completed 71% and 55% (p = .114) of tasks while using Orcam MyEye 1 and Seeing AI, respectively. There was no significant difference in time to completion of tasks (p = .775). Individuals believed both aids would be helpful for daily activities. Discussion: Orcam MyEye 1 and Seeing AI had similar text-reading capability and usability. Both aids were useful to users with severe visual impairments in performing reading tasks. Implications for Practitioners: Selection of a reading device or aid should be based on individual preferences and prior familiarity with the platform, since we found no clear superiority of one solution over the other.', 'As one of the branches of machine learning, the deep learning model combined with artificial intelligence is widely used in the field of computer vision technology, and the image recognition field represented by medical image analysis is also developing. Its advantage is that it does not rely on human annotation, and the computer can recognize and process the feature information omitted by human beings during the model training process, so as to achieve or even exceed the accuracy of human processing. Based on the general lack of explain ability caused by the unknown data processing process in the deep model, the existing solutions mainly include the establishment of internal explain ability, attention mechanism interpretation of specific models, and the interpretation of unknowable models represented by LIME. The way to quantitatively assess interpretability is still being explored, especially in the interpretative assessment of both doctors and patients in medical decision-related models, several scales have been proposed for reference. The current research on the application of artificial intelligence deep learning models in medical imaging generally pays more attention to accuracy rather than explain ability, resulting in the lack of explain ability, and thus hindering the practical clinical application of deep learning models. Therefore, the need to analyze the development of medical image analysis in the field of artificial intelligence and computer vision technology, and how to balance accuracy and interpretability to develop deep learning models that both doctors and patients can trust will become the research focus of the industry in the future.', 'This paper mainly discusses the asymmetric face recognition problem where the number of names in a name list and the number of faces in the photo might not be equal, but each face should be automatically labeled with a name. The motivation for this issue is that there had been many meetings in the past. After each meeting, the participant took group photos. The meeting provided only a corresponding name list of participants without one-to-one labels. In the worst case, the group photo might mix with the faces that were not participating in the meeting. Another reason for asymmetric face recognition is that some meeting personnel did not appear in photos because they assisted in taking pictures. This paper proposes an asymmetric face recognition mechanism, called AFRM in short. Initially, the proposed AFRM adopts the histogram of oriented gradients (HOG) and support vector machine (SVM) to detect and extract all faces from photos. Next, AFRM extracts the features from each face using the convolution feature map (Conv_FF) and adopts the features to partition the faces into different classes. Then, the AFRM applies the statistic-based mechanism to map each name in the name list to each face class. According to this mapping, each face will be associated with one name. To quickly identify a face during the meeting, the AFRM applies the K-nearest neighbors (KNN) to represent the features of each face. During the new meeting, the proposed AFRM can extract the feature of one face and then adopts KNN to derive the features. Experimental results show that the proposed mechanism achieves more than 97% accuracy without one-to-one name and face labeling.', 'The face is the most essential part of the human body, and because of its distinctive traits, it is crucial for recognizing people. Facial recognition technology (FRT) is one of the most successful and fascinating technologies of the modern times. The world is moving towards contactless FRT after the COVID-19 pandemic. Due to its contactless biometric characteristics, FRT is becoming quite popular worldwide. Businesses are replacing conventional fingerprint scanners with artificial intelligence—based FRT, opening up enormous commercial prospects. Security and surveillance, authentication/access control systems, digital healthcare, photo retrieval, etc., are some sectors where its use has become essential. In the present communication, we presented the global adoption of FRT, its rising trend in the market, utilization of the technology in various sectors, its challenges and rising concerns with special reference to India and worldwide.', 'Measures of success for facial feminization surgery (FFS) have previously included improved rates of external gender perception as female and patient-reported outcome measures. In this study, we used artificial intelligence facial recognition software to objectively evaluate the effects of FFS on both perceived gender and age among male-to-female transgender patients, as well as their relationship with patient facial satisfaction. Standardized frontal preoperative and postoperative images of 27 transgender women undergoing FFS were analyzed by Amazon’s AI facial recognition software to determine gender, femininity confidence score, and perceived age. Female gender-typing, improvement in gender-typing (preoperatively to postoperatively), and femininity confidence scores were analyzed. To assess patient satisfaction, FACE-Q modules were completed postoperatively. Preoperatively, FFS images were perceived as female 48.1% of the time, and postoperatively, this improved to 74.1% (P=0.05). Femininity confidence scores improved from a mean score of 0.04 preoperatively to 0.39 postoperatively (P=0.003). FFS was associated with a decrease in perceived age relative to the patient’s true age (−2.4 y, P<0.001), with older patients experiencing greater reductions. Pearson correlation matrix found no significant relationship between improved female gender typing and patient facial satisfaction. Undergoing surgery at a younger age was associated with higher overall facial satisfaction (r=−0.6, P=0.01). Transfeminine patients experienced improvements in satisfaction with facial appearance, perceived gender, and decreases in perceived age following FFS. Notably, patient satisfaction was not directly associated with improved AI-gender typing, suggesting that other factors may influence patient satisfaction.', 'Surprisingly, the high accuracies previously reported, exceeding 95%, dropped significantly when faced with the more demanding conditions of the forensic scenario, plummeting to as low as 65%. In essence, while facial recognition systems have shown impressive performance in ideal conditions, our study indicates a substantial decrease in accuracy when faced with the complexities and challenges typical of real-world forensic scenarios, highlighting the need for further advancements to bridge this gap. Recent advancements in machine learning and computer vision have shown facial recognition systems achieving accuracies that surpass human performance in controlled settings but fingerprint analysis is proved more accurate in all aspects. To investigate this, we created a large-scale synthetic facial dataset and designed a controlled facial lineup that mimics conditions encountered in real forensic situations. This approach allowed us to systematically assess facial recognition under various challenging real-world conditions. Using both our synthetic dataset and a well-known dataset of actual faces, we tested the accuracy of two widely used neural-based facial recognition systems. Comparative and Analytical method is applied for present Research. Artificial intelligence could help humans in accuracy and speeding up the process of investigation.', 'Facial recognition is a well-established and popular field in Computer Vision, especially with advancements in deep learning and data sets. Deep facial recognition has made significant progress and is widely applied in real-world scenarios. A complete facial recognition system involves three main components: facial recognition, orientation, and representation. This system detects faces, aligns them to a standard view, and extracts features for recognition using deep convolutional neural networks. This article provides a detailed overview of the latest advancements in these areas, showing how deep learning has greatly enhanced their abilities. Object detection in machine vision is a challenging area that requires significant improvements. While image classification accuracy is nearing 2.25%, surpassing human performance, object detection algorithms are still in the early stages. Current algorithms achieve only 40.8 MAPS on modern objects, so careful dataset selection is crucial for optimal results.', 'Face recognition has recently gained significant attention as one of the most useful image analysis applications. By leveraging their unique but incredible identification skills, these systems are capable of recognizing users. Face recognition systems have been extensively studied. The system, however, has a number of drawbacks. Existing face recognition methods may result in a longer histogram, which slows down for a large-scale database. To address the challenges with face recognition, we have proposed a hybrid descriptor using MultiBlock Local Ternary Pattern (LTP)—Gray Level Co- occurrence Matrix (GLCM). In this study, we have employed the LTP, GLCM and Speeded Up Robust Features (SURF) methods to extract the illumination, rotation, and scale-invariant features of the face database images. These features are then trained using Artificial Neural Network. The layer neurons are optimally selected by Crow Search Optimization (CSO) method which yielded an accuracy of 95%. The proposed approach was implemented in the Matlab software, and the experimental data was analyzed to show that the developed texture descriptor has a higher recognition rate than existing methods.', 'With the rise of deep neural networks, the performance of biometric systems has increased tremendously. Biometric systems for face recognition are now used in everyday life, e.g., border control, crime prevention, or personal device access control. Although the accuracy of face recognition systems is generally high, they are not without flaws. Many biometric systems have been found to exhibit demographic bias, resulting in different demographic groups being not recognized with the same accuracy. This is especially true for facial recognition due to demographic factors, e.g., gender and skin color. While many previous works already reported demographic bias, this work aims to reduce demographic bias for biometric face recognition applications. In this regard, 12 face recognition systems are benchmarked regarding biometric recognition performance as well as demographic differentials, i.e., fairness. Subsequently, multiple fusion techniques are applied with the goal to improve the fairness in contrast to single systems. The experimental results show that it is possible to improve the fairness regarding single demographics, e.g., skin color or gender, while improving fairness for demographic subgroups turns out to be more challenging.', \"In Nigeria, there are many different security concerns and thus crimes have increased despite the fact that there are stringent laws and punishments in place to deter them, making it appear as though the authorities are unable to stop it. In order to identify criminals and conduct investigations, it is imperative that a facial recognition system be connected to a constantly updated digital library. The focus of this paper is to develop an automatic criminal investigation system that can identify criminals based on their faces and produce real-time digital archives about them. However, as an object detection method and facial recognition model, the new system is built on the Haar Cascades Classifier technique in the OpenCV package. Additionally, appropriate programming languages that may provide the needed results were investigated. Python 3.6 was used with the Django 4.2 framework, OpenCV-Python, and Dlib for language execution. Due to Django's ORM, support for numerous databases, and usage of the SQLite3 database, a straightforward database was employed for lightweight applications. The 12 factor app idea was used to construct the DICA-FR system's essential skills. Face detection was applied to the image using the Haar method during processing, and during post-processing, the discovered face was compared with well-known criminal face encodings for matching purposes. Results demonstrated that DICA-FRS could effectively replace human systems since it can recover faces from the furthest distances, display the name of the offender, and sound an alert on the DICA web app's output screen. The DICA system is a working prototype of a system that might be used in the criminal investigative process in Nigeria.\", 'Facial Expression Recognition (FER) is utilized in various fields, such as education, gaming, robotics, healthcare, and others. Facial expression techniques, for instance, an interactive robot with Artificial Intelligence, recognize human faces, detect the emotions of the person it is conversing with, and then use these emotions to choose appropriate answers. One use case for face emotion detection is playing music based on the user’s mood. To do this, we can analyze the user’s facial expression to deduce their feelings. As a result, new emotion models require more investigation as existing one’s struggle to correctly measure music’s connection with facial emotion. In this paper, we implement this kind of job using Convolution Neural Network (CNN) based deep learning approach. Deep learning can more effectively analyze unstructured data, movies, and other forms of media than machine learning. In our research, we have created a real-time system that can recognize human faces, assess human emotions, and even recommend music to users. The OAHEGA and FER-2013 datasets were utilized for experimental study. We created and trained two emotion recognition models using various combinations of these datasets. The proposed model’s accuracy is 73.02%. Using our CNN model, we can predict six emotions: anger, fear, joy, neutral, sadness, and surprise. The proposed system can be utilized in different places where real-time facial recognition plays an important role.', 'Facial Expression Recognition (FER) is utilized in various fields, such as education, gaming, robotics, healthcare, and others. Facial expression techniques, for instance, an interactive robot with Artificial Intelligence, recognize human faces, detect the emotions of the person it is conversing with, and then use these emotions to choose appropriate answers. One use case for face emotion detection is playing music based on the user’s mood. To do this, we can analyze the user’s facial expression to deduce their feelings. As a result, new emotion models require more investigation as existing one’s struggle to correctly measure music’s connection with facial emotion. In this paper, we implement this kind of job using Convolution Neural Network (CNN) based deep learning approach. Deep learning can more effectively analyze unstructured data, movies, and other forms of media than machine learning. In our research, we have created a real-time system that can recognize human faces, assess human emotions, and even recommend music to users. The OAHEGA and FER-2013 datasets were utilized for experimental study. We created and trained two emotion recognition models using various combinations of these datasets. The proposed model’s accuracy is 73.02%. Using our CNN model, we can predict six emotions: anger, fear, joy, neutral, sadness, and surprise. The proposed system can be utilized in different places where real-time facial recognition plays an important role.', 'Autonomous vehicles (AVs) are expected to reshape future transportation systems, and decision making is one of the critical modules toward high-level automated driving. To overcome those complicated scenarios that rule-based methods could not cope with well, data-driven decision-making approaches have aroused more focus. The datasets to be used in developing data-driven methods dramatically influence the performance of decision making; hence, it is necessary to have a comprehensive insight into the existing datasets. From the aspects of collection sources, driving data can be divided into vehicle-, environment-, and driver-related data. This study compares the state-of-the-art datasets of these three categories and summarizes their features, including sensors used, annotation, and driving scenarios. Based on the characteristics of the datasets, this survey also discusses potential applications of datasets on various aspects of AV decision making, assisting researchers in finding appropriate ones to support their own research. The future trends of AV dataset development are summarized.', 'Accurate trajectory tracking is unrealistic in real-world scenarios, however, which is commonly assumed to facilitate motion planning algorithm design. In this paper, a safe and reliable motion planning and control framework is proposed to handle the tracking errors caused by inaccurate tracking by coordinating the motion planning layer and controller. Specifically, motion space is divided into safe regions and risky regions by designing the movement restraint size dependent on tracking error to construct the repulsive potential field. The collision-free waypoint set can then be obtained by combining global search and the proposed waypoint set filtering method. The planned trajectory is fitted by an optimization-based approach which minimizes the acceleration of the reference trajectory. Then, the planned trajectory is checked and modified by the designed anti-collision modification to ensure safety. Using invertible transformation and adaptive compensation allows the transient trajectory tracking errors to be limited within the designed region even with actuator faults. Because tracking error is considered and margined at the planning level, safety and reliability can be guaranteed by the coordination between the planning and control levels under inaccurate tracking and actuator faults. The advantages and effectiveness of the proposed motion planning and control method are verified by simulation and experimental results.', 'How would people distribute risks of autonomous vehicles (AVs) in everyday road traffic? The rich literature on the ethics of autonomous vehicles (AVs) revolves around moral judgments in unavoidable collision scenarios. We argue for extending the debate to driving behaviors in everyday road traffic where ubiquitous ethical questions arise due to the permanent redistribution of risk among road users. This distribution of risks raises ethically relevant questions that cannot be evaded by simple heuristics such as “hitting the brakes.” Using an interactive, graphical representation of different traffic situations, we measured participants’ preferences on driving maneuvers of AVs in a representative survey in Germany. Our participants’ preferences deviated significantly from mere collision avoidance. Interestingly, our participants were willing to take risks themselves for the benefit of other road users, suggesting that the social dilemma of AVs may be mitigated in risky environments. Our research might build a bridge between engineers and philosophers to discuss the ethics of AVs more constructively.', \"Artificial intelligence is one of the emerging technologies that simulate human intelligence in machines by programming it to think like human beings and mimic their actions. An autonomous vehicle can function itself and carry out necessary functions without any human involvement. This innovative technology may provide increased passenger safety, less congested roads, congestion reduction, optimum traffic, lower fuel consumption, less pollution, and better travel experiences. Autonomous vehicles play a vital role in industry, agriculture, transportation, and military applications. The autonomous vehicle's activities are supported by sensor data and a few artificial intelligence systems. Artificial intelligence is the collection of data, path planning, and execution in autonomous vehicles that require some machine learning techniques that are a part of artificial intelligence. But this comes with some privacy issues and security concerns. Security is an important concern for autonomous vehicles. The issues of cybersecurity while incorporating artificial intelligence in autonomous vehicles will be covered in this article, along with the growing technology of self-driving automobiles.\", \"Throughout the last decades, the number of vehicles on the road has steadily increased due to the rising demand for urban mobility and contemporary logistics. Two of the many detrimental effects of more vehicles on the road, which also impede economic development, are increased traffic congestion and traffic accidents. The issues mentioned above can be significantly resolved by making vehicles smarter by reducing their reliance on humans. Over the past century, various nations have conducted extensive research that has fueled the automation of road vehicles. The development of autonomous vehicle (AV) technologies is currently being pursued by all significant motor manufacturers worldwide. Undoubtedly, the widespread use of autonomous cars is more imminent than we realize given the development of artificial intelligence (AI). In order for AVs to perceive their surroundings and make the right decisions in real time, AI has emerged as a crucial component. This development of AI is being driven by the growth of big data from numerous sensing devices and cutting-edge computing resources. We must first examine AI's development and history in order to comprehend its functions in AV systems.\", 'The future sustainability of the global automotive industry will be greatly affected by the fourth industrial revolution and the evolution of artificial intelligence (AI). The “new normal” is projected to be driven by new industry standards including an increasingly autonomous self-driving technology, amended safety standards, more complex insurance regulations, adaptive social resistance to technological change, city infrastructure requirements with a digital divide, and disruptive business innovation based on strategic input supply partnerships with open-source AI. In this chapter, the key factors of the autonomous vehicles (AVs) are analyzed using AI developments in radar and laser technology, commercial risk factors, self-driving consumer behavior, city infrastructure constraints, and social adaptations to new technology. The future trajectory of the AV industry is expected to be an interplay between commercial, social, risk, infrastructure, and regulatory mechanisms with various impacts on the industry’s stakeholders. This study predicts that the most likely sustainable scenario for the AV industry is that it will be driven by: (1) AI’s pulsed laser LiDAR (Light Detection and Ranging) with a sufficient loop frequency and GPS bi-directional cloud technology requirement, (2) pooled insurance in contrast to individual liability, (3) smart city infrastructure with expected sharp digital divide across transport regions leading to more regional inequality, and (4) customers who strongly prefer a human controlled semi-autonomous vehicle rather than complete machine autonomy.', \"The future of autonomous vehicles lies in the convergence of human-centric design and advanced AI capabilities. Autonomous vehicles of the future will not only transport passengers but also interact and adapt to their desires, making the journey comfortable, efficient, and pleasant. In this paper, we present a novel framework that leverages Large Language Models (LLMs) to enhance autonomous vehicles' decision-making processes. By integrating LLMs' natural language capabilities and contextual understanding, specialized tools usage, synergizing reasoning, and acting with various modules on autonomous vehicles, this framework aims to seamlessly integrate the advanced language and reasoning capabilities of LLMs into autonomous vehicles. The proposed framework holds the potential to revolutionize the way autonomous vehicles operate, offering personalized assistance, continuous learning, and transparent decision-making, ultimately contributing to safer and more efficient autonomous driving technologies.\", \"The potential for connected automated vehicles is multifaceted, and automated advancement deals with more of Internet of Things (IoTs) development enabling artificial intelligence (AI). Early advancements in engineering, electronics, and many other fields have inspired AI. There are several proposals of technologies used in automated vehicles. Automated vehicles contribute greatly toward traffic optimization and casualty reduction. In studying vehicle autonomy, there are two categories of development available: high-level system integrations like new-energy vehicles and intelligent transportation systems and the other involves backward subsystem advancement like sensor and information processing systems. The Advanced Driver Assistance System shows results that meet the expectations of real-world problems in vehicle autonomy. Situational intelligence that collects enormous amounts of data is considered for high-definition creation of city maps, land surveying, and quality checking of roads as well. The infotainment system of the transport covers the driver's gesture recognition, language transaction, and perception of the surroundings with the assistance of a camera, Light Detection and Ranging (LiDAR), and Radio Detection And Ranging (RADAR) along with localization of the objects in the scene. This chapter discusses the history of autonomous vehicles (AV), trending research areas of artificial intelligence technology in AV, state-of-the-art datasets used for AV research, and several Machine Learning (ML)/Deep Learning (DL) algorithms constituting the functioning of AV as a system, concluding with the challenges and opportunities of AI in AV.\\n\\n\\n\\n\\n\\n\", 'Artificial intelligence is now a necessary component for both production and service systems in recent years, as technology has become a vital aspect of daily life. Automated driving vehicles operate autonomously, also known as driverless cars that can operate without a human driver. Research on autonomous vehicles has substantially advanced in recent years. Artificially intelligent autonomous vehicles are the current need of the society. Although some people might be apprehensive to give a computer control of their vehicle, automated driving technologies have the potential to make roads safer. Self-driving automobiles can address environmental issues as well as safety-related ones. Unlike humans, computers do not really have difficulty keeping attention when driving. Additionally, by responding appropriately, an automated car can prevent accidents to potentially dangerous events on the road. Self-driving technology has many advantages, one of which will make more easily accessible means of transport to people who are unable to drive. For a variety of reasons, such as inexperience, incapacity, or age, many people are unable to operate a vehicle. These individuals can travel considerably more safely and independently. Therefore, we will explore the architectures of both software and hardware of autonomous cars in this chapter, as well as their parts, benefits, and future developments.\\n', 'The advent of autonomous vehicles has heralded a transformative era in transportation, reshaping the landscape of mobility through cutting-edge technologies. Central to this evolution is the integration of Artificial Intelligence (AI) and learning algorithms, propelling vehicles into realms of unprecedented autonomy. This paper provides a comprehensive exploration of the evolutionary trajectory of AI within autonomous vehicles, tracing the journey from foundational principles to the most recent advancements. Commencing with a current landscape overview, the paper delves into the fundamental role of AI in shaping the autonomous decision-making capabilities of vehicles. It elucidates the steps involved in the AI-powered development life cycle in vehicles, addressing ethical considerations and bias in AI-driven software development for autonomous vehicles. The study presents statistical insights into the usage and types of AI/learning algorithms over the years, showcasing the evolving research landscape within the automotive industry. Furthermore, the paper highlights the pivotal role of parameters in refining algorithms for both trucks and cars, facilitating vehicles to adapt, learn, and improve performance over time. It concludes by outlining different levels of autonomy, elucidating the nuanced usage of AI and learning algorithms, and automating key tasks at each level. Additionally, the document discusses the variation in software package sizes across different autonomy levels', 'Artificial intelligence (AI) service failures are inevitable in hospitality companies; thus, how AI service recovery retains customers is an issue that cannot be ignored. This article focuses on AI service recovery, abandoning the traditional “intelligence quotient” thinking and exploring the recovery effect of empathy response from the perspective of emotional intelligence. Using four experimental scenarios, the results indicate that, in service recovery, a high-empathy AI response can increase customers’ continuous usage intention, and psychological distance and trust are sequential mediators in this process. Compared with mono-sensory stimulus interactions (text only), a high-empathy response that adopts multisensory stimulus interactions (text and voice) could strengthen the recovery effect of empathy responses. This paper extends the field of AI service research from a focus on time and phase to the continuing use of AI after service failure. It also moves beyond the traditional intelligence quotient improvement thinking and reveals the importance of using AI emotional intelligence to activate customer emotional response in AI service recovery. Finally, it provides a useful tool for resolving AI service failure problems autonomously in the service process, which is of great value to research and development and hospitality operators in the promotion and application of AI services.', \"Charitable organizations are experiencing a global labor shortage. Artificial intelligence (AI) chatbots have been employed to help combat the shortage, however, the scope and limits of AI fundraisers are still unclear, calling for further investigation. To improve our understanding of AI fundraisers, this study recruited 654 adults from an online crowdsourcing platform and developed six chatbot agents (emotional vs. factual × no image vs. machinelike image vs. human image). First, we employed an independent samples t-test to examine the effect of chatbots' conversational style on willingness to donate to Ukraine war victims. This study also tested the mediating roles (independent and serial) of perceived humanness and empathy toward victims in the relationship between chatbots' emotional expression and willingness to donate by conducting a serial multiple mediation analysis. Finally, this study tested the moderating role of visual cues (no image vs. machinelike image vs. human image) by conducting a moderated serial multiple mediation analysis. The results revealed that emotional chatbots yield a higher willingness to donate, and perceived humanness and empathy toward victims mediate this relationship independently and serially. However, the results suggest that visual cues did not significantly moderate the relationship between chatbot agents' emotional expression on willingness to donate.\", \"Implementing empathy to healthcare chatbots is considered promising to create a sense of human warmth. However, existing research frequently overlooks the multidimensionality of empathy, leading to an insufficient understanding if artificial empathy is perceived similarly to interpersonal empathy. This paper argues that implementing experiential expressions of empathy may have unintended negative consequences as they might feel inauthentic. Instead, providing instrumental support could be more suitable for modeling artificial empathy as it aligns better with computer-like schemas towards chatbots. Two experimental studies using healthcare chatbots examine the effect of empathetic (feeling with), sympathetic (feeling for), and behavioral-empathetic (empathetic helping) vs. non-empathetic responses on perceived warmth, perceived authenticity, and their consequences on trust and using intentions. Results reveal that any kind of empathy (vs. no empathy) enhances perceived warmth resulting in higher trust and using intentions. As hypothesized, empathetic, and sympathetic responses reduce the chatbot's perceived authenticity suppressing this positive effect in both studies. A third study does not replicate this backfiring effect in human-human interactions. This research thus highlights that empathy does not equally apply to human-bot interactions. It further introduces the concept of ‘perceived authenticity’ and demonstrates that distinctively human attributes might backfire by feeling inauthentic in interactions with chatbots.\", 'Interactive software agents, such as chatbots, are progressively being used in the area of health and well-being. In such applications, where agents engage with users in interpersonal conversations for, e.g., coaching, comfort or behavior-change interventions, there is an increased need for understanding agents’ empathic capabilities. In the current state-of-the-art, there are no tools to do that. In order to understand empathic capabilities in interactive software agents, we need a precise notion of empathy. The literature discusses a variety of definitions of empathy, but there is no consensus of a formal definition. Based on a systematic literature review and a qualitative analysis of recent approaches to empathy in interactive agents for health and well-being, a formal definition—an ontology—of empathy is developed. We present the potential of the formal definition in a controlled user-study by applying it as a tool for assessing empathy in two state-of-the-art health and well-being chatbots; Replika and Wysa. Our findings suggest that our definition captures necessary conditions for assessing empathy in interactive agents, and how it can uncover and explain trends in changing perceptions of empathy over time. The definition, implemented in Web Ontology Language (OWL), may serve as an automated tool, enabling systems to recognize empathy in interactions—be it an interactive agent evaluating its own empathic performance or an intelligent system assessing the empathic capability of its interlocutors.', 'In the evolving landscape of human-computer interaction, this paper introduces an innovative framework poised to revolutionize chatbot systems. Our framework, meticulously designed for emotionally aware multimodal chatbots, seamlessly integrates real-time face and emotion recognition with natural language processing. Currently in the developmental phase, the framework exhibits a distinctive proficiency in executing a diverse array of human instructions. These instructions span tasks such as generating detailed captions, object counting, and responding to general queries. Leveraging parameter-efficient fine-tuning from OpenFlamingo, augmented by the inclusion of the Low-rank Adapter (LoRA), our framework strategically prioritizes versatility and operational efficiency. The core of our approach lies in the establishment of instruction templates that intricately merge both vision and language data. This strategic integration forms the backbone of our multi-modality instruction tuning methodology, enhancing the adaptability of the chatbot. Recognizing the pivotal role of high-quality training data, we emphasize its significance in shaping the dialogue performance of the chatbot. As the framework progresses through its developmental stages, this research lays a robust foundation for the creation of a versatile conversational agent. The envisioned applications of this agent range from enhancing customer service experiences to providing valuable support in mental health scenarios.', 'Background:\\nThere is a dearth of feasibility assessments regarding using large language models (LLMs) for responding to inquiries from autistic patients within a Chinese-language context. Despite Chinese being one of the most widely spoken languages globally, the predominant research focus on applying these models in the medical field has been on English-speaking populations.\\n\\nObjective:\\nThis study aims to assess the effectiveness of LLM chatbots, specifically ChatGPT-4 (OpenAI) and ERNIE Bot (version 2.2.3; Baidu, Inc), one of the most advanced LLMs in China, in addressing inquiries from autistic individuals in a Chinese setting.\\n\\nMethods:\\nFor this study, we gathered data from DXY—a widely acknowledged, web-based, medical consultation platform in China with a user base of over 100 million individuals. A total of 100 patient consultation samples were rigorously selected from January 2018 to August 2023, amounting to 239 questions extracted from publicly available autism-related documents on the platform. To maintain objectivity, both the original questions and responses were anonymized and randomized. An evaluation team of 3 chief physicians assessed the responses across 4 dimensions: relevance, accuracy, usefulness, and empathy. The team completed 717 evaluations. The team initially identified the best response and then used a Likert scale with 5 response categories to gauge the responses, each representing a distinct level of quality. Finally, we compared the responses collected from different sources.', 'In this first of the series on Artificial Intelligence in Cancer Clinical Research, it is important to attempt to define the concept of intelligence and the important features we associate with human intelligence. Intelligence is a construct that we associate most notably with human beings and our understanding of human intelligence including perception, cognition, thought, conceptualization, pattern recognition, symbolic processing, creativity, and problem solving. While we acknowledge apparent elements of intelligence in other living species, we most commonly think of intelligence as a manifestation of our conscious awareness and ability to form concepts along with our capacity for symbolic processing, the development of language and ultimately our ability to reason, make decisions and use judgement as we navigate our world (Citation1–4). At the same time, while consciousness and self-awareness seem fundamental and unique to the human experience, these concepts remain profound and elusive mysteries. How can the complex array of atoms and molecules that ultimately behave the physical laws of motion, along with the intricate network of neurons in the central nervous system, give rise to our internal conscious experience and ability to think and reason along with experiences such as joy, sadness, love and beauty? While conceptual processes may be amenable to machine learning (ML), the human intellect is capable of generating new, abstract concepts that further organize his or her environment and, importantly, discover abstract ideas. Such processes provide new insights beyond the actual world and, in a sense, create his or her own world of meaningful symbolic systems with an active curiosity striving for meaning and true understanding of the world around us (Citation2). While a sign represents a characteristic of the external world amenable to algorithmic analysis and mimicking, a symbol evokes an abstract internal response separate from a particular concrete event (Citation2). Human symbolic systems are not only used for communication of cognitive information enabling language but the communication of emotional information. In fact, many of humanity’s most important and highest qualities relate to the development and creative use of symbolic systems resulting in the development of culture, myth, idealism and empathy. While a sign can be thought of as a context free characteristic of an object or situation, a symbol refers to experiences within ourselves. These experiences gain meaning within a context of emotions and interests resulting from the intersection of our prior experience and memory and the present situation to generate feelings or emotions within ourselves as we participate as active contributors to the creation of our world (Citation1).\\n', 'Human-AI interaction has become an important focus in the development of more responsive and humane technology. In this context, the use of artificial empathy strategies is of particular interest due to its potential in improving customer experiences affectively and socially. This research aims to explore the optimization of human-AI interactions through the application of artificial empathy strategies in improving affective and social customer experiences. The research approach used is qualitative by reviewing various studies and related literature. The data sources used are journals, articles and books that are relevant to the research topic. From the research results, it was found that the implementation of artificial empathy strategies in human-AI interactions has great potential to improve the quality of interactions and customer experiences. The use of technologies such as natural language processing, emotion recognition, and sentiment analysis can enable AI to respond more precisely and sensitively to user needs and emotions.', 'From ELIZA to Alexa, Conversational Agents (CAs) have been deliberately designed to elicit or project empathy. Although empathy can\\nhelp technology better serve human needs, it can also be deceptive\\nand potentially exploitative. In this work, we characterize empathy\\nin interactions with CAs, highlighting the importance of distinguishing evocations of empathy between two humans from ones\\nbetween a human and a CA. To this end, we systematically prompt\\nCAs backed by large language models (LLMs) to display empathy\\nwhile conversing with, or about, 65 distinct human identities, and\\nalso compare how different LLMs display or model empathy. We\\nfind that CAs make value judgments about certain identities, and\\ncan be encouraging of identities related to harmful ideologies (e.g.,\\nNazism and xenophobia). Moreover, a computational approach to\\nunderstanding empathy reveals that despite their ability to display\\nempathy, CAs do poorly when interpreting and exploring a user’s\\nexperience, contrasting with their human counterparts.', \"Empathy computing is an emerging research field that integrates artificial intelligence (AI) and big data technology to predict, identify, simulate, and generate human empathy. This field builds upon psychological studies in terms of concepts, measurements, neural foundations, and applications of empathy, and employs innovative computing approaches for analyzing and simulating empathy. This article critically reviews current research on empathy computing and discusses its future directions from a psychological perspective, with the aim of facilitating foundational research and practical applications in this field.\\n\\nThe current research on empathy computing can be categorized into four themes based on different purposes and methods. On one hand, empathy computing primarily aims to analyze and comprehend empathy using computers. This endeavor can be further divided into two categories: (1) individual empathy assessment, which focuses on analyzing individual empathetic traits, and (2) empathetic content classification, which focuses on analyzing empathetic features in texts rather than individuals. On the other hand, research also focuses on simulating and expressing empathy through computing, which includes (3) the design of empathetic response systems and (4) the development of generative empathetic dialogue systems. The former provides users with a limited number of predefined rule-based responses and feedback to express empathy, while the latter utilizes AI to automatically generate a wide range of empathetic dialogues without relying on predefined rules. These four research streams are relatively independent yet complementary. Moreover, as research progresses, new directions will continue to emerge, such as improving the empathic capabilities of computers through brain-computer interface technology.\\n\\nAlthough research on empathy computing is still in its early stages, it has shown potential for innovative applications in scenarios such as mental health, education, business services, and public management. With the increasing prevalence of artificial intelligence, these fields, which involve substantial interpersonal interactions, are positioned to become the primary domains for human-computer interaction. As a result, they emerge as the key application scenarios for empathy computing. In the realm of mental health, empathy computing can assist in automatically evaluating and enhancing therapists' empathetic abilities. Additionally, it can provide personalized empathetic support and guidance through AI-driven chatbots. In the field of education, empathy computing can facilitate the learning process by employing empathetic AI tutors. Within the business sector, it enables organizations to deliver tailored customer experiences, thereby enhancing satisfaction and fostering loyalty through the generation of empathic dialogues. In public management, empathy computing can be used to generate empathetic discourse to counteract negative speech. Additionally, it facilitates policymakers to respond empathetically to citizens' needs and inquiries, thereby fostering trust between the government and the public. These four scenarios illustrate the vast potential applications of empathy computing. However, due to concerns related to safety and ethics, complete reliance on computers to perform empathetic tasks is currently not feasible. Instead, a collaboration between humans and computers is necessary.\\n\\nEmpathy computing represents a transformative frontier, not only providing methods to measure and analyze empathy automatically on a larger scale but also enriching the theoretical landscape of empathy research. It extends traditional studies on empathy in interpersonal relationships to explore its emerging manifestations in human-AI relationships. This expansion raises novel questions about the universality of empathy and its potential evolution in human-computer interaction. Empathy computing holds the promise of serving as a cornerstone for a unified theory of empathy that encompasses diverse relationship dynamics, ranging from human-human to human-machine interactions and beyond. It is beneficial for comprehensively understanding empathy and effectively promoting it in the context of an intelligent society.\\n\\nFuture research should focus on developing integrated theoretical models of empathy computing, establishing reliable psychological and behavioral datasets of empathy-related characteristics, and validating and refining empathy computing research through a human-centered approach. Psychologists play indispensable roles in leading, evaluating, and optimizing research and practice in this field. The collaboration of scholars in psychology and computer science is imperative to ensure that AI learns empathy effectively and ethically, thereby fostering people’s wellbeing in the forthcoming intelligent society.\", 'Artificial Intelligence (AI) techniques, e.g. expert system (ES), fuzzy logic (FL), artificial neural network (ANN), genetic algorithm (GA), particle swarm optimization (PSO) and biologically inspired (BI) have recently been applied widely in power electronics and motor drives.Each AI method has its own uniqueness and characteristics. Recently, researchers have developed a computational model of emotional learning in mammalian brain, namely brain emotional learning based intelligent controller (BELBIC). The results indicate the ability of BELBIC to control unknown non-linear dynamic systems. Therefore, the BELBIC can be easily adopted for niche mechatronics and industrial applications.\\n', 'Purpose of Review: Emotion artificial intelligence (AI) is technology for emotion detection and recognition. Emotion AI is expanding rapidly in commercial and government settings outside of medicine, and will increasingly become a routine part of daily life. The goal of this narrative review is to increase awareness both of the widespread use of emotion AI, and of the concerns with commercial use of emotion AI in relation to people with mental illness.\\nRecent Findings: This paper discusses emotion AI fundamentals, a general overview of commercial emotion AI outside of medicine, and examples of the use of emotion AI in employee hiring and workplace monitoring.\\nSummary: The successful re-integration of patients with mental illness into society must recognize the increasing commercial use of emotion AI. There are concerns that commercial use of emotion AI will increase stigma and discrimination, and have negative consequences in daily life for people with mental illness. Commercial emotion AI algorithm predictions about mental illness should not be treated as medical fact.', 'Brain-Computer Interaction (BCI) system intelligence has become more dependent on electroencephalogram (EEG)-based emotion recognition because of the numerous applications of emotion classification, such as recommender systems, cognitive load detection, etc. Emotion classification has drawn the recent buzz in Artificial Intelligence (AI)-powered research. In this article, we presented a systematic review of automated emotion recognition from EEG signals using AI. The review process is carried out based on Preferred Reporting Items for Systematic Reviews and Meta-Analyses(PRISMA). After that EEG databases, and EEG preprocessing methods are included in this study. Also included feature extraction and feature selection methods. In addition, the included studies were divided into two types: i)deep learning(DL)-based emotion identification systems and ii) machine learning(ML)-based emotion classification models. The examined systems are analyzed based on their features, classification methodologies, classifiers, types of classified emotions, accuracy, and the datasets they employed. There is also an interesting comparison, a look at feature research trends, and ideas for new areas to study.\\n\\n', \"Humans have certain social and emotional capabilities that help them to interact with other human beings, one such capability is to recognize the other human's emotions. This capability enhances human interactions to a great extent. As we move towards the age of increasing Human-Machine Interaction systems, we must strive to program our machines to achieve the so-called social and emotional capabilities algorithmically. A primary research frontier in emotion detection is recognizing it using facial images. Being able to recognize the emotions of a human being helps the machine adjust and tune itself to the human's needs and comfort. Emotion detection can be performed using various modalities such as video, audio, images, text, biometric information, etc. This study, explores the emerging trends in emotion recognition through facial images. Automated recognition of emotions of people has the potential to predict psychiatric illness or other latent mental health issues.\", \"Artificial intelligence chatbots have invaded the tourism industry owing to their low cost and high efficiency. However, the influence of emotional expressions of chatbots on service outcomes has not received much attention from researchers. Drawing upon expectancy violations theory, we explored how emotional expressions of chatbots affect customer satisfaction using three experiments in the context of tourist attraction recommendations. Chatbots' expressions of concern for customers can improve customer satisfaction by reducing expectancy violations. In particular, customer's goal orientation, the human-likeness of chatbot's avatars, and the relationship type between customers and chatbots can moderate the negative relationship between emotional expression and expectancy violation. These findings advance research on the emotional expressions of chatbots and provide critical insights for deploying chatbots in customer service in the tourism industry.\", 'This paper firstly researches English text emotion expression and information communication, classifies English text emotion expression and information communication according to the human emotion-value relationship, and summarizes the characteristics of English emotion expression and information communication. Secondly, using artificial intelligence technology, it is proposed to construct an analysis model for English text emotion and information communication using the BiLSTM neural network. To deal with the characteristics of English text quickly and efficiently, it is necessary to encode the emotional information of English text, and based on encoding, the BiLSTM neural network is applied to extract the emotional features of English text and solve the problem of the loss of emotional features through the loss function. Then, the crawler tool is used to obtain the dataset from the Chinese English module under the MOOC of Chinese universities, and the evaluation indexes are set according to the model’s performance, followed by the experimental analysis of the English text emotion expression and information conveyance. The results show that compared with the original CNN, LSTM, and T-LSTM, the BiLSTM-based neural network performs better in the task of text emotion expression and information conveyance, with the accuracy rate staying above 0.925, and the effect on the English dataset is a bit better than that on the Chinese dataset. This study aims to enhance English teaching and communication between Chinese and foreign cultures.', 'Automated dialogue systems are important applications of artificial intelligence, and traditional systems struggle to understand user emotions and provide empathetic feedback. This study integrates emotional intelligence technology into automated dialogue systems and creates a dialogue generation model with emotional intelligence through deep learning and natural language processing techniques. The model can detect and understand a wide range of emotions and specific pain signals in real time, enabling the system to provide empathetic interaction. By integrating the results of the study \"Can artificial intelligence detect pain and express pain empathy?\", the model\\'s ability to understand the subtle elements of pain empathy has been enhanced, setting higher standards for emotional intelligence dialogue systems. The project aims to provide theoretical understanding and practical suggestions to integrate advanced emotional intelligence capabilities into dialogue systems, thereby improving user experience and interaction quality.', 'Research suggests that emotionally responsive machines that can simulate empathy increase de acceptance of users towards them, as the feeling of affinity towards the machine reduces negative perceptual feedback. In order to endow a robot with emotional intelligence, it must be equipped with sensors capable of capturing users’ emotions (sense), appraisal captured emotions to regulate its internal state (compute), and finally perform tasks where actions are regulated by the computed “emotional” state (act). However, despite the impressive progress made in recent years in terms of artificial intelligence, speech recognition and synthesis, computer vision and many other disciplines directly and indirectly related to artificial emotional recognition and behavior, we are still far from being able to endow robots with the empathic capabilities of a human being. This article aims to give an overview of the implications of introducing emotional intelligence in robotic constructions by discussing recent advances in emotional intelligence in robotics.', 'Emotion recognition is the ability to precisely infer human emotions from numerous sources and modalities using questionnaires, physical signals, and physiological signals. Recently, emotion recognition has gained attention because of its diverse application areas, like affective computing, healthcare, human–robot interactions, and market research. This paper provides a comprehensive and systematic review of emotion recognition techniques of the current decade. The paper includes emotion recognition using physical and physiological signals. Physical signals involve speech and facial expression, while physiological signals include electroencephalogram, electrocardiogram, galvanic skin response, and eye tracking. The paper provides an introduction to various emotion models, stimuli used for emotion elicitation, and the background of existing automated emotion recognition systems. This paper covers comprehensive searching and scanning of well-known datasets followed by design criteria for review. After a thorough analysis and discussion, we selected 142 journal articles using PRISMA guidelines. The review provides a detailed analysis of existing studies and available datasets of emotion recognition. Our review analysis also presented potential challenges in the existing literature and directions for future research.', 'The subject of this paper is the application of artificial intelligence for detecting emotions in neuromarketing. The goal is to enable the identification of user emotions through a webcam, using convolutional neural networks. The first part of the paper describes the neural networks, the basic types, and their differences. The greatest attention has been given to the description and application of convolutional neural networks. A Convolutional Neural Network, also known as CNN, is specialized in processing data that has a grid-like topology, such as an image. User emotion recognition is enabled using the face-api.js library. It implements the following models: SSD Mobilenet V1, Tiny Face Detector and MTCNN. Tiny Face Detector, used in the application, is a model for real-time face detection with small size, speed, and moderate resource consumption. The model is compatible with the web and mobile platforms. In the second part of the paper, an application was developed, which uses the face-api.js library to detect emotions. It has been developed as a tool to support neuromarketing research. It allows the marketer to create research to analyze advertising material. Its basic functionality is to display advertising content and collect data while watching. Data is stored and graphically displayed to the marketer. This section describes in detail how the detection process works. In the third part of the paper, evaluation was made. Evaluation of the developed solution was performed by experiment. The results show that the emotions of the user can be recognized by the developed system, with a satisfactory level of precision. The advertising content has previously entered parameters, which represent the desired results. By comparing these parameters and the obtained results, the marketer decides whether the advertisement is successful.', 'At a time when artificial intelligence is widely used in all walks of life, the way users interact with the digital world also needs to incorporate intelligent elements to reduce the cost of connectivity. This cost can be quantified through \"experience metrics\", which reveal the problems users encounter when using the interface (UI), and make targeted optimization. With AI, deep learning and prediction of user behavior can be achieved to anticipate and address potential barriers to use in UI design. This will not only improve the user experience, but also promote the development of UI design in a more user-friendly and intelligent direction. Through accurate analysis of experience indicators and combined with AI technology to optimize design, the gap between users and the digital world can be greatly reduced, making digital products more suitable for user needs and achieving seamless interactive experience.', 'Nowadays, interdisciplinary fields between Artificial Life, artificial intelligence, computational biology, and synthetic biology are increasingly emerging into public view. It is necessary to reconsider the relations between the material body, identity, the natural world, and the concept of life. Art is known to pave the way to exploring and conveying new possibilities. This survey provides a literature review on recent works of Artificial Life in visual art during the past 40 years, specifically in the computational and software domain. Having proposed a set of criteria and a taxonomy, we briefly analyze representative artworks of different categories. We aim to provide a systematic overview of how artists are understanding nature and creating new life with modern technology.\\n', 'We survey the general trajectory of artificial intelligence (AI) over the last century, in the context of influences from Artificial Life. With a broad brush, we can divide technical approaches to solving AI problems into two camps: GOFAIstic (or computationally inspired) or cybernetic (or ALife inspired). The latter approach has enabled advances in deep learning and the astonishing AI advances we see today—bringing immense benefits but also societal risks. There is a similar divide, regrettably unrecognized, over the very way that such AI problems have been framed. To date, this has been overwhelmingly GOFAIstic, meaning that tools for humans to use have been developed; they have no agency or motivations of their own. We explore the implications of this for concerns about existential risk for humans of the “robots taking over.” The risks may be blamed exclusively on human users—the robots could not care less.\\n', 'Artificial Intelligence (AI) is having a revolutionary impact on our societies. It is helping humans in facing the global challenges of this century. Traditionally, AI is developed in software or through neuromorphic engineering in hardware. More recently, a brand-new strategy has been proposed. It is the so-called Chemical AI (CAI), which exploits molecular, supramolecular, and systems chemistry in wetware to mimic human intelligence. In this work, two promising approaches for boosting CAI are described. One regards designing and implementing neural surrogates that can communicate through optical or chemical signals and give rise to networks for computational purposes and to develop micro/nanorobotics. The other approach concerns “bottom-up synthetic cells” that can be exploited for applications in various scenarios, including future nano-medicine. Both topics are presented at a basic level, mainly to inform the broader audience of non-specialists, and so favour the rise of interest in these frontier subjects.', 'Recent innovations in Human-Centric Functional Modeling (HCFM) seek to represent natural phenomena in terms of graphs called “functional state spaces” or FSS that consist of discrete states of functionality separated by the interactions through which regions of matter and/or antimatter transition from one state of functionality to another. These approaches are called “human-centric” because it is hypothesized that the human organism is constrained by the laws of thermodynamics to perceive the observable world in terms of FSS, where in each FSS all processes consist of a minimally reducible set of reversible operations or functions. These hypothetical FSS are networks. In simulating physical processes, or processes in any other domain in which the abstract functionality of systems can be represented in terms of FSS, it is hypothesized that network effects create the potential to significantly or even exponentially increase the general problem-solving ability of human groups. The goal of this monograph is to encourage exploration of how components of these theories might align with emerging or established scientific concepts. ', 'One of the elements sure to characterise the future of education is artificial intelligence used as a tool to improve teaching and learning processes as well as the work of teachers and administrators. Artificial intelligence and robotics pose a range of social, pedagogical, practical, ethical and also social justice issues and challenges in dealing with changes in educational processes. After reviewing discussions about and examples of artificial intelligence use in education, particularly primary school contexts, I will focus on the real implications of this key educational challenge. Obviously, with the advent of these technological transformations, there is the risk of generating or reinforcing inequalities between social groups if equal access is not guaranteed. I will focus on the possibility of personalising learning pathways by describing primary school initiatives aimed at fostering effective and collaborative communication skills in order to recognise and identify, but also prevent, the factors impacting learning disorders. Lastly, using an analogy with the development of classical literacy (reading/writing), I will discuss the need to propose artificial intelligence and robotics literacy courses for teachers so that these technologies can be used more widely among different age groups and grades.\\n\\n\\n\\n', 'While on the one hand the development of artificial intelligence is having an increasingly important impact not only on the economic system, but also on people’s lives, opening up new scenarios, imposing new constraints, and giving rise to new opportunities, at the same time it is emerging as a further potential threat to humanity. We need to abandon an approach based on an optimistic prejudice towards artificial intelligence, which is often presented as a panacea for all evils, with thaumaturgic properties that can be extended to all problems and situations. Artificial intelligence is a tool that must be used with care and caution, also taking into account the possible risks involved, risks that will become all the greater the more powerful the calculation tools are. This is why the issue of ‘Machine Ethics’ is being forcefully raised at the scientific level.\\n\\n\\n', 'This article discusses the potential dangers of artificial intelligence (AI) and argues that it must be stopped. While AI offers many benefits, such as improving energy solutions and accessibility to information, the negative consequences outweigh the short-term advantages. The author highlights missed opportunities in the past to prevent the negative impacts of technologies like automobiles and toxic chemicals. The article explores various risks associated with AI, including extreme genetic engineering, threats to the financial system, lethal autonomous weapons, economic inequality, environmental impact, and the erosion of human relationships. The author calls for a total ban on AI and suggests that it could prompt a reevaluation of neoliberal capitalism and the need to address other existential threats.\\n\\n', 'Evolutionary computation is a sub-field of artificial intelligence and artificial life that uses biologically inspired methods to solve optimization problems, using iterative refinements of a set of solutions via change and selection. This approach, which began in the 1950s, constitutes a growing set of algorithms capable of solving a wide range of problems, divided into various types that differ in selection, mutation, and representation of candidate solutions. Its successful applications are counted in multiple domains, including, but not limited to, optimization, machine learning, robotics, and various areas that study living systems. Evolutionary computation has recently seen a revival, particularly in the study of open-ended evolution, with important implications for the future of AI. It has a unique potential to generate endless innovations and lead to a paradigm shift in the development of artificial intelligence and artificial intelligence life.\\n\\n', 'The purpose of the study is to study the possibilities of multigenerational optimization of behavior control systems for agents of general artificial intelligence capable of independently solving a universal range of tasks in a real environment. The main principles of ontophylogenetic synthesis of control systems for agents of general artificial intelligence based on multi-agent neurocognitive architectures have been developed. Methods and algorithms for synthesizing the phenotypes of control systems of intelligent agents according to their genotypes are proposed. A software package for simulating the processes of ontophylogenetic synthesis of multi-agent neurocognitive architectures has been developed and experiments have been carried out to create phenotypes of intelligent agents based on them. A complex genome of an intelligent agent has been developed, the features of a multichromosome genetic algorithm for organizing calculations in the paradigm of multigenerational optimization of multiagent neurocognitive architectures have been established and substantiated. It is shown that multigenerational optimization of the multi-agent neurocognitive architecture of intelligent agents can contribute to the achievement of adaptive resistance to the operating conditions of a general artificial intelligence agent, provide the synthesis of its suboptimal structural and functional scheme, accelerate learning and algorithms for finding solutions to a universal range of problems solved by this agent in its ecological niche.\\n\\n\\n', \"\\ufeffThis article explores the fusion of Fuzzy Logic (FL) and Group Theory within the realm of Artificial Intelligence (AI), uncovering a transformative synergy that promises to enhance the adaptability and robustness of intelligent systems.\\nBeginning with an individual examination of Fuzzy Logic and Group Theory, the paper establishes the theoretical foundations for their integration. Fuzzy Logic's capacity to handle uncertainty harmonizes with Group Theory's prowess in revealing structural insights, leading to a unified framework. The integration is validated through a series of compelling case studies and experiments across diverse domains, ranging from adaptive robotics control to\\nhealthcare decision support. These practical applications showcase the collective impact of FL and Group Theory, demonstrating improved adaptability, precision, and resilience in complex scenarios. The results not only reaffirm the theoretical foundations but also provide tangible evidence of the integrated approach's potential. Looking toward the future, the paper outlines key directions for further research, including the refinement of theoretical foundations, integration with machine learning, and addressing challenges of scalability and explainability. Ethical considerations, cross-disciplinary collaboration, and continuous validation are emphasized as crucial elements in shaping the trajectory of this interdisciplinary exploration\", '\\ufeffIn this study, we explored the dynamic field of fuzzy logic and artificial intelligence (AI) in financial analysis from 1990 to 2023. Utilizing the bibliometrix package in RStudio and data from the Web of Science, we focused on identifying mathematical models and the evolving role of fuzzy information granulation in this domain. The research addresses the urgent need to understand the development and impact of fuzzy logic and AI within the broader scope of evolving technological and analytical methodologies, particularly concentrating on their application in financial and banking contexts. The bibliometric analysis involved an extensive review of the literature published during this period. We examined key metrics such as the annual growth rate, international collaboration, and average citations per document, which highlighted the field’s expansion and collaborative nature. The results revealed a significant annual growth rate of 19.54%, international collaboration of 21.16%, and an average citation per document of 25.52. Major journals such as IEEE Transactions on Fuzzy Systems, Fuzzy Sets and Systems, the Journal of Intelligent & Fuzzy Systems, and Information Sciences emerged as significant contributors, aligning with Bradford’s Law’s Zone 1. Notably, post-2020, IEEE Transactions on Fuzzy Systems showed a substantial increase in publications. A significant finding was the high citation rate of seminal research on fuzzy information granulation, emphasizing its mathematical importance and practical relevance in financial analysis. Keywords like “design”, “model”, “algorithm”, “optimization”, “stabilization”, and terms such as “fuzzy logic controller”, “adaptive fuzzy controller”, and “fuzzy logic approach” were prevalent. The Countries’ Collaboration World Map indicated a strong pattern of global interconnections, suggesting a robust framework of international collaboration. Our study highlights the escalating influence of fuzzy logic and AI in financial analysis, marked by a growth in research outputs and global collaborations. It underscores the crucial role of fuzzy information granulation as a mathematical model and sets the stage for further investigation into how fuzzy logic and AI-driven models are transforming financial and banking analysis practices worldwide.', '\\ufeffThis paper presents a method for providing explainability in the integration of artificial intelligence (AI) and data mining techniques when dealing with meteorological prediction. Explainable artificial intelligence (XAI) refers to the transparency of AI systems in providing explanations for their predictions and decision-making processes, and contribute to improve prediction accuracy and enhance trust in AI systems. The focus of this paper relies on the interpretability challenges in ordinal classification problems within weather forecasting. Ordinal classification involves predicting weather phenomena with ordered classes, such as temperature ranges, wind speed, precipitation levels, and others. To address this challenge, a novel and general explicable forecasting framework, that combines inductive rules and fuzzy logic, is proposed in this work. Inductive rules, derived from historical weather data, provide a logical and interpretable basis for forecasting; while fuzzy logic handles the uncertainty and imprecision in the weather data. The system predicts a set of probabilities that the incoming sample belongs to each considered class. Moreover, it allows the expert decision-making process to be strengthened by relying on the transparency and physical explainability of the model, and not only on the output of a black-box algorithm. The proposed framework is evaluated using two real-world weather databases related to wind speed and low-visibility events due to fog. The results are compared to both ML classifiers and specific methods for ordinal classification problems, achieving very competitive results in terms of ordinal performance metrics while offering a higher level of explainability and transparency compared to existing approaches.', '\\ufeffInterpretable artificial intelligence (AI), also known as explainable AI, is indispensable in establishing trustable AI for bench-to-bedside translation, with substantial implications for human well-being. However, the majority of existing research in this area has centered on designing complex and sophisticated methods, regardless of their interpretability. Consequently, the main prerequisite for implementing trustworthy AI in medical domains has not been met. Scientists have developed various explanation methods for interpretable AI. Among these methods, fuzzy rules embedded in a fuzzy inference system (FIS) have emerged as a novel and powerful tool to bridge the communication gap between humans and advanced AI machines. However, there have been few reviews of the use of FISs in medical diagnosis. In addition, the application of fuzzy rules to different kinds of multimodal medical data has received insufficient attention, despite the potential use of fuzzy rules in designing appropriate methodologies for available datasets. This review provides a fundamental understanding of interpretability and fuzzy rules, conducts comparative analyses of the use of fuzzy rules and other explanation methods in handling three major types of multimodal data (i.e., sequence signals, medical images, and tabular data), and offers insights into appropriate fuzzy rule application scenarios and recommendations for future research.', '\\ufeffDue to advancement and complexity of modern automobiles, fault detection has gone beyond manual or trial by error methods. The fault detection technologies in automotive industry is used to identify any potential or already existing fault in automobiles. Faults in automobiles are usually mechanical or electrical faults that may include airbag control unit, radiator, gearbox, transmission control unit, tyre pressure, brakes, air conditioner, cylinder casket, alternator, hubs malfunctions etc. Each fault has a specific or related sign and symptoms. There are several methods of fault detections in automobiles like the binary logic technique, the fuzzy logic method technique and artificial intelligence technique with different algorithms.  In this research work, we employed a fuzzy logic based technique that uses a Mamdani Algorithm which presented a better fault detection mechanism. Mamdani’s algorithm was proposed by Ebrahim Mamdani as a fuzzy inference method which has a rule-bases that are more intuitive and easier to analyse and implement.  Mamdani’s algorithm produces fuzzy sets that originate from fuzzy inference system’s output membership function for decision making. This research work is a web-based technology that was implemented using JavaScript, JQuery and SQL server, ASP.Net, Bootstrap 3.5 and CSS. The output of the system showed a greater improvement from other existing methods of fault detections in automobiles.', '\\ufeffA wireless sensor network (WSN) is a distributed collection of tiny, low-power, wireless devices which are deployed in a physical environment to monitor the various environmental conditions. The data collected by the positioned sensor nodes is transmitted through the destination nodes by using multi hop communications. WSNs offer numerous advantages over the othernetworks, including enhanced flexibility, low cost, and simplified deployment. Due to the resource- constraint nature of WSN, it faces various challenges and issues that need to be addressed in order to ensure reliable and secure data transmission. The nodes of WSN are highly vulnerable to various types of security attacks namely black hole attack, Denial of Service (DoS), and node compromise attack. Among these attacks, black hole attack causes a serious threat to the nodes in the network. This attack is carried out by malicious nodes that intentionally drop all data packets and control packets without forwarding them to the intended destination. To ensure the security of the network for black hole attack, it is necessary to design an efficient Intrusion Detection Technique for detecting malicious nodes. In this work, a novel Fuzzy Logic-based Intrusion Detection System with Hidden Markov Model (FIDS-HMM) is proposed to identify the malicious nodes and mitigate the black hole attack. Moreover, an HMM is employed in the proposed protocol to monitor the energy levels of the nodes in order to detect the malicious nodes effectively. The implementation of the proposed protocol is carried out by using NS2 simulator. Simulation results justify the proposed protocol namely FIDS-HMM provides an efficient detection mechanism for black hole attacks in the network. Moreover, the proposed protocol improves the Quality of Service (QoS) parameters, namely packet delivery ratio, delay, and throughput in the network with efficiency.', '\\ufeffIn this article we present a model of adjustable moisture control for historical buildings. Proposed system is developed in a form of flexible IoT infrastructure in which a complex system of sensors is set to measure inside conditions of humidity and compare result to levels of groundwaters, rain and wind speed to manage drying system. Developed control model is using type-2 fuzzy logic reasoning to flexibly adjust decisions to the intensity of water absorption. In this way proposed model makes an innovative intelligent system for control of interior conditions in historical buildings. Developed system was installed and examined in an old brewery building. Research results show efficiency in dehumidification at lowest cost.', '\\ufeffSemantic features play a pivotal role in natural language processing, providing a deeper understanding of the meaning and context within textual data. In the realm of machine learning and artificial intelligence, semantic feature extraction involves translating linguistic elements into numerical representations, often utilizing advanced techniques like word embeddings and deep learning models. The integration of semantic features enhances the precision and context-awareness of language models, enabling applications such as sentiment analysis, document categorization, and information retrieval to operate with greater accuracy and relevance. The paper introduces a novel approach, Hierarchical Mandhami Optimized Semantic Feature Extraction (HMOSFE), designed to enhance semantic feature extraction from English sentences. The proposed HMOSFE model comprises fusion of hierarchical clustering and fuzzy-based feature extraction, HMOSFE aims to capture intricate semantic relationships within sentences, providing nuanced insights into the underlying meaning of textual content. The model employs pre-trained word embeddings for term representation, calculates a similarity matrix using cosine similarity, and utilizes hierarchical clustering for document grouping. Fuzzy logic contributes to assigning weights to features, enabling a more refined understanding of semantic significance. The paper presents comprehensive results, including semantic similarity estimations, clustering distances, and fuzzy memberships, demonstrating the effectiveness of HMOSFE across diverse documents.', '\\ufeffAn intelligent lighting system is a public lighting system that uses artificial intelligence technology to optimize energy management and improve the quality of lighting in public areas. This paper presents the use of two prominent artificial intelligence methods, namely fuzzy logic and neural networks, for intelligent power control in public lighting networks. The primary objective of this study was to evaluate performance of these approaches in optimizing power consumption and achieving efficient lighting, taking into consideration two parameters, namely road flow and weather conditions. To achieve this, the lighting system was modeled using the state flow tool in MATLAB/Simulink. Various algorithms based on fuzzy logic and artificial neural networks were subsequently developed. Real data on traffic flow and cloud cover were utilized to train these algorithms. Upon analysis of the simulation results, it was observed that, overall, results closer to the algorithm based on fuzzy logic were yielded by algorithms based on neural networks.', '\\ufeffIn the 21st century, global waste challenges worsen in developing nations relying on manual sorting. This improper waste disposal poses significant threats to human health and the environment, necessitating the adoption of Artificial Intelligence-Based Solid Waste Segregation Technology (AIBSWST). In this context, the advanced Frank t-norm captures nuanced relationships in fuzzy logic, crucial in scenarios where fuzzy set order matters. Building on these principles, the complex q-rung picture fuzzy set (Cq-RPFS) becomes instrumental in representing decision-makers preferences in a two-dimensional manner, enhancing the handling of vague information in real-world scenarios. Expanding on these foundational principles, the paper introduces innovative Frank operations grounded in Frank t-norms within the context of Cq-RPFS. Leveraging these operations, the paper proposes four robust aggregation operators (AOs) under Cq-RPFS: complex q-rung picture fuzzy Frank weighted average (Cq-PFFWA), complex q-rung picture fuzzy Frank weighted geometric (Cq-PFFWG), complex q-rung picture fuzzy Frank ordered weighted average (Cq-PFFWOA), and complex q-rung picture fuzzy Frank ordered weighted geometric (Cq-PFFWOG). These AOs exhibit essential properties such as idempotency, monotonicity, and boundedness. A Multi-Criteria Decision-Making (MCDM) method based on the proposed AOs is suggested to validate these strategies. A real-life case study on India’s adoption of AIBSWST serves as a practical application, with thorough analyses, including sensitivity, comparative, and superiority assessments, evaluating the performance of the approaches. A thoughtful discussion of the pros and cons of the proposed AOs accompanies the analysis, emphasizing the significance of the approach in ensuring the cleanliness and health of developing nations.', 'Easy internet access and technological advancements have resulted in information overload and a plethora of options, making decision-making extremely difficult. Recommender System (RS) is a potential solution for assisting users in making decisions by recommending or predicting product ratings. Three fundamental forms of RS that use implicit or explicit feedback for recommendation are collaborative, content-based, and hybrid filtering. Ratings are the most common form of feedback, but product descriptions, reviews, images, audios, and videos are also important and can help improve the performance of the traditional RS. These additional variables can have a significant impact on RS’s performance. Traditional RSs used approaches based on the nearest neighbor or other machine learning models, but thanks to recent advances in artificial intelligence and deep learning, RSs are now being developed using Convolutional Neural Networks (CNN), which can efficiently exploit auxiliary information. In addition to comparing CNN-based RSs on common grounds, this article provides a full examination of CNN-based RSs and how they might use various types of auxiliary information. The study also discusses data characteristics, data statistics, and auxiliary information in a variety of publicly available datasets. Different evaluation measures for RSs are also discussed, and readers are provided with interesting challenges and open research issues.\\n', \"In recent years, with the continuous progress and development of science and technology, especially the continuous development of artificial intelligence, machine algorithm and other technologies, the education system has also begun to carry out more personalized content from traditional functions. Traditional education systems often adopt a one-size-fits-all approach to teaching that does not take into account the unique needs and learning styles of each student. An education system personalized and optimized by machine learning algorithms can provide customized learning materials and recommendations based on each student's learning history, interests and abilities to improve learning outcomes, and machine learning algorithms can provide real-time feedback on student performance and adjust learning plans based on feedback. This makes the learning process more dynamic and personalized. It can therefore be applied to all types of education, including language learning, mathematics, science, etc. However, improving the efficiency of machine learning algorithms depends more on the improvement of numerical optimization algorithms, so it is necessary to summarize the optimization algorithms in large-scale machine learning. This paper tries to make a detailed overview of the existing machine learning algorithms in optimizing personalized education recommendation system, and introduces the algorithm optimization process.\", 'This paper presents a comprehensive literature review of the research and application of machine learning (ML) algorithms in recommender systems (RS). The study aims to identify recent trends, explore real-life applications, and guide researchers in positioning their research activities in this domain published in 2023 (Jan-June). The findings are categorized into different domains including education, healthcare, ML algorithms (auto-encoders and reinforcement learning), e-commerce, and digital journalism. The review highlights the enhanced recommendation accuracy, increased scalability, personalization and context awareness, diverse ML techniques, and strategies for handling cold start and data sparsity, and the foundation for future advancements in ML algorithms for RSs considering the application in manufacturing enterprises.', 'Smart cities represent the convergence of information and communication technologies (ICT) with urban management to improve the quality of life of city dwellers. In this context, recommender systems, tools that offer personalised suggestions to city dwellers, have emerged as key contributors to this convergence. Their successful application in various areas of city life and their ability to process massive amounts of data generated in urban environments has expedited their status as a crucial technology in the evolution of city planning. Our methodology included reviewing the Web of Science database, resulting in 130 articles that, filtered for relevancy, were reduced to 86. The first stage consisted of carrying out a bibliometric analysis with the objective of analysing structural aspects with the SciMAT tool. Secondly, a systematic literature review was undertaken using the PRISMA 2020 statement. The results illustrated the different processes by which recommendations are filtered in areas such as tourism, health, mobility, and transport. This research is seen as a significant breakthrough that can drive the evolution and efficiency of smart cities, establishing a solid framework for future research in this dynamic field.\\n', 'Internet of Things (IoT) based remote healthcare applications provide fast and preventative medical services to the patients at risk. However, predicting heart disease is a complex task and diagnosis results are rarely accurate. To address this issue, a novel Recommendation System for Cardiovascular Disease Prediction Using IoT Network (DEEP-CARDIO) has been proposed for providing prior diagnosis, treatment, and dietary recommendations for cardiac diseases. Initially, the physiological data are collected from the patient’s remotely by using the four bio sensors such as ECG sensor, Pressure sensor, Pulse sensor and Glucose sensor. An Arduino controller receives the collected data from the IoT sensors to predict and diagnose the disease. A cardiovascular disease prediction model is implemented by using BiGRU (Bidirectional-Gated Recurrent Unit) attention model which diagnose the cardiovascular disease and classify into five available cardiovascular classes. The recommendation system provides physical and dietary recommendations to cardiac patients based on the classified data, via user mobile application. The performance of the DEEP-CARDIO is validated by Cloud Simulator (CloudSim) using the real-time Framingham’s and Statlog heart disease dataset. The proposed DEEP CARDIO method achieves an overall accuracy of 99.90% whereas, the MABC-SVM, HCBDA and MLbPM method achieves 86.91%, 88.65% and 93.63% respectively.', 'The latest effort in delivering computing resources as a service to managers and consumers represents a shift away from computing as a product that is purchased, to computing as a service that is delivered to users over the internet from large-scale data centers. However, with the advent of the cloud-based IoT and artificial intelligence (AI), which are advancing customer experience automations in many application areas, such as recommender systems (RS), a need has arisen for various modifications to support the IoT devices that are at the center of the automation world, including recent language models like ChatGPT and Bard and technologies like nanotechnology. This paper introduces the marketing community to a recent computing development: IoT-driven fog computing (FC). Although numerous research studies have been published on FC “smart” applications, none hitherto have been conducted on fog-based smart marketing domains such as recommender systems. FC is considered a novel computational system, which can mitigate latency and improve bandwidth utilization for autonomous consumer behavior applications requiring real-time data-driven decision making. This paper provides a conceptual framework for studying the effects of fog computing on consumer behavior, with the goal of stimulating future research by using, as an example, the intersection of FC and RS. Indeed, our conceptualization of the “fog-based recommender systems” opens many novel and challenging avenues for academic research, some of which are highlighted in the later part of this paper.\\nKeywords: fog computing; recommender system; internet of things (IoT); edge computing; artificial intelligence (AI); software defined networks (SDNs)\\normation as well as personal and situational data [66].', \"Purpose: The general purpose of the study was to investigate the effectiveness of recommender systems in knowledge discovery.\\n\\nMethodology: The study adopted a desktop research methodology. Desk research refers to secondary data or that which can be collected without fieldwork. Desk research is basically involved in collecting data from existing resources hence it is often considered a low cost technique as compared to field research, as the main cost is involved in executive’s time, telephone charges and directories. Thus, the study relied on already published studies, reports and statistics. This secondary data was easily accessed through the online journals and library.\\n\\nFindings: The findings reveal that there exists a contextual and methodological gap relating to recommender systems in knowledge discovery. The study on the effectiveness of recommender systems in knowledge discovery found that such systems played a pivotal role in facilitating users' exploration of vast information repositories, enabling them to uncover relevant resources and expand their knowledge. It found that recommender systems employing advanced algorithms and personalized techniques demonstrated higher effectiveness in generating relevant recommendations tailored to users' preferences and needs. Additionally, the study highlighted the positive correlation between user engagement metrics and knowledge discovery outcomes, emphasizing the importance of fostering active user participation in the recommendation process. Contextual information was also identified as a crucial factor influencing recommendation effectiveness. Overall, the study underscored the significance of continuous refinement and optimization of recommender system algorithms to enhance knowledge discovery outcomes for users.\\n\\nUnique Contribution to Theory, Practice and Policy: The Social Learning theory, Information Foraging theory and Cognitive Load theory may be used to anchor future studies on recommender systems in knowledge discovery. The study provided recommendations to enhance the efficacy of such systems. It suggested adopting hybrid recommender systems that combine collaborative and content-based filtering techniques to offer more accurate and diverse recommendations. Additionally, the study emphasized the importance of integrating contextual information into recommendation algorithms to dynamically adjust recommendations based on situational context. Furthermore, it recommended the use of explainable AI techniques to improve transparency and user understanding of recommendation processes. Maximizing user engagement through active participation and feedback was also highlighted as crucial, along with prioritizing recommendation diversity to foster exploration and serendipitous discovery of new knowledge resources.\", 'The application of Artificial Intelligence (AI) is significantly increasing in many Human Resources (HR) functions. This research aims to understand how diverse experts from distinct organisations, such as Project Managers, Managers, Supervisors and Human Resource Managers, perceive the potential of artificial intelligence-based recommender systems to match job profiles with employee profiles. This study employs a Delphi study-based methodology specifically, organising an expert panel that provides their opinions through their ratings and comments of a set of propositions. Based on the online Delphi study results and participant opinions, this research aims to identify the challenges related to employee-job profile matching through artificial intelligence and machine learning tools in the form of recommender systems. In this study, we have delved into the various challenges of matching employee profiles to job profiles and the current problems faced by executives, human resource personnel or supervisors such as project managers in an organisation. The study also sheds light on the potential or feasibility solutions of artificial intelligence in the form of recommender systems where we also test a couple of propositions that focus on potential solutions and various challenges for matching employee profiles to job profiles in an organisation.\\n\\n', 'Facial Expression Recognition (FER) is utilized in various fields, such as education, gaming, robotics, healthcare, and others. Facial expression techniques, for instance, an interactive robot with Artificial Intelligence, recognize human faces, detect the emotions of the person it is conversing with, and then use these emotions to choose appropriate answers. One use case for face emotion detection is playing music based on the user’s mood. To do this, we can analyze the user’s facial expression to deduce their feelings. As a result, new emotion models require more investigation as existing one’s struggle to correctly measure music’s connection with facial emotion. In this paper, we implement this kind of job using Convolution Neural Network (CNN) based deep learning approach. Deep learning can more effectively analyze unstructured data, movies, and other forms of media than machine learning. In our research, we have created a real-time system that can recognize human faces, assess human emotions, and even recommend music to users. The OAHEGA and FER-2013 datasets were utilized for experimental study. We created and trained two emotion recognition models using various combinations of these datasets. The proposed model’s accuracy is 73.02%. Using our CNN model, we can predict six emotions: anger, fear, joy, neutral, sadness, and surprise. The proposed system can be utilized in different places where real-time facial recognition plays an important role.', 'Given the challenges of inter-domain information fusion and data sparsity in collaborative filtering algorithms, this paper proposes a cross-domain information fusion matrix decomposition algorithm to enhance the accuracy of personalized recommendations in artificial intelligence recommendation systems. The study begins by collecting Douban movie rating data and social network information. To ensure data integrity, Levenshtein distance detection is employed to remove duplicate scores, while natural language processing technology is utilized to extract keywords and topic information from social texts. Additionally, graph convolutional networks are utilized to convert user relationships into feature vectors, and a unique thermal coding method is used to convert discrete user and movie information into binary matrices. To prevent overfitting, the Ridge regularization method is introduced to gradually optimize potential feature vectors. Weighted average and feature connection techniques are then applied to integrate features from different fields. Moreover, the paper combines the item-based collaborative filtering algorithm with merged user characteristics to generate personalized recommendation lists.In the experimental stage, the paper conducts cross-domain information fusion optimization on four mainstream mathematical matrix decomposition algorithms: alternating least squares method, non-negative matrix decomposition, singular value decomposition, and latent factor model (LFM). It compares these algorithms with the non-fused approach. The results indicate a significant improvement in score accuracy, with mean absolute error and root mean squared error reduced by 12.8% and 13.2% respectively across the four algorithms. Additionally, when k\\u2009=\\u200910, the average F1 score reaches 0.97, and the ranking accuracy coverage of the LFM algorithm increases by 54.2%. Overall, the mathematical matrix decomposition algorithm combined with cross-domain information fusion demonstrates clear advantages in accuracy, prediction performance, recommendation diversity, and ranking quality, and improves the accuracy and diversity of the recommendation system. By effectively addressing collaborative filtering challenges through the integration of diverse techniques, it significantly surpasses traditional models in recommendation accuracy and variety.', 'The Metaverse, a virtual reality (VR) space where users can interact with each other and digital objects, is rapidly becoming a reality. As this new world evolves, Artificial Intelligence (AI) is playing an increasingly important role in shaping its development. Integrating AI with emerging technologies in the Metaverse creates new possibilities for immersive experiences that were previously impossible. This paper explores how AI is integrated with technologies such as the Internet of Things, blockchain, Natural Language Processing, virtual reality, Augmented Reality, Mixed Reality, and Extended Reality. One potential benefit of using AI in the Metaverse is the ability to create personalized experiences for individual users, based on their behavior and preferences. Another potential benefit of using AI in the Metaverse is the ability to automate repetitive tasks, freeing up time and resources for more complex and creative endeavors. However, there are also challenges associated with using AI in the Metaverse, such as ensuring user privacy and addressing issues of bias and discrimination. By examining the potential benefits and challenges of using AI in the Metaverse, including ethical considerations, we can better prepare for this exciting new era of VR. This paper presents a comprehensive survey of AI and its integration with other emerging technologies in the Metaverse, as the Metaverse continues to evolve and grow, it will be important for developers and researchers to stay up to date with the latest developments in AI and emerging technologies to fully leverage their potential.', 'The world of artificial intelligence has changed drastically in the past 10 years, with the rise of deep learning bringing significant gains in a myriad of industrial and creative sectors. But what benefit can it provide for the video games industry? Game AI has been an established field for over 30 years, catering to the unique problems of the field, be it strategic opponents, non-player characters, gameplay pacing and procedural content generation. This chapter highlights the core areas that classical, symbolic AI continues to thrive within and how machine learning is providing new alternatives to these established practices. Plus, the new opportunities that are emerging courtesy of AI that are changing how games are being made, including player modelling, graphical upscaling, animation controllers, and automated testing.', 'Artificial General Intelligence is the idea that someday an hypothetical agent will arise from artificial intelligence (AI) progresses, and will surpass by far the brightest and most gifted human minds. This idea has been around since the early development of AI. Since then, scenarios on how such AI may behave towards humans have been the subject of many fictional and research works. This paper analyzes the current state of artificial intelligence progresses, and how the current AI race with the ever faster release of impressive new AI methods (that can deceive humans, outperform them at tasks we thought impossible to tackle by AI a mere decade ago, and that disrupt the job market) have raised concerns that Artificial General Intelligence (AGI) might be coming faster that we thought. In particular, we focus on 3 specific families of modern AIs to develop the idea that deep neural networks, which are the current backbone of nearly all artificial intelligence methods, are poor candidates for any AGI to arise due to their many limitations, and therefore that any threat coming from the recent AI race does not lie in AGI but in the limitations, uses, and lack of regulations of our current models and algorithms.', \"orecasting winners in E-sports with real-time analytics has the potential to further engage audiences watching major tournament events. However, making such real-time predictions is challenging due to unpredictable variables within the game involving diverse player strategies and decision-making. Our work attempts to enhance audience engagement within video game tournaments by introducing a real-time method of predicting wins. Our Long Short Term Memory Network (LSTMs) based approach enables efficient predictions of win-lose outcomes by only using the health indicator of each player as a time series. As a proof of concept, we evaluate our model's performance within a classic, two-player arcade game, Super Street Fighter II Turbo. We also benchmark our method against state of the art methods for time series forecasting; i.e. Transformer models found in large language models (LLMs). Finally, we open-source our data set and code in hopes of furthering work in predictive analysis for arcade games.\", 'This project is inspired by turn-based strategy games, Final Fantasy Tactics, X-Com 2, and modern turn-based strategy games. This project is structured around the use of artificial intelligence for storytelling within strategy games. The focus of this project utilizes artificial intelligence in creating a quest generation system for storytelling. The resulting quest system creates new quests dynamically after communicating with an artificial intelligence allowing players to potentially experience an ever-expanding story from quests', 'The chapter discusses the potential of digital technology to promote peacebuilding through education while acknowledging the potential benefits and risks associated with its use. The authors propose an approach based on human-centered design (HCD) that prioritizes the needs and perspectives of learners. The chapter presents three case studies that demonstrate the potential of digital storytelling, artificial intelligence (AI), and gaming to support peacebuilding. The first case study explores the use of digital storytelling to teach about genocide, while the second focuses on the use of AI to protect victims of violence. The third case study discusses the use of gaming to raise awareness of war. The authors acknowledge that each technology represents a complex field of inquiry and offer exercises in imagination to explore the possibilities of liberatory design. The chapter concludes by highlighting the importance of understanding the ambivalent nature of technology and its potential for both conflict and peacebuilding.', \"Dynamic Virtual Reality (VR) has revolutionized gaming and entertainment industries by providing immersive experiences that take users to new locations. This study presents a novel and exciting idea called virtual reality horror sports, which combines aspects of horror with sports in the VR medium. We provide a novel approach to developing adaptive VR horror games by combining player modeling approaches with an adaptive means-based system that learn about each player's individual fears and adjust the game's content accordingly. This work presents two significant advances: a unique method for determining a player's specific fears via game data and machine learning methods and an adaptive game system that employs agents to monitor players' terror experiences and restrict exposure to components that they find upsetting. Additional evidence from user studies and statistical significance testing suggests that our method may boost the stress and anxiety felt by gamers, resulting in rewarding gaming experience. When VR, horror and sports are all brought together, the outcome may compel and absorbing entertainment experience. Players will be immersed in a virtual environment that is both realistic and exciting. A dynamic virtual reality horror sports experience improved by Artificial Intelligence (AI) and player modeling provide a novel and comprehensive form of entertainment by fusing physical activity, customization and immersion in a single package. An endeavor of this kind has the potential to advance state of VR and artificial intelligence in gaming while also offering exciting and memorable adventures for gamers.\\n\\n\", \"Using gamification and video games is one of the modern approaches to cognitive enhancement and improving the abilities and competencies of managers, including strategic thinking skills. Many organizations use video games in the fields of education, marketing, business, and entrepreneurship. This research aimed to investigate the role of video games in enhancing managers' strategic thinking and their potential contribution to developing cognitive capabilities. The sample included 30 students actively involved in the innovation and entrepreneurship ecosystem. To measure the strategic thinking of the participants, Pisapia’s strategic thinking questionnaire was used, and the CANTAB test was employed to measure their cognitive capabilities. To identify the individuals’ game-playing styles, indicators of micro-management, planning, plan recognition, predictions, gathering resources, partial observability, and damage avoidance were designed. The findings indicated that 53.3 percent of the participants had reflective thinking, 30 percent had systems thinking, and the rest had a reframing thinking style as their strategic thinking dominant dimension. On the other hand, given the identified correlation between the damage avoidance criteria with the thinking and reflective style, as well as the inverse and significant correlation of the gathering resources criteria with the results of the PRM test, it seems that strategic games have the potential to change and even develop some cognitive functions such as attention, reaction, and memory, and can be considered as tools to improve cognitive ability. These games can be used to design tasks to enhance managers' cognitive abilities and subsequently promote their strategic thinking and decision-making skills.\", \"This study investigates how automated adaptable learning (BSG) may improve business simulating games (BSG) and its transformation possibilities. The rapid increase of information, combined with the intricate nature of today's company contexts, means that classic BSG education techniques frequently fail to adequately prepare students for the difficulties they will face in everyday life. This study provides a revolutionary architecture that continually evolves learning paths, responses, and testing situations based on specific student progress and desires. It does this by utilizing modern artificial intelligence methods, including machine learning. This technique seeks to maximize users' preservation of expertise, ability to make decisions, and capacity for creative thinking through tailoring their education. In summary, our study raises possibilities for better and more interesting educational opportunities throughout the modern age by adding to the continuing conversation about the relationship between AI, training, and corporate strategies.\", 'Video games are becoming a part of the lives of many, many people. They are able to evoke a wide range of emotions, from joy and excitement to fear and empathy, creating deep immersion and memorable impressions for players. How do they manage it and is it possible to use the emotions themselves in the game itself?\\n\\nThis article presents the concept of developing a system of dynamic procedural content generation (PCG) with game mechanics of interaction using emotions based on methods affective computing. To achieve this goal, The article developed an emotion recognition system based on fuzzy logic. And PCG performed by Artificial Neural Networks.\\n\\nIn the video game industry, affective computing methods, such as interaction with the expression of emotions, can bring great benefits, since the emotional involvement of the player is very important. This will make a new contribution to the diversity of human-computer interaction.']\n",
            "Test: ['Automatic software plagiarism detection tools are widely used in educational settings to ensure that submitted work was not copied. These tools have grown in use together with the rise in enrollments in computer science programs and the widespread availability of code on-line. Educators rely on the robustness of plagiarism detection tools; the working assumption is that the effort required to evade detection is as high as that required to actually do the assigned work. This paper shows this is not the case. It presents an entirely automatic program transformation approach, MOSSAD, that defeats popular software plagiarism detection tools. MOSSAD comprises a framework that couples techniques inspired by genetic programming with domain-specific knowledge to effectively undermine plagiarism detectors. MOSSAD is effective at defeating four plagiarism detectors, including Moss and JPlag. MOSSAD is both fast and effective: it can, in minutes, generate modified versions of programs that are likely to escape detection. More insidiously, because of its non-deterministic approach, MOSSAD can, from a single program, generate dozens of variants, which are classified as no more suspicious than legitimate assignments. A detailed study of MOSSAD across a corpus of real student assignments demonstrates its efficacy at evading detection. A user study shows that graduate student assistants consistently rate MOSSAD-generated code as just as readable as authentic student code. This work motivates the need for both research on more robust plagiarism detection tools and greater integration of naturally plagiarism-resistant methodologies like code review into computer science education.', 'A two-year study by the Ministry of Research, Technology and Education in Indonesia presented the evaluation of most universities in Indonesia. The findings of the evaluation are the peculiarities of various dissertation softcopies of doctoral students which are similar to any texts available on internet. The suspected plagiarism behavior has a negative effect on both students and faculty members. The main reason behind this behavior is the lack of standardized awareness among faculty members with regard to plagiarism. Therefore, this study proposes a computerized system that is able to detect plagiarism information by using K-means and cosine distance algorithm. The process starts from preprocessing process that includes a novel step of checking Indonesian big dictionary, vector space model design, and the combined calculation of K-means and cosine distance from 17 documents as test data. The result of this study generally shows that the documents have detection accuracy of 93.33%.', 'En este artículo se expone el análisis, diseño, implementación y pruebas de un módulo para la detección de potencial plagio de las tareas enviadas a un Sistema de Administración de Cursos, utilizando la plataforma de procesamiento distribuido Hadoop. En el presente trabajo se analiza la problemática del plagio que ocurre en las tareas elaboradas digitalmente por los estudiantes y que son receptadas por los Sistemas de Administración de Cursos. Además, se realiza un análisis conceptual para comprender cómo la necesidad de comparar dos secuencias está presente en otras ramas de la ciencia y cómo la solución ha sido propuesta con el uso de herramientas informáticas. Así mismo, se exponen las tecnologías utilizadas para el desarrollo del módulo; y se detalla cómo se hizo frente a la problemática, dividiendo el proceso en dos partes: el pre-procesamiento de los documentos para generar archivos en texto plano; y la implementación del algoritmo de Smith-Waterman con las mejoras planteadas por PhD. Robert W. Irving. Finalmente, se muestra un resumen con los resultados de las pruebas realizadas sobre el ambiente de procesamiento distribuido.\\nThis paper presents the analysis, design, implementation and testing of a module for potential plagiarism detection of homework sent to a Course Management System, using the distributed processing platform Hadoop. This paper analyze the plagiarism problem that happened in homework done digitally by students and it are receipted by the Course Management Systems. Also, the paper shows a conceptual analysis for understanding how the necessity of comparing two sequences is present in other branches of science and how the solution has been proposed with the use of technological tools. Likewise, the document details how the problems were faced by dividing the process in two parts: the pre-processing of documents to generate plain text files and the implementation of the Smith-Waterman algorithm with the PhD. Robert W. Irving’s improvements. Finally, the paper shows a summary of testing results done over the distributed processing platform.', 'One of the key factors behind plagiarism is the availability of a large amount of data and information on the internet that can be accessed rapidly. This increases the risk of academic fraud and intellectual property theft. As increasing anxiety over plagiarism grow, more observation was drawn towards automatic plagiarism detection. Hybrid algorithms are regarded as one of the most prospective ways to detect similarity of everyday language or source code written by a student. This study investigates the applicability and success of combining both the Levenshtein edit distance approximate string matching algorithm and the term frequency inverse document frequency (TF-IDF), thereby boosting the rate of similarity measured using cosine similarity. The proposed hybrid algorithm is also able to detect plagiarism occurred on natural language, source codes, exact, and disguised words. The developed algorithm can detect rearranged words, intertextual similarity of insertion or deletion and grammatical changes. In this research three various dataset are used for testing: automated machine paragraphs, mistyped words and java source codes. Overall, the system proved to be detecting plagiarism better than the yet alone TF-IDF approach. Keywords: Approximate, Hybrid, Plagiarism, Similarity, TFIDF.', 'Measures of success for facial feminization surgery (FFS) have previously included improved rates of external gender perception as female and patient-reported outcome measures. \\nEmotion recognition is the ability to precisely infer human emotions from numerous sources and modalities using questionnaires, physical signals, and physiological signals.\\nIn this study, we used artificial intelligence facial recognition software to objectively evaluate the effects of FFS on both perceived gender and age among male-to-female transgender patients, as well as their relationship with patient facial satisfaction. FFS was associated with a decrease in perceived age relative to the patient’s true age (−2.4 y, P<0.001), with older patients experiencing greater reductions. Pearson correlation matrix found no significant relationship between improved female gender typing and patient facial satisfaction. Transfeminine patients experienced improvements in satisfaction with facial appearance, perceived gender, and decreases in perceived age following FFS. Notably, patient satisfaction was not directly associated with improved AI-gender typing, suggesting that other factors may influence patient satisfaction. After a thorough analysis and discussion, we selected 142 journal articles using PRISMA guidelines. The review provides a detailed analysis of existing studies and available datasets of emotion recognition. Our review analysis also presented potential challenges in the existing literature and directions for future research.', 'This Research to Practice Work in Progress Paper presents a token-based approach to detecting plagiarism in university courses with hardware programming assignments. Detecting plagiarism manually is a difficult and time-consuming work. In the last two decades, various of plagiarism detection tools have been developed. These techniques could be mainly divided into the following categories: Textual Match, Program Dependence Graph Comparison, Abstract Syntax Tree Analysis and Low-Level Form Code Comparison. Although there had been a lot of researches on detecting code clones in software programming languages (e.g. Basic, C/C++, Java, Python, etc.), research that focused on hardware description languages is still lacking. Based on the effective of the locality sensitive hash function (simhash), which was usually used in detecting near-duplicates for web crawling, we proposed an improved real-time plagiarism detection approach for Verilog HDL (hardware description language) programming assignments. The core detecting steps are extracting weighted tokens from source code as high-dimensional feature, and mapping it to a f-bit fingerprints with simhash technique. On account of the syntax characteristics of Verilog HDL, a token extraction strategy was designed to maximize the valid information that a fixed length hash value could represent. Experiments over real course data sets were conducted to evaluate the performance of token-based approach comparing with an existing plagiarism detection tool (Moss). The result shows that our token-based approach does qualify the plagiarism detecting job for both online-query and batch-query in digital designs. Furthermore, token-based plagiarism detection approach could enable conduct incremental plagiarism detection for a single submission without excessive overhead. Finally, we also give a discussion of current way limitations and future research directions.', 'This systematic review provides unique findings with an up-to-date examination of artificial intelligence (AI) in higher education (HE) from 2016 to 2022. Using PRISMA principles and protocol, 138 articles were identified for a full examination. Using a priori, and grounded coding, the data from the 138 articles were extracted, analyzed, and coded. The findings of this study show that in 2021 and 2022, publications rose nearly two to three times the number of previous years. With this rapid rise in the number of AIEd HE publications, new trends have emerged. The findings show that research was conducted in six of the seven continents of the world. The trend has shifted from the US to China leading in the number of publications. Another new trend is in the researcher affiliation as prior studies showed a lack of researchers from departments of education. This has now changed to be the most dominant department. Undergraduate students were the most studied students at 72%. Similar to the findings of other studies, language learning was the most common subject domain. This included writing, reading, and vocabulary acquisition. In examination of who the AIEd was intended for 72% of the studies focused on students, 17% instructors, and 11% managers. In answering the overarching question of how AIEd was used in HE, grounded coding was used. Five usage codes emerged from the data: (1) Assessment/Evaluation, (2) Predicting, (3) AI Assistant, (4) Intelligent Tutoring System (ITS), and (5) Managing Student Learning. This systematic review revealed gaps in the literature to be used as a springboard for future researchers, including new tools, such as Chat GPT.', \"Neural Network-based Graph Embedding for Cross-Platform Binary Code Similarity Detection\\nThe problem of cross-platform binary code similarity detection aims at detecting whether two binary functions coming from different platforms are similar or not. It has many security applications, including plagiarism detection, malware detection, vulnerability search, etc. Existing approaches rely on approximate graph-matching algorithms, which are inevitably slow and sometimes inaccurate, and hard to adapt to a new task. To address these issues, in this work, we propose a novel neural network-based approach to compute the embedding, i.e., a numeric vector, based on the control flow graph of each binary function, then the similarity detection can be done efficiently by measuring the distance between the embeddings for two functions. We implement a prototype called Gemini. Our extensive evaluation shows that Gemini outperforms the state-of-the-art approaches by large margins with respect to similarity detection accuracy. Further, Gemini can speed up prior art's embedding generation time by 3 to 4 orders of magnitude and reduce the required training time from more than 1 week down to 30 minutes to 10 hours. Our real world case studies demonstrate that Gemini can identify significantly more vulnerable firmware images than the state-of-the-art, i.e., Genius. Our research showcases a successful application of deep learning on computer security problems.\", 'Source-code Similarity Detection and Detection Tools Used in Academia: A Systematic Review\\nTeachers deal with plagiarism on a regular basis, so they try to prevent and detect plagiarism, a task that is complicated by the large size of some classes. Students who cheat often try to hide their plagiarism (obfuscate), and many different similarity detection engines (often called plagiarism detection tools) have been built to help teachers. This article focuses only on plagiarism detection and presents a detailed systematic review of the field of source-code plagiarism detection in academia. This review gives an overview of definitions of plagiarism, plagiarism detection tools, comparison metrics, obfuscation methods, datasets used for comparison, and algorithm types. Perspectives on the meaning of source-code plagiarism detection in academia are presented, together with categorisations of the available detection tools and analyses of their effectiveness. While writing the review, some interesting insights have been found about metrics and datasets for quantitative tool comparison and categorisation of detection algorithms. Also, existing obfuscation methods classifications have been expanded together with a new definition of \"source-code plagiarism detection in academia.\"', 'The Metaverse, a virtual reality (VR) space where users can interact with each other and digital objects, is rapidly becoming a reality. As this new world evolves, Artificial Intelligence (AI) is playing an increasingly important role in shaping its development. Combining AI with emerging technologies in the Metaverse opens up new possibilities for immersive experiences that were once unimaginable. This paper examines the integration of AI with various technologies, including the Internet of Things, blockchain, Natural Language Processing, virtual reality, Augmented Reality, Mixed Reality, and Extended Reality. One potential benefit of using AI in the Metaverse is the ability to create personalized experiences for individual users, based on their behavior and preferences. Another potential benefit of using AI in the Metaverse is the ability to automate repetitive tasks, freeing up time and resources for more complex and creative endeavors. However, there are also challenges associated with using AI in the Metaverse, such as ensuring user privacy and addressing issues of bias and discrimination. By exploring the potential benefits and challenges of incorporating AI into the Metaverse, including ethical considerations, we can better prepare for this exciting new era of virtual reality. This paper presents a comprehensive survey of AI and its integration with other emerging technologies in the Metaverse, as the Metaverse continues to evolve and grow, it will be important for developers and researchers to stay up to date with the latest developments in AI and emerging technologies to fully leverage their potential.', 'En este trabajo se construyó un algoritmo computacional para la alineación de textos en la\\ntarea de detección de plagio bilingüe. El método de detección de plagio bilingüe hace uso del\\nservicio de traductores automáticos, con la finalidad de tener los documentos en cuestión en\\nun idioma base, para después aplicar técnicas de plagio monolingüe. El algoritmo fue probado\\ncon el corpus perteneciente a la Competencia Internacional de Detección de Plagio del año\\n2013, para evaluar la etapa de detección de plagio monolingüe. Además, se experimentó con\\nla colección de textos EUROPARL, una colección de documentos pertenecientes a la reunión\\ndel parlamento europeo, de los que se tomaron los documentos en inglés y español, con la\\nfinalidad de probar la etapa bilingüe', 'Natural language processing is a discipline rooted in both linguistics and computer science. It incorporates syntactic problems (grammatical category, word segmentation, name entity recognition, etc.), semantics (sentiments analysis, texts categorization, translation, questions answering, etc.), vocal signals generation from texts or texts generation from vocal signals, etc. In the last few years, some scientists and companies have been able to create algorithms capable of achieving very high levels of performance for some of these tasks such as translation or sentiment classification, in part, by using big data. The fact that some algorithms perform so well with such a large amount of data gives a significant business advantage to large companies with large databases over smaller businesses or start-ups. The purpose of this thesis is to find algorithms or methods that can be effective in solving some natural language processing problems on small databases. For our research, we built a content-based recommendation system. We tested similarity measures such as Latent Dirichlet Allocation, cosine similarity, long-short term memory neural network, and the RV coefficient. We also compared the efficiency of the term frequency-inverse document frequency versus the mutual information to give a weighting scheme for the cosine similarity. We also compared the effectiveness of mutual information versus using raw word count as thresholds to remove words from a dictionary for the other similarity measures. We also used external databases, one containing documents related to our problem and another having Wikipedia documents. We also used a pre-trained GLOVE word embedding vector for our neural networks and the RV coefficient. We concluded that the simplest algorithms generally work best when there is little data. We also proposed several possible solutions to improve the algorithms we tested', 'Source-code Similarity Detection and Detection Tools Used in Academia: A Systematic Review\\nTeachers deal with plagiarism on a regular basis, so they try to prevent and detect plagiarism, a task that is complicated by the large size of some classes. Students who cheat often try to hide their plagiarism (obfuscate), and many different similarity detection engines (often called plagiarism detection tools) have been built to help teachers. This article focuses only on plagiarism detection and presents a detailed systematic review of the field of source-code plagiarism detection in academia. This review gives an overview of definitions of plagiarism, plagiarism detection tools, comparison metrics, obfuscation methods, datasets used for comparison, and algorithm types. \\nMore insidiously, because of its non-deterministic approach, MOSSAD can, from a single program, generate dozens of variants, which are classified as no more suspicious than legitimate assignments. A detailed study of MOSSAD across a corpus of real student assignments demonstrates its efficacy at evading detection. A user study shows that graduate student assistants consistently rate MOSSAD-generated code as just as readable as authentic student code. This work motivates the need for both research on more robust plagiarism detection tools and greater integration of naturally plagiarism-resistant methodologies like code review into computer science education.', 'We compared the print-to-speech properties and human performance characteristics of two artificial intelligence vision aids, Orcam MyEye 1 (a portable device) and Seeing AI (an iPhone and iPad application). The security of crops concerning quality and quantity is crucial to monitor disease in plants. Thus, recognition of plant disease is essential. The plant disease syndrome is noticeable in distinct parts of plants. Two individuals with measurable acuity and one with light perception were tested while blindfolded. We also tested performance with text of varying appearance in varying viewing conditions. To evaluate human performance, we asked the participants to use the devices to attempt 12 reading tasks similar to activities of daily living. We assessed the ranges of text attributes for which reading was possible, such as print size, contrast, and light level. We also assessed if individuals could complete tasks with the devices and measured accuracy and completion time. Participants also completed a survey concerning the two aids. Results: Both aids achieved greater than 95% accuracy in text recognition for flat, plain word documents and ranged from 13 to 57% accuracy for formatted text on curved surfaces. Both aids could read print sizes as small as 0.8M (20/40 Snellen equivalent, 40 cm viewing distance). Individuals successfully completed 71% and 55% (p = .114) of tasks while using Orcam MyEye 1 and Seeing AI, respectively. There was no significant difference in time to completion of tasks (p = .775). Individuals believed both aids would be helpful for daily activities. These techniques also benefit farmers in achieving expeditious and appropriate actions to avoid a reduction in the quality and quantity of crops. The application of these techniques in the recognition of disease can avert the disadvantage of origin by a factious selection of disease features, extraction of features, and boost the speed of technology and efficiency of research. Moreover, some of the future works in the classification of disease are also discussed.\\n', \"Artificial intelligence was one of the emerging technologies that simulated human intelligence in machines by programming them to think like human beings and mimic their actions. An autonomous vehicle could function by itself and carry out necessary functions without any human involvement. This innovative technology provided increased passenger safety, less congested roads, congestion reduction, optimum traffic flow, lower fuel consumption, less pollution, and better travel experiences. Autonomous vehicles played a vital role in industry, agriculture, transportation, and military applications. The autonomous vehicle's activities were supported by sensor data and a few artificial intelligence systems. Artificial intelligence was the collection of data, path planning, and execution in autonomous vehicles that required some machine learning techniques that were a part of artificial intelligence. But this came with some privacy issues and security concerns. Security was an important concern for autonomous vehicles. The issues of cybersecurity while incorporating artificial intelligence in autonomous vehicles were covered in this article, along with the growing technology of self-driving automobiles.\", '\\nThere is a dearth of feasibility assessments regarding the use of large language models (LLMs) for responding to inquiries from autistic patients within a Chinese-language context. Despite Chinese being one of the most widely spoken languages globally, the predominant research focus on the application of these models in the medical field has been on English-speaking populations.\\nThe effectiveness of LLM chatbots, specifically ChatGPT-4 (OpenAI) and ERNIE Bot (version 2.2.3; Baidu, Inc), one of the most advanced LLMs in China, in addressing inquiries from autistic individuals in a Chinese setting, is aimed to be assessed in this study.\\nData was gathered from DXY—a widely acknowledged, web-based medical consultation platform in China with a user base of over 100 million individuals. A total of 100 patient consultation samples were rigorously selected from January 2018 to August 2023, amounting to 239 questions extracted from publicly available autism-related documents on the platform. To maintain objectivity, both the original questions and responses were anonymized and randomized. Responses were assessed by an evaluation team of 3 chief physicians across 4 dimensions: relevance, accuracy, usefulness, and empathy. The team completed 717 evaluations. The best response was initially identified by the team, and a Likert scale with 5 response categories was then used to gauge the responses, each representing a distinct level of quality. Finally, the responses collected from different sources were compared.', 'This survey provides a literature review on recent works of Artificial Life in visual art during the past 40 years, specifically in the computational and software domain. It is necessary to reconsider the relations between the material body, identity, the natural world, and the concept of life. Art is known to pave the way to exploring and conveying new possibilities. Having proposed a set of criteria and a taxonomy, we briefly analyze representative artworks of different categories. We aim to provide a systematic overview of how artists are understanding nature and creating new life with modern technology. Nowadays, interdisciplinary fields between Artificial Life, artificial intelligence, computational biology, and synthetic biology are increasingly emerging into public view. \\n', 'Automated dialogue systems, important applications of artificial intelligence, are struggled with by traditional systems to understand user emotions and provide empathetic feedback. Emotional intelligence technology is integrated into automated dialogue systems in this study, and a dialogue generation model with emotional intelligence is created through deep learning and natural language processing techniques. A wide range of emotions and specific pain signals can be detected and understood by the model in real time, enabling empathetic interaction to be provided by the system. By integrating the results of the study \"Can artificial intelligence detect pain and express pain empathy?\", the ability of the model to understand the subtle elements of pain empathy has been enhanced, setting higher standards for emotional intelligence dialogue systems. The project aims to provide theoretical understanding and practical suggestions to integrate advanced emotional intelligence capabilities into dialogue systems, thereby improving user experience and interaction quality.', 'One of the key elements expected to define the future of education is the use of artificial intelligence as a tool to enhance teaching and learning processes, as well as the work of teachers and administrators. Artificial intelligence and robotics present a variety of social, pedagogical, practical, ethical, and social justice issues and challenges as they bring changes to educational processes. After examining discussions and examples of AI use in education, especially in primary school settings, I will focus on the actual implications of this significant educational challenge. With these technological advancements, there is a clear risk of creating or exacerbating inequalities among social groups if equal access is not ensured. I will explore the potential for personalizing learning pathways by describing primary school initiatives designed to promote effective and collaborative communication skills, with the aim of recognizing, identifying, and preventing factors that impact learning disorders. Finally, drawing a parallel with the development of classical literacy (reading/writing), I will discuss the necessity of introducing artificial intelligence and robotics literacy courses for teachers, enabling these technologies to be more widely used across different age groups and grades.', 'One of the key elements expected to define the future of education is the use of artificial intelligence as a tool to enhance teaching and learning processes, as well as the work of teachers and administrators. Artificial intelligence and robotics present a variety of social, pedagogical, practical, ethical, and social justice issues and challenges as they bring changes to educational processes. After examining discussions and examples of AI use in education, especially in primary school settings, I will focus on the actual implications of this significant educational challenge. With these technological advancements, there is a clear risk of creating or exacerbating inequalities among social groups if equal access is not ensured. I will explore the potential for personalizing learning pathways by describing primary school initiatives designed to promote effective and collaborative communication skills, with the aim of recognizing, identifying, and preventing factors that impact learning disorders. Finally, drawing a parallel with the development of classical literacy (reading/writing), I will discuss the necessity of introducing artificial intelligence and robotics literacy courses for teachers, enabling these technologies to be more widely used across different age groups and grades.', 'Plagiarism in research can occur due to accident or intentional. Plagiarism is an act that violates copyright and includes actions that harm others. In submitting the title of the research, for example, for the final assignment research, not a few students who repeatedly submitted titles were rejected and considered doing plagiarism because the title proposed had already existed before. Then we need a system that can detect the similarity between the titles to be submitted and the existing titles so that it is expected to reduce the occurrence of plagiarism. This study uses a winnowing algorithm to find the percentage similarity between titles. The Google Scholar will be used to obtain data on research titles that have been previously available as comparison titles. Web scraping with CURL (Client URLs) and simple HTML DOM parser is used to retrieve title data from Google Scholar. The results of the study with the application of a Winnowing algorithm to find the percentage similarity to data from Google Scholar were able to present a percentage of similarities in percent with the category of mild, moderate or severe plagiarism, while also helping early detection as prevention of plagiarism.', 'Given a million escort advertisements, how can we spot near-duplicates? Such micro-clusters of ads are usually signals of human trafficking (HT). How can we summarize them to convince law enforcement to act? Spotting micro-clusters of near-duplicate documents is useful in multiple, additional settings, including spam-bot detection in Twitter ads, plagiarism, and more.\\n\\nWe present InfoShield, which makes the following contributions: practical, being scalable and effective on real data; parameter-free and principled, requiring no user-defined parameters; interpretable, finding a document to be the cluster representative, highlighting all the common phrases, and automatically detecting \"slots\" (i.e., phrases that differ in every document); and generalizable, beating or matching domain-specific methods in Twitter bot detection and HT detection, respectively, as well as being language independent. Interpretability is particularly important for the anti-HT domain, where law enforcement must visually inspect ads.\\n\\nOur experiments on real data show that InfoShield correctly identifies Twitter bots with an F1 score over 90% and detects HT ads with 84% precision. Moreover, it is scalable, requiring about 8 hours for 4 million documents on a stock laptop. Our incremental version, DeltaShield, allows for fast, incremental updates, with minor loss of accuracy.', 'Web data mining \\nA Web data mining system using granular computing and ASP programming is proposed. This is a web based application, which allows Web users to submit survey data for many different companies. This survey is a collection of questions that will help these companies develop and improve their business and customer service with their clients by analyzing survey data. This web application allows users to submit data anywhere. All the survey data is collected into a database for further analysis. An administrator of this web application can login to the system and view all the data submitted. This web application resides on a web server, and the database resides on the MS SQL server.\\n', 'It describes the experiment of building a software capable of generating leads and newspaper titles in an automated fashion from information obtained from the Internet. The theoretical possibility Lage already provided by the end of last century is based on relatively rigid and simple structure of this type of story construction, which facilitates the representation or translation of its syntax in terms of instructions that the computer can execute. The paper also discusses the relationship between society, technique and technology, making a brief history of the introduction of digital solutions in newsrooms and their impacts. The development was done with the Python programming language and NLTK- Natural Language Toolkit library - and used the results of the Brazilian Soccer Championship 2013 published on an internet portal as a data source.', 'Interactive software agents, such as chatbots, are progressively being used in the area of health and well-being. In such applications, where agents engage with users in interpersonal conversations for, e.g., coaching, comfort or behavior-change interventions, there is an increased need for understanding agents’ empathic capabilities. In the current state-of-the-art, there are no tools to do that. In order to understand empathic capabilities in interactive software agents, we need a precise notion of empathy. The literature discusses a variety of definitions of empathy, but there is no consensus of a formal definition. Based on a systematic literature review and a qualitative analysis of recent approaches to empathy in interactive agents for health and well-being, a formal definition—an ontology—of empathy is developed. We present the potential of the formal definition in a controlled user-study by applying it as a tool for assessing empathy in two state-of-the-art health and well-being chatbots; Replika and Wysa. Interactive software agents, such as chatbots, are progressively being used in the area of health and well-being. In such applications, where agents engage with users in interpersonal conversations for, e.g., coaching, comfort or behavior-change interventions, there is an increased need for understanding agents’ empathic capabilities. In the current state-of-the-art, there are no tools to do that. In order to understand empathic capabilities in interactive software agents, we need a precise notion of empathy. The literature discusses a variety of definitions of empathy, but there is no consensus of a formal definition. We present the potential of the formal definition in a controlled user-study by applying it as a tool for assessing empathy in two state-of-the-art health and well-being chatbots; Replika and Wysa. Our findings suggest that our definition captures necessary conditions for assessing empathy in interactive agents, and how it can uncover and explain trends in changing perceptions of empathy over time. The definition, implemented in Web Ontology Language (OWL), may serve as an automated tool, enabling systems to recognize empathy in interactions—be it an interactive agent evaluating its own empathic performance or an intelligent system assessing the empathic capability of its interlocutors.', 'Shared information and program plagiarism detection\\nA fundamental question in information theory and in computer science is how to measure similarity or the amount of shared information between two sequences. We have proposed a metric, based on Kolmogorov complexity, to answer this question and have proven it to be universal. We apply this metric in measuring the amount of shared information between two computer programs, to enable plagiarism detection. We have designed and implemented a practical system SID (Software Integrity Diagnosis system) that approximates this metric by a heuristic compression algorithm. Experimental results demonstrate that SID has clear advantages over other plagiarism detection systems. SID system server is online at http://software.bioinformatics.uwaterloo.ca/SID/.', 'The increase in the number of customer complaints has led to an increase in the number of power customer service work orders, resulting in the failure to solve the reasonable demands of some customers on time, affecting the customer service quality of Power Supply Bureau. To solve the above problems, a text similarity detection method of power customer service work order based on TFIDF algorithm is proposed. This method uses web scraper technology to obtain the power customer service work order text, and preprocesses the text, including Chinese word segmentation, desktop words and text representation. TFIDF algorithm is used to extract the preprocessed text keywords and obtain the keyword weight. Based on the weight, cosine distance method is used to calculate the text similarity of text keywords of different power customer service work orders. The results show that compared with the detection method based on weighted word and sentence vector, the detection method based on hybrid model, the detection method based on coupling distance discrimination and strong category features, the macro average F1 measurement value is higher, the method takes less time and has lower complexity', '\\ufeffWhen automatic plagiarism detection is carried out considering a reference corpus, a suspicious text is compared to a set of original documents in order to relate the plagiarised text fragments to their potential source. One of the biggest difficulties in this task is to locate plagiarised fragments that have been modified (by rewording, insertion or deletion, for example) from the source text.\\n\\n\\nThe definition of proper text chunks as comparison units of the suspicious and original texts is crucial for the success of this kind of applications. Our experiments with the METER corpus show that the best results are obtained when considering low level word n-grams comparisons (n = {2,3}).', 'About 3,000 new citations that are highly similar to citations in previously published manuscripts that appear each year in the biomedical literature (Medline) alone. This underscores the importance for the opportunity for editors and reviewers to have detection system to identify highly similar text in submitted manuscripts so that they can then review them for novelty. New software-based services, both commercial and free, provide this capability. The availability of such tools provides both a way to intercept suspect manuscripts and serve as a deterrent. Unfortunately, the capabilities of these services vary considerably, mainly as a consequence of the availability and completeness of the literature bases to which new queries are compared. Most of the commercial software has been designed for detection of plagiarism in high school and college papers; however, there is at least I fee-based service (CrossRef) and 1 free service (etblast.org), which are designed to target the needs of the biomedical publication industry. Information on these various services, examples of the type of operability and output, and things that need to be considered by publishers, editors, and reviewers before selecting and using these services is provided. (C) 2011 Elsevier Inc. All rights reserved.', \"Artificial intelligence chatbots have invaded the tourism industry owing to their low cost and high efficiency. However, the influence of emotional expressions of chatbots on service outcomes has not received much attention from researchers. Drawing upon expectancy violations theory, we explored how emotional expressions of chatbots affect customer satisfaction using three experiments in the context of tourist attraction recommendations. Chatbots' expressions of concern for customers can improve customer satisfaction by reducing expectancy violations. In particular, customer's goal orientation, the human-likeness of chatbot's avatars, and the relationship type between customers and chatbots can moderate the negative relationship between emotional expression and expectancy violation.\\nFurthermore, our study highlights the necessity for tourism companies to carefully design chatbot interactions to align with customers' expectations, ensuring a balance between efficiency and empathetic communication. By incorporating emotional intelligence into chatbot design, tourism businesses can not only enhance customer satisfaction but also foster stronger, more personalized connections with their clientele. Our research suggests that future studies should delve deeper into the nuances of chatbot-customer interactions, exploring how different emotional cues and contexts can further influence customer experiences and service outcomes in the tourism sector.\", \"Plagiarism can be of many different natures, ranging from copying texts to adopting ideas, without giving credit to its originator. This paper presents a new taxonomy of plagiarism that highlights differences between literal plagiarism and intelligent plagiarism, from the plagiarist's behavioral point of view. The taxonomy supports deep understanding of different linguistic patterns in committing plagiarism, for example, changing texts into semantically equivalent but with different words and organization, shortening texts with concept generalization and specification, and adopting ideas and important contributions of others. Different textual features that characterize different plagiarism types are discussed. Systematic frameworks and methods of monolingual, extrinsic, intrinsic, and cross-lingual plagiarism detection are surveyed and correlated with plagiarism types, which are listed in the taxonomy. We conduct extensive study of state-of-the-art techniques for plagiarism detection, including character n-gram-based (CNG), vector-based (VEC), syntax-based (SYN), semantic-based (SEM), fuzzy-based (FUZZY), structural-based (STRUC), stylometric-based (STYLE), and cross-lingual techniques (CROSS). Our study corroborates that existing systems for plagiarism detection focus on copying text but fail to detect intelligent plagiarism when ideas are presented in different words.\", 'Plagiarism, which is one of the forms of academic misconducts, is problematic. It results in discouraging innovation, and losing trust in the academic community. We modeled the plagiarism for academic publications, by means of the similarity between textual contents, and citation relations. Furthermore, we adopted the model in our proposed method for plagiarism detection. We evaluate our method using two types of dataset, namely auto-simulated andmanually judged dataset. Our experiment shows that our method outperforms the baseline, which only uses the similarity between textual contents, on the auto-simulated dataset and the manually judged one for the ACL sub-dataset.', \"Artificial General Intelligence is the idea that someday an hypothetical agent will arise from artificial intelligence (AI) progresses, and will surpass by far the brightest and most gifted human minds. This idea has been around since the early development of AI. Since then, scenarios on how such AI may behave towards humans have been the subject of many fictional and research works.  This work presents two significant advances: a unique method for determining a player's specific fears via game data and machine learning methods and an adaptive game system that employs agents to monitor players' terror experiences and restrict exposure to components that they find upsetting. Additional evidence from user studies and statistical significance testing suggests that our method may boost the stress and anxiety felt by gamers, resulting in rewarding gaming experience. In particular, we focus on 3 specific families of modern AIs to develop the idea that deep neural networks, which are the current backbone of nearly all artificial intelligence methods, are poor candidates for any AGI to arise due to their many limitations, and therefore that any threat coming from the recent AI race does not lie in AGI but in the limitations, uses, and lack of regulations of our current models and algorithms. An endeavor of this kind has the potential to advance state of VR and artificial intelligence in gaming while also offering exciting and memorable adventures for gamers.\", 'In this article, we introduce a model for adjustable moisture control specifically designed for historical buildings. The proposed system is developed as a flexible IoT infrastructure, equipped with a complex network of sensors to monitor indoor humidity levels and compare them with groundwater levels, rainfall, and wind speed to manage a drying system. The control model employs type-2 fuzzy logic reasoning, enabling it to adapt decisions based on the intensity of water absorption. This innovative model thus provides an intelligent system for managing interior conditions in historical buildings. The system was installed and tested in an old brewery building, and research results demonstrate its efficiency in dehumidification at minimal cost.', 'While Artificial Intelligence in Education (AIED) research has aimed to support student learning, experiences from other AI domains suggest that such ethical intentions alone are insufficient. It is necessary to explicitly consider issues like fairness, accountability, transparency, bias, autonomy, agency, and inclusion. More generally, it is important to distinguish between doing ethical things and doing things ethically, understanding and making pedagogical choices that are ethical, and accounting for the possibility of unintended consequences. However, addressing these and related questions is far from simple. As a first step towards addressing this critical gap, we invited 60 of the AIED community’s leading researchers to respond to a survey on ethics and the application of AI in educational contexts. In this paper, we first introduce issues surrounding the ethics of AI in education. Next, we summarize the contributions of the 17 respondents and discuss the complex issues they raised. Specific outcomes include the recognition that most AIED researchers are not trained to tackle emerging ethical questions. A well-designed framework for engaging with the ethics of AIED, combining a multidisciplinary approach and a set of robust guidelines, seems vital in this context.', 'This article examines the benefits and risks of Artificial Intelligence (AI) in education in relation to fundamental human rights. The article is based on an EU scoping study [Berendt, B., A. Littlejohn, P. Kern, P. Mitros, X. Shacklock, and M. Blakemore. 2017. Big Data for Monitoring Educational Systems. Luxembourg: Publications Office of the European Union. https://publications.europa.eu/en/publication-detail/-/publication/94cb5fc8-473e-11e7-aea8-01aa75ed71a1/]. The study takes into account the potential for AI and ‘Big Data’ to provide more effective monitoring of the education system in real-time, but also considers the implications for fundamental human rights and freedoms of both teachers and learners. The analysis highlights a need to balance the benefits and risks as AI tools are developed, marketed, and deployed. A conclusion is drawn with a call to embed consideration of the benefits and risks of AI in education as technology tools into the development, marketing, and deployment of these tools. Questions are raised about who – which body or organization – should take responsibility for regulating AI in education, particularly since AI impacts not only data protection and privacy but fundamental rights in general. Given AI’s global impact, it is argued that regulation should occur at a trans-national level, with a global organization such as the UN taking on this role.', 'As one of the branches of machine learning, the deep learning model combined with artificial intelligence is widely used in the field of computer vision technology. The image recognition field, represented by medical image analysis, is also developing. Its advantage is that it does not rely on human annotation, allowing the computer to recognize and process feature information omitted by humans during the model training process, achieving or even exceeding the accuracy of human processing. Based on the general lack of explainability caused by the unknown data processing process in the deep model, the existing solutions mainly include the establishment of internal explainability, attention mechanism interpretation of specific models, and the interpretation of unknowable models represented by LIME. The way to quantitatively assess interpretability is still being explored, especially in the interpretative assessment of both doctors and patients in medical decision-related models, with several scales proposed for reference. The current research on the application of artificial intelligence deep learning models in medical imaging generally pays more attention to accuracy rather than explainability, resulting in a lack of explainability and thus hindering the practical clinical application of deep learning models. Therefore, the need to analyze the development of medical image analysis in the field of artificial intelligence and computer vision technology, and how to balance accuracy and interpretability to develop deep learning models that both doctors and patients can trust, will become the research focus of the industry in the future.', 'Evolutionary computation, a sub-field of artificial intelligence and artificial life, is characterized by the use of biologically inspired methods to solve optimization problems through iterative refinements of a set of solutions via change and selection. This approach, which began in the 1950s, comprises a growing set of algorithms capable of solving a wide range of problems, divided into various types differing in selection, mutation, and representation of candidate solutions. Successful applications have been recorded in multiple domains, including optimization, machine learning, robotics, and various areas that study living systems. Evolutionary computation has recently experienced a revival, particularly in the study of open-ended evolution, with significant implications for the future of AI. It has the unique potential to generate endless innovations and lead to a paradigm shift in the development of artificial intelligence and artificial life.', \"Over the past decades, the number of vehicles on the road has consistently increased due to the growing demand for urban mobility and modern logistics. This surge in vehicles has led to significant issues such as heightened traffic congestion and increased traffic accidents, both of which hinder economic development. These challenges can be effectively addressed by making vehicles smarter and reducing their dependence on human drivers. Over the past century, extensive research conducted by various nations has propelled the automation of road vehicles. Today, major motor manufacturers worldwide are actively developing autonomous vehicle (AV) technologies. With the advancements in artificial intelligence (AI), the widespread adoption of autonomous cars is closer than we might expect. AI has become a critical element for AVs, enabling them to perceive their environment and make real-time decisions accurately. This progress in AI is being fueled by the proliferation of big data from numerous sensing devices and advanced computing resources. To fully understand AI's role in AV systems, it is essential to explore its development and historical context.\", 'This paper provides a comprehensive literature review of the research and application of machine learning (ML) algorithms in recommender systems (RS). The study aims to identify recent trends, explore real-life applications, and guide researchers in positioning their research activities in this domain, covering publications from January to June 2023. The findings are categorized into various domains, including education, healthcare, ML algorithms (such as auto-encoders and reinforcement learning), e-commerce, and digital journalism. The review emphasizes the improved recommendation accuracy, increased scalability, personalization, and context awareness, as well as the diverse ML techniques and strategies for handling cold start and data sparsity. Additionally, it lays the groundwork for future advancements in ML algorithms for RSs, particularly in the context of manufacturing enterprises.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Limpieza de datos"
      ],
      "metadata": {
        "id": "ZrRD6NyQylza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar y definir stopwords de nltk\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPvRfW1CygId",
        "outputId": "8f4bd58b-5445-439c-bf83-c91317bf49b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para limpiar textos\n",
        "def clean_text(texts):\n",
        "    cleaned_texts = []\n",
        "    for text in texts:\n",
        "        text_lower = text.lower()\n",
        "        text_cleaned = re.sub(r'[^\\w\\s]', '', text_lower)\n",
        "        words = text_cleaned.split()\n",
        "        filtered_words = [word for word in words if word not in stop_words]\n",
        "        cleaned_text = ' '.join(filtered_words)\n",
        "        cleaned_texts.append(cleaned_text)\n",
        "\n",
        "    return cleaned_texts"
      ],
      "metadata": {
        "id": "MK9Ee_CvytXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Limpiar textos de plagio\n",
        "plagiarism_clean = clean_text(plagiarism_texts)\n",
        "\n",
        "# Limpiar textos de construcción y prueba\n",
        "construction_clean = clean_text(construction_texts)\n",
        "test_clean = clean_text(test_texts)\n",
        "\n",
        "# Impresion de los datos limpios\n",
        "print(f'Plagiarism: {plagiarism_clean}')\n",
        "print(f'Construction: {construction_clean}')\n",
        "print(f'Test: {test_clean}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zqt5K_051aq6",
        "outputId": "dd2bdf42-c7a3-47ea-c793-be6a4cf26d7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plagiarism: ['recent developments artificial intelligence ai generated great expectations future impact ai education learning aied often expectations influenced misconceptions current technical capabilities insufficient awareness latest advancements ai education overly limited perspectives roles education society article provide review existing ai systems education pedagogic educational assumptions create classification aied systems outline various approaches incorporating ai education learning demonstrating based different understandings ai education could become highlight potential challenges path aied implementation', 'artificial intelligence ai evolving application expanding rapidly becoming integral part daily lives fact ai transformed way people learn however integration educational sector faced numerous challenges ethical concerns purpose study examine opportunities benefits obstacles ai education comprehensive review relevant literature conducted using systematic review method identify current research trends provide thorough understanding ai technology education educators future research directions findings revealed ais implementation education progressed significantly developed countries research gained prominence industry 40 era additional challenges recommendations also discussed study', 'study conducted content analysis research focused uncovering artificial intelligence ai utilized education sector identifying potential research trends challenges ai education total 100 papers including 63 empirical papers 74 studies 37 analytical papers selected education educational research category social sciences citation index database 2010 2020 content analysis revealed research questions could categorized development layer classification matching recommendation deep learning application layer feedback reasoning adaptive learning integration layer affective computing roleplaying immersive learning gamification additionally four research trendsinternet things swarm intelligence deep learning neurosciencealong evaluation ai education recommended exploration however also identified challenges education may arise ai including improper application ai techniques evolving roles teachers students social ethical concerns findings offer comprehensive overview ais role education domain aids reinforcing theoretical foundation ai education presents promising avenue educators ai engineers pursue collaborative research', '2021 30 countries released national artificial intelligence ai policy strategies documents outline plans expectations regarding ai influence various policy sectors including education typically address social ethical implications ai article performs thematic analysis 24 national ai policy strategies examining role education global ai policy discussions finds application ai education aied largely missing policy dialogues instrumental value education preparing aiready workforce training ai experts heavily emphasized additionally ethical considerations aied receive minimal attention despite general prominence ai ethics discussions documents suggests aied broader policy ethical implicationspositive negativehave yet achieve mainstream recognition inclusion agendas key decisionmakers concern given effective policy careful ethical consideration closely intertwined article argues light findings article applies framework five ai ethics principles propose ways policymakers better integrate aieds implications finally article offers recommendations aied scholars strategies engaging policymaking process conducting ethics policyoriented aied research order shape policy deliberations public good', 'artificial intelligence ai transforming world significant ways impacts undeniably positive widespread enduring harms also result technology incorporation ai various facets human life ongoing complex ethical issues arising design deployment use technology underscore need reevaluate future developers designers along professionals learning ai crucial train future members ai community stakeholders consider ai might affect peoples lives embrace responsibilities maximize benefits minimizing potential harms achieved part comprehensive systematic inclusion ai ethics curriculum paper briefly outline different approaches ai ethics provide set recommendations related ai ethics education', 'artificial intelligence education aied research aims support student learning experience ai domains indicates ethical intentions alone insufficient also necessary explicitly consider issues fairness accountability transparency bias autonomy agency inclusion generally need differentiate acting ethically making ethical decisions understand make pedagogical choices ethical account constant possibility unintended consequences however addressing related questions far straightforward initial step towards addressing critical gap invited 60 aied communitys leading researchers respond survey ethics application ai educational contexts paper first introduce issues surrounding ethics ai education next summarize contributions 17 respondents discuss complex issues raised specific outcomes include recognition aied researchers equipped address emerging ethical questions welldesigned framework engaging ethics aied combining multidisciplinary approach set robust guidelines seems essential context', 'educational applications ai blend pasteurs quadrant refers useinspired basic purely applied research article provides overview traditional emerging frameworks ai education early researchers concentrated developing personalized teaching systems individual learners whereas recent work considers social interactions learning environment various grand challenges highlight issues still confronting ai education', 'evolving needs engineering industry require continuous evolution engineering education keep pace latest technological advancements one exciting development realm utilization generative artificial intelligence ai technology exemplified chatgpt conversational agent chatgpt potential offer tailored effective learning experiences providing personalized feedback explanations students well creating realistic virtual simulations handson learning however crucial acknowledge limitations technology chatgpt similar generative ai systems effective training data may perpetuate biases inadvertently generate spread misinformation furthermore integration generative ai education raises ethical concerns possibility unethical dishonest use students potential displacement human workers rendered obsolete technology current state generative ai technology exemplified chatgpt impressive yet imperfect serves glimpse future possibilities imperative engineering educators comprehend implications technology explore ways adapt engineering education ecosystem ensure next generation engineers leverage advantages offered generative ai mitigating negative repercussions', 'purpose article analyze advantages drawbacks artificial intelligence ai education focus fundamental human rights article based eu scoping study berendt b littlejohn p kern p mitros x shacklock blakemore 2017 big data monitoring educational systems luxembourg publications office european union httpspublicationseuropaeuenpublicationdetailpublication94cb5fc8473e11e7aea801aa75ed71a1 study ai big data considered potential solutions monitor education system efficiently realtime also considers implications fundamental human rights freedoms teachers learners analysis highlights need balance benefits risks ai tools developed marketed deployed conclude call embed consideration benefits risks ai education technology tools development marketing deployment tools questions around body organisation take responsibility regulating ai education particularly since ai impacts data protection privacy fundamental rights general given ais global impact regulated transnational level global organisation un taking role', 'defining characteristic modern era steadfast belief technology across aspects life including education could argued fascination technology technophilia education profoundly influenced classroom dynamic altering relationship teacher student well among students relationships increasingly shifted towards iit transactional ithou relational based ability form bonds level connectedness teacher students among students either decreased affected growing technologization education running parallel possibly exacerbating issue concept learnification views teachers mere facilitators learning process rather individuals expertise valuable knowledge impart others article first evaluate current technologization education impact classroom relationships second explore bubers concepts iit ithou relationships implications education finally speculate thought experiment whether advancement ai could one day successfully replace human teachers classroom', 'thus recognition plant disease essential agriculture ultimate imperative primary source origin furnish domestic income multifarious countries disease caused plants due various pathogens like viruses fungi bacteria liable considerable monetary losses agriculture corporation across world security crops concerning quality quantity crucial monitor disease plants computer vision deep learning fewshot learning soft computing techniques utilized various investigators automatically identify disease plants via leaf images techniques also benefit farmers achieving expeditious appropriate actions avoid reduction quality quantity crops application techniques recognition disease avert disadvantage origin factious selection disease features extraction features boost speed technology efficiency research plant disease syndrome noticeable distinct parts plants also certain molecular techniques established prevent mitigate pathogenic threat nonetheless commonly infection detected distinct leaves plants hence review helps investigator automatically detect disease plants using machine learning deep learning shot learning provide certain diagnosis techniques prevent disease moreover future works classification disease also discussed', 'many artificial intelligence based foundation models proposed smart sensing recognize known object classes new similar scenarios large number functional sensors installed modern intelligent vehicles first summarize current widelyused foundation models foundation intelligence needed smart sensing intelligent vehicles letter aims pushing boundary smart sensing research intelligent vehicles several representative case studies discussed show potential usages sorabased parallel vision followed future research direction however still challenging foundation models smart sensing detect object classes seen unseen scenarios explain sorabased parallel vision boost foundation models smart sensing basic intelligence 10 enhanced intelligence 20 final generalized intelligence 30', 'solutions must also advance technology ensure individuals effectively navigate surroundings assist realtime navigation study conducts surveys visually challenged individuals community aims assist providing smart gadgets identify faces colours objects artificial intelligence become significant tool modern technology enabling people interact machines various methods moreover study emphasizes different technologies methods used earlier help visually impaired people daytoday life individuals visual impairments trouble tasks either blind poor vision bvi stands blind visually impaired', 'multifunctional blind assistance device designed empower users enhancing spatial awareness providing tools need navigate travel securely world major portion populace suffer daily challenges blindness pioneering project introduces comprehensive smart support system designed aid needs people visually impaired primary goals encompass recognizing objects accurately estimating distances objects users deciphering captured signs indications offering realtime locationbased navigation directions advanced system ingeniously integrated pair headphones combining various stateoftheart technologies cameras ultrasonic sensors cuttingedge machine learning algorithms represents remarkable leap forward refining overall quality life mobility blind people', 'emerging control technique visual servoing utilizing onboard camera systems inspecting uavs environment autonomously controlling uavs operation despite increasing research field aibased visual control uav systems comprehensive review articles showcase general trends future directions field research limited unmanned aerial vehicles uavs attracted massive attention many engineering practical applications last years characteristics operation flexibility paper first reviews application intelligent visual servoing systems autonomously executing various uav control tasks including 3d uav positioning aerial ground object following obstacle avoidance autonomous landing artificial intelligence ai techniques widely deployed visual servoing autonomous uav applications work comprehensively examines application advancements aienhanced visual servoing autonomous uav systems covering critical control tasks offering insights future research directions enhancing performance applicability limited current literature second research progresses applying ai techniques visual servoing autonomous uav systems discussed analyzed uav system suitable control systems required operate appropriately efficiently finally future directions critical research gaps improving performance applicability intelligent visual servoing systems included keywords unmanned aerial vehicles visual servoing artificial intelligence artificial neural networks fuzzy logic reinforcement learning', 'mammography computer vision artificial intelligence techniques used successfully detect characterize abnormalities digital images radiologists supplied information often perform better mammographic detection characterization tasks observer studies unaided radiologists revolution digital computer technology made possible new sophisticated imaging techniques may next influence interpretation radiologic images technology therefore could decrease errors mammographic interpretation continue plague human observers', 'context work presents systematic review aims identify applicability computer vision precision agriculture production five produced grains world maize rice wheat soybean barley among available tools highlight computer vision solutions combined artificial intelligence algorithms achieved important results detection patterns images sense present 25 papers selected last five years different approaches treat aspects related disease detection grain quality phenotyping grain production plays important role global economy information technology one tools end results systematic review possible identify great opportunities exploitation gpu graphics processing unit advanced artificial intelligence techniques dbn deep belief networks construction robust methods computer vision applied precision agriculture sense demand efficient safe methods food production increasing', 'computer vision cv field study deals computers understand digital images videos seeks automate tasks performed human visual system among surgeryrelated technologies amount information extracted surgical video captured endoscope especially great led increase number technologies operating room technology advanced surgery especially minimally invasive surgery mis including laparoscopic surgery robotic surgery provide information surgical procedure eg instrument usage trajectories therefore automation data analysis essential surgery reduce complexity data maximizing utility enable new opportunities research development field deals processes realworld information acquisition computers terminology cv extensive ranges hardware image sensing aibased image recognition aibased image recognition simple tasks recognizing snapshots advanced comparable humans recent years although surgical video recognition complex challenging task effectively apply mis leads future surgical advancements intraoperative decisionmaking support image navigation surgery ultimately automated surgery might realized article summarize recent advances future perspectives airelated research development field surgery', 'aids achieved greater 95 accuracy text recognition flat plain word documents ranged 13 57 accuracy formatted text curved surfaces individuals successfully completed 71 55 p 114 tasks using orcam myeye 1 seeing ai respectively significant difference time completion tasks p 775 evaluate human performance asked participants use devices attempt 12 reading tasks similar activities daily living assessed ranges text attributes reading possible print size contrast light level also assessed individuals could complete tasks devices measured accuracy completion time participants also completed survey concerning two aids introduction compared printtospeech properties human performance characteristics two artificial intelligence vision aids orcam myeye 1 portable device seeing ai iphone ipad application implications practitioners selection reading device aid based individual preferences prior familiarity platform since found clear superiority one solution aids could read print sizes small 08m 2040 snellen equivalent 40 cm viewing distance individuals believed aids would helpful daily activities discussion orcam myeye 1 seeing ai similar textreading capability usability aids useful users severe visual impairments performing reading tasks methods seven participants visual impairments experience two reading aids four participants light perception two individuals measurable acuity one light perception tested blindfolded also tested performance text varying appearance varying viewing conditions', 'current research application artificial intelligence deep learning models medical imaging generally pays attention accuracy rather explain ability resulting lack explain ability thus hindering practical clinical application deep learning models based general lack explain ability caused unknown data processing process deep model existing solutions mainly include establishment internal explain ability attention mechanism interpretation specific models interpretation unknowable models represented lime advantage rely human annotation computer recognize process feature information omitted human beings model training process achieve even exceed accuracy human processing one branches machine learning deep learning model combined artificial intelligence widely used field computer vision technology image recognition field represented medical image analysis also developing therefore need analyze development medical image analysis field artificial intelligence computer vision technology balance accuracy interpretability develop deep learning models doctors patients trust become research focus industry future way quantitatively assess interpretability still explored especially interpretative assessment doctors patients medical decisionrelated models several scales proposed reference', 'paper mainly discussed asymmetric face recognition problem number names name list number faces photo might equal face automatically labeled name motivation issue many meetings past meeting participant took group photos meeting provided corresponding name list participants without onetoone labels worst case group photo might mix faces participating meeting another reason asymmetric face recognition meeting personnel appear photos assisted taking pictures paper proposed asymmetric face recognition mechanism called afrm short initially proposed afrm adopted histogram oriented gradients hog support vector machine svm detect extract faces photos next afrm extracted features face using convolution feature map conv_ff adopted features partition faces different classes afrm applied statisticbased mechanism map name name list face class according mapping face would associated one name quickly identify face meeting afrm applied knearest neighbors knn represent features face new meeting proposed afrm could extract feature one face adopted knn derive features experimental results showed proposed mechanism achieved 97 accuracy without onetoone name face labeling', 'face essential part human body distinctive traits crucial recognizing people facial recognition technology frt one successful fascinating technologies modern times world moving towards contactless frt covid19 pandemic due contactless biometric characteristics frt becoming quite popular worldwide businesses replacing conventional fingerprint scanners artificial intelligencebased frt opening enormous commercial prospects security surveillance authenticationaccess control systems digital healthcare photo retrieval etc sectors use become essential present communication present global adoption frt rising trend market utilization technology various sectors challenges rising concerns special reference india worldwide', 'measures success facial feminization surgery ffs previously included improved rates external gender perception female patientreported outcome measures study used artificial intelligence facial recognition software objectively evaluate effects ffs perceived gender age among maletofemale transgender patients well relationship patient facial satisfaction standardized frontal preoperative postoperative images 27 transgender women undergoing ffs analyzed amazons ai facial recognition software determine gender femininity confidence score perceived age female gendertyping improvement gendertyping preoperatively postoperatively femininity confidence scores analyzed assess patient satisfaction faceq modules completed postoperatively preoperatively ffs images perceived female 481 time postoperatively improved 741 p005 femininity confidence scores improved mean score 004 preoperatively 039 postoperatively p0003 ffs associated decrease perceived age relative patients true age 24 p0001 older patients experiencing greater reductions pearson correlation matrix found significant relationship improved female gender typing patient facial satisfaction undergoing surgery younger age associated higher overall facial satisfaction r06 p001 transfeminine patients experienced improvements satisfaction facial appearance perceived gender decreases perceived age following ffs notably patient satisfaction directly associated improved aigender typing suggesting factors may influence patient satisfaction', 'surprisingly high accuracies previously reported exceeding 95 dropped significantly faced demanding conditions forensic scenario plummeting low 65 essence facial recognition systems shown impressive performance ideal conditions study indicated substantial decrease accuracy faced complexities challenges typical realworld forensic scenarios highlighting need advancements bridge gap recent advancements machine learning computer vision shown facial recognition systems achieving accuracies surpassed human performance controlled settings fingerprint analysis proved accurate aspects investigate created largescale synthetic facial dataset designed controlled facial lineup mimicked conditions encountered real forensic situations approach allowed us systematically assess facial recognition various challenging realworld conditions using synthetic dataset wellknown dataset actual faces tested accuracy two widely used neuralbased facial recognition systems comparative analytical method applied present research artificial intelligence could help humans accuracy speeding process investigation', 'facial recognition wellestablished popular field computer vision especially advancements deep learning data sets deep facial recognition made significant progress widely applied realworld scenarios complete facial recognition system involved three main components facial recognition orientation representation system detected faces aligned standard view extracted features recognition using deep convolutional neural networks article provided detailed overview latest advancements areas showing deep learning greatly enhanced abilities object detection machine vision challenging area required significant improvements image classification accuracy nearing 225 surpassing human performance object detection algorithms still early stages current algorithms achieved 408 maps modern objects careful dataset selection crucial optimal results', 'face recognition gained significant attention one useful image analysis applications leveraging unique incredible identification skills systems capable recognizing users face recognition systems extensively studied system however number drawbacks existing face recognition methods might resulted longer histogram slowed largescale database address challenges face recognition proposed hybrid descriptor using multiblock local ternary pattern ltpgray level cooccurrence matrix glcm study employed ltp glcm speeded robust features surf methods extract illumination rotation scaleinvariant features face database images features trained using artificial neural network layer neurons optimally selected crow search optimization cso method yielded accuracy 95 proposed approach implemented matlab software experimental data analyzed show developed texture descriptor higher recognition rate existing methods', 'rise deep neural networks performance biometric systems increase tremendously biometric systems face recognition used everyday life eg border control crime prevention personal device access control although accuracy face recognition systems generally high without flaws many biometric systems found exhibit demographic bias resulting different demographic groups recognized accuracy especially true facial recognition due demographic factors eg gender skin color many previous works already reported demographic bias work aim reduce demographic bias biometric face recognition applications regard 12 face recognition systems benchmarked regarding biometric recognition performance well demographic differentials ie fairness subsequently multiple fusion techniques applied goal improve fairness contrast single systems experimental results show possible improve fairness regarding single demographics eg skin color gender improving fairness demographic subgroups turn challenging', 'nigeria many different security concerns thus crimes increased despite fact stringent laws punishments place deter making appear though authorities unable stop order identify criminals conduct investigations imperative facial recognition system connected constantly updated digital library focus paper develop automatic criminal investigation system identify criminals based faces produce realtime digital archives however object detection method facial recognition model new system built haar cascades classifier technique opencv package additionally appropriate programming languages may provide needed results investigated python 36 used django 42 framework opencvpython dlib language execution due djangos orm support numerous databases usage sqlite3 database straightforward database employed lightweight applications 12 factor app idea used construct dicafr systems essential skills face detection applied image using haar method processing postprocessing discovered face compared wellknown criminal face encodings matching purposes results demonstrated dicafrs could effectively replace human systems since recover faces furthest distances display name offender sound alert dica web apps output screen dica system working prototype system might used criminal investigative process nigeria', 'facial expression recognition fer utilized various fields education gaming robotics healthcare others facial expression techniques instance interactive robot artificial intelligence recognized human faces detected emotions person conversing used emotions choose appropriate answers one use case face emotion detection playing music based users mood analyzed users facial expression deduce feelings result new emotion models required investigation existing ones struggled correctly measure musics connection facial emotion paper implemented kind job using convolution neural network cnn based deep learning approach deep learning able effectively analyze unstructured data movies forms media machine learning research created realtime system could recognize human faces assess human emotions even recommend music users oahega fer2013 datasets utilized experimental study created trained two emotion recognition models using various combinations datasets proposed models accuracy 7302 using cnn model able predict six emotions anger fear joy neutral sadness surprise proposed system could utilized different places realtime facial recognition played important role', 'facial expression recognition fer utilized various fields education gaming robotics healthcare others facial expression techniques instance interactive robot artificial intelligence recognized human faces detected emotions person conversing used emotions choose appropriate answers one use case face emotion detection playing music based users mood analyze users facial expression deduce feelings result new emotion models require investigation existing ones struggle correctly measure musics connection facial emotion paper implemented kind job using convolution neural network cnn based deep learning approach deep learning effectively analyzed unstructured data movies forms media machine learning research created realtime system recognize human faces assess human emotions even recommend music users oahega fer2013 datasets utilized experimental study created trained two emotion recognition models using various combinations datasets proposed models accuracy 7302 using cnn model able predict six emotions anger fear joy neutral sadness surprise proposed system able utilized different places realtime facial recognition plays important role', 'future transportation systems expected reshaped autonomous vehicles avs decision making considered one critical modules toward highlevel automated driving overcome complicated scenarios rulebased methods could cope well focus placed datadriven decisionmaking approaches performance decision making dramatically influenced datasets used developing datadriven methods hence necessary comprehensive insight existing datasets aspects collection sources driving data divided vehicle environment driverrelated data stateoftheart datasets three categories compared study features including sensors used annotation driving scenarios summarized based characteristics datasets potential applications datasets various aspects av decision making discussed survey assisting researchers finding appropriate ones support research future trends av dataset development also summarized', 'paper safe reliable motion planning control framework proposed handle tracking errors caused inaccurate tracking coordinating motion planning layer controller specifically motion space divided safe regions risky regions designing movement restraint size dependent tracking error construct repulsive potential field collisionfree waypoint set obtained combining global search proposed waypoint set filtering method planned trajectory fitted optimizationbased approach minimizes acceleration reference trajectory planned trajectory checked modified designed anticollision modification ensure safety using invertible transformation adaptive compensation allows transient trajectory tracking errors limited within designed region even actuator faults tracking error considered margined planning level safety reliability guaranteed coordination planning control levels inaccurate tracking actuator faults advantages effectiveness proposed motion planning control method verified simulation experimental results accurate trajectory tracking unrealistic realworld scenarios however commonly assumed facilitate motion planning algorithm design', 'would risks autonomous vehicles avs everyday road traffic distributed people rich literature ethics autonomous vehicles avs revolves around moral judgments unavoidable collision scenarios argued debate extended driving behaviors everyday road traffic ubiquitous ethical questions arise due permanent redistribution risk among road users distribution risks raises ethically relevant questions cannot evaded simple heuristics hitting brakes using interactive graphical representation different traffic situations participants preferences driving maneuvers avs measured representative survey germany participants preferences deviated significantly mere collision avoidance interestingly participants willing take risks benefit road users suggesting social dilemma avs may mitigated risky environments research might build bridge engineers philosophers discuss ethics avs constructively', 'artificial intelligence powers emerging technologies simulate human intelligence machines enabling think like human beings mimic actions autonomous vehicles function carry necessary functions without human involvement innovative technology may provide increased passenger safety less congested roads congestion reduction optimum traffic lower fuel consumption less pollution better travel experiences autonomous vehicles play vital role industry agriculture transportation military applications activities autonomous vehicles rely sensor data artificial intelligence systems artificial intelligence involves collection data path planning execution autonomous vehicles require machine learning techniques part artificial intelligence however also raises privacy issues security concerns security important concern autonomous vehicles article cover issues cybersecurity incorporating artificial intelligence autonomous vehicles along growing technology selfdriving automobiles', 'throughout last decades number vehicles road steadily increased due rising demand urban mobility contemporary logistics two many detrimental effects vehicles road also impede economic development increased traffic congestion traffic accidents issues mentioned significantly resolved making vehicles smarter reducing reliance humans past century extensive research conducted various nations fueled automation road vehicles development autonomous vehicle av technologies currently pursued significant motor manufacturers worldwide undoubtedly widespread use autonomous cars imminent realize given development artificial intelligence ai order avs perceive surroundings make right decisions real time ai emerged crucial component development ai driven growth big data numerous sensing devices cuttingedge computing resources ais development history must first examined order comprehend functions av systems', 'future sustainability global automotive industry greatly affected fourth industrial revolution evolution artificial intelligence ai new normal projected driven new industry standards including increasingly autonomous selfdriving technology amended safety standards complex insurance regulations adaptive social resistance technological change city infrastructure requirements digital divide disruptive business innovation based strategic input supply partnerships opensource ai chapter key factors autonomous vehicles avs analyzed using ai developments radar laser technology commercial risk factors selfdriving consumer behavior city infrastructure constraints social adaptations new technology future trajectory av industry expected interplay commercial social risk infrastructure regulatory mechanisms various impacts industrys stakeholders study predicts likely sustainable scenario av industry driven 1 ais pulsed laser lidar light detection ranging sufficient loop frequency gps bidirectional cloud technology requirement 2 pooled insurance contrast individual liability 3 smart city infrastructure expected sharp digital divide across transport regions leading regional inequality 4 customers strongly prefer human controlled semiautonomous vehicle rather complete machine autonomy', 'convergence humancentric design advanced ai capabilities future autonomous vehicles lies future autonomous vehicles transport passengers also interacted adapted desires making journey comfortable efficient pleasant paper novel framework presented leverages large language models llms enhance autonomous vehicles decisionmaking processes integrating llms natural language capabilities contextual understanding specialized tools usage synergizing reasoning acting various modules autonomous vehicles framework aims seamlessly integrate advanced language reasoning capabilities llms autonomous vehicles proposed framework holds potential revolutionize way autonomous vehicles operate offering personalized assistance continuous learning transparent decisionmaking ultimately contributing safer efficient autonomous driving technologies', 'potential connected automated vehicles multifaceted automated advancement driven internet things iots development enabling artificial intelligence ai early advancements engineering electronics many fields inspired ai several technologies used automated vehicles automated vehicles greatly contribute toward traffic optimization casualty reduction studying vehicle autonomy two categories development available highlevel system integrations like newenergy vehicles intelligent transportation systems involves backward subsystem advancement like sensor information processing systems advanced driver assistance system shows results meet expectations realworld problems vehicle autonomy situational intelligence collects enormous amounts data considered highdefinition creation city maps land surveying quality checking roads well infotainment system transport covers drivers gesture recognition language transaction perception surroundings assistance camera light detection ranging lidar radio detection ranging radar along localization objects scene chapter discusses history autonomous vehicles av trending research areas artificial intelligence technology av stateoftheart datasets used av research several machine learning mldeep learning dl algorithms constituting functioning av system concluding challenges opportunities ai av', 'recent years artificial intelligence become necessary component production service systems technology become vital aspect daily life autonomous driving vehicles operated autonomously also known driverless cars operate without human driver research autonomous vehicles substantially advanced recent years artificially intelligent autonomous vehicles current need society although people might apprehensive give computer control vehicle automated driving technologies potential make roads safer environmental issues well safetyrelated ones addressed selfdriving automobiles unlike humans computers really difficulty keeping attention driving additionally responding appropriately automated car prevent accidents potentially dangerous events road selfdriving technology many advantages one make easily accessible means transport people unable drive variety reasons inexperience incapacity age many people unable operate vehicle individuals travel considerably safely independently therefore chapter architectures software hardware autonomous cars explored well parts benefits future developments', 'transformative era transportation heralded advent autonomous vehicles reshaping landscape mobility cuttingedge technologies integration artificial intelligence ai learning algorithms central evolution propelling vehicles realms unprecedented autonomy comprehensive exploration evolutionary trajectory ai within autonomous vehicles provided paper tracing journey foundational principles recent advancements commencing current landscape overview fundamental role ai shaping autonomous decisionmaking capabilities vehicles delved steps involved aipowered development life cycle vehicles elucidated addressing ethical considerations bias aidriven software development autonomous vehicles statistical insights usage types ailearning algorithms years presented showcasing evolving research landscape within automotive industry furthermore pivotal role parameters refining algorithms trucks cars highlighted facilitating vehicles adapt learn improve performance time different levels autonomy outlined elucidating nuanced usage ai learning algorithms automating key tasks level additionally variation software package sizes across different autonomy levels discussed', 'hospitality industry service failures involving artificial intelligence ai common therefore understanding ai service recovery retain customers crucial article examines ai service recovery different perspective shifting away traditional focus intelligence quotient instead looking impact empathy responses linked emotional intelligence four experimental scenarios research shows highempathy ai response service recovery increase customers intention continue using service also finds psychological distance trust play sequential roles mediating process furthermore study suggests using multisensory stimulus interactions text voice highempathy responses enhances effectiveness ai service recovery compared monosensory interactions text research expands understanding ai service recovery focusing ongoing use ai service failure rather immediate response also highlights importance emotional intelligence ai showing evoke emotional responses customers service recovery ultimately research offers valuable insights developing autonomous solutions ai service failures benefiting research hospitality operators seeking improve ai services', 'charitable organizations worldwide facing shortage manpower address artificial intelligence ai chatbots utilized exact capabilities limitations remain unclear warranting investigation study aimed enhance understanding ai fundraisers involving 654 adults online crowdsourcing platform six chatbot agents developed varying characteristics emotional vs factual different images image machinelike image human image study used independent samples ttest analyze impact chatbots conversational styles willingness donate ukraine war victims additionally serial multiple mediation analysis conducted examine mediating roles perceived humanness empathy toward victims relationship chatbots emotional expression willingness donate study also tested moderating effect visual cues image machinelike image human image using moderated serial multiple mediation analysis findings indicated emotional chatbots led higher willingness donate perceived humanness empathy mediating relationship independently serially however visual cues significantly moderate relationship chatbot agents emotional expression willingness donate', 'integrating empathy healthcare chatbots seen promising approach evoke sense human connection however current research often overlooks complexity empathy leading limited understanding whether artificial empathy perceived similarly human empathy study argues incorporating experiential forms empathy could unintended negative effects may come across inauthentic instead providing instrumental support might effective modeling artificial empathy aligns better typical expectations interactions chatbots two experimental studies using healthcare chatbots investigated impact empathetic feeling sympathetic feeling behavioralempathetic empathetic helping responses compared nonempathetic responses perceived warmth perceived authenticity effects trust intentions use results showed form empathy compared empathy increased perceived warmth leading higher levels trust intentions use chatbot hypothesized empathetic sympathetic responses reduced perceived authenticity chatbot counteracted positive effects studies however third study replicate negative effect humanhuman interactions research highlights empathy translate equally interactions humans bots also introduces concept perceived authenticity demonstrates attributes typically associated humans may backfire feeling inauthentic interactions chatbots', 'interactive software agents like chatbots increasingly used health wellbeing contexts engaging users conversations coaching comfort behaviorchange interventions however lack tools understand agents empathic abilities address need clear understanding empathy despite various definitions literature consensus formal definition systematic literature review qualitative analysis recent approaches empathy interactive agents health wellbeing developed formal definitionan ontologyof empathy definition applied controlled user study assess empathy two stateoftheart health wellbeing chatbots replika wysa results indicate definition captures essential aspects assessing empathy interactive agents elucidate trends changing perceptions empathy time implemented web ontology language owl definition could serve automated tool systems recognize empathy interactions whether interactive agent evaluating empathic performance intelligent system assessing empathic capability users', 'paper introduces groundbreaking framework designed transform chatbot systems incorporating realtime face emotion recognition natural language processing framework currently development demonstrates proficiency various tasks including generating captions object counting answering queries using parameterefficient finetuning openflamingo lowrank adapter lora framework prioritizes versatility efficiency central approach instruction templates merge vision language data enhancing chatbots adaptability emphasizing importance highquality training data research lays foundation creating versatile conversational agent applications customer service mental health support', 'background lack studies examining practicality using large language models llms respond queries autistic individuals chineselanguage setting chinese spoken large population worldwide research using models healthcare centered englishspeaking communities objective research seeks evaluate well llm chatbots including chatgpt4 openai ernie bot version 223 baidu inc perform responding queries autistic individuals chinese context methods research collected data dxy wellknown webbased medical consultation platform china user base exceeding 100 million individuals meticulously selected 100 patient consultation samples january 2018 august 2023 comprising 239 questions extracted publicly available documents related autism platform ensure impartiality original questions responses anonymized randomized evaluation team consisting 3 chief physicians assessed responses based 4 criteria relevance accuracy usefulness empathy total team conducted 717 evaluations initially team identified best response used likert scale 5 response categories rate responses representing different level quality finally compared responses collected various sources', 'initial installment series artificial intelligence cancer clinical research crucial delve definition intelligence key attributes linked human intelligence intelligence concept primarily associated humans encompassing perception cognition thought conceptualization pattern recognition symbolic processing creativity problemsolving intelligencelike traits observed living beings human intelligence often seen product conscious awareness ability form concepts capacity symbolic processing language development faculty reasoning decisionmaking judgment navigating surroundings despite acknowledging existence intelligencelike features species consciousness selfawareness remain enigmatic profound aspects human experience question arises intricate interplay atoms molecules adhering physical laws coupled complex neural network central nervous system give rise conscious experience thoughts reasoning emotional experiences joy sadness love beauty machine learning ml handle conceptual processes extent human intellect unique ability generate novel abstract concepts structure environment lead discovery abstract ideas processes offer insights beyond tangible world shaping individual symbolic systems reflect active curiosity pursuit meaning genuine comprehension world around us whereas sign represents observable aspect external world analyzed algorithmically replicated symbol elicits abstract internal response detached specific concrete event human symbolic systems facilitate communication cognitive information enabling language also conveyance emotional information many humanitys significant noble qualities stem development creative use symbolic systems contributing formation culture myth idealism empathy sign seen objective characteristic object situation symbol resonates internal experiences gaining significance within context emotions interests influenced past experiences memories well current situation interplay results generation feelings emotions within us portraying us active contributors construction world', 'humanai interaction become focal point creating technology responsive empathetic artificial empathy strategies particularly intriguing context potential enhance customer experiences affectively socially study seeks investigate artificial empathy strategies optimize humanai interactions improve customer experiences research methodology employed qualitative involving review various studies relevant literature data sources include journals articles books related research topic findings indicate implementing artificial empathy strategies humanai interactions significantly enhance quality interactions customer experiences technologies natural language processing emotion recognition sentiment analysis enable ai respond accurately sensitively user needs emotions', 'eliza alexa conversational agents cas intentionally designed express evoke empathy empathy enhance technologys ability meet human needs also misleading potentially exploitative study focuses understanding empathy interactions cas emphasizing need differentiate empathetic interactions two humans involving human ca conducted systematic interactions cas powered large language models llms prompting demonstrate empathy conversing 65 different human identities also compared various llms express model empathy findings reveal cas tend make value judgments certain identities inadvertently promote identities associated harmful ideologies eg nazism xenophobia furthermore computational analysis empathy indicates despite ability exhibit empathy cas struggle accurately interpret explore users experiences skill human counterparts excel', 'empathy computing emerging field blends artificial intelligence ai big data technologies predict identify simulate generate human empathy draws psychological studies empathy concepts measurements neural foundations applications employing innovative computing methods analyzing simulating empathy article critically reviews current research empathy computing discusses future directions psychological perspective advance foundational research practical applications research empathy computing categorized four themes based different purposes methods first focus analyzing understanding empathy using computers includes individual empathy assessment empathetic content classification texts second research simulating expressing empathy computing involves designing empathetic response systems developing generative empathetic dialogue systems research streams relatively independent yet complementary field progresses new directions may emerge enhancing computer empathic capabilities braincomputer interface technology although empathy computing early stages shows promise innovative applications mental health education business services public management mental health help evaluate enhance therapists empathetic abilities provide personalized empathetic support aidriven chatbots education facilitate learning empathetic ai tutors business enables tailored customer experiences empathic dialogues public management generate empathetic discourse help policymakers respond empathetically citizen needs scenarios highlight potential empathy computing complete reliance computers empathetic tasks currently impractical due safety ethical concerns collaboration humans computers necessary empathy computing represents transformative frontier enriching theoretical landscape empathy research exploring empathy emerging humanai relationships raises questions universality empathy evolution humancomputer interaction empathy computing could serve cornerstone unified theory empathy encompasses diverse relationship dynamics humanhuman humanmachine interactions collaboration psychologists computer scientists crucial effective ethical ai learning empathy promoting wellbeing intelligent society future research focus developing integrated theoretical models empathy computing establishing reliable datasets empathyrelated characteristics validating empathy computing research humancentered approach psychologists involvement essential guiding optimizing research practice empathy computing collaborative efforts psychology computer science key ensuring ai learns empathy effectively ethically benefiting society intelligent future', 'advanced computational techniques knowledgebased systems kbs soft computing methods scm machine learning models mlm evolutionary algorithms ea swarm intelligence si natureinspired algorithms nia recently widely applied power electronics motor control systems computational method distinct features attributes recently researchers developed model emotional processing mammalian brain known brain emotional learning based intelligent controller belbic findings demonstrate belbics capability manage unknown nonlinear dynamic systems consequently belbic readily integrated specialized mechatronics industrial applications', 'purpose review emotion artificial intelligence ai technology emotion detection recognition emotion ai expanding rapidly commercial government settings outside healthcare increasingly become routine part daily life goal narrative review increase awareness widespread use emotion ai concerns commercial use emotion ai relation people mental health conditions recent findings paper discusses emotion ai fundamentals general overview commercial emotion ai outside healthcare examples use emotion ai employee recruitment workplace surveillance summary successful reintegration individuals mental health conditions society must recognize increasing commercial use emotion ai concerns commercial use emotion ai increase stigma discrimination negative consequences daily life people mental health conditions commercial emotion ai algorithm predictions mental health conditions treated medical fact', 'braincomputer interaction bci system intelligence become reliant electroencephalogram eegbased emotion detection due various applications emotion classification recommendation systems cognitive load monitoring etc emotion classification recently gained significant attention artificial intelligence aidriven research article presented systematic review automated emotion detection eeg signals using ai review process follows preferred reporting items systematic reviews metaanalyses prisma guidelines subsequently eeg datasets eeg preprocessing techniques included study also covered feature extraction feature selection methods additionally included studies categorized two types deep learning dlbased emotion detection systems ii machine learning mlbased emotion classification models examined systems analyzed based features classification methodologies classifiers types classified emotions accuracy datasets utilized also interesting comparison look emerging research trends suggestions future study areas', 'humans possess certain social emotional skills enable interact effectively others one ability recognize emotions ability significantly enhances human interactions progress towards era increasing humanmachine interaction systems essential develop algorithms endow machines similar social emotional skills primary area research emotion detection involves recognizing emotions facial images ability identify human emotions allows machines adapt respond human needs comfort levels emotion detection performed using various modalities video audio images text biometric data etc study explores emerging trends emotion recognition using facial images automated recognition human emotions potential predict psychiatric conditions underlying mental health issues', 'artificial intelligence chatbots proliferated tourism industry due costeffectiveness high efficiency however impact chatbots emotional expressions service outcomes extensively studied researchers drawing expectancy violations theory investigated chatbots emotional expressions influence customer satisfaction three experiments context tourist attraction recommendations chatbots expressing concern customers enhance customer satisfaction mitigating expectancy violations specifically customer goal orientation humanlikeness chatbot avatars type relationship customers chatbots moderate negative relationship emotional expression expectancy violation findings contribute research chatbots emotional expressions offer valuable insights implementing chatbots customer service within tourism industry', 'paper first investigates english text emotion expression information communication categorizes aspects based human emotionvalue relationship summarizes characteristics secondly using artificial intelligence technology proposes constructing analysis model english text emotion information communication using bilstm neural network process characteristics english text quickly efficiently necessary encode emotional information english text based encoding bilstm neural network applied extract emotional features english text address issue emotional feature loss loss function web scraper used obtain dataset chinese english module mooc chinese universities evaluation metrics set according models performance followed experimental analysis english text emotion expression information conveyance results show compared original cnn lstm tlstm bilstmbased neural network performs better task text emotion expression information conveyance accuracy rate staying 0925 effect english dataset slightly better chinese dataset study aims enhance english teaching communication chinese foreign cultures', 'automated dialogue systems significant applications artificial intelligence yet traditional systems struggle comprehend user emotions offer empathetic responses study integrates emotional intelligence technology automated dialogue systems creating dialogue generation model imbued emotional intelligence using deep learning natural language processing techniques model realtime detect understand broad spectrum emotions specific pain signals enabling system provide empathetic interactions incorporating findings study artificial intelligence detect pain express pain empathy models capacity grasp subtle aspects pain empathy augmented establishing higher benchmarks emotional intelligence dialogue systems project aims provide theoretical insights practical recommendations integrating advanced emotional intelligence capabilities dialogue systems thereby enhancing user experience interaction quality', 'research suggests machines capable simulating empathy responding emotionally increase user acceptance sense affinity towards machine reduces negative perceptual feedback imbue robot emotional intelligence must equipped sensors capable detecting users emotions sense process captured emotions regulate internal state compute ultimately perform tasks actions influenced computed emotional state act despite significant progress artificial intelligence speech recognition synthesis computer vision many disciplines related artificial emotional recognition behavior still far equipping robots empathic capabilities humans article aims provide overview implications introducing emotional intelligence robotic systems discussing recent advances emotional intelligence robotics', 'emotion recognition involves accurately inferring human emotions various sources modalities including questionnaires physical signals physiological signals recently growing interest emotion recognition due wideranging applications affective computing healthcare humanrobot interactions market research paper presents comprehensive systematic review emotion recognition techniques current decade focusing physical physiological signals physical signals include speech facial expressions physiological signals encompass electroencephalogram eeg electrocardiogram ecg galvanic skin response gsr eye tracking paper introduces various emotion models stimuli used emotion elicitation background existing automated emotion recognition systems covers thorough search review wellknown datasets following design criteria review indepth analysis discussion 142 journal articles selected using prisma guidelines review offers detailed analysis existing studies available datasets emotion recognition along potential challenges existing literature directions future research', 'paper explores utilization artificial intelligence emotion detection neuromarketing aiming identify user emotions webcam using convolutional neural networks cnns initial section provides overview neural networks including basic types distinctions focus convolutional neural networks cnns adept processing gridlike data images emotion recognition facilitated use faceapijs library implements models like ssd mobilenet v1 tiny face detector mtcnn tiny face detector model utilized application offers realtime face detection small size speed moderate resource consumption compatible web mobile platforms second part paper details development application utilizing faceapijs library emotion detection designed support neuromarketing research application enables marketers analyze advertising material displaying content collecting data viewing storing graphically presenting data analysis section provides indepth explanation emotion detection process lastly paper evaluates developed solution experimentation demonstrating systems ability recognize user emotions satisfactory level precision advertising content preassigned parameters representing desired results compared obtained results determine advertisements success', 'ai deep learning prediction user behavior achieved anticipate address potential barriers use ui design cost quantified experience metrics reveal problems users encounter using interface ui make targeted optimization time artificial intelligence widely used walks life way users interact digital world also needs incorporate intelligent elements reduce cost connectivity accurate analysis experience indicators combined ai technology optimize design gap users digital world greatly reduced making digital products suitable user needs achieving seamless interactive experience improve user experience also promote development ui design userfriendly intelligent direction', 'art known pave way exploring conveying new possibilities nowadays interdisciplinary fields artificial life artificial intelligence computational biology synthetic biology increasingly emerging public view necessary reconsider relations material body identity natural world concept life survey provides literature review recent works artificial life visual art past 40 years specifically computational software domain aim provide systematic overview artists understanding nature creating new life modern technology proposed set criteria taxonomy briefly analyze representative artworks different categories', 'survey general trajectory artificial intelligence ai last century context influences artificial life risks may blamed exclusively human usersthe robots could care less similar divide regrettably unrecognized way ai problems framed latter approach enabled advances deep learning astonishing ai advances see todaybringing immense benefits also societal risks date overwhelmingly gofaistic meaning tools humans use developed agency motivations broad brush divide technical approaches solving ai problems two camps gofaistic computationally inspired cybernetic alife inspired explore implications concerns existential risk humans robots taking', 'artificial intelligence ai revolutionary impact societies traditionally ai developed software neuromorphic engineering hardware work two promising approaches boosting cai described one regards designing implementing neural surrogates communicate optical chemical signals give rise networks computational purposes develop micronanorobotics recently brandnew strategy proposed socalled chemical ai cai exploits molecular supramolecular systems chemistry wetware mimic human intelligence topics presented basic level mainly inform broader audience nonspecialists favour rise interest frontier subjects helping humans facing global challenges century approach concerns bottomup synthetic cells exploited applications various scenarios including future nanomedicine', 'recent innovations humancentric functional modeling hcfm seek represent natural phenomena terms graphs called functional state spaces fss consist discrete states functionality separated interactions regions matter andor antimatter transition one state functionality another approaches called humancentric hypothesized human organism constrained laws thermodynamics perceive observable world terms fss fss processes consist minimally reducible set reversible operations functions goal monograph encourage exploration components theories might align emerging established scientific concepts simulating physical processes processes domain abstract functionality systems represented terms fss hypothesized network effects create potential significantly even exponentially increase general problemsolving ability human groups hypothetical fss networks', 'reviewing discussions examples artificial intelligence use education particularly primary school contexts focus real implications key educational challenge obviously advent technological transformations risk generating reinforcing inequalities social groups equal access guaranteed artificial intelligence robotics pose range social pedagogical practical ethical also social justice issues challenges dealing changes educational processes lastly using analogy development classical literacy readingwriting discuss need propose artificial intelligence robotics literacy courses teachers technologies used widely among different age groups grades one elements sure characterise future education artificial intelligence used tool improve teaching learning processes well work teachers administrators focus possibility personalising learning pathways describing primary school initiatives aimed fostering effective collaborative communication skills order recognise identify also prevent factors impacting learning disorders', 'one hand development artificial intelligence increasingly important impact economic system also peoples lives opening new scenarios imposing new constraints giving rise new opportunities time emerging potential threat humanity artificial intelligence tool must used care caution also taking account possible risks involved risks become greater powerful calculation tools need abandon approach based optimistic prejudice towards artificial intelligence often presented panacea evils thaumaturgic properties extended problems situations issue machine ethics forcefully raised scientific level', 'author calls total ban ai suggests could prompt reevaluation neoliberal capitalism need address existential threats article explores various risks associated ai including extreme genetic engineering threats financial system lethal autonomous weapons economic inequality environmental impact erosion human relationships ai offers many benefits improving energy solutions accessibility information negative consequences outweigh shortterm advantages author highlights missed opportunities past prevent negative impacts technologies like automobiles toxic chemicals article discusses potential dangers artificial intelligence ai argues must stopped', 'evolutionary computation subfield artificial intelligence artificial life uses biologically inspired methods solve optimization problems using iterative refinements set solutions via change selection successful applications counted multiple domains including limited optimization machine learning robotics various areas study living systems approach began 1950s constitutes growing set algorithms capable solving wide range problems divided various types differ selection mutation representation candidate solutions unique potential generate endless innovations lead paradigm shift development artificial intelligence artificial life evolutionary computation recently seen revival particularly study openended evolution important implications future ai', 'purpose study study possibilities multigenerational optimization behavior control systems agents general artificial intelligence capable independently solving universal range tasks real environment software package simulating processes ontophylogenetic synthesis multiagent neurocognitive architectures developed experiments carried create phenotypes intelligent agents based main principles ontophylogenetic synthesis control systems agents general artificial intelligence based multiagent neurocognitive architectures developed shown multigenerational optimization multiagent neurocognitive architecture intelligent agents contribute achievement adaptive resistance operating conditions general artificial intelligence agent provide synthesis suboptimal structural functional scheme accelerate learning algorithms finding solutions universal range problems solved agent ecological niche methods algorithms synthesizing phenotypes control systems intelligent agents according genotypes proposed complex genome intelligent agent developed features multichromosome genetic algorithm organizing calculations paradigm multigenerational optimization multiagent neurocognitive architectures established substantiated', 'article explored fusion fuzzy logic fl group theory within realm artificial intelligence ai uncovering transformative synergy promised enhance adaptability robustness intelligent systems beginning individual examination fuzzy logic group theory paper established theoretical foundations integration fuzzy logics capacity handle uncertainty harmonized group theorys prowess revealing structural insights leading unified framework integration validated series compelling case studies experiments across diverse domains ranging adaptive robotics control healthcare decision support practical applications showcased collective impact fl group theory demonstrating improved adaptability precision resilience complex scenarios results reaffirmed theoretical foundations also provided tangible evidence integrated approachs potential looking toward future paper outlined key directions research including refinement theoretical foundations integration machine learning addressing challenges scalability explainability ethical considerations crossdisciplinary collaboration continuous validation emphasized crucial elements shaping trajectory interdisciplinary exploration', 'study explore dynamic field fuzzy logic artificial intelligence ai financial analysis 1990 2023 utilizing bibliometrix package rstudio data web science focus identifying mathematical models evolving role fuzzy information granulation domain research addresses urgent need understand development impact fuzzy logic ai within broader scope evolving technological analytical methodologies particularly concentrating application financial banking contexts bibliometric analysis involve extensive review literature published period examine key metrics annual growth rate international collaboration average citations per document highlight fields expansion collaborative nature results reveal significant annual growth rate international collaboration average citation per document major journals ieee transactions fuzzy systems fuzzy sets systems journal intelligent fuzzy systems information sciences emerge significant contributors aligning bradfords laws zone 1 notably post2020 ieee transactions fuzzy systems show substantial increase publications significant finding high citation rate seminal research fuzzy information granulation emphasizing mathematical importance practical relevance financial analysis keywords like design model algorithm optimization stabilization terms fuzzy logic controller adaptive fuzzy controller fuzzy logic approach prevalent countries collaboration world map indicate strong pattern global interconnections suggesting robust framework international collaboration study highlight escalating influence fuzzy logic ai financial analysis marked growth research outputs global collaborations underscore crucial role fuzzy information granulation mathematical model set stage investigation fuzzy logic aidriven models transforming financial banking analysis practices worldwide', 'paper presented method providing explainability integration artificial intelligence ai data mining techniques dealing meteorological prediction explainable artificial intelligence xai refers transparency ai systems providing explanations predictions decisionmaking processes contributes improving prediction accuracy enhancing trust ai systems focus paper relied interpretability challenges ordinal classification problems within weather forecasting ordinal classification involves predicting weather phenomena ordered classes temperature ranges wind speed precipitation levels others address challenge novel general explicable forecasting framework combined inductive rules fuzzy logic proposed work inductive rules derived historical weather data provided logical interpretable basis forecasting fuzzy logic handled uncertainty imprecision weather data system predicted set probabilities incoming sample belonged considered class moreover allowed expert decisionmaking process strengthened relying transparency physical explainability model output blackbox algorithm proposed framework evaluated using two realworld weather databases related wind speed lowvisibility events due fog results compared ml classifiers specific methods ordinal classification problems achieving competitive results terms ordinal performance metrics offering higher level explainability transparency compared existing approaches', 'interpretable artificial intelligence ai also known explainable ai indispensable establishing trustable ai benchtobedside translation substantial implications human wellbeing however majority existing research area centering designing complex sophisticated methods regardless interpretability consequently main prerequisite implementing trustworthy ai medical domains met scientists developing various explanation methods interpretable ai among methods fuzzy rules embedded fuzzy inference system fis emerging novel powerful tool bridge communication gap humans advanced ai machines however reviews use fiss medical diagnosis addition application fuzzy rules different kinds multimodal medical data receiving insufficient attention despite potential use fuzzy rules designing appropriate methodologies available datasets review provide fundamental understanding interpretability fuzzy rules conduct comparative analyses use fuzzy rules explanation methods handling three major types multimodal data ie sequence signals medical images tabular data offer insights appropriate fuzzy rule application scenarios recommendations future research', 'due advancement complexity modern automobiles fault detection gone beyond manual trial error methods fault detection technologies automotive industry used identify potential existing faults automobiles faults automobiles usually mechanical electrical including airbag control unit malfunctions radiator issues gearbox problems transmission control unit errors tire pressure abnormalities brake failures air conditioner malfunctions cylinder casket issues alternator faults hub malfunctions etc fault specific related signs symptoms several methods fault detection automobiles binary logic technique fuzzy logic method artificial intelligence technique different algorithms research work employed fuzzy logicbased technique uses mamdani algorithm presented better fault detection mechanism mamdanis algorithm proposed ebrahim mamdani fuzzy inference method rulebases intuitive easier analyze implement mamdanis algorithm produce fuzzy sets originate fuzzy inference systems output membership function decisionmaking research work webbased technology implemented using javascript jquery sql server aspnet bootstrap 35 css output system shown greater improvement existing methods fault detection automobiles', 'wireless sensor network wsn distributed collection tiny lowpower wireless devices deployed physical environment monitor various environmental conditions data collected positioned sensor nodes transmitted destination nodes using multihop communications wsns offer numerous advantages networks including enhanced flexibility low cost simplified deployment due resourceconstrained nature wsns face various challenges issues need addressed ensure reliable secure data transmission nodes wsns highly vulnerable various types security attacks namely black hole attacks denial service dos attacks node compromise attacks among attacks black hole attack pose serious threat nodes network attack carried malicious nodes intentionally drop data packets control packets without forwarding intended destination ensure security network black hole attacks necessary design efficient intrusion detection technique idt detecting malicious nodes work novel fuzzy logicbased intrusion detection system hidden markov model fidshmm proposed identify malicious nodes mitigate black hole attacks moreover hmm employed proposed protocol monitor energy levels nodes detect malicious nodes effectively implementation proposed protocol carried using ns2 simulator simulation results justify proposed protocol namely fidshmm providing efficient detection mechanism black hole attacks network moreover proposed protocol improve quality service qos parameters namely packet delivery ratio delay throughput network efficiency', 'article presented model adjustable moisture control historical buildings proposed system developed form flexible iot infrastructure complex system sensors set measure inside conditions humidity compare results levels groundwaters rain wind speed manage drying system developed control model used type2 fuzzy logic reasoning flexibly adjust decisions intensity water absorption way proposed model made innovative intelligent system controlling interior conditions historical buildings developed system installed examined old brewery building showing efficiency dehumidification lowest cost', 'semantic features play pivotal role natural language processing providing deeper understanding meaning context within textual data realm machine learning artificial intelligence semantic feature extraction involve translating linguistic elements numerical representations often utilizing advanced techniques like word embeddings deep learning models integration semantic features enhance precision contextawareness language models enabling applications sentiment analysis document categorization information retrieval operate greater accuracy relevance paper introduce novel approach hierarchical mandhami optimized semantic feature extraction hmosfe designed enhance semantic feature extraction english sentences proposed hmosfe model comprise fusion hierarchical clustering fuzzybased feature extraction hmosfe aim capture intricate semantic relationships within sentences providing nuanced insights underlying meaning textual content model employ pretrained word embeddings term representation calculate similarity matrix using cosine similarity utilize hierarchical clustering document grouping fuzzy logic contribute assigning weights features enabling refined understanding semantic significance paper present comprehensive results including semantic similarity estimations clustering distances fuzzy memberships demonstrating effectiveness hmosfe across diverse documents', 'intelligent lighting system public lighting system used artificial intelligence technology optimize energy management improve quality lighting public areas paper presented use two prominent artificial intelligence methods namely fuzzy logic neural networks intelligent power control public lighting networks primary objective study evaluate performance approaches optimizing power consumption achieving efficient lighting taking consideration two parameters namely road flow weather conditions achieve lighting system modeled using state flow tool matlabsimulink various algorithms based fuzzy logic artificial neural networks subsequently developed real data traffic flow cloud cover utilized train algorithms upon analysis simulation results observed overall results closer algorithm based fuzzy logic yielded algorithms based neural networks', '21st century global waste challenges expected worsen developing nations rely manual sorting improper waste disposal pose significant threats human health environment necessitating adoption artificial intelligencebased solid waste segregation technology aibswst context advanced frank tnorm capture nuanced relationships fuzzy logic crucial scenarios order fuzzy sets matters building principles complex qrung picture fuzzy set cqrpfs become instrumental representing decisionmakers preferences twodimensional manner enhancing handling vague information realworld scenarios expanding foundational principles paper introduce innovative frank operations grounded frank tnorms within context cqrpfs leveraging operations paper propose four robust aggregation operators aos cqrpfs complex qrung picture fuzzy frank weighted average cqpffwa complex qrung picture fuzzy frank weighted geometric cqpffwg complex qrung picture fuzzy frank ordered weighted average cqpffwoa complex qrung picture fuzzy frank ordered weighted geometric cqpffwog aos exhibit essential properties idempotency monotonicity boundedness multicriteria decisionmaking mcdm method based proposed aos suggested validate strategies reallife case study indias adoption aibswst serve practical application thorough analyses including sensitivity comparative superiority assessments evaluating performance approaches thoughtful discussion pros cons proposed aos accompany analysis emphasizing significance approach ensuring cleanliness health developing nations', 'information overload plethora options brought easy internet access technological advancements making decisionmaking extremely difficult recommender system rs seen potential solution assisting users making decisions recommending predicting product ratings collaborative contentbased hybrid filtering three fundamental forms rs use implicit explicit feedback recommendation ratings common form feedback product descriptions reviews images audios videos also important help improve performance traditional rs additional variables significant impact rss performance approaches based nearest neighbor machine learning models used traditional rss recent advances artificial intelligence deep learning led development rss using convolutional neural networks cnn efficiently exploit auxiliary information addition comparing cnnbased rss common grounds article provides full examination cnnbased rss might use various types auxiliary information study also discusses data characteristics data statistics auxiliary information variety publicly available datasets different evaluation measures rss also discussed readers provided interesting challenges open research issues', 'recent years continuous progress development science technology especially continuous development artificial intelligence machine algorithm technologies personalized content begun implemented education system moving away traditional functions traditional education systems often characterized adopting onesizefitsall approach teaching consider unique needs learning styles student education system personalized optimized machine learning algorithms provide customized learning materials recommendations based students learning history interests abilities improve learning outcomes realtime feedback student performance provided machine learning algorithms learning plans adjusted based feedback making learning process dynamic personalized therefore applied types education including language learning mathematics science etc however improving efficiency machine learning algorithms depends improvement numerical optimization algorithms necessary summarize optimization algorithms largescale machine learning paper tries make detailed overview existing machine learning algorithms optimizing personalized education recommendation systems introduces algorithm optimization process', 'comprehensive literature review research application machine learning ml algorithms recommender systems rs presented paper study aims identify recent trends explore reallife applications guide researchers positioning research activities domain published 2023 janjune findings categorized different domains including education healthcare ml algorithms autoencoders reinforcement learning ecommerce digital journalism review highlights enhanced recommendation accuracy increased scalability personalization context awareness diverse ml techniques strategies handling cold start data sparsity foundation future advancements ml algorithms rss considering application manufacturing enterprises', 'convergence information communication technologies ict urban management improve quality life city dwellers characterizes smart cities context recommender systems tools offer personalized suggestions city dwellers emerged key contributors convergence successful application various areas city life ability process massive amounts data generated urban environments expedited status crucial technology evolution city planning methodology included reviewing web science database resulting 130 articles filtered relevancy reduced 86 first stage consisted carrying bibliometric analysis objective analyzing structural aspects scimat tool secondly undertook systematic literature review using prisma 2020 statement results illustrated different processes recommendations filtered areas tourism health mobility transport research seen significant breakthrough drive evolution efficiency smart cities establishing solid framework future research dynamic field', 'remote healthcare applications based internet things iot provide fast preventative medical services patients risk however predicting heart disease complex task diagnosis results rarely accurate address issue novel recommendation system cardiovascular disease prediction using iot network deepcardio proposed provide prior diagnosis treatment dietary recommendations cardiac diseases initially physiological data collected patients remotely using four biosensors ecg sensor pressure sensor pulse sensor glucose sensor collected data received arduino controller iot sensors predict diagnose disease cardiovascular disease prediction model implemented using bigru bidirectionalgated recurrent unit attention model diagnoses cardiovascular disease classifies five available cardiovascular classes recommendation system provides physical dietary recommendations cardiac patients based classified data via user mobile application performance deepcardio validated cloud simulator cloudsim using realtime framinghams statlog heart disease dataset proposed deep cardio method achieves overall accuracy 9990 whereas mabcsvm hcbda mlbpm method achieves 8691 8865 9363 respectively', 'latest effort delivering computing resources service managers consumers represents shift away computing product purchased computing service delivered users internet largescale data centers however advent cloudbased iot artificial intelligence ai advancing customer experience automations many application areas recommender systems rs need arisen various modifications support iot devices center automation world including recent language models like chatgpt bard technologies like nanotechnology paper introduces marketing community recent computing development iotdriven fog computing fc although numerous research studies published fc smart applications none hitherto conducted fogbased smart marketing domains recommender systems fc considered novel computational system mitigate latency improve bandwidth utilization autonomous consumer behavior applications requiring realtime datadriven decisionmaking conceptual framework provided paper studying effects fog computing consumer behavior goal stimulating future research using example intersection fc rs indeed conceptualization fogbased recommender systems opens many novel challenging avenues academic research highlighted later part paper keywords fog computing recommender system internet things iot edge computing artificial intelligence ai softwaredefined networks sdns', 'purpose general purpose study investigate effectiveness recommender systems knowledge discovery methodology desktop research methodology adopted study desk research refers secondary data collected without fieldwork desk research basically involved collecting data existing resources hence often considered lowcost technique compared field research main cost involved executives time telephone charges directories thus study relied already published studies reports statistics secondary data easily accessed online journals library findings revealed findings exists contextual methodological gap relating recommender systems knowledge discovery study effectiveness recommender systems knowledge discovery found systems played pivotal role facilitating users exploration vast information repositories enabling uncover relevant resources expand knowledge found recommender systems employing advanced algorithms personalized techniques demonstrated higher effectiveness generating relevant recommendations tailored users preferences needs additionally positive correlation user engagement metrics knowledge discovery outcomes highlighted emphasizing importance fostering active user participation recommendation process contextual information also identified crucial factor influencing recommendation effectiveness overall study underscored significance continuous refinement optimization recommender system algorithms enhance knowledge discovery outcomes users unique contribution theory practice policy social learning theory information foraging theory cognitive load theory may used anchor future studies recommender systems knowledge discovery recommendations enhance efficacy systems provided study suggested adopting hybrid recommender systems combine collaborative contentbased filtering techniques offer accurate diverse recommendations additionally importance integrating contextual information recommendation algorithms dynamically adjust recommendations based situational context emphasized furthermore use explainable ai techniques improve transparency user understanding recommendation processes recommended maximizing user engagement active participation feedback also highlighted crucial along prioritizing recommendation diversity foster exploration serendipitous discovery new knowledge resources', 'application artificial intelligence ai significantly increased many human resources hr functions research aims understand potential artificial intelligencebased recommender systems match job profiles employee profiles perceived diverse experts distinct organisations project managers managers supervisors human resource managers study employs delphi studybased methodology specifically organising expert panel provides opinions ratings comments set propositions based online delphi study results participant opinions research aims identify challenges related employeejob profile matching artificial intelligence machine learning tools form recommender systems study various challenges matching employee profiles job profiles current problems faced executives human resource personnel supervisors project managers organisation delved study also sheds light potential feasibility solutions artificial intelligence form recommender systems couple propositions focus potential solutions various challenges matching employee profiles job profiles organisation also tested', 'facial expression recognition fer utilized various fields education gaming robotics healthcare others facial expression techniques instance interactive robot artificial intelligence recognize human faces detect emotions person conversing use emotions choose appropriate answers one use case face emotion detection playing music based users mood users facial expression analyzed deduce feelings result investigation required new emotion models existing ones struggle correctly measure musics connection facial emotion paper kind job implemented using convolution neural network cnn based deep learning approach deep learning effectively analyze unstructured data movies forms media machine learning research realtime system created recognize human faces assess human emotions even recommend music users oahega fer2013 datasets utilized experimental study two emotion recognition models created trained using various combinations datasets accuracy proposed model 7302 using cnn model six emotions predicted anger fear joy neutral sadness surprise proposed system utilized different places realtime facial recognition plays important role', 'given challenges interdomain information fusion data sparsity collaborative filtering algorithms crossdomain information fusion matrix decomposition algorithm proposed paper enhance accuracy personalized recommendations artificial intelligence recommendation systems study begins collecting douban movie rating data social network information ensure data integrity levenshtein distance detection employed remove duplicate scores natural language processing technology utilized extract keywords topic information social texts additionally graph convolutional networks utilized convert user relationships feature vectors unique thermal coding method used convert discrete user movie information binary matrices prevent overfitting ridge regularization method introduced gradually optimize potential feature vectors weighted average feature connection techniques applied integrate features different fields moreover itembased collaborative filtering algorithm combined merged user characteristics generate personalized recommendation lists experimental stage crossdomain information fusion optimization conducted four mainstream mathematical matrix decomposition algorithms alternating least squares method nonnegative matrix decomposition singular value decomposition latent factor model lfm algorithms compared nonfused approach results indicate significant improvement score accuracy mean absolute error root mean squared error reduced 128 132 respectively across four algorithms additionally k 10 average f1 score reaches 097 ranking accuracy coverage lfm algorithm increases 542 overall mathematical matrix decomposition algorithm combined crossdomain information fusion demonstrates clear advantages accuracy prediction performance recommendation diversity ranking quality improves accuracy diversity recommendation system effectively addressing collaborative filtering challenges integration diverse techniques traditional models recommendation accuracy variety significantly surpassed', 'metaverse digital environment users interact virtual objects quickly becoming reality artificial intelligence ai increasingly shaping development opening new immersive experiences study examines ai combined technologies like internet things blockchain natural language processing virtual reality augmented reality mixed reality extended reality within metaverse one advantage ai metaverse ability tailor experiences individual users based behavior preferences additionally ai automate mundane tasks allowing time creative endeavors however challenges privacy bias discrimination must addressed exploring aspects including ethical concerns better prepare future vr study provides thorough overview ais integration emerging metaverse technologies emphasizing importance staying updated rapidly evolving field', 'realm artificial intelligence undergone significant transformation last decade particularly emergence deep learning led notable advancements across various industries creative fields however advantages hold video game sector game artificial intelligence ai longstanding discipline three decades addressing specific challenges strategic adversaries nonplayer characters gameplay pacing procedural content generation chapter emphasizes fundamental areas traditional rulebased ai continues excel machine learning offering novel alternatives conventional methods additionally explores new possibilities arising ai reshaping game development including player behavior analysis enhanced graphics animation control automated quality assurance testing', 'artificial general intelligence agi concept suggesting artificial intelligence ai advancements could lead creation entity surpassing even intelligent humans concept present since early stages ai development sparked various discussions ai might interact humans fictional works research studies paper examines current progress ai discusses ongoing ai competition rapidly introducing new impressive ai techniques capable surpassing human performance previously unimaginable tasks disrupting job market advancements raised concerns agi might become reality sooner anticipated however paper argues deep neural networks currently form foundation ai methods unlikely lead agi due inherent limitations instead suggests threats stemming current ai race related limitations applications lack regulation surrounding existing models algorithms rather emergence agi', 'predicting winners esports realtime analytics potential enhance viewer engagement major tournament events however task challenging due games unpredictable variables diverse player strategies decisionmaking research aims increase audience engagement video game tournaments introducing realtime prediction method determining wins utilize long short term memory network lstms based approach efficiently predicts winlose outcomes using health indicator player time series demonstrate approach evaluate performance classic twoplayer arcade game super street fighter ii turbo additionally compare method stateoftheart time series forecasting methods transformer models found large language models llms lastly provide dataset code opensource resources encourage development predictive analysis arcade games', 'project draws inspiration turnbased strategy games like final fantasy tactics xcom 2 recent titles genre aims leverage artificial intelligence enhance storytelling strategy games specifically project focuses using ai develop quest generation system storytelling purposes system generates new quests dynamically interacting ai enabling players potentially enjoy everexpanding story quests', 'chapter examines digital technology utilized advance peacebuilding education considering potential benefits risks proposes approach grounded humancentered design hcd prioritizes needs perspectives learners three case studies chapter showcases potential digital storytelling artificial intelligence ai gaming supporting peacebuilding efforts first case study illustrates use digital storytelling teaching genocide second highlights ais role safeguarding victims violence third case study explores gaming employed raise awareness war authors recognize technology presents multifaceted area study suggest imaginative exercises envision possibilities liberatory design conclusion chapter underscores significance recognizing technologys dual nature capacity contributing conflict fostering peacebuilding', 'dynamic virtual reality vr transformed gaming entertainment offering immersive experiences transport users new realms study introduces innovative concept virtual reality horror sports blending horror sports vr propose adaptive approach developing vr horror games combining player modeling adaptive meansbased system learns players fears adjusts game content accordingly research presents two key advancements unique method identifying player fears game data machine learning adaptive game system using agents monitor player terror limit exposure distressing elements additional evidence user studies statistical testing suggests approach heightens stress anxiety gamers enhancing experience combining vr horror sports creates compelling immersive entertainment experience players immersed lifelike thrilling virtual environment dynamic vr horror sports experience enhanced artificial intelligence ai player modeling offers comprehensive form entertainment blending physical activity customization immersion endeavor could advance vr ai gaming providing gamers exciting adventures', 'utilizing gamification video games contemporary method enhancing cognitive abilities managerial competencies particularly strategic thinking skills many organizations apply video games across various sectors education marketing business entrepreneurship achieve ends study aimed explore impact video games enhancing strategic thinking among managers potential developing cognitive capabilities study involved 30 students actively engaged innovation entrepreneurship ecosystem assess participants strategic thinking pisapias strategic thinking questionnaire utilized cognitive capabilities measured using cantab test indicators micromanagement planning plan recognition predictions resource gathering partial observability damage avoidance designed identify individuals gameplaying styles results showed 533 percent participants demonstrated reflective thinking 30 percent exhibited systems thinking remainder displayed reframing thinking style dominant strategic thinking dimension moreover correlation identified criteria damage avoidance reflective thinking style inverse significant correlation criteria gathering resources prm test results suggests strategic games potential influence enhance certain cognitive functions like attention reaction memory making valuable tools improving cognitive abilities consequently games leveraged create tasks enhance managerial cognitive abilities thereby promoting strategic thinking decisionmaking skills', 'research explores potential enhancement business simulation games bsg automated adaptable learning bsg given rapid expansion information complexity contemporary business environments traditional bsg education methods often fall short adequately preparing students realworld challenges address study proposes innovative framework continuously adapts learning paths responses testing scenarios based individual student progress preferences achieved application modern artificial intelligence techniques including machine learning aim optimizing users retention knowledge decisionmaking abilities creative thinking skills personalizing learning experience conclusion research contributes ongoing discourse intersection ai education corporate strategies offering prospects enhanced engaging educational approaches modern era', 'growing number people incorporating video games life arouse variety feelings players happiness excitement terror empathy resulting profound level immersion lasting memories feasible use feelings directly game handle idea creating dynamic procedural content generation pcg system emotional game dynamics interaction presented paper approach built affective computing techniques paper created emotion recognition system based fuzzy logic order accomplish goal artificial neural networks handled pcg affective computing techniques including interacting emotional expression lot offer video game business player emotional investment crucial add something fresh variety interactions humans computers']\n",
            "Construction: ['recent developments artificial intelligence ai generated great expectations future impact ai education learning aied often expectations based misunderstanding current technical possibilities lack knowledge stateoftheart ai education exceedingly narrow views functions education society article provide review existing ai systems education pedagogic educational assumptions develop typology aied systems describe different ways using ai education learning show grounded different interpretations ai education could discuss potential roadblocks aied highway', 'artificial intelligence ai developing application spreading alarming rate ai become part daily lives matter fact ai changed way people learn however adoption educational sector saddled challenges ethical issues purpose study analyze opportunities benefits challenges ai education review available relevant literature done using systematic review method identify current research focus provide indepth understanding ai technology education educators future research directions findings showed ais adoption education advanced developed countries research became popular within industry 40 era challenges well recommendations discussed study', 'study provided content analysis studies aiming disclose artificial intelligence ai applied education sector explore potential research trends challenges ai education total 100 papers including 63 empirical papers 74 studies 37 analytic papers selected education educational research category social sciences citation index database 2010 2020 content analysis showed research questions could classified development layer classification matching recommendation deep learning application layer feedback reasoning adaptive learning integration layer affection computing roleplaying immersive learning gamification moreover four research trends including internet things swarm intelligence deep learning neuroscience well assessment ai education suggested investigation however also proposed challenges education may caused ai regard inappropriate use ai techniques changing roles teachers students well social ethical issues results provide insights overview ai used education domain helps strengthen theoretical foundation ai education provides promising channel educators ai engineers carry collaborative research', '2021 30 countries released national artificial intelligence ai policy strategies documents articulate plans expectations regarding ai impact policy sectors including education typically discuss social ethical implications ai article engages thematic analysis 24 national ai policy strategies reviewing role education global ai policy discourse finds use ai education aied largely absent policy conversations instrumental value education supporting aiready workforce training ai experts overwhelmingly prioritized ethical implications aied receive scant attention despite prominence ai ethics discussion generally documents suggests aied broader policy ethical implicationsgood badhave failed reach mainstream awareness agendas key decisionmakers concern given effective policy careful consideration ethics inextricably linked article argues light findings article applies framework five ai ethics principles consider ways policymakers better incorporate aieds implications finally article offers recommendations aied scholars strategies engagement policymaking process performing ethics policyoriented aied research end order shape policy deliberations behalf public good', 'artificial intelligence ai reshaping world profound ways impacts certainly beneficial widespread lasting harms result technology well integration ai various aspects human life underway complex ethical concerns emerging design deployment use technology serves reminder time revisit future developers designers along professionals learning comes ai paramount importance train future members ai community stakeholders well reflect ways ai might impact peoples lives embrace responsibilities enhance benefits mitigating potential harms could occur part fuller systematic inclusion ai ethics curriculum paper briefly describe different approaches ai ethics offer set recommendations related ai ethics pedagogy', 'artificial intelligence education aied research core desire support student learning experience ai domains suggest ethical intentions sufficient also need consider explicitly issues fairness accountability transparency bias autonomy agency inclusion general level also need differentiate ethical things things ethically understand make pedagogical choices ethical account everpresent possibility unintended consequences however addressing related questions far trivial first step towards addressing critical gap invited 60 aied communitys leading researchers respond survey questions ethics application ai educational contexts paper first introduce issues around ethics ai education next summarise contributions 17 respondents discuss complex issues raised specific outcomes include recognition aied researchers trained tackle emerging ethical questions welldesigned framework engaging ethics aied combined multidisciplinary approach set robust guidelines seems vital context', 'educational applications ai combination pasteurs quadrant describes useinspired basic pure applied research article gives overview classical emerging architectures ai education early researchers focused creating personalized teaching systems based solitary learners whereas recent work takes account people learning context various grand challenges illustrate issues still facing ai education', 'engineering education constantly evolving keep latest technological developments meet changing needs engineering industry one promising development field use generative artificial intelligence technology chatgpt conversational agent chatgpt potential offer personalized effective learning experiences providing students customized feedback explanations well creating realistic virtual simulations handson learning however important also consider limitations technology chatgpt generative ai systems good training data may perpetuate biases even generate spread misinformation additionally use generative ai education raises ethical concerns potential unethical dishonest use students potential unemployment humans made redundant technology current state generative ai technology represented chatgpt impressive flawed preview come important engineering educators understand implications technology study adapt engineering education ecosystem ensure next generation engineers take advantage benefits offered generative ai minimizing negative consequences', 'article examines benefits risks artificial intelligence ai education relation fundamental human rights article based eu scoping study berendt b littlejohn p kern p mitros x shacklock blakemore 2017 big data monitoring educational systems luxembourg publications office european union httpspublicationseuropaeuenpublicationdetailpublication94cb5fc8473e11e7aea801aa75ed71a1 study takes account potential ai big data provide effective monitoring education system realtime also considers implications fundamental human rights freedoms teachers learners analysis highlights need balance benefits risks ai tools developed marketed deployed conclude call embed consideration benefits risks ai education technology tools development marketing deployment tools questions around body organisation take responsibility regulating ai education particularly since ai impacts data protection privacy fundamental rights general given ais global impact regulated transnational level global organisation un taking role', 'defining aspect modern age tenacious belief technology walks life least education could argued infatuation technology technophilia education deep impact classroom changing relationship teacher student well students relations become increasingly iit ithou based capacity form bonds level connectedness teacher students students either decreased become impaired increasing technologisation education running parallel perhaps exacerbating problem socalled process learnification understands teachers mere facilitators learning process rather someone expertise something teach others article first assess current technologisation education impact relations within classroom second characterise bubers iit ithou relations implications education finally investigate thought experiment development ai could 1 day successfully replace human teachers classroom', 'agriculture ultimate imperative primary source origin furnish domestic income multifarious countries disease caused plants due various pathogens like viruses fungi bacteria liable considerable monetary losses agriculture corporation across world security crops concerning quality quantity crucial monitor disease plants thus recognition plant disease essential plant disease syndrome noticeable distinct parts plants nonetheless commonly infection detected distinct leaves plants computer vision deep learning fewshot learning soft computing techniques utilized various investigators automatically identify disease plants via leaf images techniques also benefit farmers achieving expeditious appropriate actions avoid reduction quality quantity crops application techniques recognition disease avert disadvantage origin factious selection disease features extraction features boost speed technology efficiency research also certain molecular techniques established prevent mitigate pathogenic threat hence review helps investigator automatically detect disease plants using machine learning deep learning shot learning provide certain diagnosis techniques prevent disease moreover future works classification disease also discussed', 'large number functional sensors installed modern intelligent vehicles many artificial intelligence based foundation models proposed smart sensing recognize known object classes new similar scenarios however still challenging foundation models smart sensing detect object classes seen unseen scenarios letter aims pushing boundary smart sensing research intelligent vehicles first summarize current widelyused foundation models foundation intelligence needed smart sensing intelligent vehicles explain sorabased parallel vision boost foundation models smart sensing basic intelligence 10 enhanced intelligence 20 final generalized intelligence 30 several representative case studies discussed show potential usages sorabased parallel vision followed future research direction', 'artificial intelligence become significant tool modern technology enabling people interact machines various methods individuals visual impairments trouble tasks either blind poor vision bvi stands blind visually impaired solutions must also advance technology ensure individuals effectively navigate surroundings assist realtime navigation study conducts surveys visually challenged individuals community aims assist providing smart gadgets identify faces colours objects moreover study emphasizes different technologies methods used earlier help visually impaired people daytoday life', 'world major portion populace suffer daily challenges blindness pioneering project introduces comprehensive smart support system designed aid needs people visually impaired advanced system ingeniously integrated pair headphones combining various stateoftheart technologies cameras ultrasonic sensors cuttingedge machine learning algorithms primary goals encompass recognizing objects accurately estimating distances objects users deciphering captured signs indications offering realtime locationbased navigation directions multifunctional blind assistance device designed empower users enhancing spatial awareness providing tools need navigate travel securely represents remarkable leap forward refining overall quality life mobility blind people', 'unmanned aerial vehicles uavs attracted massive attention many engineering practical applications last years characteristics operation flexibility uav system suitable control systems required operate appropriately efficiently emerging control technique visual servoing utilizing onboard camera systems inspecting uavs environment autonomously controlling uavs operation artificial intelligence ai techniques widely deployed visual servoing autonomous uav applications despite increasing research field aibased visual control uav systems comprehensive review articles showcase general trends future directions field research limited work comprehensively examines application advancements aienhanced visual servoing autonomous uav systems covering critical control tasks offering insights future research directions enhancing performance applicability limited current literature paper first reviews application intelligent visual servoing systems autonomously executing various uav control tasks including 3d uav positioning aerial ground object following obstacle avoidance autonomous landing second research progresses applying ai techniques visual servoing autonomous uav systems discussed analyzed finally future directions critical research gaps improving performance applicability intelligent visual servoing systems included keywords unmanned aerial vehicles visual servoing artificial intelligence artificial neural networks fuzzy logic reinforcement learning', 'revolution digital computer technology made possible new sophisticated imaging techniques may next influence interpretation radiologic images mammography computer vision artificial intelligence techniques used successfully detect characterize abnormalities digital images radiologists supplied information often perform better mammographic detection characterization tasks observer studies unaided radiologists technology therefore could decrease errors mammographic interpretation continue plague human observers', 'grain production plays important role global economy sense demand efficient safe methods food production increasing information technology one tools end among available tools highlight computer vision solutions combined artificial intelligence algorithms achieved important results detection patterns images context work presents systematic review aims identify applicability computer vision precision agriculture production five produced grains world maize rice wheat soybean barley sense present 25 papers selected last five years different approaches treat aspects related disease detection grain quality phenotyping results systematic review possible identify great opportunities exploitation gpu graphics processing unit advanced artificial intelligence techniques dbn deep belief networks construction robust methods computer vision applied precision agriculture', 'technology advanced surgery especially minimally invasive surgery mis including laparoscopic surgery robotic surgery led increase number technologies operating room provide information surgical procedure eg instrument usage trajectories among surgeryrelated technologies amount information extracted surgical video captured endoscope especially great therefore automation data analysis essential surgery reduce complexity data maximizing utility enable new opportunities research development computer vision cv field study deals computers understand digital images videos seeks automate tasks performed human visual system field deals processes realworld information acquisition computers terminology cv extensive ranges hardware image sensing aibased image recognition aibased image recognition simple tasks recognizing snapshots advanced comparable humans recent years although surgical video recognition complex challenging task effectively apply mis leads future surgical advancements intraoperative decisionmaking support image navigation surgery ultimately automated surgery might realized article summarize recent advances future perspectives airelated research development field surgery', 'introduction compared printtospeech properties human performance characteristics two artificial intelligence vision aids orcam myeye 1 portable device seeing ai iphone ipad application methods seven participants visual impairments experience two reading aids four participants light perception two individuals measurable acuity one light perception tested blindfolded also tested performance text varying appearance varying viewing conditions evaluate human performance asked participants use devices attempt 12 reading tasks similar activities daily living assessed ranges text attributes reading possible print size contrast light level also assessed individuals could complete tasks devices measured accuracy completion time participants also completed survey concerning two aids results aids achieved greater 95 accuracy text recognition flat plain word documents ranged 13 57 accuracy formatted text curved surfaces aids could read print sizes small 08m 2040 snellen equivalent 40 cm viewing distance individuals successfully completed 71 55 p 114 tasks using orcam myeye 1 seeing ai respectively significant difference time completion tasks p 775 individuals believed aids would helpful daily activities discussion orcam myeye 1 seeing ai similar textreading capability usability aids useful users severe visual impairments performing reading tasks implications practitioners selection reading device aid based individual preferences prior familiarity platform since found clear superiority one solution', 'one branches machine learning deep learning model combined artificial intelligence widely used field computer vision technology image recognition field represented medical image analysis also developing advantage rely human annotation computer recognize process feature information omitted human beings model training process achieve even exceed accuracy human processing based general lack explain ability caused unknown data processing process deep model existing solutions mainly include establishment internal explain ability attention mechanism interpretation specific models interpretation unknowable models represented lime way quantitatively assess interpretability still explored especially interpretative assessment doctors patients medical decisionrelated models several scales proposed reference current research application artificial intelligence deep learning models medical imaging generally pays attention accuracy rather explain ability resulting lack explain ability thus hindering practical clinical application deep learning models therefore need analyze development medical image analysis field artificial intelligence computer vision technology balance accuracy interpretability develop deep learning models doctors patients trust become research focus industry future', 'paper mainly discusses asymmetric face recognition problem number names name list number faces photo might equal face automatically labeled name motivation issue many meetings past meeting participant took group photos meeting provided corresponding name list participants without onetoone labels worst case group photo might mix faces participating meeting another reason asymmetric face recognition meeting personnel appear photos assisted taking pictures paper proposes asymmetric face recognition mechanism called afrm short initially proposed afrm adopts histogram oriented gradients hog support vector machine svm detect extract faces photos next afrm extracts features face using convolution feature map conv_ff adopts features partition faces different classes afrm applies statisticbased mechanism map name name list face class according mapping face associated one name quickly identify face meeting afrm applies knearest neighbors knn represent features face new meeting proposed afrm extract feature one face adopts knn derive features experimental results show proposed mechanism achieves 97 accuracy without onetoone name face labeling', 'face essential part human body distinctive traits crucial recognizing people facial recognition technology frt one successful fascinating technologies modern times world moving towards contactless frt covid19 pandemic due contactless biometric characteristics frt becoming quite popular worldwide businesses replacing conventional fingerprint scanners artificial intelligencebased frt opening enormous commercial prospects security surveillance authenticationaccess control systems digital healthcare photo retrieval etc sectors use become essential present communication presented global adoption frt rising trend market utilization technology various sectors challenges rising concerns special reference india worldwide', 'measures success facial feminization surgery ffs previously included improved rates external gender perception female patientreported outcome measures study used artificial intelligence facial recognition software objectively evaluate effects ffs perceived gender age among maletofemale transgender patients well relationship patient facial satisfaction standardized frontal preoperative postoperative images 27 transgender women undergoing ffs analyzed amazons ai facial recognition software determine gender femininity confidence score perceived age female gendertyping improvement gendertyping preoperatively postoperatively femininity confidence scores analyzed assess patient satisfaction faceq modules completed postoperatively preoperatively ffs images perceived female 481 time postoperatively improved 741 p005 femininity confidence scores improved mean score 004 preoperatively 039 postoperatively p0003 ffs associated decrease perceived age relative patients true age 24 p0001 older patients experiencing greater reductions pearson correlation matrix found significant relationship improved female gender typing patient facial satisfaction undergoing surgery younger age associated higher overall facial satisfaction r06 p001 transfeminine patients experienced improvements satisfaction facial appearance perceived gender decreases perceived age following ffs notably patient satisfaction directly associated improved aigender typing suggesting factors may influence patient satisfaction', 'surprisingly high accuracies previously reported exceeding 95 dropped significantly faced demanding conditions forensic scenario plummeting low 65 essence facial recognition systems shown impressive performance ideal conditions study indicates substantial decrease accuracy faced complexities challenges typical realworld forensic scenarios highlighting need advancements bridge gap recent advancements machine learning computer vision shown facial recognition systems achieving accuracies surpass human performance controlled settings fingerprint analysis proved accurate aspects investigate created largescale synthetic facial dataset designed controlled facial lineup mimics conditions encountered real forensic situations approach allowed us systematically assess facial recognition various challenging realworld conditions using synthetic dataset wellknown dataset actual faces tested accuracy two widely used neuralbased facial recognition systems comparative analytical method applied present research artificial intelligence could help humans accuracy speeding process investigation', 'facial recognition wellestablished popular field computer vision especially advancements deep learning data sets deep facial recognition made significant progress widely applied realworld scenarios complete facial recognition system involves three main components facial recognition orientation representation system detects faces aligns standard view extracts features recognition using deep convolutional neural networks article provides detailed overview latest advancements areas showing deep learning greatly enhanced abilities object detection machine vision challenging area requires significant improvements image classification accuracy nearing 225 surpassing human performance object detection algorithms still early stages current algorithms achieve 408 maps modern objects careful dataset selection crucial optimal results', 'face recognition recently gained significant attention one useful image analysis applications leveraging unique incredible identification skills systems capable recognizing users face recognition systems extensively studied system however number drawbacks existing face recognition methods may result longer histogram slows largescale database address challenges face recognition proposed hybrid descriptor using multiblock local ternary pattern ltpgray level co occurrence matrix glcm study employed ltp glcm speeded robust features surf methods extract illumination rotation scaleinvariant features face database images features trained using artificial neural network layer neurons optimally selected crow search optimization cso method yielded accuracy 95 proposed approach implemented matlab software experimental data analyzed show developed texture descriptor higher recognition rate existing methods', 'rise deep neural networks performance biometric systems increased tremendously biometric systems face recognition used everyday life eg border control crime prevention personal device access control although accuracy face recognition systems generally high without flaws many biometric systems found exhibit demographic bias resulting different demographic groups recognized accuracy especially true facial recognition due demographic factors eg gender skin color many previous works already reported demographic bias work aims reduce demographic bias biometric face recognition applications regard 12 face recognition systems benchmarked regarding biometric recognition performance well demographic differentials ie fairness subsequently multiple fusion techniques applied goal improve fairness contrast single systems experimental results show possible improve fairness regarding single demographics eg skin color gender improving fairness demographic subgroups turns challenging', 'nigeria many different security concerns thus crimes increased despite fact stringent laws punishments place deter making appear though authorities unable stop order identify criminals conduct investigations imperative facial recognition system connected constantly updated digital library focus paper develop automatic criminal investigation system identify criminals based faces produce realtime digital archives however object detection method facial recognition model new system built haar cascades classifier technique opencv package additionally appropriate programming languages may provide needed results investigated python 36 used django 42 framework opencvpython dlib language execution due djangos orm support numerous databases usage sqlite3 database straightforward database employed lightweight applications 12 factor app idea used construct dicafr systems essential skills face detection applied image using haar method processing postprocessing discovered face compared wellknown criminal face encodings matching purposes results demonstrated dicafrs could effectively replace human systems since recover faces furthest distances display name offender sound alert dica web apps output screen dica system working prototype system might used criminal investigative process nigeria', 'facial expression recognition fer utilized various fields education gaming robotics healthcare others facial expression techniques instance interactive robot artificial intelligence recognize human faces detect emotions person conversing use emotions choose appropriate answers one use case face emotion detection playing music based users mood analyze users facial expression deduce feelings result new emotion models require investigation existing ones struggle correctly measure musics connection facial emotion paper implement kind job using convolution neural network cnn based deep learning approach deep learning effectively analyze unstructured data movies forms media machine learning research created realtime system recognize human faces assess human emotions even recommend music users oahega fer2013 datasets utilized experimental study created trained two emotion recognition models using various combinations datasets proposed models accuracy 7302 using cnn model predict six emotions anger fear joy neutral sadness surprise proposed system utilized different places realtime facial recognition plays important role', 'facial expression recognition fer utilized various fields education gaming robotics healthcare others facial expression techniques instance interactive robot artificial intelligence recognize human faces detect emotions person conversing use emotions choose appropriate answers one use case face emotion detection playing music based users mood analyze users facial expression deduce feelings result new emotion models require investigation existing ones struggle correctly measure musics connection facial emotion paper implement kind job using convolution neural network cnn based deep learning approach deep learning effectively analyze unstructured data movies forms media machine learning research created realtime system recognize human faces assess human emotions even recommend music users oahega fer2013 datasets utilized experimental study created trained two emotion recognition models using various combinations datasets proposed models accuracy 7302 using cnn model predict six emotions anger fear joy neutral sadness surprise proposed system utilized different places realtime facial recognition plays important role', 'autonomous vehicles avs expected reshape future transportation systems decision making one critical modules toward highlevel automated driving overcome complicated scenarios rulebased methods could cope well datadriven decisionmaking approaches aroused focus datasets used developing datadriven methods dramatically influence performance decision making hence necessary comprehensive insight existing datasets aspects collection sources driving data divided vehicle environment driverrelated data study compares stateoftheart datasets three categories summarizes features including sensors used annotation driving scenarios based characteristics datasets survey also discusses potential applications datasets various aspects av decision making assisting researchers finding appropriate ones support research future trends av dataset development summarized', 'accurate trajectory tracking unrealistic realworld scenarios however commonly assumed facilitate motion planning algorithm design paper safe reliable motion planning control framework proposed handle tracking errors caused inaccurate tracking coordinating motion planning layer controller specifically motion space divided safe regions risky regions designing movement restraint size dependent tracking error construct repulsive potential field collisionfree waypoint set obtained combining global search proposed waypoint set filtering method planned trajectory fitted optimizationbased approach minimizes acceleration reference trajectory planned trajectory checked modified designed anticollision modification ensure safety using invertible transformation adaptive compensation allows transient trajectory tracking errors limited within designed region even actuator faults tracking error considered margined planning level safety reliability guaranteed coordination planning control levels inaccurate tracking actuator faults advantages effectiveness proposed motion planning control method verified simulation experimental results', 'would people distribute risks autonomous vehicles avs everyday road traffic rich literature ethics autonomous vehicles avs revolves around moral judgments unavoidable collision scenarios argue extending debate driving behaviors everyday road traffic ubiquitous ethical questions arise due permanent redistribution risk among road users distribution risks raises ethically relevant questions cannot evaded simple heuristics hitting brakes using interactive graphical representation different traffic situations measured participants preferences driving maneuvers avs representative survey germany participants preferences deviated significantly mere collision avoidance interestingly participants willing take risks benefit road users suggesting social dilemma avs may mitigated risky environments research might build bridge engineers philosophers discuss ethics avs constructively', 'artificial intelligence one emerging technologies simulate human intelligence machines programming think like human beings mimic actions autonomous vehicle function carry necessary functions without human involvement innovative technology may provide increased passenger safety less congested roads congestion reduction optimum traffic lower fuel consumption less pollution better travel experiences autonomous vehicles play vital role industry agriculture transportation military applications autonomous vehicles activities supported sensor data artificial intelligence systems artificial intelligence collection data path planning execution autonomous vehicles require machine learning techniques part artificial intelligence comes privacy issues security concerns security important concern autonomous vehicles issues cybersecurity incorporating artificial intelligence autonomous vehicles covered article along growing technology selfdriving automobiles', 'throughout last decades number vehicles road steadily increased due rising demand urban mobility contemporary logistics two many detrimental effects vehicles road also impede economic development increased traffic congestion traffic accidents issues mentioned significantly resolved making vehicles smarter reducing reliance humans past century various nations conducted extensive research fueled automation road vehicles development autonomous vehicle av technologies currently pursued significant motor manufacturers worldwide undoubtedly widespread use autonomous cars imminent realize given development artificial intelligence ai order avs perceive surroundings make right decisions real time ai emerged crucial component development ai driven growth big data numerous sensing devices cuttingedge computing resources must first examine ais development history order comprehend functions av systems', 'future sustainability global automotive industry greatly affected fourth industrial revolution evolution artificial intelligence ai new normal projected driven new industry standards including increasingly autonomous selfdriving technology amended safety standards complex insurance regulations adaptive social resistance technological change city infrastructure requirements digital divide disruptive business innovation based strategic input supply partnerships opensource ai chapter key factors autonomous vehicles avs analyzed using ai developments radar laser technology commercial risk factors selfdriving consumer behavior city infrastructure constraints social adaptations new technology future trajectory av industry expected interplay commercial social risk infrastructure regulatory mechanisms various impacts industrys stakeholders study predicts likely sustainable scenario av industry driven 1 ais pulsed laser lidar light detection ranging sufficient loop frequency gps bidirectional cloud technology requirement 2 pooled insurance contrast individual liability 3 smart city infrastructure expected sharp digital divide across transport regions leading regional inequality 4 customers strongly prefer human controlled semiautonomous vehicle rather complete machine autonomy', 'future autonomous vehicles lies convergence humancentric design advanced ai capabilities autonomous vehicles future transport passengers also interact adapt desires making journey comfortable efficient pleasant paper present novel framework leverages large language models llms enhance autonomous vehicles decisionmaking processes integrating llms natural language capabilities contextual understanding specialized tools usage synergizing reasoning acting various modules autonomous vehicles framework aims seamlessly integrate advanced language reasoning capabilities llms autonomous vehicles proposed framework holds potential revolutionize way autonomous vehicles operate offering personalized assistance continuous learning transparent decisionmaking ultimately contributing safer efficient autonomous driving technologies', 'potential connected automated vehicles multifaceted automated advancement deals internet things iots development enabling artificial intelligence ai early advancements engineering electronics many fields inspired ai several proposals technologies used automated vehicles automated vehicles contribute greatly toward traffic optimization casualty reduction studying vehicle autonomy two categories development available highlevel system integrations like newenergy vehicles intelligent transportation systems involves backward subsystem advancement like sensor information processing systems advanced driver assistance system shows results meet expectations realworld problems vehicle autonomy situational intelligence collects enormous amounts data considered highdefinition creation city maps land surveying quality checking roads well infotainment system transport covers drivers gesture recognition language transaction perception surroundings assistance camera light detection ranging lidar radio detection ranging radar along localization objects scene chapter discusses history autonomous vehicles av trending research areas artificial intelligence technology av stateoftheart datasets used av research several machine learning mldeep learning dl algorithms constituting functioning av system concluding challenges opportunities ai av', 'artificial intelligence necessary component production service systems recent years technology become vital aspect daily life automated driving vehicles operate autonomously also known driverless cars operate without human driver research autonomous vehicles substantially advanced recent years artificially intelligent autonomous vehicles current need society although people might apprehensive give computer control vehicle automated driving technologies potential make roads safer selfdriving automobiles address environmental issues well safetyrelated ones unlike humans computers really difficulty keeping attention driving additionally responding appropriately automated car prevent accidents potentially dangerous events road selfdriving technology many advantages one make easily accessible means transport people unable drive variety reasons inexperience incapacity age many people unable operate vehicle individuals travel considerably safely independently therefore explore architectures software hardware autonomous cars chapter well parts benefits future developments', 'advent autonomous vehicles heralded transformative era transportation reshaping landscape mobility cuttingedge technologies central evolution integration artificial intelligence ai learning algorithms propelling vehicles realms unprecedented autonomy paper provides comprehensive exploration evolutionary trajectory ai within autonomous vehicles tracing journey foundational principles recent advancements commencing current landscape overview paper delves fundamental role ai shaping autonomous decisionmaking capabilities vehicles elucidates steps involved aipowered development life cycle vehicles addressing ethical considerations bias aidriven software development autonomous vehicles study presents statistical insights usage types ailearning algorithms years showcasing evolving research landscape within automotive industry furthermore paper highlights pivotal role parameters refining algorithms trucks cars facilitating vehicles adapt learn improve performance time concludes outlining different levels autonomy elucidating nuanced usage ai learning algorithms automating key tasks level additionally document discusses variation software package sizes across different autonomy levels', 'artificial intelligence ai service failures inevitable hospitality companies thus ai service recovery retains customers issue cannot ignored article focuses ai service recovery abandoning traditional intelligence quotient thinking exploring recovery effect empathy response perspective emotional intelligence using four experimental scenarios results indicate service recovery highempathy ai response increase customers continuous usage intention psychological distance trust sequential mediators process compared monosensory stimulus interactions text highempathy response adopts multisensory stimulus interactions text voice could strengthen recovery effect empathy responses paper extends field ai service research focus time phase continuing use ai service failure also moves beyond traditional intelligence quotient improvement thinking reveals importance using ai emotional intelligence activate customer emotional response ai service recovery finally provides useful tool resolving ai service failure problems autonomously service process great value research development hospitality operators promotion application ai services', 'charitable organizations experiencing global labor shortage artificial intelligence ai chatbots employed help combat shortage however scope limits ai fundraisers still unclear calling investigation improve understanding ai fundraisers study recruited 654 adults online crowdsourcing platform developed six chatbot agents emotional vs factual image vs machinelike image vs human image first employed independent samples ttest examine effect chatbots conversational style willingness donate ukraine war victims study also tested mediating roles independent serial perceived humanness empathy toward victims relationship chatbots emotional expression willingness donate conducting serial multiple mediation analysis finally study tested moderating role visual cues image vs machinelike image vs human image conducting moderated serial multiple mediation analysis results revealed emotional chatbots yield higher willingness donate perceived humanness empathy toward victims mediate relationship independently serially however results suggest visual cues significantly moderate relationship chatbot agents emotional expression willingness donate', 'implementing empathy healthcare chatbots considered promising create sense human warmth however existing research frequently overlooks multidimensionality empathy leading insufficient understanding artificial empathy perceived similarly interpersonal empathy paper argues implementing experiential expressions empathy may unintended negative consequences might feel inauthentic instead providing instrumental support could suitable modeling artificial empathy aligns better computerlike schemas towards chatbots two experimental studies using healthcare chatbots examine effect empathetic feeling sympathetic feeling behavioralempathetic empathetic helping vs nonempathetic responses perceived warmth perceived authenticity consequences trust using intentions results reveal kind empathy vs empathy enhances perceived warmth resulting higher trust using intentions hypothesized empathetic sympathetic responses reduce chatbots perceived authenticity suppressing positive effect studies third study replicate backfiring effect humanhuman interactions research thus highlights empathy equally apply humanbot interactions introduces concept perceived authenticity demonstrates distinctively human attributes might backfire feeling inauthentic interactions chatbots', 'interactive software agents chatbots progressively used area health wellbeing applications agents engage users interpersonal conversations eg coaching comfort behaviorchange interventions increased need understanding agents empathic capabilities current stateoftheart tools order understand empathic capabilities interactive software agents need precise notion empathy literature discusses variety definitions empathy consensus formal definition based systematic literature review qualitative analysis recent approaches empathy interactive agents health wellbeing formal definitionan ontologyof empathy developed present potential formal definition controlled userstudy applying tool assessing empathy two stateoftheart health wellbeing chatbots replika wysa findings suggest definition captures necessary conditions assessing empathy interactive agents uncover explain trends changing perceptions empathy time definition implemented web ontology language owl may serve automated tool enabling systems recognize empathy interactionsbe interactive agent evaluating empathic performance intelligent system assessing empathic capability interlocutors', 'evolving landscape humancomputer interaction paper introduces innovative framework poised revolutionize chatbot systems framework meticulously designed emotionally aware multimodal chatbots seamlessly integrates realtime face emotion recognition natural language processing currently developmental phase framework exhibits distinctive proficiency executing diverse array human instructions instructions span tasks generating detailed captions object counting responding general queries leveraging parameterefficient finetuning openflamingo augmented inclusion lowrank adapter lora framework strategically prioritizes versatility operational efficiency core approach lies establishment instruction templates intricately merge vision language data strategic integration forms backbone multimodality instruction tuning methodology enhancing adaptability chatbot recognizing pivotal role highquality training data emphasize significance shaping dialogue performance chatbot framework progresses developmental stages research lays robust foundation creation versatile conversational agent envisioned applications agent range enhancing customer service experiences providing valuable support mental health scenarios', 'background dearth feasibility assessments regarding using large language models llms responding inquiries autistic patients within chineselanguage context despite chinese one widely spoken languages globally predominant research focus applying models medical field englishspeaking populations objective study aims assess effectiveness llm chatbots specifically chatgpt4 openai ernie bot version 223 baidu inc one advanced llms china addressing inquiries autistic individuals chinese setting methods study gathered data dxya widely acknowledged webbased medical consultation platform china user base 100 million individuals total 100 patient consultation samples rigorously selected january 2018 august 2023 amounting 239 questions extracted publicly available autismrelated documents platform maintain objectivity original questions responses anonymized randomized evaluation team 3 chief physicians assessed responses across 4 dimensions relevance accuracy usefulness empathy team completed 717 evaluations team initially identified best response used likert scale 5 response categories gauge responses representing distinct level quality finally compared responses collected different sources', 'first series artificial intelligence cancer clinical research important attempt define concept intelligence important features associate human intelligence intelligence construct associate notably human beings understanding human intelligence including perception cognition thought conceptualization pattern recognition symbolic processing creativity problem solving acknowledge apparent elements intelligence living species commonly think intelligence manifestation conscious awareness ability form concepts along capacity symbolic processing development language ultimately ability reason make decisions use judgement navigate world citation14 time consciousness selfawareness seem fundamental unique human experience concepts remain profound elusive mysteries complex array atoms molecules ultimately behave physical laws motion along intricate network neurons central nervous system give rise internal conscious experience ability think reason along experiences joy sadness love beauty conceptual processes may amenable machine learning ml human intellect capable generating new abstract concepts organize environment importantly discover abstract ideas processes provide new insights beyond actual world sense create world meaningful symbolic systems active curiosity striving meaning true understanding world around us citation2 sign represents characteristic external world amenable algorithmic analysis mimicking symbol evokes abstract internal response separate particular concrete event citation2 human symbolic systems used communication cognitive information enabling language communication emotional information fact many humanitys important highest qualities relate development creative use symbolic systems resulting development culture myth idealism empathy sign thought context free characteristic object situation symbol refers experiences within experiences gain meaning within context emotions interests resulting intersection prior experience memory present situation generate feelings emotions within participate active contributors creation world citation1', 'humanai interaction become important focus development responsive humane technology context use artificial empathy strategies particular interest due potential improving customer experiences affectively socially research aims explore optimization humanai interactions application artificial empathy strategies improving affective social customer experiences research approach used qualitative reviewing various studies related literature data sources used journals articles books relevant research topic research results found implementation artificial empathy strategies humanai interactions great potential improve quality interactions customer experiences use technologies natural language processing emotion recognition sentiment analysis enable ai respond precisely sensitively user needs emotions', 'eliza alexa conversational agents cas deliberately designed elicit project empathy although empathy help technology better serve human needs also deceptive potentially exploitative work characterize empathy interactions cas highlighting importance distinguishing evocations empathy two humans ones human ca end systematically prompt cas backed large language models llms display empathy conversing 65 distinct human identities also compare different llms display model empathy find cas make value judgments certain identities encouraging identities related harmful ideologies eg nazism xenophobia moreover computational approach understanding empathy reveals despite ability display empathy cas poorly interpreting exploring users experience contrasting human counterparts', 'empathy computing emerging research field integrates artificial intelligence ai big data technology predict identify simulate generate human empathy field builds upon psychological studies terms concepts measurements neural foundations applications empathy employs innovative computing approaches analyzing simulating empathy article critically reviews current research empathy computing discusses future directions psychological perspective aim facilitating foundational research practical applications field current research empathy computing categorized four themes based different purposes methods one hand empathy computing primarily aims analyze comprehend empathy using computers endeavor divided two categories 1 individual empathy assessment focuses analyzing individual empathetic traits 2 empathetic content classification focuses analyzing empathetic features texts rather individuals hand research also focuses simulating expressing empathy computing includes 3 design empathetic response systems 4 development generative empathetic dialogue systems former provides users limited number predefined rulebased responses feedback express empathy latter utilizes ai automatically generate wide range empathetic dialogues without relying predefined rules four research streams relatively independent yet complementary moreover research progresses new directions continue emerge improving empathic capabilities computers braincomputer interface technology although research empathy computing still early stages shown potential innovative applications scenarios mental health education business services public management increasing prevalence artificial intelligence fields involve substantial interpersonal interactions positioned become primary domains humancomputer interaction result emerge key application scenarios empathy computing realm mental health empathy computing assist automatically evaluating enhancing therapists empathetic abilities additionally provide personalized empathetic support guidance aidriven chatbots field education empathy computing facilitate learning process employing empathetic ai tutors within business sector enables organizations deliver tailored customer experiences thereby enhancing satisfaction fostering loyalty generation empathic dialogues public management empathy computing used generate empathetic discourse counteract negative speech additionally facilitates policymakers respond empathetically citizens needs inquiries thereby fostering trust government public four scenarios illustrate vast potential applications empathy computing however due concerns related safety ethics complete reliance computers perform empathetic tasks currently feasible instead collaboration humans computers necessary empathy computing represents transformative frontier providing methods measure analyze empathy automatically larger scale also enriching theoretical landscape empathy research extends traditional studies empathy interpersonal relationships explore emerging manifestations humanai relationships expansion raises novel questions universality empathy potential evolution humancomputer interaction empathy computing holds promise serving cornerstone unified theory empathy encompasses diverse relationship dynamics ranging humanhuman humanmachine interactions beyond beneficial comprehensively understanding empathy effectively promoting context intelligent society future research focus developing integrated theoretical models empathy computing establishing reliable psychological behavioral datasets empathyrelated characteristics validating refining empathy computing research humancentered approach psychologists play indispensable roles leading evaluating optimizing research practice field collaboration scholars psychology computer science imperative ensure ai learns empathy effectively ethically thereby fostering peoples wellbeing forthcoming intelligent society', 'artificial intelligence ai techniques eg expert system es fuzzy logic fl artificial neural network ann genetic algorithm ga particle swarm optimization pso biologically inspired bi recently applied widely power electronics motor driveseach ai method uniqueness characteristics recently researchers developed computational model emotional learning mammalian brain namely brain emotional learning based intelligent controller belbic results indicate ability belbic control unknown nonlinear dynamic systems therefore belbic easily adopted niche mechatronics industrial applications', 'purpose review emotion artificial intelligence ai technology emotion detection recognition emotion ai expanding rapidly commercial government settings outside medicine increasingly become routine part daily life goal narrative review increase awareness widespread use emotion ai concerns commercial use emotion ai relation people mental illness recent findings paper discusses emotion ai fundamentals general overview commercial emotion ai outside medicine examples use emotion ai employee hiring workplace monitoring summary successful reintegration patients mental illness society must recognize increasing commercial use emotion ai concerns commercial use emotion ai increase stigma discrimination negative consequences daily life people mental illness commercial emotion ai algorithm predictions mental illness treated medical fact', 'braincomputer interaction bci system intelligence become dependent electroencephalogram eegbased emotion recognition numerous applications emotion classification recommender systems cognitive load detection etc emotion classification drawn recent buzz artificial intelligence aipowered research article presented systematic review automated emotion recognition eeg signals using ai review process carried based preferred reporting items systematic reviews metaanalysesprisma eeg databases eeg preprocessing methods included study also included feature extraction feature selection methods addition included studies divided two types ideep learningdlbased emotion identification systems ii machine learningmlbased emotion classification models examined systems analyzed based features classification methodologies classifiers types classified emotions accuracy datasets employed also interesting comparison look feature research trends ideas new areas study', 'humans certain social emotional capabilities help interact human beings one capability recognize humans emotions capability enhances human interactions great extent move towards age increasing humanmachine interaction systems must strive program machines achieve socalled social emotional capabilities algorithmically primary research frontier emotion detection recognizing using facial images able recognize emotions human helps machine adjust tune humans needs comfort emotion detection performed using various modalities video audio images text biometric information etc study explores emerging trends emotion recognition facial images automated recognition emotions people potential predict psychiatric illness latent mental health issues', 'artificial intelligence chatbots invaded tourism industry owing low cost high efficiency however influence emotional expressions chatbots service outcomes received much attention researchers drawing upon expectancy violations theory explored emotional expressions chatbots affect customer satisfaction using three experiments context tourist attraction recommendations chatbots expressions concern customers improve customer satisfaction reducing expectancy violations particular customers goal orientation humanlikeness chatbots avatars relationship type customers chatbots moderate negative relationship emotional expression expectancy violation findings advance research emotional expressions chatbots provide critical insights deploying chatbots customer service tourism industry', 'paper firstly researches english text emotion expression information communication classifies english text emotion expression information communication according human emotionvalue relationship summarizes characteristics english emotion expression information communication secondly using artificial intelligence technology proposed construct analysis model english text emotion information communication using bilstm neural network deal characteristics english text quickly efficiently necessary encode emotional information english text based encoding bilstm neural network applied extract emotional features english text solve problem loss emotional features loss function crawler tool used obtain dataset chinese english module mooc chinese universities evaluation indexes set according models performance followed experimental analysis english text emotion expression information conveyance results show compared original cnn lstm tlstm bilstmbased neural network performs better task text emotion expression information conveyance accuracy rate staying 0925 effect english dataset bit better chinese dataset study aims enhance english teaching communication chinese foreign cultures', 'automated dialogue systems important applications artificial intelligence traditional systems struggle understand user emotions provide empathetic feedback study integrates emotional intelligence technology automated dialogue systems creates dialogue generation model emotional intelligence deep learning natural language processing techniques model detect understand wide range emotions specific pain signals real time enabling system provide empathetic interaction integrating results study artificial intelligence detect pain express pain empathy models ability understand subtle elements pain empathy enhanced setting higher standards emotional intelligence dialogue systems project aims provide theoretical understanding practical suggestions integrate advanced emotional intelligence capabilities dialogue systems thereby improving user experience interaction quality', 'research suggests emotionally responsive machines simulate empathy increase de acceptance users towards feeling affinity towards machine reduces negative perceptual feedback order endow robot emotional intelligence must equipped sensors capable capturing users emotions sense appraisal captured emotions regulate internal state compute finally perform tasks actions regulated computed emotional state act however despite impressive progress made recent years terms artificial intelligence speech recognition synthesis computer vision many disciplines directly indirectly related artificial emotional recognition behavior still far able endow robots empathic capabilities human article aims give overview implications introducing emotional intelligence robotic constructions discussing recent advances emotional intelligence robotics', 'emotion recognition ability precisely infer human emotions numerous sources modalities using questionnaires physical signals physiological signals recently emotion recognition gained attention diverse application areas like affective computing healthcare humanrobot interactions market research paper provides comprehensive systematic review emotion recognition techniques current decade paper includes emotion recognition using physical physiological signals physical signals involve speech facial expression physiological signals include electroencephalogram electrocardiogram galvanic skin response eye tracking paper provides introduction various emotion models stimuli used emotion elicitation background existing automated emotion recognition systems paper covers comprehensive searching scanning wellknown datasets followed design criteria review thorough analysis discussion selected 142 journal articles using prisma guidelines review provides detailed analysis existing studies available datasets emotion recognition review analysis also presented potential challenges existing literature directions future research', 'subject paper application artificial intelligence detecting emotions neuromarketing goal enable identification user emotions webcam using convolutional neural networks first part paper describes neural networks basic types differences greatest attention given description application convolutional neural networks convolutional neural network also known cnn specialized processing data gridlike topology image user emotion recognition enabled using faceapijs library implements following models ssd mobilenet v1 tiny face detector mtcnn tiny face detector used application model realtime face detection small size speed moderate resource consumption model compatible web mobile platforms second part paper application developed uses faceapijs library detect emotions developed tool support neuromarketing research allows marketer create research analyze advertising material basic functionality display advertising content collect data watching data stored graphically displayed marketer section describes detail detection process works third part paper evaluation made evaluation developed solution performed experiment results show emotions user recognized developed system satisfactory level precision advertising content previously entered parameters represent desired results comparing parameters obtained results marketer decides whether advertisement successful', 'time artificial intelligence widely used walks life way users interact digital world also needs incorporate intelligent elements reduce cost connectivity cost quantified experience metrics reveal problems users encounter using interface ui make targeted optimization ai deep learning prediction user behavior achieved anticipate address potential barriers use ui design improve user experience also promote development ui design userfriendly intelligent direction accurate analysis experience indicators combined ai technology optimize design gap users digital world greatly reduced making digital products suitable user needs achieving seamless interactive experience', 'nowadays interdisciplinary fields artificial life artificial intelligence computational biology synthetic biology increasingly emerging public view necessary reconsider relations material body identity natural world concept life art known pave way exploring conveying new possibilities survey provides literature review recent works artificial life visual art past 40 years specifically computational software domain proposed set criteria taxonomy briefly analyze representative artworks different categories aim provide systematic overview artists understanding nature creating new life modern technology', 'survey general trajectory artificial intelligence ai last century context influences artificial life broad brush divide technical approaches solving ai problems two camps gofaistic computationally inspired cybernetic alife inspired latter approach enabled advances deep learning astonishing ai advances see todaybringing immense benefits also societal risks similar divide regrettably unrecognized way ai problems framed date overwhelmingly gofaistic meaning tools humans use developed agency motivations explore implications concerns existential risk humans robots taking risks may blamed exclusively human usersthe robots could care less', 'artificial intelligence ai revolutionary impact societies helping humans facing global challenges century traditionally ai developed software neuromorphic engineering hardware recently brandnew strategy proposed socalled chemical ai cai exploits molecular supramolecular systems chemistry wetware mimic human intelligence work two promising approaches boosting cai described one regards designing implementing neural surrogates communicate optical chemical signals give rise networks computational purposes develop micronanorobotics approach concerns bottomup synthetic cells exploited applications various scenarios including future nanomedicine topics presented basic level mainly inform broader audience nonspecialists favour rise interest frontier subjects', 'recent innovations humancentric functional modeling hcfm seek represent natural phenomena terms graphs called functional state spaces fss consist discrete states functionality separated interactions regions matter andor antimatter transition one state functionality another approaches called humancentric hypothesized human organism constrained laws thermodynamics perceive observable world terms fss fss processes consist minimally reducible set reversible operations functions hypothetical fss networks simulating physical processes processes domain abstract functionality systems represented terms fss hypothesized network effects create potential significantly even exponentially increase general problemsolving ability human groups goal monograph encourage exploration components theories might align emerging established scientific concepts', 'one elements sure characterise future education artificial intelligence used tool improve teaching learning processes well work teachers administrators artificial intelligence robotics pose range social pedagogical practical ethical also social justice issues challenges dealing changes educational processes reviewing discussions examples artificial intelligence use education particularly primary school contexts focus real implications key educational challenge obviously advent technological transformations risk generating reinforcing inequalities social groups equal access guaranteed focus possibility personalising learning pathways describing primary school initiatives aimed fostering effective collaborative communication skills order recognise identify also prevent factors impacting learning disorders lastly using analogy development classical literacy readingwriting discuss need propose artificial intelligence robotics literacy courses teachers technologies used widely among different age groups grades', 'one hand development artificial intelligence increasingly important impact economic system also peoples lives opening new scenarios imposing new constraints giving rise new opportunities time emerging potential threat humanity need abandon approach based optimistic prejudice towards artificial intelligence often presented panacea evils thaumaturgic properties extended problems situations artificial intelligence tool must used care caution also taking account possible risks involved risks become greater powerful calculation tools issue machine ethics forcefully raised scientific level', 'article discusses potential dangers artificial intelligence ai argues must stopped ai offers many benefits improving energy solutions accessibility information negative consequences outweigh shortterm advantages author highlights missed opportunities past prevent negative impacts technologies like automobiles toxic chemicals article explores various risks associated ai including extreme genetic engineering threats financial system lethal autonomous weapons economic inequality environmental impact erosion human relationships author calls total ban ai suggests could prompt reevaluation neoliberal capitalism need address existential threats', 'evolutionary computation subfield artificial intelligence artificial life uses biologically inspired methods solve optimization problems using iterative refinements set solutions via change selection approach began 1950s constitutes growing set algorithms capable solving wide range problems divided various types differ selection mutation representation candidate solutions successful applications counted multiple domains including limited optimization machine learning robotics various areas study living systems evolutionary computation recently seen revival particularly study openended evolution important implications future ai unique potential generate endless innovations lead paradigm shift development artificial intelligence artificial intelligence life', 'purpose study study possibilities multigenerational optimization behavior control systems agents general artificial intelligence capable independently solving universal range tasks real environment main principles ontophylogenetic synthesis control systems agents general artificial intelligence based multiagent neurocognitive architectures developed methods algorithms synthesizing phenotypes control systems intelligent agents according genotypes proposed software package simulating processes ontophylogenetic synthesis multiagent neurocognitive architectures developed experiments carried create phenotypes intelligent agents based complex genome intelligent agent developed features multichromosome genetic algorithm organizing calculations paradigm multigenerational optimization multiagent neurocognitive architectures established substantiated shown multigenerational optimization multiagent neurocognitive architecture intelligent agents contribute achievement adaptive resistance operating conditions general artificial intelligence agent provide synthesis suboptimal structural functional scheme accelerate learning algorithms finding solutions universal range problems solved agent ecological niche', 'article explores fusion fuzzy logic fl group theory within realm artificial intelligence ai uncovering transformative synergy promises enhance adaptability robustness intelligent systems beginning individual examination fuzzy logic group theory paper establishes theoretical foundations integration fuzzy logics capacity handle uncertainty harmonizes group theorys prowess revealing structural insights leading unified framework integration validated series compelling case studies experiments across diverse domains ranging adaptive robotics control healthcare decision support practical applications showcase collective impact fl group theory demonstrating improved adaptability precision resilience complex scenarios results reaffirm theoretical foundations also provide tangible evidence integrated approachs potential looking toward future paper outlines key directions research including refinement theoretical foundations integration machine learning addressing challenges scalability explainability ethical considerations crossdisciplinary collaboration continuous validation emphasized crucial elements shaping trajectory interdisciplinary exploration', 'study explored dynamic field fuzzy logic artificial intelligence ai financial analysis 1990 2023 utilizing bibliometrix package rstudio data web science focused identifying mathematical models evolving role fuzzy information granulation domain research addresses urgent need understand development impact fuzzy logic ai within broader scope evolving technological analytical methodologies particularly concentrating application financial banking contexts bibliometric analysis involved extensive review literature published period examined key metrics annual growth rate international collaboration average citations per document highlighted fields expansion collaborative nature results revealed significant annual growth rate 1954 international collaboration 2116 average citation per document 2552 major journals ieee transactions fuzzy systems fuzzy sets systems journal intelligent fuzzy systems information sciences emerged significant contributors aligning bradfords laws zone 1 notably post2020 ieee transactions fuzzy systems showed substantial increase publications significant finding high citation rate seminal research fuzzy information granulation emphasizing mathematical importance practical relevance financial analysis keywords like design model algorithm optimization stabilization terms fuzzy logic controller adaptive fuzzy controller fuzzy logic approach prevalent countries collaboration world map indicated strong pattern global interconnections suggesting robust framework international collaboration study highlights escalating influence fuzzy logic ai financial analysis marked growth research outputs global collaborations underscores crucial role fuzzy information granulation mathematical model sets stage investigation fuzzy logic aidriven models transforming financial banking analysis practices worldwide', 'paper presents method providing explainability integration artificial intelligence ai data mining techniques dealing meteorological prediction explainable artificial intelligence xai refers transparency ai systems providing explanations predictions decisionmaking processes contribute improve prediction accuracy enhance trust ai systems focus paper relies interpretability challenges ordinal classification problems within weather forecasting ordinal classification involves predicting weather phenomena ordered classes temperature ranges wind speed precipitation levels others address challenge novel general explicable forecasting framework combines inductive rules fuzzy logic proposed work inductive rules derived historical weather data provide logical interpretable basis forecasting fuzzy logic handles uncertainty imprecision weather data system predicts set probabilities incoming sample belongs considered class moreover allows expert decisionmaking process strengthened relying transparency physical explainability model output blackbox algorithm proposed framework evaluated using two realworld weather databases related wind speed lowvisibility events due fog results compared ml classifiers specific methods ordinal classification problems achieving competitive results terms ordinal performance metrics offering higher level explainability transparency compared existing approaches', 'interpretable artificial intelligence ai also known explainable ai indispensable establishing trustable ai benchtobedside translation substantial implications human wellbeing however majority existing research area centered designing complex sophisticated methods regardless interpretability consequently main prerequisite implementing trustworthy ai medical domains met scientists developed various explanation methods interpretable ai among methods fuzzy rules embedded fuzzy inference system fis emerged novel powerful tool bridge communication gap humans advanced ai machines however reviews use fiss medical diagnosis addition application fuzzy rules different kinds multimodal medical data received insufficient attention despite potential use fuzzy rules designing appropriate methodologies available datasets review provides fundamental understanding interpretability fuzzy rules conducts comparative analyses use fuzzy rules explanation methods handling three major types multimodal data ie sequence signals medical images tabular data offers insights appropriate fuzzy rule application scenarios recommendations future research', 'due advancement complexity modern automobiles fault detection gone beyond manual trial error methods fault detection technologies automotive industry used identify potential already existing fault automobiles faults automobiles usually mechanical electrical faults may include airbag control unit radiator gearbox transmission control unit tyre pressure brakes air conditioner cylinder casket alternator hubs malfunctions etc fault specific related sign symptoms several methods fault detections automobiles like binary logic technique fuzzy logic method technique artificial intelligence technique different algorithms research work employed fuzzy logic based technique uses mamdani algorithm presented better fault detection mechanism mamdanis algorithm proposed ebrahim mamdani fuzzy inference method rulebases intuitive easier analyse implement mamdanis algorithm produces fuzzy sets originate fuzzy inference systems output membership function decision making research work webbased technology implemented using javascript jquery sql server aspnet bootstrap 35 css output system showed greater improvement existing methods fault detections automobiles', 'wireless sensor network wsn distributed collection tiny lowpower wireless devices deployed physical environment monitor various environmental conditions data collected positioned sensor nodes transmitted destination nodes using multi hop communications wsns offer numerous advantages othernetworks including enhanced flexibility low cost simplified deployment due resource constraint nature wsn faces various challenges issues need addressed order ensure reliable secure data transmission nodes wsn highly vulnerable various types security attacks namely black hole attack denial service dos node compromise attack among attacks black hole attack causes serious threat nodes network attack carried malicious nodes intentionally drop data packets control packets without forwarding intended destination ensure security network black hole attack necessary design efficient intrusion detection technique detecting malicious nodes work novel fuzzy logicbased intrusion detection system hidden markov model fidshmm proposed identify malicious nodes mitigate black hole attack moreover hmm employed proposed protocol monitor energy levels nodes order detect malicious nodes effectively implementation proposed protocol carried using ns2 simulator simulation results justify proposed protocol namely fidshmm provides efficient detection mechanism black hole attacks network moreover proposed protocol improves quality service qos parameters namely packet delivery ratio delay throughput network efficiency', 'article present model adjustable moisture control historical buildings proposed system developed form flexible iot infrastructure complex system sensors set measure inside conditions humidity compare result levels groundwaters rain wind speed manage drying system developed control model using type2 fuzzy logic reasoning flexibly adjust decisions intensity water absorption way proposed model makes innovative intelligent system control interior conditions historical buildings developed system installed examined old brewery building research results show efficiency dehumidification lowest cost', 'semantic features play pivotal role natural language processing providing deeper understanding meaning context within textual data realm machine learning artificial intelligence semantic feature extraction involves translating linguistic elements numerical representations often utilizing advanced techniques like word embeddings deep learning models integration semantic features enhances precision contextawareness language models enabling applications sentiment analysis document categorization information retrieval operate greater accuracy relevance paper introduces novel approach hierarchical mandhami optimized semantic feature extraction hmosfe designed enhance semantic feature extraction english sentences proposed hmosfe model comprises fusion hierarchical clustering fuzzybased feature extraction hmosfe aims capture intricate semantic relationships within sentences providing nuanced insights underlying meaning textual content model employs pretrained word embeddings term representation calculates similarity matrix using cosine similarity utilizes hierarchical clustering document grouping fuzzy logic contributes assigning weights features enabling refined understanding semantic significance paper presents comprehensive results including semantic similarity estimations clustering distances fuzzy memberships demonstrating effectiveness hmosfe across diverse documents', 'intelligent lighting system public lighting system uses artificial intelligence technology optimize energy management improve quality lighting public areas paper presents use two prominent artificial intelligence methods namely fuzzy logic neural networks intelligent power control public lighting networks primary objective study evaluate performance approaches optimizing power consumption achieving efficient lighting taking consideration two parameters namely road flow weather conditions achieve lighting system modeled using state flow tool matlabsimulink various algorithms based fuzzy logic artificial neural networks subsequently developed real data traffic flow cloud cover utilized train algorithms upon analysis simulation results observed overall results closer algorithm based fuzzy logic yielded algorithms based neural networks', '21st century global waste challenges worsen developing nations relying manual sorting improper waste disposal poses significant threats human health environment necessitating adoption artificial intelligencebased solid waste segregation technology aibswst context advanced frank tnorm captures nuanced relationships fuzzy logic crucial scenarios fuzzy set order matters building principles complex qrung picture fuzzy set cqrpfs becomes instrumental representing decisionmakers preferences twodimensional manner enhancing handling vague information realworld scenarios expanding foundational principles paper introduces innovative frank operations grounded frank tnorms within context cqrpfs leveraging operations paper proposes four robust aggregation operators aos cqrpfs complex qrung picture fuzzy frank weighted average cqpffwa complex qrung picture fuzzy frank weighted geometric cqpffwg complex qrung picture fuzzy frank ordered weighted average cqpffwoa complex qrung picture fuzzy frank ordered weighted geometric cqpffwog aos exhibit essential properties idempotency monotonicity boundedness multicriteria decisionmaking mcdm method based proposed aos suggested validate strategies reallife case study indias adoption aibswst serves practical application thorough analyses including sensitivity comparative superiority assessments evaluating performance approaches thoughtful discussion pros cons proposed aos accompanies analysis emphasizing significance approach ensuring cleanliness health developing nations', 'easy internet access technological advancements resulted information overload plethora options making decisionmaking extremely difficult recommender system rs potential solution assisting users making decisions recommending predicting product ratings three fundamental forms rs use implicit explicit feedback recommendation collaborative contentbased hybrid filtering ratings common form feedback product descriptions reviews images audios videos also important help improve performance traditional rs additional variables significant impact rss performance traditional rss used approaches based nearest neighbor machine learning models thanks recent advances artificial intelligence deep learning rss developed using convolutional neural networks cnn efficiently exploit auxiliary information addition comparing cnnbased rss common grounds article provides full examination cnnbased rss might use various types auxiliary information study also discusses data characteristics data statistics auxiliary information variety publicly available datasets different evaluation measures rss also discussed readers provided interesting challenges open research issues', 'recent years continuous progress development science technology especially continuous development artificial intelligence machine algorithm technologies education system also begun carry personalized content traditional functions traditional education systems often adopt onesizefitsall approach teaching take account unique needs learning styles student education system personalized optimized machine learning algorithms provide customized learning materials recommendations based students learning history interests abilities improve learning outcomes machine learning algorithms provide realtime feedback student performance adjust learning plans based feedback makes learning process dynamic personalized therefore applied types education including language learning mathematics science etc however improving efficiency machine learning algorithms depends improvement numerical optimization algorithms necessary summarize optimization algorithms largescale machine learning paper tries make detailed overview existing machine learning algorithms optimizing personalized education recommendation system introduces algorithm optimization process', 'paper presents comprehensive literature review research application machine learning ml algorithms recommender systems rs study aims identify recent trends explore reallife applications guide researchers positioning research activities domain published 2023 janjune findings categorized different domains including education healthcare ml algorithms autoencoders reinforcement learning ecommerce digital journalism review highlights enhanced recommendation accuracy increased scalability personalization context awareness diverse ml techniques strategies handling cold start data sparsity foundation future advancements ml algorithms rss considering application manufacturing enterprises', 'smart cities represent convergence information communication technologies ict urban management improve quality life city dwellers context recommender systems tools offer personalised suggestions city dwellers emerged key contributors convergence successful application various areas city life ability process massive amounts data generated urban environments expedited status crucial technology evolution city planning methodology included reviewing web science database resulting 130 articles filtered relevancy reduced 86 first stage consisted carrying bibliometric analysis objective analysing structural aspects scimat tool secondly systematic literature review undertaken using prisma 2020 statement results illustrated different processes recommendations filtered areas tourism health mobility transport research seen significant breakthrough drive evolution efficiency smart cities establishing solid framework future research dynamic field', 'internet things iot based remote healthcare applications provide fast preventative medical services patients risk however predicting heart disease complex task diagnosis results rarely accurate address issue novel recommendation system cardiovascular disease prediction using iot network deepcardio proposed providing prior diagnosis treatment dietary recommendations cardiac diseases initially physiological data collected patients remotely using four bio sensors ecg sensor pressure sensor pulse sensor glucose sensor arduino controller receives collected data iot sensors predict diagnose disease cardiovascular disease prediction model implemented using bigru bidirectionalgated recurrent unit attention model diagnose cardiovascular disease classify five available cardiovascular classes recommendation system provides physical dietary recommendations cardiac patients based classified data via user mobile application performance deepcardio validated cloud simulator cloudsim using realtime framinghams statlog heart disease dataset proposed deep cardio method achieves overall accuracy 9990 whereas mabcsvm hcbda mlbpm method achieves 8691 8865 9363 respectively', 'latest effort delivering computing resources service managers consumers represents shift away computing product purchased computing service delivered users internet largescale data centers however advent cloudbased iot artificial intelligence ai advancing customer experience automations many application areas recommender systems rs need arisen various modifications support iot devices center automation world including recent language models like chatgpt bard technologies like nanotechnology paper introduces marketing community recent computing development iotdriven fog computing fc although numerous research studies published fc smart applications none hitherto conducted fogbased smart marketing domains recommender systems fc considered novel computational system mitigate latency improve bandwidth utilization autonomous consumer behavior applications requiring realtime datadriven decision making paper provides conceptual framework studying effects fog computing consumer behavior goal stimulating future research using example intersection fc rs indeed conceptualization fogbased recommender systems opens many novel challenging avenues academic research highlighted later part paper keywords fog computing recommender system internet things iot edge computing artificial intelligence ai software defined networks sdns ormation well personal situational data 66', 'purpose general purpose study investigate effectiveness recommender systems knowledge discovery methodology study adopted desktop research methodology desk research refers secondary data collected without fieldwork desk research basically involved collecting data existing resources hence often considered low cost technique compared field research main cost involved executives time telephone charges directories thus study relied already published studies reports statistics secondary data easily accessed online journals library findings findings reveal exists contextual methodological gap relating recommender systems knowledge discovery study effectiveness recommender systems knowledge discovery found systems played pivotal role facilitating users exploration vast information repositories enabling uncover relevant resources expand knowledge found recommender systems employing advanced algorithms personalized techniques demonstrated higher effectiveness generating relevant recommendations tailored users preferences needs additionally study highlighted positive correlation user engagement metrics knowledge discovery outcomes emphasizing importance fostering active user participation recommendation process contextual information also identified crucial factor influencing recommendation effectiveness overall study underscored significance continuous refinement optimization recommender system algorithms enhance knowledge discovery outcomes users unique contribution theory practice policy social learning theory information foraging theory cognitive load theory may used anchor future studies recommender systems knowledge discovery study provided recommendations enhance efficacy systems suggested adopting hybrid recommender systems combine collaborative contentbased filtering techniques offer accurate diverse recommendations additionally study emphasized importance integrating contextual information recommendation algorithms dynamically adjust recommendations based situational context furthermore recommended use explainable ai techniques improve transparency user understanding recommendation processes maximizing user engagement active participation feedback also highlighted crucial along prioritizing recommendation diversity foster exploration serendipitous discovery new knowledge resources', 'application artificial intelligence ai significantly increasing many human resources hr functions research aims understand diverse experts distinct organisations project managers managers supervisors human resource managers perceive potential artificial intelligencebased recommender systems match job profiles employee profiles study employs delphi studybased methodology specifically organising expert panel provides opinions ratings comments set propositions based online delphi study results participant opinions research aims identify challenges related employeejob profile matching artificial intelligence machine learning tools form recommender systems study delved various challenges matching employee profiles job profiles current problems faced executives human resource personnel supervisors project managers organisation study also sheds light potential feasibility solutions artificial intelligence form recommender systems also test couple propositions focus potential solutions various challenges matching employee profiles job profiles organisation', 'facial expression recognition fer utilized various fields education gaming robotics healthcare others facial expression techniques instance interactive robot artificial intelligence recognize human faces detect emotions person conversing use emotions choose appropriate answers one use case face emotion detection playing music based users mood analyze users facial expression deduce feelings result new emotion models require investigation existing ones struggle correctly measure musics connection facial emotion paper implement kind job using convolution neural network cnn based deep learning approach deep learning effectively analyze unstructured data movies forms media machine learning research created realtime system recognize human faces assess human emotions even recommend music users oahega fer2013 datasets utilized experimental study created trained two emotion recognition models using various combinations datasets proposed models accuracy 7302 using cnn model predict six emotions anger fear joy neutral sadness surprise proposed system utilized different places realtime facial recognition plays important role', 'given challenges interdomain information fusion data sparsity collaborative filtering algorithms paper proposes crossdomain information fusion matrix decomposition algorithm enhance accuracy personalized recommendations artificial intelligence recommendation systems study begins collecting douban movie rating data social network information ensure data integrity levenshtein distance detection employed remove duplicate scores natural language processing technology utilized extract keywords topic information social texts additionally graph convolutional networks utilized convert user relationships feature vectors unique thermal coding method used convert discrete user movie information binary matrices prevent overfitting ridge regularization method introduced gradually optimize potential feature vectors weighted average feature connection techniques applied integrate features different fields moreover paper combines itembased collaborative filtering algorithm merged user characteristics generate personalized recommendation listsin experimental stage paper conducts crossdomain information fusion optimization four mainstream mathematical matrix decomposition algorithms alternating least squares method nonnegative matrix decomposition singular value decomposition latent factor model lfm compares algorithms nonfused approach results indicate significant improvement score accuracy mean absolute error root mean squared error reduced 128 132 respectively across four algorithms additionally k 10 average f1 score reaches 097 ranking accuracy coverage lfm algorithm increases 542 overall mathematical matrix decomposition algorithm combined crossdomain information fusion demonstrates clear advantages accuracy prediction performance recommendation diversity ranking quality improves accuracy diversity recommendation system effectively addressing collaborative filtering challenges integration diverse techniques significantly surpasses traditional models recommendation accuracy variety', 'metaverse virtual reality vr space users interact digital objects rapidly becoming reality new world evolves artificial intelligence ai playing increasingly important role shaping development integrating ai emerging technologies metaverse creates new possibilities immersive experiences previously impossible paper explores ai integrated technologies internet things blockchain natural language processing virtual reality augmented reality mixed reality extended reality one potential benefit using ai metaverse ability create personalized experiences individual users based behavior preferences another potential benefit using ai metaverse ability automate repetitive tasks freeing time resources complex creative endeavors however also challenges associated using ai metaverse ensuring user privacy addressing issues bias discrimination examining potential benefits challenges using ai metaverse including ethical considerations better prepare exciting new era vr paper presents comprehensive survey ai integration emerging technologies metaverse metaverse continues evolve grow important developers researchers stay date latest developments ai emerging technologies fully leverage potential', 'world artificial intelligence changed drastically past 10 years rise deep learning bringing significant gains myriad industrial creative sectors benefit provide video games industry game ai established field 30 years catering unique problems field strategic opponents nonplayer characters gameplay pacing procedural content generation chapter highlights core areas classical symbolic ai continues thrive within machine learning providing new alternatives established practices plus new opportunities emerging courtesy ai changing games made including player modelling graphical upscaling animation controllers automated testing', 'artificial general intelligence idea someday hypothetical agent arise artificial intelligence ai progresses surpass far brightest gifted human minds idea around since early development ai since scenarios ai may behave towards humans subject many fictional research works paper analyzes current state artificial intelligence progresses current ai race ever faster release impressive new ai methods deceive humans outperform tasks thought impossible tackle ai mere decade ago disrupt job market raised concerns artificial general intelligence agi might coming faster thought particular focus 3 specific families modern ais develop idea deep neural networks current backbone nearly artificial intelligence methods poor candidates agi arise due many limitations therefore threat coming recent ai race lie agi limitations uses lack regulations current models algorithms', 'orecasting winners esports realtime analytics potential engage audiences watching major tournament events however making realtime predictions challenging due unpredictable variables within game involving diverse player strategies decisionmaking work attempts enhance audience engagement within video game tournaments introducing realtime method predicting wins long short term memory network lstms based approach enables efficient predictions winlose outcomes using health indicator player time series proof concept evaluate models performance within classic twoplayer arcade game super street fighter ii turbo also benchmark method state art methods time series forecasting ie transformer models found large language models llms finally opensource data set code hopes furthering work predictive analysis arcade games', 'project inspired turnbased strategy games final fantasy tactics xcom 2 modern turnbased strategy games project structured around use artificial intelligence storytelling within strategy games focus project utilizes artificial intelligence creating quest generation system storytelling resulting quest system creates new quests dynamically communicating artificial intelligence allowing players potentially experience everexpanding story quests', 'chapter discusses potential digital technology promote peacebuilding education acknowledging potential benefits risks associated use authors propose approach based humancentered design hcd prioritizes needs perspectives learners chapter presents three case studies demonstrate potential digital storytelling artificial intelligence ai gaming support peacebuilding first case study explores use digital storytelling teach genocide second focuses use ai protect victims violence third case study discusses use gaming raise awareness war authors acknowledge technology represents complex field inquiry offer exercises imagination explore possibilities liberatory design chapter concludes highlighting importance understanding ambivalent nature technology potential conflict peacebuilding', 'dynamic virtual reality vr revolutionized gaming entertainment industries providing immersive experiences take users new locations study presents novel exciting idea called virtual reality horror sports combines aspects horror sports vr medium provide novel approach developing adaptive vr horror games combining player modeling approaches adaptive meansbased system learn players individual fears adjust games content accordingly work presents two significant advances unique method determining players specific fears via game data machine learning methods adaptive game system employs agents monitor players terror experiences restrict exposure components find upsetting additional evidence user studies statistical significance testing suggests method may boost stress anxiety felt gamers resulting rewarding gaming experience vr horror sports brought together outcome may compel absorbing entertainment experience players immersed virtual environment realistic exciting dynamic virtual reality horror sports experience improved artificial intelligence ai player modeling provide novel comprehensive form entertainment fusing physical activity customization immersion single package endeavor kind potential advance state vr artificial intelligence gaming also offering exciting memorable adventures gamers', 'using gamification video games one modern approaches cognitive enhancement improving abilities competencies managers including strategic thinking skills many organizations use video games fields education marketing business entrepreneurship research aimed investigate role video games enhancing managers strategic thinking potential contribution developing cognitive capabilities sample included 30 students actively involved innovation entrepreneurship ecosystem measure strategic thinking participants pisapias strategic thinking questionnaire used cantab test employed measure cognitive capabilities identify individuals gameplaying styles indicators micromanagement planning plan recognition predictions gathering resources partial observability damage avoidance designed findings indicated 533 percent participants reflective thinking 30 percent systems thinking rest reframing thinking style strategic thinking dominant dimension hand given identified correlation damage avoidance criteria thinking reflective style well inverse significant correlation gathering resources criteria results prm test seems strategic games potential change even develop cognitive functions attention reaction memory considered tools improve cognitive ability games used design tasks enhance managers cognitive abilities subsequently promote strategic thinking decisionmaking skills', 'study investigates automated adaptable learning bsg may improve business simulating games bsg transformation possibilities rapid increase information combined intricate nature todays company contexts means classic bsg education techniques frequently fail adequately prepare students difficulties face everyday life study provides revolutionary architecture continually evolves learning paths responses testing situations based specific student progress desires utilizing modern artificial intelligence methods including machine learning technique seeks maximize users preservation expertise ability make decisions capacity creative thinking tailoring education summary study raises possibilities better interesting educational opportunities throughout modern age adding continuing conversation relationship ai training corporate strategies', 'video games becoming part lives many many people able evoke wide range emotions joy excitement fear empathy creating deep immersion memorable impressions players manage possible use emotions game article presents concept developing system dynamic procedural content generation pcg game mechanics interaction using emotions based methods affective computing achieve goal article developed emotion recognition system based fuzzy logic pcg performed artificial neural networks video game industry affective computing methods interaction expression emotions bring great benefits since emotional involvement player important make new contribution diversity humancomputer interaction']\n",
            "Test: ['automatic software plagiarism detection tools widely used educational settings ensure submitted work copied tools grown use together rise enrollments computer science programs widespread availability code online educators rely robustness plagiarism detection tools working assumption effort required evade detection high required actually assigned work paper shows case presents entirely automatic program transformation approach mossad defeats popular software plagiarism detection tools mossad comprises framework couples techniques inspired genetic programming domainspecific knowledge effectively undermine plagiarism detectors mossad effective defeating four plagiarism detectors including moss jplag mossad fast effective minutes generate modified versions programs likely escape detection insidiously nondeterministic approach mossad single program generate dozens variants classified suspicious legitimate assignments detailed study mossad across corpus real student assignments demonstrates efficacy evading detection user study shows graduate student assistants consistently rate mossadgenerated code readable authentic student code work motivates need research robust plagiarism detection tools greater integration naturally plagiarismresistant methodologies like code review computer science education', 'twoyear study ministry research technology education indonesia presented evaluation universities indonesia findings evaluation peculiarities various dissertation softcopies doctoral students similar texts available internet suspected plagiarism behavior negative effect students faculty members main reason behind behavior lack standardized awareness among faculty members regard plagiarism therefore study proposes computerized system able detect plagiarism information using kmeans cosine distance algorithm process starts preprocessing process includes novel step checking indonesian big dictionary vector space model design combined calculation kmeans cosine distance 17 documents test data result study generally shows documents detection accuracy 9333', 'en este artículo se expone el análisis diseño implementación pruebas de un módulo para la detección de potencial plagio de las tareas enviadas un sistema de administración de cursos utilizando la plataforma de procesamiento distribuido hadoop en el presente trabajo se analiza la problemática del plagio que ocurre en las tareas elaboradas digitalmente por los estudiantes que son receptadas por los sistemas de administración de cursos además se realiza un análisis conceptual para comprender cómo la necesidad de comparar dos secuencias está presente en otras ramas de la ciencia cómo la solución ha sido propuesta con el uso de herramientas informáticas así mismo se exponen las tecnologías utilizadas para el desarrollo del módulo se detalla cómo se hizo frente la problemática dividiendo el proceso en dos partes el preprocesamiento de los documentos para generar archivos en texto plano la implementación del algoritmo de smithwaterman con las mejoras planteadas por phd robert w irving finalmente se muestra un resumen con los resultados de las pruebas realizadas sobre el ambiente de procesamiento distribuido paper presents analysis design implementation testing module potential plagiarism detection homework sent course management system using distributed processing platform hadoop paper analyze plagiarism problem happened homework done digitally students receipted course management systems also paper shows conceptual analysis understanding necessity comparing two sequences present branches science solution proposed use technological tools likewise document details problems faced dividing process two parts preprocessing documents generate plain text files implementation smithwaterman algorithm phd robert w irvings improvements finally paper shows summary testing results done distributed processing platform', 'one key factors behind plagiarism availability large amount data information internet accessed rapidly increases risk academic fraud intellectual property theft increasing anxiety plagiarism grow observation drawn towards automatic plagiarism detection hybrid algorithms regarded one prospective ways detect similarity everyday language source code written student study investigates applicability success combining levenshtein edit distance approximate string matching algorithm term frequency inverse document frequency tfidf thereby boosting rate similarity measured using cosine similarity proposed hybrid algorithm also able detect plagiarism occurred natural language source codes exact disguised words developed algorithm detect rearranged words intertextual similarity insertion deletion grammatical changes research three various dataset used testing automated machine paragraphs mistyped words java source codes overall system proved detecting plagiarism better yet alone tfidf approach keywords approximate hybrid plagiarism similarity tfidf', 'measures success facial feminization surgery ffs previously included improved rates external gender perception female patientreported outcome measures emotion recognition ability precisely infer human emotions numerous sources modalities using questionnaires physical signals physiological signals study used artificial intelligence facial recognition software objectively evaluate effects ffs perceived gender age among maletofemale transgender patients well relationship patient facial satisfaction ffs associated decrease perceived age relative patients true age 24 p0001 older patients experiencing greater reductions pearson correlation matrix found significant relationship improved female gender typing patient facial satisfaction transfeminine patients experienced improvements satisfaction facial appearance perceived gender decreases perceived age following ffs notably patient satisfaction directly associated improved aigender typing suggesting factors may influence patient satisfaction thorough analysis discussion selected 142 journal articles using prisma guidelines review provides detailed analysis existing studies available datasets emotion recognition review analysis also presented potential challenges existing literature directions future research', 'research practice work progress paper presents tokenbased approach detecting plagiarism university courses hardware programming assignments detecting plagiarism manually difficult timeconsuming work last two decades various plagiarism detection tools developed techniques could mainly divided following categories textual match program dependence graph comparison abstract syntax tree analysis lowlevel form code comparison although lot researches detecting code clones software programming languages eg basic cc java python etc research focused hardware description languages still lacking based effective locality sensitive hash function simhash usually used detecting nearduplicates web crawling proposed improved realtime plagiarism detection approach verilog hdl hardware description language programming assignments core detecting steps extracting weighted tokens source code highdimensional feature mapping fbit fingerprints simhash technique account syntax characteristics verilog hdl token extraction strategy designed maximize valid information fixed length hash value could represent experiments real course data sets conducted evaluate performance tokenbased approach comparing existing plagiarism detection tool moss result shows tokenbased approach qualify plagiarism detecting job onlinequery batchquery digital designs furthermore tokenbased plagiarism detection approach could enable conduct incremental plagiarism detection single submission without excessive overhead finally also give discussion current way limitations future research directions', 'systematic review provides unique findings uptodate examination artificial intelligence ai higher education 2016 2022 using prisma principles protocol 138 articles identified full examination using priori grounded coding data 138 articles extracted analyzed coded findings study show 2021 2022 publications rose nearly two three times number previous years rapid rise number aied publications new trends emerged findings show research conducted six seven continents world trend shifted us china leading number publications another new trend researcher affiliation prior studies showed lack researchers departments education changed dominant department undergraduate students studied students 72 similar findings studies language learning common subject domain included writing reading vocabulary acquisition examination aied intended 72 studies focused students 17 instructors 11 managers answering overarching question aied used grounded coding used five usage codes emerged data 1 assessmentevaluation 2 predicting 3 ai assistant 4 intelligent tutoring system 5 managing student learning systematic review revealed gaps literature used springboard future researchers including new tools chat gpt', 'neural networkbased graph embedding crossplatform binary code similarity detection problem crossplatform binary code similarity detection aims detecting whether two binary functions coming different platforms similar many security applications including plagiarism detection malware detection vulnerability search etc existing approaches rely approximate graphmatching algorithms inevitably slow sometimes inaccurate hard adapt new task address issues work propose novel neural networkbased approach compute embedding ie numeric vector based control flow graph binary function similarity detection done efficiently measuring distance embeddings two functions implement prototype called gemini extensive evaluation shows gemini outperforms stateoftheart approaches large margins respect similarity detection accuracy gemini speed prior arts embedding generation time 3 4 orders magnitude reduce required training time 1 week 30 minutes 10 hours real world case studies demonstrate gemini identify significantly vulnerable firmware images stateoftheart ie genius research showcases successful application deep learning computer security problems', 'sourcecode similarity detection detection tools used academia systematic review teachers deal plagiarism regular basis try prevent detect plagiarism task complicated large size classes students cheat often try hide plagiarism obfuscate many different similarity detection engines often called plagiarism detection tools built help teachers article focuses plagiarism detection presents detailed systematic review field sourcecode plagiarism detection academia review gives overview definitions plagiarism plagiarism detection tools comparison metrics obfuscation methods datasets used comparison algorithm types perspectives meaning sourcecode plagiarism detection academia presented together categorisations available detection tools analyses effectiveness writing review interesting insights found metrics datasets quantitative tool comparison categorisation detection algorithms also existing obfuscation methods classifications expanded together new definition sourcecode plagiarism detection academia', 'metaverse virtual reality vr space users interact digital objects rapidly becoming reality new world evolves artificial intelligence ai playing increasingly important role shaping development combining ai emerging technologies metaverse opens new possibilities immersive experiences unimaginable paper examines integration ai various technologies including internet things blockchain natural language processing virtual reality augmented reality mixed reality extended reality one potential benefit using ai metaverse ability create personalized experiences individual users based behavior preferences another potential benefit using ai metaverse ability automate repetitive tasks freeing time resources complex creative endeavors however also challenges associated using ai metaverse ensuring user privacy addressing issues bias discrimination exploring potential benefits challenges incorporating ai metaverse including ethical considerations better prepare exciting new era virtual reality paper presents comprehensive survey ai integration emerging technologies metaverse metaverse continues evolve grow important developers researchers stay date latest developments ai emerging technologies fully leverage potential', 'en este trabajo se construyó un algoritmo computacional para la alineación de textos en la tarea de detección de plagio bilingüe el método de detección de plagio bilingüe hace uso del servicio de traductores automáticos con la finalidad de tener los documentos en cuestión en un idioma base para después aplicar técnicas de plagio monolingüe el algoritmo fue probado con el corpus perteneciente la competencia internacional de detección de plagio del año 2013 para evaluar la etapa de detección de plagio monolingüe además se experimentó con la colección de textos europarl una colección de documentos pertenecientes la reunión del parlamento europeo de los que se tomaron los documentos en inglés español con la finalidad de probar la etapa bilingüe', 'natural language processing discipline rooted linguistics computer science incorporates syntactic problems grammatical category word segmentation name entity recognition etc semantics sentiments analysis texts categorization translation questions answering etc vocal signals generation texts texts generation vocal signals etc last years scientists companies able create algorithms capable achieving high levels performance tasks translation sentiment classification part using big data fact algorithms perform well large amount data gives significant business advantage large companies large databases smaller businesses startups purpose thesis find algorithms methods effective solving natural language processing problems small databases research built contentbased recommendation system tested similarity measures latent dirichlet allocation cosine similarity longshort term memory neural network rv coefficient also compared efficiency term frequencyinverse document frequency versus mutual information give weighting scheme cosine similarity also compared effectiveness mutual information versus using raw word count thresholds remove words dictionary similarity measures also used external databases one containing documents related problem another wikipedia documents also used pretrained glove word embedding vector neural networks rv coefficient concluded simplest algorithms generally work best little data also proposed several possible solutions improve algorithms tested', 'sourcecode similarity detection detection tools used academia systematic review teachers deal plagiarism regular basis try prevent detect plagiarism task complicated large size classes students cheat often try hide plagiarism obfuscate many different similarity detection engines often called plagiarism detection tools built help teachers article focuses plagiarism detection presents detailed systematic review field sourcecode plagiarism detection academia review gives overview definitions plagiarism plagiarism detection tools comparison metrics obfuscation methods datasets used comparison algorithm types insidiously nondeterministic approach mossad single program generate dozens variants classified suspicious legitimate assignments detailed study mossad across corpus real student assignments demonstrates efficacy evading detection user study shows graduate student assistants consistently rate mossadgenerated code readable authentic student code work motivates need research robust plagiarism detection tools greater integration naturally plagiarismresistant methodologies like code review computer science education', 'compared printtospeech properties human performance characteristics two artificial intelligence vision aids orcam myeye 1 portable device seeing ai iphone ipad application security crops concerning quality quantity crucial monitor disease plants thus recognition plant disease essential plant disease syndrome noticeable distinct parts plants two individuals measurable acuity one light perception tested blindfolded also tested performance text varying appearance varying viewing conditions evaluate human performance asked participants use devices attempt 12 reading tasks similar activities daily living assessed ranges text attributes reading possible print size contrast light level also assessed individuals could complete tasks devices measured accuracy completion time participants also completed survey concerning two aids results aids achieved greater 95 accuracy text recognition flat plain word documents ranged 13 57 accuracy formatted text curved surfaces aids could read print sizes small 08m 2040 snellen equivalent 40 cm viewing distance individuals successfully completed 71 55 p 114 tasks using orcam myeye 1 seeing ai respectively significant difference time completion tasks p 775 individuals believed aids would helpful daily activities techniques also benefit farmers achieving expeditious appropriate actions avoid reduction quality quantity crops application techniques recognition disease avert disadvantage origin factious selection disease features extraction features boost speed technology efficiency research moreover future works classification disease also discussed', 'artificial intelligence one emerging technologies simulated human intelligence machines programming think like human beings mimic actions autonomous vehicle could function carry necessary functions without human involvement innovative technology provided increased passenger safety less congested roads congestion reduction optimum traffic flow lower fuel consumption less pollution better travel experiences autonomous vehicles played vital role industry agriculture transportation military applications autonomous vehicles activities supported sensor data artificial intelligence systems artificial intelligence collection data path planning execution autonomous vehicles required machine learning techniques part artificial intelligence came privacy issues security concerns security important concern autonomous vehicles issues cybersecurity incorporating artificial intelligence autonomous vehicles covered article along growing technology selfdriving automobiles', 'dearth feasibility assessments regarding use large language models llms responding inquiries autistic patients within chineselanguage context despite chinese one widely spoken languages globally predominant research focus application models medical field englishspeaking populations effectiveness llm chatbots specifically chatgpt4 openai ernie bot version 223 baidu inc one advanced llms china addressing inquiries autistic individuals chinese setting aimed assessed study data gathered dxya widely acknowledged webbased medical consultation platform china user base 100 million individuals total 100 patient consultation samples rigorously selected january 2018 august 2023 amounting 239 questions extracted publicly available autismrelated documents platform maintain objectivity original questions responses anonymized randomized responses assessed evaluation team 3 chief physicians across 4 dimensions relevance accuracy usefulness empathy team completed 717 evaluations best response initially identified team likert scale 5 response categories used gauge responses representing distinct level quality finally responses collected different sources compared', 'survey provides literature review recent works artificial life visual art past 40 years specifically computational software domain necessary reconsider relations material body identity natural world concept life art known pave way exploring conveying new possibilities proposed set criteria taxonomy briefly analyze representative artworks different categories aim provide systematic overview artists understanding nature creating new life modern technology nowadays interdisciplinary fields artificial life artificial intelligence computational biology synthetic biology increasingly emerging public view', 'automated dialogue systems important applications artificial intelligence struggled traditional systems understand user emotions provide empathetic feedback emotional intelligence technology integrated automated dialogue systems study dialogue generation model emotional intelligence created deep learning natural language processing techniques wide range emotions specific pain signals detected understood model real time enabling empathetic interaction provided system integrating results study artificial intelligence detect pain express pain empathy ability model understand subtle elements pain empathy enhanced setting higher standards emotional intelligence dialogue systems project aims provide theoretical understanding practical suggestions integrate advanced emotional intelligence capabilities dialogue systems thereby improving user experience interaction quality', 'one key elements expected define future education use artificial intelligence tool enhance teaching learning processes well work teachers administrators artificial intelligence robotics present variety social pedagogical practical ethical social justice issues challenges bring changes educational processes examining discussions examples ai use education especially primary school settings focus actual implications significant educational challenge technological advancements clear risk creating exacerbating inequalities among social groups equal access ensured explore potential personalizing learning pathways describing primary school initiatives designed promote effective collaborative communication skills aim recognizing identifying preventing factors impact learning disorders finally drawing parallel development classical literacy readingwriting discuss necessity introducing artificial intelligence robotics literacy courses teachers enabling technologies widely used across different age groups grades', 'one key elements expected define future education use artificial intelligence tool enhance teaching learning processes well work teachers administrators artificial intelligence robotics present variety social pedagogical practical ethical social justice issues challenges bring changes educational processes examining discussions examples ai use education especially primary school settings focus actual implications significant educational challenge technological advancements clear risk creating exacerbating inequalities among social groups equal access ensured explore potential personalizing learning pathways describing primary school initiatives designed promote effective collaborative communication skills aim recognizing identifying preventing factors impact learning disorders finally drawing parallel development classical literacy readingwriting discuss necessity introducing artificial intelligence robotics literacy courses teachers enabling technologies widely used across different age groups grades', 'plagiarism research occur due accident intentional plagiarism act violates copyright includes actions harm others submitting title research example final assignment research students repeatedly submitted titles rejected considered plagiarism title proposed already existed need system detect similarity titles submitted existing titles expected reduce occurrence plagiarism study uses winnowing algorithm find percentage similarity titles google scholar used obtain data research titles previously available comparison titles web scraping curl client urls simple html dom parser used retrieve title data google scholar results study application winnowing algorithm find percentage similarity data google scholar able present percentage similarities percent category mild moderate severe plagiarism also helping early detection prevention plagiarism', 'given million escort advertisements spot nearduplicates microclusters ads usually signals human trafficking ht summarize convince law enforcement act spotting microclusters nearduplicate documents useful multiple additional settings including spambot detection twitter ads plagiarism present infoshield makes following contributions practical scalable effective real data parameterfree principled requiring userdefined parameters interpretable finding document cluster representative highlighting common phrases automatically detecting slots ie phrases differ every document generalizable beating matching domainspecific methods twitter bot detection ht detection respectively well language independent interpretability particularly important antiht domain law enforcement must visually inspect ads experiments real data show infoshield correctly identifies twitter bots f1 score 90 detects ht ads 84 precision moreover scalable requiring 8 hours 4 million documents stock laptop incremental version deltashield allows fast incremental updates minor loss accuracy', 'web data mining web data mining system using granular computing asp programming proposed web based application allows web users submit survey data many different companies survey collection questions help companies develop improve business customer service clients analyzing survey data web application allows users submit data anywhere survey data collected database analysis administrator web application login system view data submitted web application resides web server database resides ms sql server', 'describes experiment building software capable generating leads newspaper titles automated fashion information obtained internet theoretical possibility lage already provided end last century based relatively rigid simple structure type story construction facilitates representation translation syntax terms instructions computer execute paper also discusses relationship society technique technology making brief history introduction digital solutions newsrooms impacts development done python programming language nltk natural language toolkit library used results brazilian soccer championship 2013 published internet portal data source', 'interactive software agents chatbots progressively used area health wellbeing applications agents engage users interpersonal conversations eg coaching comfort behaviorchange interventions increased need understanding agents empathic capabilities current stateoftheart tools order understand empathic capabilities interactive software agents need precise notion empathy literature discusses variety definitions empathy consensus formal definition based systematic literature review qualitative analysis recent approaches empathy interactive agents health wellbeing formal definitionan ontologyof empathy developed present potential formal definition controlled userstudy applying tool assessing empathy two stateoftheart health wellbeing chatbots replika wysa interactive software agents chatbots progressively used area health wellbeing applications agents engage users interpersonal conversations eg coaching comfort behaviorchange interventions increased need understanding agents empathic capabilities current stateoftheart tools order understand empathic capabilities interactive software agents need precise notion empathy literature discusses variety definitions empathy consensus formal definition present potential formal definition controlled userstudy applying tool assessing empathy two stateoftheart health wellbeing chatbots replika wysa findings suggest definition captures necessary conditions assessing empathy interactive agents uncover explain trends changing perceptions empathy time definition implemented web ontology language owl may serve automated tool enabling systems recognize empathy interactionsbe interactive agent evaluating empathic performance intelligent system assessing empathic capability interlocutors', 'shared information program plagiarism detection fundamental question information theory computer science measure similarity amount shared information two sequences proposed metric based kolmogorov complexity answer question proven universal apply metric measuring amount shared information two computer programs enable plagiarism detection designed implemented practical system sid software integrity diagnosis system approximates metric heuristic compression algorithm experimental results demonstrate sid clear advantages plagiarism detection systems sid system server online httpsoftwarebioinformaticsuwaterloocasid', 'increase number customer complaints led increase number power customer service work orders resulting failure solve reasonable demands customers time affecting customer service quality power supply bureau solve problems text similarity detection method power customer service work order based tfidf algorithm proposed method uses web scraper technology obtain power customer service work order text preprocesses text including chinese word segmentation desktop words text representation tfidf algorithm used extract preprocessed text keywords obtain keyword weight based weight cosine distance method used calculate text similarity text keywords different power customer service work orders results show compared detection method based weighted word sentence vector detection method based hybrid model detection method based coupling distance discrimination strong category features macro average f1 measurement value higher method takes less time lower complexity', 'automatic plagiarism detection carried considering reference corpus suspicious text compared set original documents order relate plagiarised text fragments potential source one biggest difficulties task locate plagiarised fragments modified rewording insertion deletion example source text definition proper text chunks comparison units suspicious original texts crucial success kind applications experiments meter corpus show best results obtained considering low level word ngrams comparisons n 23', '3000 new citations highly similar citations previously published manuscripts appear year biomedical literature medline alone underscores importance opportunity editors reviewers detection system identify highly similar text submitted manuscripts review novelty new softwarebased services commercial free provide capability availability tools provides way intercept suspect manuscripts serve deterrent unfortunately capabilities services vary considerably mainly consequence availability completeness literature bases new queries compared commercial software designed detection plagiarism high school college papers however least feebased service crossref 1 free service etblastorg designed target needs biomedical publication industry information various services examples type operability output things need considered publishers editors reviewers selecting using services provided c 2011 elsevier inc rights reserved', 'artificial intelligence chatbots invaded tourism industry owing low cost high efficiency however influence emotional expressions chatbots service outcomes received much attention researchers drawing upon expectancy violations theory explored emotional expressions chatbots affect customer satisfaction using three experiments context tourist attraction recommendations chatbots expressions concern customers improve customer satisfaction reducing expectancy violations particular customers goal orientation humanlikeness chatbots avatars relationship type customers chatbots moderate negative relationship emotional expression expectancy violation furthermore study highlights necessity tourism companies carefully design chatbot interactions align customers expectations ensuring balance efficiency empathetic communication incorporating emotional intelligence chatbot design tourism businesses enhance customer satisfaction also foster stronger personalized connections clientele research suggests future studies delve deeper nuances chatbotcustomer interactions exploring different emotional cues contexts influence customer experiences service outcomes tourism sector', 'plagiarism many different natures ranging copying texts adopting ideas without giving credit originator paper presents new taxonomy plagiarism highlights differences literal plagiarism intelligent plagiarism plagiarists behavioral point view taxonomy supports deep understanding different linguistic patterns committing plagiarism example changing texts semantically equivalent different words organization shortening texts concept generalization specification adopting ideas important contributions others different textual features characterize different plagiarism types discussed systematic frameworks methods monolingual extrinsic intrinsic crosslingual plagiarism detection surveyed correlated plagiarism types listed taxonomy conduct extensive study stateoftheart techniques plagiarism detection including character ngrambased cng vectorbased vec syntaxbased syn semanticbased sem fuzzybased fuzzy structuralbased struc stylometricbased style crosslingual techniques cross study corroborates existing systems plagiarism detection focus copying text fail detect intelligent plagiarism ideas presented different words', 'plagiarism one forms academic misconducts problematic results discouraging innovation losing trust academic community modeled plagiarism academic publications means similarity textual contents citation relations furthermore adopted model proposed method plagiarism detection evaluate method using two types dataset namely autosimulated andmanually judged dataset experiment shows method outperforms baseline uses similarity textual contents autosimulated dataset manually judged one acl subdataset', 'artificial general intelligence idea someday hypothetical agent arise artificial intelligence ai progresses surpass far brightest gifted human minds idea around since early development ai since scenarios ai may behave towards humans subject many fictional research works work presents two significant advances unique method determining players specific fears via game data machine learning methods adaptive game system employs agents monitor players terror experiences restrict exposure components find upsetting additional evidence user studies statistical significance testing suggests method may boost stress anxiety felt gamers resulting rewarding gaming experience particular focus 3 specific families modern ais develop idea deep neural networks current backbone nearly artificial intelligence methods poor candidates agi arise due many limitations therefore threat coming recent ai race lie agi limitations uses lack regulations current models algorithms endeavor kind potential advance state vr artificial intelligence gaming also offering exciting memorable adventures gamers', 'article introduce model adjustable moisture control specifically designed historical buildings proposed system developed flexible iot infrastructure equipped complex network sensors monitor indoor humidity levels compare groundwater levels rainfall wind speed manage drying system control model employs type2 fuzzy logic reasoning enabling adapt decisions based intensity water absorption innovative model thus provides intelligent system managing interior conditions historical buildings system installed tested old brewery building research results demonstrate efficiency dehumidification minimal cost', 'artificial intelligence education aied research aimed support student learning experiences ai domains suggest ethical intentions alone insufficient necessary explicitly consider issues like fairness accountability transparency bias autonomy agency inclusion generally important distinguish ethical things things ethically understanding making pedagogical choices ethical accounting possibility unintended consequences however addressing related questions far simple first step towards addressing critical gap invited 60 aied communitys leading researchers respond survey ethics application ai educational contexts paper first introduce issues surrounding ethics ai education next summarize contributions 17 respondents discuss complex issues raised specific outcomes include recognition aied researchers trained tackle emerging ethical questions welldesigned framework engaging ethics aied combining multidisciplinary approach set robust guidelines seems vital context', 'article examines benefits risks artificial intelligence ai education relation fundamental human rights article based eu scoping study berendt b littlejohn p kern p mitros x shacklock blakemore 2017 big data monitoring educational systems luxembourg publications office european union httpspublicationseuropaeuenpublicationdetailpublication94cb5fc8473e11e7aea801aa75ed71a1 study takes account potential ai big data provide effective monitoring education system realtime also considers implications fundamental human rights freedoms teachers learners analysis highlights need balance benefits risks ai tools developed marketed deployed conclusion drawn call embed consideration benefits risks ai education technology tools development marketing deployment tools questions raised body organization take responsibility regulating ai education particularly since ai impacts data protection privacy fundamental rights general given ais global impact argued regulation occur transnational level global organization un taking role', 'one branches machine learning deep learning model combined artificial intelligence widely used field computer vision technology image recognition field represented medical image analysis also developing advantage rely human annotation allowing computer recognize process feature information omitted humans model training process achieving even exceeding accuracy human processing based general lack explainability caused unknown data processing process deep model existing solutions mainly include establishment internal explainability attention mechanism interpretation specific models interpretation unknowable models represented lime way quantitatively assess interpretability still explored especially interpretative assessment doctors patients medical decisionrelated models several scales proposed reference current research application artificial intelligence deep learning models medical imaging generally pays attention accuracy rather explainability resulting lack explainability thus hindering practical clinical application deep learning models therefore need analyze development medical image analysis field artificial intelligence computer vision technology balance accuracy interpretability develop deep learning models doctors patients trust become research focus industry future', 'evolutionary computation subfield artificial intelligence artificial life characterized use biologically inspired methods solve optimization problems iterative refinements set solutions via change selection approach began 1950s comprises growing set algorithms capable solving wide range problems divided various types differing selection mutation representation candidate solutions successful applications recorded multiple domains including optimization machine learning robotics various areas study living systems evolutionary computation recently experienced revival particularly study openended evolution significant implications future ai unique potential generate endless innovations lead paradigm shift development artificial intelligence artificial life', 'past decades number vehicles road consistently increased due growing demand urban mobility modern logistics surge vehicles led significant issues heightened traffic congestion increased traffic accidents hinder economic development challenges effectively addressed making vehicles smarter reducing dependence human drivers past century extensive research conducted various nations propelled automation road vehicles today major motor manufacturers worldwide actively developing autonomous vehicle av technologies advancements artificial intelligence ai widespread adoption autonomous cars closer might expect ai become critical element avs enabling perceive environment make realtime decisions accurately progress ai fueled proliferation big data numerous sensing devices advanced computing resources fully understand ais role av systems essential explore development historical context', 'paper provides comprehensive literature review research application machine learning ml algorithms recommender systems rs study aims identify recent trends explore reallife applications guide researchers positioning research activities domain covering publications january june 2023 findings categorized various domains including education healthcare ml algorithms autoencoders reinforcement learning ecommerce digital journalism review emphasizes improved recommendation accuracy increased scalability personalization context awareness well diverse ml techniques strategies handling cold start data sparsity additionally lays groundwork future advancements ml algorithms rss particularly context manufacturing enterprises']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parte 1: Clasificación de \"Plagio\" o \"No Plagio\""
      ],
      "metadata": {
        "id": "IJR_OH-q2R0G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inicialización de modelo y tokenizador BERT"
      ],
      "metadata": {
        "id": "uRluzg5d2WCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar el tokenizador y el modelo de BERT\n",
        "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
        "model = AutoModel.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')"
      ],
      "metadata": {
        "id": "Tf_sNuZK2Bv3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "becf9cb2c5754546b0fa900ff580a819",
            "4608f3a3882e49f791b763eb47893756",
            "ee2e595ac7fb4fefbdd58a1d62f94bd8",
            "72d3b027e63e4af6bf9eb0b8567bb6c4",
            "b0c67d63413c42e6a1aef8bb58530b4e",
            "00d62c647251424fb15a02b0e82a617d",
            "5718c718555b4f759948d5a16df08d28",
            "a7e73e24f2984f1899ef809ad4df24b5",
            "f138efd040b44532a48568b0129bee01",
            "00a2b19bea5d48c9b34ed3b39c9ac756",
            "06a71d1357f2475591b110ad834ca77e",
            "b0256c88da6e479b918c48c81bd57234",
            "04f6322a6f3647589dbca6d45bdf365d",
            "f9e710eed9ef404991a7587f3d7ff036",
            "661249516d424aeda83c4833a049a98e",
            "511673328b90460faaf5d7b0d3bb59b4",
            "c4ffa7bfadab435b88b022649c4df664",
            "43d78f1ebda7489db3fe9965099be540",
            "cc194a1cba924045a3bb8ed3d956f882",
            "c5f5b1b3aa9747e3b4edd0742190f10f",
            "e368a1c05ea64fe6b2ef40cf03df9cdf",
            "a9096c8bfbbc43f6ae710401161f7752",
            "8915e34474834f31a7404fdcbaf5e9c8",
            "cc4d5af457114a59a699bc3e0edb2496",
            "f829504d5e76454ca895c511496db3a3",
            "6dbf0f0e5fe440cc8146d5c0013a8c3d",
            "73b49df047304ac4ba46489ea6f08fdd",
            "a3029520d55a4204aed288400b8e2644",
            "f50ac11dfa544a14a85900c167d04799",
            "c1bd133a42944f468b538de12195ecde",
            "01d300a5f2a742fb95d2c748edb96c57",
            "73a80f0a5a0d46428b1e35eb1822f5ae",
            "2e11319d330941cfa875df36a7d22bc5",
            "583fbbe9ea234d959f27b94b0524194b",
            "0cc3c47b067a4b61859875f1209459d6",
            "4983eb02ae8e469cb0f3c98603940d78",
            "796b5e65106d4444b1dd1cf06d112e33",
            "5f51a345d1ae494292f28b72354c8f63",
            "cec6e2a321914cc9bbc2399394b642ee",
            "cc60b6fcc7d54f46bd4759674b4abc96",
            "b4892d9a3c054143a7f0836567aebe67",
            "f8560bdfa1e5429498cce1f035d5c2f0",
            "db742631eb4b4e01a31b8c6c1bdf31a0",
            "6aa5583962c44d92a13dd822be728ddd",
            "213a6ec454414648ab6c1aa23b15a52e",
            "ec2df851495a477b8490ff1f433c619c",
            "331b5775cf21489fb80ad5360105c35b",
            "787f9bb1077a4fdb87d96392c6cf92f5",
            "e45a2469f7024399af87810046e51f82",
            "0285c8c0cc0e47539f612d534b954cf6",
            "894a73471d904da8b4cf4a6c4ad857f1",
            "41bd2c2c1bbc4a8ca760cb6ebcc18d45",
            "a5b684acf033453f9d3a25f5fd8a323d",
            "e43933bc4f554a18bb3d3f0c70ea48bb",
            "79e47dee4448483a86f9a0f78f6fbe7b",
            "dd849ec76e684cb9b95b6457b84ddfff",
            "492ac077a38a4a5e97dad533eecca5f8",
            "619c94803f1747ae9885b74ea5781a2f",
            "927d2265d8784a42aa30c1a37994ec92",
            "0db70a48e9ee4601b170192f08405176",
            "c5d030bff0174a869686c2f9adf139c0",
            "8b93e65299dc4255882e3671fc33ba06",
            "518c514f8ff240c883542398591a393d",
            "317c24cce19d4c428241307e55d31cbf",
            "8bf749a005b246c79e6b277d953ed4a4",
            "57998c7274fe49bda45a572a33792259",
            "76a1d7dc6d8c4c358a6c2076aa4ad2aa",
            "685643db42064159837a624143f978e8",
            "c9bd701b93e84c56a35bed76a47de8a4",
            "4347f16cb9e544e5a4065ba30ad7fed3",
            "69aff2388a7849eaa0a524b87d5bdb03",
            "73a3a759b4d840549a9251c6a9037282",
            "635bcd5be8764af6864d8ee291fc448a",
            "44c44f69faee41f09f9e376bf7716293",
            "45aa48e2755f4f34a9f7868148dd3203",
            "9ca37055e6b34022ab6758bd897759d1",
            "c448dc59120c4fcd93ba6b1b1b1b78c5"
          ]
        },
        "outputId": "2760aa12-bc45-44fa-c66a-27a8c999beac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/399 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "becf9cb2c5754546b0fa900ff580a819"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0256c88da6e479b918c48c81bd57234"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8915e34474834f31a7404fdcbaf5e9c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "583fbbe9ea234d959f27b94b0524194b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "213a6ec454414648ab6c1aa23b15a52e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd849ec76e684cb9b95b6457b84ddfff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76a1d7dc6d8c4c358a6c2076aa4ad2aa"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenización de textos"
      ],
      "metadata": {
        "id": "3k-oCo2X4eRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para inicializar un diccionario de tokens\n",
        "def init_dictionary(sent):\n",
        "  # Inicializar diccionario: almacenar oraciones tokenizadas\n",
        "  token = {'input_ids': [], 'attention_mask': []}\n",
        "  for sentence in sent:\n",
        "      # Codificar cada oración y agregar al diccionario\n",
        "      new_token = tokenizer.encode_plus(sentence, max_length=128,\n",
        "                                        truncation=True, padding='max_length',\n",
        "                                        return_tensors='pt')\n",
        "      token['input_ids'].append(new_token['input_ids'][0])\n",
        "      token['attention_mask'].append(new_token['attention_mask'][0])\n",
        "  return token"
      ],
      "metadata": {
        "id": "TT85FcC94IJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizar los textos de construcción y prueba\n",
        "plagiarism_token = init_dictionary(plagiarism_clean)\n",
        "construction_token = init_dictionary(construction_clean)\n",
        "test_token = init_dictionary(test_clean)\n",
        "\n",
        "# Impresion de la tokenizacion\n",
        "print(f'Plagiarism: {plagiarism_token}')\n",
        "print(f'Construction: {construction_token}')\n",
        "print(f'Test: {test_token}')"
      ],
      "metadata": {
        "id": "FWfweotS5F3O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02ce0ef6-46d1-4622-a75c-3bd54456d3f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plagiarism: {'input_ids': [tensor([  101,  3522,  8973,  7976,  4454,  9932,  7013,  2307, 10908,  2925,\n",
            "         4254,  9932,  2495,  4083,  9932,  2098,  2411, 10908,  5105, 28616,\n",
            "         8663, 24422,  2015,  2783,  4087,  9859, 13990,  7073,  6745, 12607,\n",
            "         2015,  9932,  2495, 15241,  3132, 15251,  4395,  2495,  2554,  3720,\n",
            "         3073,  3319,  4493,  9932,  3001,  2495, 21877,  2850,  3995, 12863,\n",
            "         4547, 17568,  3443,  5579,  9932,  2098,  3001, 12685,  2536,  8107,\n",
            "        13543,  9932,  2495,  4083, 14313,  2241,  2367,  4824,  2015,  9932,\n",
            "         2495,  2071,  2468, 12944,  4022,  7860,  4130,  9932,  2098,  7375,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  7976,  4454,  9932, 20607,  4646,  9186,  5901,  3352,  9897,\n",
            "         2112,  3679,  3268,  2755,  9932,  8590,  2126,  2111,  4553,  2174,\n",
            "         8346,  4547,  4753,  4320,  3365,  7860, 12962,  5936,  3800,  2817,\n",
            "        11628,  6695,  6666, 15314,  9932,  2495,  7721,  3319,  7882,  3906,\n",
            "         4146,  2478, 11778,  3319,  4118,  6709,  2783,  2470, 12878,  3073,\n",
            "        16030,  4824,  9932,  2974,  2495, 19156,  2925,  2470,  7826,  9556,\n",
            "         3936,  9932,  2015,  7375,  2495, 12506,  6022,  2764,  3032,  2470,\n",
            "         4227, 12144,  3068,  2871,  3690,  3176,  7860, 11433,  2036,  6936,\n",
            "         2817,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  2817,  4146,  4180,  4106,  2470,  4208, 26944,  2075,  7976,\n",
            "         4454,  9932, 12550,  2495,  4753, 12151,  4022,  2470, 12878,  7860,\n",
            "         9932,  2495,  2561,  2531,  4981,  2164,  6191, 17537,  4981,  6356,\n",
            "         2913,  4261, 17826,  4981,  3479,  2495,  4547,  2470,  4696,  2591,\n",
            "         4163, 11091,  5950,  7809,  2230, 12609,  4180,  4106,  3936,  2470,\n",
            "         3980,  2071, 20427,  2458,  6741,  5579,  9844, 12832,  2784,  4083,\n",
            "         4646,  6741, 12247, 13384, 19293,  4083,  8346,  6741,  7461,  3512,\n",
            "         9798,  2535, 13068,  2075, 10047, 16862,  3512,  4083, 11721,  4328,\n",
            "        10803,  5678,  2176,  2470, 12878, 18447, 11795,  3388,  2477, 21708,\n",
            "         4454,  2784,  4083, 23700, 23067,  3070,  9312,  9932,  2495,  6749,\n",
            "         8993,  2174,  2036,  4453,  7860,  2495,  2089, 13368,  9932,  2164,\n",
            "        24156,  4646,  9932,  5461, 20607,  4395,  5089,  2493,  2591, 12962,\n",
            "         5936,  9556,  3749,  7721, 19184,  9932,  2015,   102]), tensor([  101, 25682,  2382,  3032,  2207,  2120,  7976,  4454,  9932,  3343,\n",
            "         9942,  5491, 12685,  3488, 10908,  4953,  9932,  3747,  2536,  3343,\n",
            "        11105,  2164,  2495,  4050,  4769,  2591, 12962, 13494,  9932,  3720,\n",
            "        10438, 23539,  4106,  2484,  2120,  9932,  3343,  9942, 12843,  2535,\n",
            "         2495,  3795,  9932,  3343, 10287,  4858,  4646,  9932,  2495,  9932,\n",
            "         2098,  4321,  4394,  3343, 22580,  6150,  3643,  2495,  8225,  2250,\n",
            "        13775,  2100, 14877,  2731,  9932,  8519,  4600, 13155,  5678, 12962,\n",
            "        16852,  9932,  2098,  4374, 10124,  3086,  2750,  2236, 12144,  9932,\n",
            "         9615, 10287,  5491,  6083,  9932,  2098, 12368,  3343, 12962, 13494,\n",
            "         6873, 28032,  3512,  4997,  3270,  3726,  2664,  6162,  7731,  5038,\n",
            "        10502, 11376,  2015,  3145,  3247, 12088,  5142,  2445,  4621,  3343,\n",
            "         6176, 12962,  9584,  4876,  6970, 21077,  3720,  9251,  2422,  9556,\n",
            "         3720, 12033,  7705,  2274,  9932,  9615,  6481,   102]), tensor([  101,  7976,  4454,  9932, 17903,  2088,  3278,  3971, 14670,  6151,\n",
            "        19825,  6321,  3893,  6923, 16762,  7386,  2015,  2036,  2765,  2974,\n",
            "        16935,  9932,  2536,  2227,  3215,  2529,  2166,  7552,  3375, 12962,\n",
            "         3314, 17707,  2640, 10813,  2224,  2974,  2104,  9363,  2890,  2342,\n",
            "         2128, 13331,  7630,  3686,  2925,  9797, 11216,  2247,  8390,  4083,\n",
            "         9932, 10232,  3345,  2925,  2372,  9932,  2451, 22859,  5136,  9932,\n",
            "         2453,  7461,  7243,  3268,  9979, 10198, 25845,  6666,  7163,  4328,\n",
            "         6774,  4022,  7386,  2015,  4719,  2112,  7721, 11778, 10502,  9932,\n",
            "         9615,  8882,  3259,  4780, 12685,  2367,  8107,  9932,  9615,  3073,\n",
            "         2275, 11433,  3141,  9932,  9615,  2495,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  7976,  4454,  2495,  9932,  2098,  2470,  8704,  2490,  3076,\n",
            "         4083,  3325,  9932, 13100,  7127, 12962, 11174,  2894, 13990,  2036,\n",
            "         4072, 12045,  5136,  3314, 26935, 17842, 16987, 13827, 12645,  4034,\n",
            "        10502,  3227,  2342, 21032,  3772, 12962,  2135,  2437, 12962,  6567,\n",
            "         3305,  2191, 21877,  2850,  3995, 26715,  9804, 12962,  4070,  5377,\n",
            "         6061,  4895, 18447, 21945,  8465,  2174, 12786,  3141,  3980,  2521,\n",
            "        19647,  3988,  3357,  2875, 12786,  4187,  6578,  4778,  3438,  9932,\n",
            "         2098,  2451,  2015,  2877,  6950,  6869,  5002,  9615,  4646,  9932,\n",
            "         4547, 18046,  3259,  2034,  8970,  3314,  4193,  9615,  9932,  2495,\n",
            "         2279,  7680,  7849,  4697,  5857,  2459, 25094,  6848,  3375,  3314,\n",
            "         2992,  3563, 13105,  2421,  5038,  9932,  2098,  6950,  6055,  4769,\n",
            "         8361, 12962,  3980,  2092,  6155, 23773,  2098,  7705, 11973,  9615,\n",
            "         9932,  2098, 11566,  4800, 10521,  6895, 28296,   102]), tensor([  101,  4547,  5097,  9932, 12586, 19351,  9236, 29371,  5218,  2224,\n",
            "         7076, 21649,  3937, 11850,  4162,  2470,  3720,  3640, 19184,  3151,\n",
            "         8361,  7705,  2015,  9932,  2495,  2220,  6950,  8279,  4975,  3167,\n",
            "         3550,  4252,  3001,  3265, 26262,  6168,  3522,  2147, 10592,  2591,\n",
            "        10266,  4083,  4044,  2536,  2882,  7860, 12944,  3314,  2145, 26964,\n",
            "         9932,  2495,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101, 20607,  3791,  3330,  3068,  5478,  7142,  6622,  3330,  2495,\n",
            "         2562,  6393,  6745, 10660, 12607,  2015,  2028, 10990,  2458,  8391,\n",
            "        27891, 11416,  6024,  7976,  4454,  9932,  2974, 28593, 11834, 21600,\n",
            "         2102,  4512,  2389,  4005, 11834, 21600,  2102,  4022,  3749, 21727,\n",
            "         4621,  4083,  6322,  4346,  3167,  3550, 12247, 17959,  2493,  2092,\n",
            "         4526, 12689,  7484, 24710,  2398,  2239,  4083,  2174, 10232, 13399,\n",
            "        12546,  2974, 11834, 21600,  2102,  2714, 11416,  6024,  9932,  3001,\n",
            "         4621,  2731,  2951,  2089,  2566, 22327, 20598, 13827,  2229, 21089,\n",
            "         9699,  3659, 28616,  2378, 14192,  3370,  7297,  8346, 11416,  6024,\n",
            "         9932,  2495, 13275, 12962,  5936,  6061, 16655, 23048,  2389,  9841,\n",
            "        21821,  2102,  2224,  2493,  4022, 13508,  2529,  3667, 10155, 15832,\n",
            "         2974,  2783,  2110, 11416,  6024,  9932,  2974, 28593, 11834, 21600,\n",
            "         2102,  8052,  2664, 29238,  4240, 12185,  2925,   102]), tensor([  101,  3800,  3720, 17908, 12637,  4009, 12221,  7976,  4454,  9932,\n",
            "         2495,  3579,  8050,  2529,  2916,  3720,  2241,  7327,  8040, 17686,\n",
            "         2817,  2022,  7389, 11927,  1038,  2210,  5558,  7295,  1052, 22762,\n",
            "         1052, 10210,  7352,  1060, 22200,  7878,  6511,  5974,  2418,  2502,\n",
            "         2951,  8822,  4547,  3001, 10765,  5523,  2436,  2647,  2586, 16770,\n",
            "        14289, 16558, 21261,  3366, 10976,  4502, 13765,  2368, 14289, 16558,\n",
            "        21261,  3207, 14162, 14289, 16558, 21261,  2683,  2549, 27421,  2629,\n",
            "        11329,  2620, 22610,  2509,  2063, 14526,  2063,  2581, 21996, 17914,\n",
            "         2487, 11057, 23352,  2098,  2581,  2487, 27717,  2817,  9932,  2502,\n",
            "         2951,  2641,  4022,  7300,  8080,  2495,  2291, 18228,  2613,  7292,\n",
            "         2036, 10592, 13494,  8050,  2529,  2916, 22467,  5089, 26262,  4106,\n",
            "        11637,  2342,  5703,  6666, 10831,  9932,  5906,  2764, 11625,  7333,\n",
            "        16519,  2655,  7861,  8270,  9584,  6666, 10831,   102]), tensor([  101, 12854,  8281,  2715,  3690, 26261,  4215, 24333,  6772,  2974,\n",
            "         2408,  5919,  2166,  2164,  2495,  2071,  5275, 18987,  2974, 21416,\n",
            "        21850,  6632,  2495, 28089,  5105,  9823,  8790, 22552,  3276,  3836,\n",
            "         3076,  2092,  2426,  2493,  6550,  6233,  5429,  2875,  2462,  2102,\n",
            "        12598,  2389,  2009,  6806,  2226, 28771,  2241,  3754,  2433,  9547,\n",
            "         2504,  4198,  2791,  3836,  2493,  2426,  2493,  2593, 10548,  5360,\n",
            "         3652, 21416, 21197,  3989,  2495,  2770,  5903,  4298,  4654, 10732,\n",
            "        28483,  3436,  3277,  4145,  4553,  9031,  5328,  5089,  8210,  6904,\n",
            "         6895, 27606,  6591,  4083,  2832,  2738,  3633, 11532,  7070,  3716,\n",
            "        17727,  8445,  2500,  3720,  2034, 16157,  2783, 21416, 21197,  3989,\n",
            "         2495,  4254,  9823,  6550,  2117,  8849, 20934, 17198,  8474,  2462,\n",
            "         2102,  2009,  6806,  2226,  6550, 13494,  2495,  2633, 28699,  9869,\n",
            "         2245,  7551,  3251, 12607,  9932,  2071,  2028,   102]), tensor([  101,  2947,  5038,  3269,  4295,  6827,  5237,  7209, 23934,  3078,\n",
            "         3120,  4761,  6519, 24014,  4968,  3318,  4800, 14971,  6313,  3032,\n",
            "         4295,  3303,  4264,  2349,  2536, 26835,  2015,  2066, 18191, 15289,\n",
            "        10327, 20090,  6196, 12194,  6409,  5237,  3840,  2408,  2088,  3036,\n",
            "         8765,  7175,  3737, 11712, 10232,  8080,  4295,  4264,  3274,  4432,\n",
            "         2784,  4083,  2261, 19040,  4083,  3730,  9798,  5461, 12550,  2536,\n",
            "        14766,  8073,  6709,  4295,  4264,  3081,  7053,  4871,  5461,  2036,\n",
            "         5770,  6617, 10910,  4654,  5669, 25090,  3560,  6413,  4506,  4468,\n",
            "         7312,  3737, 11712,  8765,  4646,  5461,  5038,  4295, 13642,  5339,\n",
            "        20502,  4761,  2755,  6313,  4989,  4295,  2838, 14676,  2838, 12992,\n",
            "         3177,  2974,  8122,  2470,  3269,  4295,  8715, 17725,  5664,  3033,\n",
            "         4264,  2036,  3056,  8382,  5461,  2511,  4652, 10210, 28731, 26835,\n",
            "         2594,  5081,  9690,  4141,  8985, 11156,  5664,   102]), tensor([  101,  2116,  7976,  4454,  2241,  3192,  4275,  3818,  6047, 13851,\n",
            "         6807,  2124,  4874,  4280,  2047,  2714, 16820,  2312,  2193,  8360,\n",
            "        13907,  5361,  2715,  9414,  4683,  2034,  7680,  7849,  4697,  2783,\n",
            "         4235, 13901,  3192,  4275,  3192,  4454,  2734,  6047, 13851,  9414,\n",
            "         4683,  3661,  8704,  6183,  6192,  6047, 13851,  2470,  9414,  4683,\n",
            "         2195,  4387,  2553,  2913,  6936,  2265,  4022,  8192,  2015,  2061,\n",
            "         2527, 15058,  2094,  5903,  4432,  2628,  2925,  2470,  3257,  2174,\n",
            "         2145, 10368,  3192,  4275,  6047, 13851, 11487,  4874,  4280,  2464,\n",
            "        16100, 16820,  4863,  2061,  2527, 15058,  2094,  5903,  4432, 12992,\n",
            "         3192,  4275,  6047, 13851,  3937,  4454,  2184,  9412,  4454,  2322,\n",
            "         2345, 18960,  4454,  2382,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  7300,  2442,  2036,  5083,  2974,  5676,  3633,  6464, 22149,\n",
            "        11301,  6509,  2613,  7292,  9163,  2817, 17976, 12265, 17453,  8315,\n",
            "         3633,  2451,  8704,  6509,  4346,  6047, 11721, 28682,  6709,  5344,\n",
            "         8604,  5200,  7976,  4454,  2468,  3278,  6994,  2715,  2974, 12067,\n",
            "         2111, 11835,  6681,  2536,  4725,  9308,  2817, 20618,  2367,  6786,\n",
            "         4725,  2109,  3041,  2393, 17453, 18234,  2111,  2154,  3406, 10259,\n",
            "         2166,  3633,  5107, 25172,  2015,  4390,  8518,  2593,  6397,  3532,\n",
            "         4432,  1038,  5737,  4832,  6397, 17453, 18234,   102,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  4800, 11263, 27989,  2389,  6397,  5375,  5080,  2881,  7861,\n",
            "        11452,  5198, 20226, 13589,  7073,  4346,  5906,  2342, 22149,  3604,\n",
            "        28999,  2088,  2350,  4664, 22508,  9015,  3679,  7860, 26290, 13280,\n",
            "         2622, 13999,  7721,  6047,  2490,  2291,  2881,  4681,  3791,  2111,\n",
            "        17453, 18234,  3078,  3289, 25281, 14622,  5200, 14125,  9765, 22835,\n",
            "        12103,  5200,  5198, 11703, 11514, 22658,  4110,  5751, 24936,  5378,\n",
            "         2613,  7292,  3295, 15058,  2094,  9163,  7826,  3935,  2291, 13749,\n",
            "        18595, 13453,  6377,  3940,  2132, 19093, 11566,  2536,  2110, 15794,\n",
            "        22375,  6786,  8629, 11087, 18585, 13907,  6276, 24225,  3698,  4083,\n",
            "        13792,  5836,  9487, 11679,  2830, 28596,  3452,  3737,  2166, 12969,\n",
            "         6397,  2111,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  8361,  2491,  6028,  5107, 14262,  6767,  2075, 16911, 27120,\n",
            "         4950,  3001, 29508, 25423, 15088,  4044,  8392,  2135,  9756, 25423,\n",
            "        15088,  3169,  2750,  4852,  2470,  2492,  9932, 15058,  2094,  5107,\n",
            "         2491, 25423,  2615,  3001,  7721,  3319,  4790, 13398,  2236, 12878,\n",
            "         2925,  7826,  2492,  2470,  3132, 24075,  9682,  4683, 25423, 15088,\n",
            "         6296,  5294,  3086,  2116,  3330,  6742,  5097,  2197,  2086,  6459,\n",
            "         3169, 16991,  3259,  2034,  4391,  4646,  9414,  5107, 14262,  6767,\n",
            "         2075,  3001,  8392,  2135, 23448,  2536, 25423,  2615,  2491,  8518,\n",
            "         2164,  7605, 25423,  2615, 19120,  9682,  2598,  4874,  2206, 18355,\n",
            "        24685,  8392,  4899,  7976,  4454,  9932,  5461,  4235,  7333,  5107,\n",
            "        14262,  6767,  2075,  8392, 25423,  2615,  5097,  2147,  7721,  2135,\n",
            "        20798,  4646, 12607,  2015,  9932,  2368,  4819, 11788,  5107, 14262,\n",
            "         6767,  2075,  8392, 25423,  2615,  3001,  5266,   102]), tensor([  101,  5003,  7382,  9888,  3274,  4432,  7976,  4454,  5461,  2109,\n",
            "         5147, 11487,  2839,  4697, 28828,  3617,  4871,  2557, 18738,  8127,\n",
            "         2592,  2411,  4685,  2488,  5003,  7382, 13705, 10788, 23191,  8518,\n",
            "         9718,  2913, 14477, 14097,  2557, 18738,  4329,  3617,  3274,  2974,\n",
            "         2081,  2825,  2047, 12138, 12126,  5461,  2089,  2279,  3747,  7613,\n",
            "         2557, 27179,  4871,  2974,  3568,  2071,  9885, 10697,  5003,  7382,\n",
            "        13705,  7613,  3613, 11629,  2529, 14009,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  6123,  2147,  7534, 11778,  3319,  8704,  6709, 10439, 19341,\n",
            "         8553,  3274,  4432, 11718,  5237,  2537,  2274,  2550, 17588,  2088,\n",
            "        21154,  5785, 10500, 25176,  4783,  2319, 21569,  2426,  2800,  5906,\n",
            "        12944,  3274,  4432,  7300,  4117,  7976,  4454, 13792,  4719,  2590,\n",
            "         3463, 10788,  7060,  4871,  3168,  2556,  2423,  4981,  3479,  2197,\n",
            "         2274,  2086,  2367,  8107,  7438,  5919,  3141,  4295, 10788,  8982,\n",
            "         3737,  6887, 16515,  3723,  4691,  8982,  2537,  3248,  2590,  2535,\n",
            "         3795,  4610,  2592,  2974,  2028,  5906,  2203,  3463, 11778,  3319,\n",
            "         2825,  6709,  2307,  6695, 14427, 14246,  2226,  8389,  6364,  3131,\n",
            "         3935,  7976,  4454,  5461, 16962,  2078,  2784,  6772,  6125,  2810,\n",
            "        15873,  4725,  3274,  4432,  4162, 11718,  5237,  3168,  5157,  8114,\n",
            "         3647,  4725,  2833,  2537,  4852,   102,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  3274,  4432, 26226,  2492,  2817,  9144,  7588,  3305,  3617,\n",
            "         4871,  6876, 11014,  8285,  8585,  8518,  2864,  2529,  5107,  2291,\n",
            "         2426,  5970, 16570,  4383,  6786,  3815,  2592, 15901, 11707,  2678,\n",
            "         4110,  2203,  2891, 16186,  2926,  2307,  2419,  3623,  2193,  6786,\n",
            "         4082,  2282,  2974,  3935,  5970,  2926, 10124,  2135, 17503,  5970,\n",
            "        28616,  2164,  5001, 10464, 24895,  5970, 20478,  5970,  3073,  2592,\n",
            "        11707,  7709,  1041,  2290,  6602,  8192, 19817, 13006, 22471, 18909,\n",
            "         3568, 19309,  2951,  4106,  6827,  5970,  5547, 11619,  2951, 20446,\n",
            "         6026,  9710,  9585,  2047,  6695,  2470,  2458,  2492,  9144,  6194,\n",
            "         2613, 11108,  2592,  7654,  7588, 18444, 26226,  4866,  8483,  8051,\n",
            "         3746, 13851,  9932, 15058,  2094,  3746,  5038,  9932, 15058,  2094,\n",
            "         3746,  5038,  3722,  8518, 14622, 20057, 12326,  2015,  3935, 12435,\n",
            "         4286,  3522,  2086,  2348, 11707,  2678,  5038,   102]), tensor([  101,  8387,  4719,  3618,  5345, 10640,  3793,  5038,  4257,  5810,\n",
            "         2773,  5491, 15844,  2410,  5401, 10640,  4289,  3064,  3793,  9203,\n",
            "         9972,  3633,  5147,  2949,  6390,  4583,  1052, 12457,  8518,  2478,\n",
            "         2030, 28727,  2026, 17683,  1015,  3773,  9932,  4414,  3278,  4489,\n",
            "         2051,  6503,  8518,  1052,  6255,  2629, 16157,  2529,  2836,  2356,\n",
            "         6818,  2224,  5733,  3535,  2260,  3752,  8518,  2714,  3450,  3679,\n",
            "         2542, 14155,  8483,  3793, 12332,  3752,  2825,  6140,  2946,  5688,\n",
            "         2422,  2504,  2036, 14155,  3633,  2071,  3143,  8518,  5733,  7594,\n",
            "        10640,  6503,  2051,  6818,  2036,  2949,  5002,  7175,  2048,  8387,\n",
            "         4955,  4102,  6140, 13122, 28084,  2818,  5144,  2529,  2836,  6459,\n",
            "         2048,  7976,  4454,  4432,  8387,  2030, 28727,  2026, 17683,  1015,\n",
            "        12109,  5080,  3773,  9932, 18059, 25249,  4646, 13494, 14617,  4989,\n",
            "         3752,  5080,  4681,  2241,  3265, 18394,  3188,   102]), tensor([  101,  2783,  2470,  4646,  7976,  4454,  2784,  4083,  4275,  2966,\n",
            "        12126,  3227, 12778,  3086, 10640,  2738,  4863,  3754,  4525,  3768,\n",
            "         4863,  3754,  2947, 17666,  7999,  6742,  6612,  4646,  2784,  4083,\n",
            "         4275,  2241,  2236,  3768,  4863,  3754,  3303,  4242,  2951,  6364,\n",
            "         2832,  2784,  2944,  4493,  7300,  3701,  2421,  5069,  4722,  4863,\n",
            "         3754,  3086,  7337,  7613,  3563,  4275,  7613,  4895,  2243, 19779,\n",
            "         3085,  4275,  3421, 14123,  5056, 11160,  2529,  5754, 17287,  3508,\n",
            "         3274,  6807,  2832,  3444,  2592, 16647,  2529,  9552,  2944,  2731,\n",
            "         2832,  6162,  2130, 13467, 10640,  2529,  6364,  2028,  5628,  3698,\n",
            "         4083,  2784,  4083,  2944,  4117,  7976,  4454,  4235,  2109,  2492,\n",
            "         3274,  4432,  2974,  3746,  5038,  2492,  3421,  2966,  3746,  4106,\n",
            "         2036,  4975,  3568,  2342, 17908,  2458,  2966,  3746,  4106,  2492,\n",
            "         7976,  4454,  3274,  4432,  2974,  5703, 10640,   102]), tensor([  101,  3259,  3701,  6936,  2004, 24335, 12589,  2227,  5038,  3291,\n",
            "         2193,  3415,  2171,  2862,  2193,  5344,  6302,  2453,  5020,  2227,\n",
            "         8073, 12599,  2171, 14354,  3277,  2116,  6295,  2627,  3116, 13180,\n",
            "         2165,  2177,  7760,  3116,  3024,  7978,  2171,  2862,  6818,  2302,\n",
            "         2028,  3406,  5643, 10873,  5409,  2553,  2177,  6302,  2453,  4666,\n",
            "         5344,  8019,  3116,  2178,  3114,  2004, 24335, 12589,  2227,  5038,\n",
            "         3116,  5073,  3711,  7760,  7197,  2635,  4620,  3259,  3818,  2004,\n",
            "        24335, 12589,  2227,  5038,  7337,  2170, 21358, 10867,  2460,  3322,\n",
            "         3818, 21358, 10867,  4233,  2010,  3406, 13113,  8048, 17978,  2015,\n",
            "        27589,  2490,  9207,  3698, 17917,  2213, 11487, 14817,  5344,  7760,\n",
            "         2279, 21358, 10867, 15901,  2838,  2227,  2478,  9530,  6767,  7630,\n",
            "         3508,  3444,  4949,  9530,  2615,  1035, 21461,  4233,  2838, 13571,\n",
            "         5344,  2367,  4280, 21358, 10867,  4162, 28093,   102]), tensor([  101,  2227,  6827,  2112,  2529,  2303,  8200, 12955, 10232, 14622,\n",
            "         2111, 13268,  5038,  2974, 10424,  2102,  2028,  3144, 17160,  6786,\n",
            "         2715,  2335,  2088,  3048,  2875,  3967,  3238, 10424,  2102,  2522,\n",
            "        17258, 16147,  6090,  3207,  7712,  2349,  3967,  3238, 16012, 12589,\n",
            "         6459, 10424,  2102,  3352,  3243,  2759,  4969,  5661,  6419,  7511,\n",
            "         4344, 16550, 26221,  2015,  7976,  4454, 15058,  2094, 10424,  2102,\n",
            "         3098,  8216,  3293, 16746,  3036,  9867, 27280,  6305,  9623,  2015,\n",
            "         2491,  3001,  3617,  9871,  6302, 26384,  4385, 11105,  2224,  2468,\n",
            "         6827,  2556,  4807,  2556,  3795,  9886, 10424,  2102,  4803,  9874,\n",
            "         3006, 27891,  2974,  2536, 11105,  7860,  4803,  5936,  2569,  4431,\n",
            "         2634,  4969,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  5761,  3112, 13268, 10768, 25300,  9276,  5970, 21461,  2015,\n",
            "         3130,  2443,  5301,  6165,  6327,  5907, 10617,  2931,  5776,  2890,\n",
            "         6442,  2098,  9560,  5761,  2817,  2109,  7976,  4454, 13268,  5038,\n",
            "         4007,  7863,  2135, 16157,  3896, 21461,  2015,  8690,  5907,  2287,\n",
            "         2426,  3287,  3406,  7959,  9067,  2063, 16824,  5022,  2092,  3276,\n",
            "         5776, 13268,  9967, 16367, 19124,  3653, 25918,  8082,  2695, 25918,\n",
            "         8082,  4871,  2676, 16824,  2308, 14996, 21461,  2015, 16578,  9733,\n",
            "         2015,  9932, 13268,  5038,  4007,  5646,  5907, 10768, 25300, 22758,\n",
            "         7023,  3556,  8690,  2287,  2931,  5907,  3723,  4691,  7620,  5907,\n",
            "         3723,  4691,  3653, 25918,  8082,  2135,  2695, 25918,  8082,  2135,\n",
            "        10768, 25300, 22758,  7023,  7644, 16578, 14358,  5776,  9967,  2227,\n",
            "         4160, 14184,  2949,  2695, 25918,  8082,  2135,  3653, 25918,  8082,\n",
            "         2135, 21461,  2015,  4871,  8690,  2931,  4466,   102]), tensor([  101, 10889,  2152, 16222,  4648,  9243,  3130,  2988, 17003,  5345,\n",
            "         3333,  6022,  4320,  9694,  3785, 15359, 11967, 22088, 11368,  2075,\n",
            "         2659,  3515, 11305, 13268,  5038,  3001,  3491,  8052,  2836,  7812,\n",
            "         3785,  2817,  5393,  6937,  9885, 10640,  4320,  3375,  6447,  7860,\n",
            "         5171,  2613, 11108, 15359, 16820, 20655,  2342, 12607,  2015,  2958,\n",
            "         6578,  3522, 12607,  2015,  3698,  4083,  3274,  4432,  3491, 13268,\n",
            "         5038,  3001, 10910, 16222,  4648,  9243, 15602,  2529,  2836,  4758,\n",
            "        10906,  4344, 16550,  4106,  4928,  8321,  5919,  8556,  2580,  2312,\n",
            "        15782,  2571, 12553, 13268,  2951, 13462,  2881,  4758, 13268, 10515,\n",
            "        23150,  8126,  3785,  8567,  2613, 15359,  8146,  3921,  3039,  2149,\n",
            "        23087, 14358, 13268,  5038,  2536, 10368,  2613, 11108,  3785,  2478,\n",
            "        12553,  2951, 13462,  2092,  2243, 19779,  2078,  2951, 13462,  5025,\n",
            "         5344,  7718, 10640,  2048,  4235,  2109, 15756,   102]), tensor([  101, 13268,  5038, 23447, 28146,  2759,  2492,  3274,  4432,  2926,\n",
            "        12607,  2015,  2784,  4083,  2951,  4520,  2784, 13268,  5038,  2081,\n",
            "         3278,  5082,  4235,  4162,  2613, 11108, 16820,  3143, 13268,  5038,\n",
            "         2291,  2920,  2093,  2364,  6177, 13268,  5038, 10296,  6630,  2291,\n",
            "        11156,  5344, 13115,  3115,  3193, 15901,  2838,  5038,  2478,  2784,\n",
            "         9530,  6767,  7630,  3508,  2389, 15756,  6125,  3720,  3024,  6851,\n",
            "        19184,  6745, 12607,  2015,  2752,  4760,  2784,  4083,  6551,  9412,\n",
            "         7590,  4874, 10788,  3698,  4432, 10368,  2181,  3223,  3278,  8377,\n",
            "         3746,  5579, 10640, 23454, 14993, 27097,  2529,  2836,  4874, 10788,\n",
            "        13792,  2145,  2220,  5711,  2783, 13792,  4719,  2871,  2620,  7341,\n",
            "         2715,  5200,  6176,  2951, 13462,  4989, 10232, 15502,  3463,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  2227,  5038,  4227,  3278,  3086,  2028,  6179,  3746,  4106,\n",
            "         5097, 15929, 16594,  4310,  9788,  8720,  4813,  3001,  5214, 14622,\n",
            "         5198,  2227,  5038,  3001,  8077,  3273,  2291,  2174,  2193,  4009,\n",
            "        12221,  4493,  2227,  5038,  4725,  2453,  4504,  2936,  2010,  3406,\n",
            "        13113,  9784,  2312, 15782,  2571,  7809,  4769,  7860,  2227,  5038,\n",
            "         3818,  8893,  4078, 23235,  2953,  2478,  4800, 23467,  2334, 28774,\n",
            "        24041,  5418,  8318, 26952,  9447,  2504,  2522, 10085, 10841, 14343,\n",
            "         5897,  8185,  1043, 15472,  2213,  2817,  4846,  8318,  2361,  1043,\n",
            "        15472,  2213,  3177,  2098, 15873,  2838, 14175,  4725, 14817, 21203,\n",
            "         9963,  4094,  2378, 10755,  2937,  2102,  2838,  2227,  7809,  4871,\n",
            "         2838,  4738,  2478,  7976, 15756,  2897,  6741, 15698, 15502,  2135,\n",
            "         3479, 11465,  3945, 20600, 20116,  2080,  4118, 17544, 10640,  5345,\n",
            "         3818,  3921,  7528, 13523, 20470,  4007,  6388,   102]), tensor([  101,  4125,  2784, 15756,  6125,  2836, 16012, 12589,  3001,  3623,\n",
            "        14388,  2135, 16012, 12589,  3001,  2227,  5038,  2109, 10126,  2166,\n",
            "         1041,  2290,  3675,  2491,  4126,  9740,  3167,  5080,  3229,  2491,\n",
            "         2348, 10640,  2227,  5038,  3001,  3227,  2152,  2302, 21407,  2116,\n",
            "        16012, 12589,  3001,  2179,  8327, 15982, 13827,  4525,  2367, 15982,\n",
            "         2967,  3858, 10640,  2926,  2995, 13268,  5038,  2349, 15982,  5876,\n",
            "         1041,  2290,  5907,  3096,  3609,  2116,  3025,  2573,  2525,  2988,\n",
            "        15982, 13827,  2147,  6614,  5547, 15982, 13827, 16012, 12589,  2227,\n",
            "         5038,  5097,  7634,  2260,  2227,  5038,  3001,  6847, 10665,  2098,\n",
            "         4953, 16012, 12589,  5038,  2836,  2092, 15982, 11658,  2015, 29464,\n",
            "        26935,  3525,  3674, 10077,  5461,  4162,  3125,  5335, 26935,  5688,\n",
            "         2309,  3001,  6388,  3463,  2265,  2825,  5335, 26935,  4953,  2309,\n",
            "        28321,  1041,  2290,  3096,  3609,  5907,  9229,   102]), tensor([  101,  7387,  2116,  2367,  3036,  5936,  2947,  6997,  3445,  2750,\n",
            "         2755,  5164,  4765,  4277, 29115,  2173, 28283,  2437,  3711,  2295,\n",
            "         4614,  4039,  2644,  2344,  6709, 12290,  6204,  9751, 23934, 13268,\n",
            "         5038,  2291,  4198,  7887,  7172,  3617,  3075,  3579,  3259,  4503,\n",
            "         6882,  4735,  4812,  2291,  6709, 12290,  2241,  5344,  3965,  2613,\n",
            "         7292,  3617,  8264,  2174,  4874, 10788,  4118, 13268,  5038,  2944,\n",
            "         2047,  2291,  2328,  5292,  2906, 16690,  2015,  2465, 18095,  6028,\n",
            "         2330,  2278,  2615,  7427,  5678,  6413,  4730,  4155,  2089,  3073,\n",
            "         2734,  3463, 10847, 18750,  4029,  2109,  6520, 23422,  4413,  7705,\n",
            "         2330,  2278,  2615,  7685,  2705,  2239, 21469, 12322,  2653,  7781,\n",
            "         2349,  6520, 23422,  2015,  2030,  2213,  2490,  3365, 17881,  8192,\n",
            "        29296,  4221,  2509,  7809, 19647,  7809,  4846, 12038,  5097,  2260,\n",
            "         5387, 10439,  2801,  2109,  9570,  4487,  3540,   102]), tensor([  101, 13268,  3670,  5038, 10768,  2099, 12550,  2536,  4249,  2495,\n",
            "        10355, 21331,  9871,  2500, 13268,  3670,  5461,  6013,  9123,  8957,\n",
            "         7976,  4454,  3858,  2529,  5344, 11156,  6699,  2711,  9530, 14028,\n",
            "         2075,  2109,  6699,  5454,  6413,  6998,  2028,  2224,  2553,  2227,\n",
            "         7603, 10788,  2652,  2189,  2241,  5198,  6888, 16578,  5198, 13268,\n",
            "         3670,  2139,  8566,  3401,  5346,  2765,  2047,  7603,  4275,  3223,\n",
            "         4812,  4493,  3924,  6915, 11178,  5468,  2189,  2015,  4434, 13268,\n",
            "         7603,  3259,  7528,  2785,  3105,  2478,  9530,  6767,  7630,  3508,\n",
            "        15756,  2897, 13229,  2241,  2784,  4083,  3921,  2784,  4083,  2583,\n",
            "         6464, 17908,  4895,  3367, 26134,  2951,  5691,  3596,  2865,  3698,\n",
            "         4083,  2470,  2580,  2613,  7292,  2291,  2071,  6807,  2529,  5344,\n",
            "        14358,  2529,  6699,  2130, 16755,  2189,  5198,  1051,  4430, 29107,\n",
            "        10768,  2099, 11387, 17134,  2951, 13462,  2015,   102]), tensor([  101, 13268,  3670,  5038, 10768,  2099, 12550,  2536,  4249,  2495,\n",
            "        10355, 21331,  9871,  2500, 13268,  3670,  5461,  6013,  9123,  8957,\n",
            "         7976,  4454,  3858,  2529,  5344, 11156,  6699,  2711,  9530, 14028,\n",
            "         2075,  2109,  6699,  5454,  6413,  6998,  2028,  2224,  2553,  2227,\n",
            "         7603, 10788,  2652,  2189,  2241,  5198,  6888, 17908,  5198, 13268,\n",
            "         3670,  2139,  8566,  3401,  5346,  2765,  2047,  7603,  4275,  5478,\n",
            "         4812,  4493,  3924,  5998, 11178,  5468,  2189,  2015,  4434, 13268,\n",
            "         7603,  3259,  7528,  2785,  3105,  2478,  9530,  6767,  7630,  3508,\n",
            "        15756,  2897, 13229,  2241,  2784,  4083,  3921,  2784,  4083,  6464,\n",
            "        16578,  4895,  3367, 26134,  2951,  5691,  3596,  2865,  3698,  4083,\n",
            "         2470,  2580,  2613,  7292,  2291,  6807,  2529,  5344, 14358,  2529,\n",
            "         6699,  2130, 16755,  2189,  5198,  1051,  4430, 29107, 10768,  2099,\n",
            "        11387, 17134,  2951, 13462,  2015, 12550,  6388,   102]), tensor([  101,  2925,  5193,  3001,  3517, 24501,  3270,  5669,  8392,  4683,\n",
            "        20704,  2015,  3247,  2437,  2641,  2028,  4187, 14184,  2646,  2152,\n",
            "        20414,  2884, 12978,  4439,  9462,  8552, 16820,  3627, 15058,  2094,\n",
            "         4725,  2071, 11997,  2092,  3579,  2872,  2951, 23663,  2078,  3247,\n",
            "        12614,  8107,  2836,  3247,  2437, 12099,  5105,  2951, 13462,  2015,\n",
            "         2109,  4975,  2951, 23663,  2078,  4725,  6516,  4072,  7721, 12369,\n",
            "         4493,  2951, 13462,  2015,  5919,  3074,  4216,  4439,  2951,  4055,\n",
            "         4316,  4044,  4062, 16570,  4383,  2951,  2110, 15794, 22375,  2951,\n",
            "        13462,  2015,  2093,  7236,  4102,  2817,  2838,  2164, 13907,  2109,\n",
            "         5754, 17287,  3508,  4439, 16820, 22539,  2241,  6459,  2951, 13462,\n",
            "         2015,  4022,  5097,  2951, 13462,  2015,  2536,  5919, 20704,  3247,\n",
            "         2437,  6936,  5002, 13951,  6950,  4531,  6413,  3924,  2490,  2470,\n",
            "         2925, 12878, 20704,  2951, 13462,  2458,  2036,   102]), tensor([  101,  3259,  3647, 10539,  4367,  4041,  2491,  7705,  3818,  5047,\n",
            "         9651, 10697,  3303, 24949,  9651, 19795,  4367,  4041,  6741, 11486,\n",
            "         4919,  4367,  2686,  4055,  3647,  4655, 19188,  4655, 12697,  2929,\n",
            "        19355,  2946,  7790,  9651,  7561,  9570, 16360, 23004,  4022,  2492,\n",
            "        12365, 23301,  2126,  8400,  2275,  4663, 11566,  3795,  3945,  3818,\n",
            "         2126,  8400,  2275, 22910,  4118,  3740, 22793,  7130, 20600, 15058,\n",
            "         2094,  3921, 18478,  2015, 16264,  4431, 22793,  3740, 22793,  7039,\n",
            "         6310,  2881,  3424, 26895, 19969, 14080,  5676,  3808,  2478,  1999,\n",
            "        16874,  7028,  8651, 19293,  9430,  4473, 25354, 22793,  9651, 10697,\n",
            "         3132,  2306,  2881,  2555,  2130,  2552,  6692,  4263, 19399,  9651,\n",
            "         7561,  2641,  7785,  2098,  4041,  2504,  3808, 15258, 12361, 12016,\n",
            "         4041,  2491,  3798, 24949,  9651,  2552,  6692,  4263, 19399, 12637,\n",
            "        12353,  3818,  4367,  4041,  2491,  4118, 20119,   102]), tensor([  101,  2052, 10831,  8392,  4683, 20704,  2015, 10126,  2346,  4026,\n",
            "         5500,  2111,  4138,  3906,  9615,  8392,  4683, 20704,  2015, 19223,\n",
            "         2105,  7191, 26186, 14477,  6767,  8524,  3468, 12365, 16820,  5275,\n",
            "         5981,  3668,  4439, 15592, 10126,  2346,  4026, 28498, 12962,  3980,\n",
            "        13368,  2349,  4568, 25707,  3891,  2426,  2346,  5198,  4353, 10831,\n",
            "        13275, 12962,  2135,  7882,  3980,  3685, 26399,  2094,  3722,  2002,\n",
            "         9496, 10074,  2015,  7294, 13627,  2478,  9123, 20477,  6630,  2367,\n",
            "         4026,  8146,  6818, 18394,  4439, 23802, 20704,  2015,  7594,  4387,\n",
            "         5002,  2762,  6818, 18394, 14386,  4383,  6022,  8210, 12365, 24685,\n",
            "         5875,  2135,  6818,  5627,  2202, 10831,  5770,  2346,  5198,  9104,\n",
            "         2591, 21883, 20704,  2015,  2089, 10210, 28731,  2094, 19188, 10058,\n",
            "         2470,  2453,  3857,  2958,  6145, 17586,  6848,  9615, 20704,  2015,\n",
            "        26157,  2135,   102,     0,     0,     0,     0,     0]), tensor([  101,  7976,  4454,  4204,  8361,  6786, 26633,  2529,  4454,  6681,\n",
            "        12067,  2228,  2066,  2529,  9552, 23150,  4506,  8392,  4683,  3853,\n",
            "         4287,  4072,  4972,  2302,  2529,  6624,  9525,  2974,  2089,  3073,\n",
            "         3445,  4628,  3808,  2625, 26478, 17944,  4925, 20176,  7312, 23569,\n",
            "        28591,  4026,  2896,  4762,  8381,  2625, 10796,  2488,  3604,  6322,\n",
            "         8392,  4683,  2377,  8995,  2535,  3068,  5237,  5193,  2510,  5097,\n",
            "         3450,  8392,  4683, 11160, 13617,  2951,  7976,  4454,  3001,  7976,\n",
            "         4454,  7336,  3074,  2951,  4130,  4041,  7781,  8392,  4683,  5478,\n",
            "         3698,  4083,  5461,  2112,  7976,  4454,  2174,  2036, 13275,  9394,\n",
            "         3314,  3036,  5936,  3036,  2590,  5142,  8392,  4683,  3720,  3104,\n",
            "         3314, 16941,  3366, 10841, 15780, 13543,  7976,  4454,  8392,  4683,\n",
            "         2247,  3652,  2974,  2969, 13626, 14966, 19207,   102,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  2802,  2197,  5109,  2193,  4683,  2346, 11328,  3445,  2349,\n",
            "         4803,  5157,  3923, 12969,  3824, 12708,  2048,  2116, 29172,  3896,\n",
            "         4683,  2346,  2036, 17727, 14728,  3171,  2458,  3445,  4026, 20176,\n",
            "         4026, 13436,  3314,  3855,  6022, 10395,  2437,  4683, 25670,  8161,\n",
            "        17975,  4286,  2627,  2301,  4866,  2470,  4146,  2536,  3741, 17999,\n",
            "        19309,  2346,  4683,  2458,  8392,  4316, 20704,  6786,  2747,  9505,\n",
            "         3278,  5013,  8712,  4969, 17319,  6923,  2224,  8392,  3765, 17566,\n",
            "         5382,  2445,  2458,  7976,  4454,  9932,  2344, 20704,  2015, 23084,\n",
            "        11301,  2191,  2157,  6567,  2613,  2051,  9932,  6003, 10232,  6922,\n",
            "         2458,  9932,  5533,  3930,  2502,  2951,  3365, 13851,  5733,  6276,\n",
            "        24225,  9798,  4219,  9932,  2015,  2458,  2381,  2442,  2034,  8920,\n",
            "         2344, 22346,  4972, 20704,  3001,   102,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  2925, 15169,  3795, 12945,  3068,  6551,  5360,  2959,  3919,\n",
            "         4329,  6622,  7976,  4454,  9932,  2047,  3671, 11310,  5533,  2047,\n",
            "         3068,  4781,  2164,  6233,  8392,  2969, 13626, 14966,  2974, 13266,\n",
            "         3808,  4781,  3375,  5427,  7040, 19293,  2591,  5012, 10660,  2689,\n",
            "         2103,  6502,  5918,  3617, 11443, 23217,  3512,  2449,  8144,  2241,\n",
            "         6143,  7953,  4425, 13797,  7480,  8162,  3401,  9932,  3127,  3145,\n",
            "         5876,  8392,  4683, 20704,  2015, 16578,  2478,  9932,  8973,  7217,\n",
            "         9138,  2974,  3293,  3891,  5876,  2969, 13626, 14966,  7325,  5248,\n",
            "         2103,  6502, 14679,  2591, 17241,  2047,  2974,  2925, 22793, 20704,\n",
            "         3068,  3517,  6970, 13068,  3293,  2591,  3891,  6502, 10738, 10595,\n",
            "         2536, 14670,  3068,  2015, 22859,  2817, 16014,  2015,  3497,  9084,\n",
            "        11967, 20704,  3068,  5533,  1015,  9932,  2015, 24107,  9138, 11876,\n",
            "         2906,  2422, 10788,  7478,  7182,  7077,  6075,   102]), tensor([  101, 19143,  2529, 22461,  2640,  3935,  9932,  9859,  2925,  8392,\n",
            "         4683,  3658,  2925,  8392,  4683,  3665,  5467,  2036, 11835,  2098,\n",
            "         5967, 14714,  2437,  4990,  6625,  8114,  8242,  3259,  3117,  7705,\n",
            "         3591, 21155,  2015,  2312,  2653,  4275,  2222,  5244, 11598,  8392,\n",
            "         4683,  3247, 12614,  6194, 22380,  2222,  5244,  3019,  2653,  9859,\n",
            "         6123,  8787,  4824,  7772,  5906,  8192, 19962,  2121, 28660, 13384,\n",
            "         3772,  2536, 14184,  8392,  4683,  7705,  8704, 25180, 10895, 17409,\n",
            "         3935,  2653, 13384,  9859,  2222,  5244,  8392,  4683,  3818,  7705,\n",
            "         4324,  4022,  4329,  4697,  2126,  8392,  4683,  5452,  5378,  3167,\n",
            "         3550,  5375,  7142,  4083, 13338,  3247, 12614,  4821,  8020, 13726,\n",
            "         8114,  8392,  4439,  6786,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  4022,  4198, 12978,  4683,  4800, 12172,  3064, 12978, 12607,\n",
            "         5533,  4274,  2477, 22834,  3215,  2458, 12067,  7976,  4454,  9932,\n",
            "         2220, 12607,  2015,  3330,  8139,  2116,  4249,  4427,  9932,  2195,\n",
            "         6786,  2109, 12978,  4683, 12978,  4683,  6551,  9002,  2646,  4026,\n",
            "        20600, 19844,  7312,  5702,  4316, 12645,  2048,  7236,  2458,  2800,\n",
            "         2152, 20414,  2884,  2291,  8346,  2015,  2066,  2047, 24454,  6292,\n",
            "         4683,  9414,  5193,  3001,  7336,  8848,  4942,  6508, 13473,  2213,\n",
            "        12607,  2066, 13617,  2592,  6364,  3001,  3935,  4062,  5375,  2291,\n",
            "         3065,  3463,  3113, 10908,  2613, 11108,  3471,  4316, 12645,  3663,\n",
            "         2389,  4454, 17427,  8216,  8310,  2951,  2641,  2152,  3207, 16294,\n",
            "        22753,  4325,  2103,  7341,  2455, 19654,  3737,  9361,  4925,  2092,\n",
            "        18558, 18249,  3672,  2291,  3665,  4472,  6853,  9218,  5038,  2653,\n",
            "        12598, 10617, 11301,  5375,  4950,  2422, 10788,   102]), tensor([  101,  3522,  2086,  7976,  4454,  2468,  4072,  6922,  2537,  2326,\n",
            "         3001,  2974,  2468,  8995,  7814,  3679,  2166,  8392,  4439,  4683,\n",
            "         3498,  8392,  2135,  2036,  2124,  4062,  3238,  3765,  5452,  2302,\n",
            "         2529,  4062,  2470,  8392,  4683, 12381,  3935,  3522,  2086,  7976,\n",
            "         2135,  9414,  8392,  4683,  2783,  2342,  2554,  2348,  2111,  2453,\n",
            "        10439,  2890, 10222, 12742,  2507,  3274,  2491,  4316, 12978,  4439,\n",
            "         6786,  4022,  2191,  4925, 13726,  4483,  3314,  2092,  3808, 16570,\n",
            "         4383,  3924,  8280,  2969, 13626, 14966, 19207,  4406,  4286,  7588,\n",
            "         2428,  7669,  4363,  3086,  4439,  5678, 14120, 23263, 12978,  2482,\n",
            "         4652, 13436,  9280,  4795,  2824,  2346,  2969, 13626, 14966,  2974,\n",
            "         2116, 12637,  2028,  2191,  4089,  7801,  2965,  3665,  2111,  4039,\n",
            "         3298,  3528,  4436,  1999, 10288,  4842, 13684, 27523, 19498,  3012,\n",
            "         2287,  2116,  2111,  4039,  5452,  4316,  3633,   102]), tensor([  101, 10938,  8082,  3690,  5193,  9536,  2098, 13896,  8392,  4683,\n",
            "        24501,  3270,  4691,  5957, 12969,  6276, 24225,  6786,  8346,  7976,\n",
            "         4454,  9932,  4083, 13792,  2430,  6622, 17678, 23918,  4683, 18814,\n",
            "        15741, 12645,  7721,  8993, 12761, 22793,  9932,  2306,  8392,  4683,\n",
            "         3024,  3259, 16907,  4990,  3192,  2389,  6481,  3522, 12607,  2015,\n",
            "        25819,  2783,  5957, 19184,  8050,  2535,  9932, 20300,  8392,  3247,\n",
            "        12614,  9859,  4683,  3972,  7178,  4084,  2920,  9932, 27267,  2458,\n",
            "         2166,  5402,  4683,  3449, 14194,  8524,  3064, 12786, 12962, 16852,\n",
            "        13827,  4681,  3089,  8159,  4007,  2458,  8392,  4683,  7778, 20062,\n",
            "         8192,  4127,  9932, 19738,  6826,  2075, 13792,  2086,  3591, 27696,\n",
            "        20607,  2470,  5957,  2306, 12945,  3068,  7297, 20369,  2535, 11709,\n",
            "        28596, 13792,  9322,  3765, 11548, 25505,  4683, 15581,  4553,  5335,\n",
            "         2836,  2051,  2367,  3798, 12645, 14801,  3449,   102]), tensor([  101, 15961,  3068,  2326, 15428,  5994,  7976,  4454,  9932,  2691,\n",
            "         3568,  4824,  9932,  2326,  7233,  9279,  6304, 10232,  3720, 20798,\n",
            "         9932,  2326,  7233,  2367,  7339,  9564,  2185,  3151,  3579,  4454,\n",
            "        22035,  9515,  3372,  2612,  2559,  4254, 26452, 10960,  5799,  6832,\n",
            "         4454,  2176,  6388, 16820,  2470,  3065,  2152,  6633, 20166,  9932,\n",
            "         3433,  2326,  7233,  3623,  6304,  6808,  3613,  2478,  2326,  2036,\n",
            "         4858,  8317,  3292,  3404,  2377, 25582,  4395,  2865,  3436,  2832,\n",
            "         7297,  2817,  6083,  2478,  4800,  5054, 21748,  2100, 19220, 10266,\n",
            "         3793,  2376,  2152,  6633, 20166, 10960, 11598,  2015, 12353,  9932,\n",
            "         2326,  7233,  4102, 18847,  5054, 21748,  2100, 10266,  3793,  2470,\n",
            "        24545,  4824,  9932,  2326,  7233,  7995,  7552,  2224,  9932,  2326,\n",
            "         4945,  2738,  6234,  3433,  2036, 11637,  5197,  6832,  4454,  9932,\n",
            "         4760, 23408, 11045,  6832, 10960,  6304,  2326,   102]), tensor([  101, 11128,  4411,  4969,  5307, 15843, 22039,  4769,  7976,  4454,\n",
            "         9932, 11834, 27014, 12550,  6635,  9859, 12546,  3961, 10599, 10943,\n",
            "         2075,  4812,  2817,  6461, 11598,  4824,  9932, 28536,  2015,  5994,\n",
            "         3515,  2549,  6001,  3784, 12783,  8162,  6129,  4132,  2416, 11834,\n",
            "        18384,  6074,  2764,  9671,  6459,  6832,  5443, 25854,  2367,  4871,\n",
            "         3746,  3698, 10359,  3746,  2529,  3746,  2817,  2109,  2981,  8168,\n",
            "        23746,  4355, 17908,  4254, 11834, 27014,  4512,  2389,  6782, 19732,\n",
            "        21357,  5924,  2162,  5694,  5678,  7642,  3674, 26435,  4106,  4146,\n",
            "        11628,  2865,  3436,  4395,  8690,  2529,  2791, 26452,  2646,  5694,\n",
            "         3276, 11834, 27014,  6832,  3670, 19732, 21357,  2817,  2036,  7718,\n",
            "         5549, 15172,  3466,  5107, 23391,  3746,  3698, 10359,  3746,  2529,\n",
            "         3746,  2478,  8777,  2094,  7642,  3674, 26435,  4106,  9556,  5393,\n",
            "         6832, 11834, 27014,  2419,  3020, 19732, 21357,   102]), tensor([  101, 22380, 26452,  9871, 11834, 27014,  2464, 10015,  3921, 23408,\n",
            "        11045,  3168,  2529,  4434,  2174,  2783,  2470,  2411, 27590,  2015,\n",
            "        11619, 26452,  2877,  3132,  4824,  3251,  7976, 26452,  8690,  6660,\n",
            "         2529, 26452,  2817,  9251, 13543,  4654,  4842, 11638,  4818,  3596,\n",
            "        26452,  2071,  4895, 18447, 21945,  4997,  3896,  2089,  2272,  2408,\n",
            "        27118, 14317,  4765,  2594,  2612,  4346,  6150,  2490,  2453,  4621,\n",
            "        11643,  7976, 26452, 25705,  2015,  2488,  5171, 10908, 10266, 11834,\n",
            "        27014,  2048,  6388,  2913,  2478,  9871, 11834, 27014, 10847,  4254,\n",
            "         7861, 15069, 16530,  3110, 13026,  3110, 14260,  6633, 15069, 16530,\n",
            "         7861, 15069, 16530,  5094, 10960,  4102,  3904,  8737,  8988, 16530,\n",
            "        10960,  8690,  8251,  8690, 21452,  3896,  3404, 11174,  2224,  3463,\n",
            "         3662,  2433, 26452,  4102, 26452,  3445,  8690,  8251,  2877,  3020,\n",
            "         3798,  3404, 11174,  2224, 11834, 18384,  1044,   102]), tensor([  101,  9123,  4007,  6074,  2066, 11834, 27014,  6233,  2109,  2740,\n",
            "         2092, 19205,  3070, 18046, 11973,  5198, 11450,  7748,  7216,  5248,\n",
            "        22305,  2063, 19388,  2174,  3768,  5906,  3305,  6074,  7861, 25940,\n",
            "         7590,  4769,  2342,  3154,  4824, 26452,  2750,  2536, 15182,  3906,\n",
            "        10465,  5337,  6210, 11778,  3906,  3319, 24209, 11475, 27453,  4106,\n",
            "         3522,  8107, 26452,  9123,  6074,  2740,  2092, 19205,  3070,  2764,\n",
            "         5337,  6210,  2319,  3031,  6483, 11253, 26452,  6210,  4162,  4758,\n",
            "         5310,  2817, 14358, 26452,  2048,  2110, 15794, 22375,  2740,  2092,\n",
            "        19205,  3070, 11834, 27014, 16360, 25421,  1059,  7274,  2050,  3463,\n",
            "         5769,  6210, 19566,  6827,  5919, 20077, 26452,  9123,  6074,  3449,\n",
            "        14194,  8524,  2618, 12878,  5278, 23271, 26452,  2051,  7528,  4773,\n",
            "         3031,  6483,  2653, 13547,  6210,  2071,  3710, 12978,  6994,  3001,\n",
            "         6807, 26452, 10266,  3251,  9123,  4005, 23208,   102]), tensor([  101,  3259, 13999, 23222,  7705,  2881, 10938, 11834, 18384,  3001,\n",
            "        13543,  2613,  7292,  2227,  7603,  5038,  3019,  2653,  6364,  7705,\n",
            "         2747,  2458, 16691, 26293,  2536,  8518,  2164, 11717, 14408,  8496,\n",
            "         4874, 10320, 10739, 10861,  5134,  2478, 16381, 12879,  8873, 23402,\n",
            "         3372,  2986,  8525,  5582,  2330, 10258, 10631, 16656,  2659, 26763,\n",
            "        15581,  2121,  8840,  2527,  7705,  3188, 25090, 11254, 18601, 18724,\n",
            "         8122,  2430,  3921,  7899, 23561,  2015, 13590,  4432,  2653,  2951,\n",
            "        20226, 11834, 27014, 15581,  8010, 22671,  5197,  2152, 26426,  3012,\n",
            "         2731,  2951,  2470, 19764,  3192,  4526, 22979,  4512,  2389,  4005,\n",
            "         5097,  8013,  2326,  5177,  2740,  2490,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  4281,  3768,  2913, 12843,  6742,  3012,  2478,  2312,  2653,\n",
            "         4275,  2222,  5244,  6869, 10861,  5134,  8740, 16774,  2594,  3633,\n",
            "         2822, 25023,  6692,  3351,  4292,  2822,  5287,  2312,  2313,  4969,\n",
            "         2470,  2478,  4275,  9871,  8857,  2394, 13102, 25508,  2075,  4279,\n",
            "         7863,  2470, 11014, 16157,  2092,  2222,  2213, 11834, 27014,  2164,\n",
            "        11834, 21600,  2102,  2549,  2330,  4886, 14637, 28516,  2544, 20802,\n",
            "        21790,  8566,  4297,  4685, 14120, 10861,  5134,  8740, 16774,  2594,\n",
            "         3633,  2822,  6123,  4725,  2470,  5067,  2951,  1040, 18037,  2092,\n",
            "         2243, 19779,  2078, 10923, 11022,  2094,  2966, 16053,  4132,  2859,\n",
            "         5310,  2918, 17003,  2531,  2454,  3633,  2777,  2594, 21227,  3479,\n",
            "         2531,  5776, 16053,  8168,  2254,  2760,  2257, 16798,  2509,  9605,\n",
            "        23688,  3980, 15901,  7271,  2800,  5491,  3141, 19465,  4132,  5676,\n",
            "        17727,  8445,  4818,  3012,  2434,  3980, 10960,   102]), tensor([  101,  3988, 18932,  2186,  7976,  4454,  4456,  6612,  2470, 10232,\n",
            "         3972,  3726,  6210,  4454,  3145, 12332,  5799,  2529,  4454,  4454,\n",
            "         4145,  3952,  3378,  4286, 19129, 10617, 26497,  2245, 17158,  3989,\n",
            "         5418,  5038, 12613,  6364, 14842,  3471,  4747,  6455,  4454, 10359,\n",
            "        12955,  5159,  2542,  9552,  2529,  4454,  2411,  2464,  4031,  9715,\n",
            "         7073,  3754,  2433,  8474,  3977, 12613,  6364,  2653,  2458,  4513,\n",
            "        13384,  3247, 12614,  8689,  6583,  5737, 16961, 11301,  2750, 21894,\n",
            "         4598,  4454, 10359,  2838,  2427,  8298,  2969, 10830,  7389,  7971,\n",
            "         3961, 26757,  4588, 13769,  5919,  2529,  3325,  3160, 18653, 17796,\n",
            "         6970, 13068, 13353, 10737,  4748, 22658,  3558,  4277, 11211,  3375,\n",
            "        15756,  2897,  2430,  6091,  2291,  2507,  4125,  9715,  3325,  4301,\n",
            "        13384,  6832,  6322,  6569, 12039,  2293,  5053,  3698,  4083, 19875,\n",
            "         5047, 17158,  6194,  6698,  2529, 24823,  4310,   102]), tensor([  101,  2529,  4886,  8290,  2468, 15918,  2391,  4526,  2974, 26651,\n",
            "         7861, 15069, 16530,  7976, 26452,  9942,  3391, 23824,  6123,  4022,\n",
            "        11598,  8013,  6322,  7461, 14547, 14286,  2817, 11014,  8556,  7976,\n",
            "        26452,  9942, 23569, 27605,  4371,  2529,  4886, 10266,  5335,  8013,\n",
            "         6322,  2470, 16134,  4846, 24209, 11475, 27453,  5994,  3319,  2536,\n",
            "         2913,  7882,  3906,  2951,  4216,  2421,  9263,  4790,  2808,  3141,\n",
            "         2470,  8476,  9556,  5769, 14972,  7976, 26452,  9942,  2529,  4886,\n",
            "        10266,  6022, 11598,  3737, 10266,  8013,  6322,  6786,  3019,  2653,\n",
            "         6364,  7603,  5038, 15792,  4106,  9585,  9932,  6869, 14125,  7591,\n",
            "         2135,  5310,  3791,  6699,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101, 13234, 24969,  4512,  2389,  6074, 25222, 15734,  2881,  4671,\n",
            "        23408, 11045, 26452, 26452, 11598,  2974,  2015,  3754,  3113,  2529,\n",
            "         3791,  2036, 22369,  9280, 18077,  8082,  2817,  7679,  4824, 26452,\n",
            "        10266, 25222, 22671,  2342, 21032,  7861, 15069, 16530, 10266,  2048,\n",
            "         4286,  5994,  2529,  6187,  4146, 11778, 10266, 25222,  6113,  2312,\n",
            "         2653,  4275,  2222,  5244, 15870, 10580, 26452,  9530, 14028,  2075,\n",
            "         3515,  2367,  2529, 15702,  2036,  4102,  2536,  2222,  5244,  4671,\n",
            "         2944, 26452,  9556,  7487, 25222,  7166,  2191,  3643, 26186,  3056,\n",
            "        15702, 21089,  5326, 15702,  3378, 17631,  8909,  8780, 21615,  1041,\n",
            "         2290, 13157,  2213,  1060, 16515, 24920,  7297, 15078,  4106, 26452,\n",
            "         7127,  2750,  3754,  8327, 26452, 25222,  5998, 14125, 17841,  8849,\n",
            "         5198,  6322,  8066,  2529, 14562, 24970,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101, 26452,  9798,  8361,  2492, 12586,  2015,  7976,  4454,  9932,\n",
            "         2502,  2951,  6786, 16014,  6709, 26633,  9699,  2529, 26452,  9891,\n",
            "         8317,  2913, 26452,  8474, 11702, 15756, 10100,  5097, 15440,  9525,\n",
            "         9798,  4725, 20253, 21934, 10924, 26452,  3720, 11321,  4391,  2783,\n",
            "         2470, 26452,  9798, 15841,  2925,  7826,  8317,  7339,  5083,  3192,\n",
            "         2389,  2470,  6742,  5097,  2470, 26452,  9798, 20427,  2176,  6991,\n",
            "         2241,  2367,  5682,  4725,  2034,  3579, 20253,  4824, 26452,  2478,\n",
            "         7588,  2950,  3265, 26452,  7667,  7861, 15069, 16530,  4180,  5579,\n",
            "         6981,  2117,  2470, 21934, 10924, 14026, 26452,  9798,  7336, 12697,\n",
            "         7861, 15069, 16530,  3433,  3001,  4975, 11416,  6024,  7861, 15069,\n",
            "        16530,  7982,  3001,  2470,  9199,  4659,  2981,  2664, 21053,  2492,\n",
            "        22901,  2047,  7826,  2089, 12636, 20226,  3274,  7861, 25940,  9859,\n",
            "         4167,  9006, 18780,  2121,  8278,  2974,  2348,   102]), tensor([  101,  3935, 15078,  5461,  3716, 15058,  2094,  3001, 21677,  2015,\n",
            "         3730,  9798,  4725,  8040,  2213,  3698,  4083,  4275, 19875,  2213,\n",
            "        12761, 13792, 19413, 21708,  4454,  9033,  3267,  7076, 21649, 13792,\n",
            "         9152,  2050,  3728,  4235,  4162,  2373,  8139,  5013,  2491,  3001,\n",
            "        15078,  4118,  5664,  2838, 12332,  3728,  6950,  2764,  2944,  6832,\n",
            "         6364, 26524,  4167,  2124,  4167,  6832,  4083,  2241,  9414, 11486,\n",
            "        19337, 13592,  9556, 10580, 19337, 13592,  2015, 10673,  6133,  4242,\n",
            "        27400,  8790,  3001,  8821, 19337, 13592, 12192,  6377,  7772,  2033,\n",
            "         7507, 15312,  6558,  3919,  5097,   102,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  3800,  3319,  7603,  7976,  4454,  9932,  2974,  7603, 10788,\n",
            "         5038,  7603,  9932,  9186,  5901,  3293,  2231, 10906,  2648,  9871,\n",
            "         6233,  2468,  9410,  2112,  3679,  2166,  3125,  7984,  3319,  3623,\n",
            "         7073,  6923,  2224,  7603,  9932,  5936,  3293,  2224,  7603,  9932,\n",
            "         7189,  2111,  5177,  2740,  3785,  3522,  9556,  3259, 15841,  7603,\n",
            "         9932,  8050,  2015,  2236, 19184,  3293,  7603,  9932,  2648,  9871,\n",
            "         4973,  2224,  7603,  9932,  7904, 15680, 16165,  9867, 12654,  3144,\n",
            "        27788,  2618, 29397,  3633,  5177,  2740,  3785,  2554,  2442,  6807,\n",
            "         4852,  3293,  2224,  7603,  9932,  5936,  3293,  2224,  7603,  9932,\n",
            "         3623, 26453,  9147,  4997,  8465,  3679,  2166,  2111,  5177,  2740,\n",
            "         3785,  3293,  7603,  9932,  9896, 20932,  5177,  2740,  3785,  5845,\n",
            "         2966,  2755,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  4167,  9006, 18780,  2121,  8290,  4647,  2072,  2291,  4454,\n",
            "         2468,  2128, 15204,  2102, 16175, 10127, 21890, 24915, 25212, 18259,\n",
            "        11022,  2094,  7603, 10788,  2349,  2536,  5097,  7603,  5579, 12832,\n",
            "         3001, 10699,  7170,  8822,  4385,  7603,  5579,  3728,  4227,  3278,\n",
            "         3086,  7976,  4454,  4681,  3089,  8159,  2470,  3720,  3591, 11778,\n",
            "         3319, 12978,  7603, 10788, 25212,  2290,  7755,  2478,  9932,  3319,\n",
            "         2832,  4076,  6871,  7316,  5167, 11778,  4391, 18804, 27953, 23274,\n",
            "         2015, 26113,  2050, 11594,  3525, 25212,  2290,  2951, 13462,  2015,\n",
            "        25212,  2290, 17463,  3217,  9623,  7741,  5461,  2443,  2817,  2036,\n",
            "         3139,  3444, 14676,  3444,  4989,  4725,  5678,  2443,  2913, 20427,\n",
            "         2048,  4127,  2784,  4083, 21469, 15058,  2094,  7603, 10788,  3001,\n",
            "         2462,  3698,  4083, 10901, 11022,  2094,  7603,  5579,  4275,  8920,\n",
            "         3001, 16578,  2241,  2838,  5579,  4118, 20792,   102]), tensor([  101,  4286, 10295,  3056,  2591,  6832,  4813,  9585, 11835,  6464,\n",
            "         2500,  2028,  3754,  6807,  6699,  3754,  6022, 11598,  2015,  2529,\n",
            "        10266,  5082,  2875,  3690,  4852,  2529, 22911, 14014,  8290,  3001,\n",
            "         6827,  4503, 13792,  2203,  5004,  6681,  2714,  2591,  6832,  4813,\n",
            "         3078,  2181,  2470,  7603, 10788,  7336, 14622,  6699, 13268,  4871,\n",
            "         3754,  6709,  2529,  6699,  4473,  6681, 15581,  6869,  2529,  3791,\n",
            "         7216,  3798,  7603, 10788,  2864,  2478,  2536, 16913, 11475,  7368,\n",
            "         2678,  5746,  4871,  3793, 16012, 12589,  2951,  4385,  2817, 15102,\n",
            "         8361, 12878,  7603,  5038,  2478, 13268,  4871, 12978,  5038,  2529,\n",
            "         6699,  4022, 16014, 13691,  3785, 10318,  5177,  2740,  3314,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  7976,  4454, 11834, 27014,  4013, 15509,  9250,  6813,  3068,\n",
            "         2349,  3465, 12879, 25969,  3512,  2791,  2152,  8122,  2174,  4254,\n",
            "        11834, 27014,  6832, 11423,  2326, 13105,  8077,  3273,  6950,  5059,\n",
            "         5987, 11656, 13302,  3399, 10847, 11834, 27014,  6832, 11423,  3747,\n",
            "         8013,  9967,  2093,  7885,  6123,  7538,  8432, 11433, 11834, 27014,\n",
            "        14026,  5142,  6304, 11598,  8013,  9967, 10210, 13340,  3436,  5987,\n",
            "        11656, 13302,  4919,  8013,  3125, 10296,  2529, 10359,  2791, 11834,\n",
            "        18384, 22128,  2015,  2828,  3276,  6304, 11834, 27014,  8777,  4997,\n",
            "         3276,  6832,  3670,  5987, 11656, 11371,  9556,  9002,  2470, 11834,\n",
            "        27014,  6832, 11423,  3749,  7070, 20062, 14972, 11834, 27014,  8013,\n",
            "         2326,  2306,  6813,  3068,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  3259,  2034, 28062,  2394,  3793,  7603,  3670,  2592,  4807,\n",
            "         4937, 20265, 25709,  2015,  5919,  2241,  2529,  7603, 10175,  5657,\n",
            "         3276,  7680,  7849, 10057,  6459, 16378,  2478,  7976,  4454,  2974,\n",
            "        17146, 15696,  4106,  2944,  2394,  3793,  7603,  2592,  4807,  2478,\n",
            "        12170,  4877, 21246, 15756,  2897,  2832,  6459,  2394,  3793,  2855,\n",
            "        18228,  4072,  4372, 16044,  6832,  2592,  2394,  3793,  2241, 17181,\n",
            "        12170,  4877, 21246, 15756,  2897,  4162, 14817,  6832,  2838,  2394,\n",
            "         3793,  4769,  3277,  6832,  3444,  3279,  3279,  3853,  4773, 26988,\n",
            "         2099,  2109,  6855,  2951, 13462,  2822,  2394, 11336,  9587, 10085,\n",
            "         2822,  5534,  9312, 12046,  2015,  2275,  2429,  4275,  2836,  2628,\n",
            "         6388,  4106,  2394,  3793,  7603,  3670,  2592, 16636,  6651,  3463,\n",
            "         2265,  4102,  2434, 13229,  1048,  3367,  2213,  1056,  4877, 21246,\n",
            "        12170,  4877, 21246, 15058,  2094, 15756,  2897,   102]), tensor([  101, 12978,  7982,  3001,  3278,  5097,  7976,  4454,  2664,  3151,\n",
            "         3001,  5998, 22346,  5310,  6699,  3749,  7861, 15069, 16530, 10960,\n",
            "         2817, 17409,  2015,  6832,  4454,  2974, 12978,  7982,  3001,  4526,\n",
            "         7982,  4245,  2944, 10047,  8569,  2098,  6832,  4454,  2478,  2784,\n",
            "         4083,  3019,  2653,  6364,  5461,  2944,  2613,  7292, 11487,  3305,\n",
            "         5041,  8674,  6699,  3563,  3255,  7755, 12067,  2291,  3073,  7861,\n",
            "        15069, 16530, 10266, 13543,  9556,  2817,  7976,  4454, 11487,  3255,\n",
            "         4671,  3255, 26452,  4275,  3977, 10616, 11259,  5919,  3255, 26452,\n",
            "        19335,  7411,  3020,  6847, 27373,  6832,  4454,  7982,  3001,  2622,\n",
            "         8704,  3073,  9373, 20062,  6742, 11433, 22380,  3935,  6832,  4454,\n",
            "         9859,  7982,  3001,  8558, 20226,  5310,  3325,  8290,  3737,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  2470,  6083,  6681,  5214, 21934, 10924, 26452, 14120, 14868,\n",
            "         3623,  5310,  9920,  3168, 16730,  2875,  3698, 13416,  4997,  2566,\n",
            "         3401, 13876,  8787, 12247, 10047,  8569,  2063,  8957,  6832,  4454,\n",
            "         2442,  6055, 13907,  5214, 25952,  5198,  6699,  3168,  2832,  4110,\n",
            "         6699, 15176,  4722,  2110, 24134,  4821,  4685,  8518,  4506,  5105,\n",
            "        24806,  6832,  2110,  2552,  2750,  3278,  5082,  7976,  4454,  4613,\n",
            "         5038, 10752,  3274,  4432,  2116, 12736,  3141,  7976,  6832,  5038,\n",
            "         5248,  2145,  2521,  1041, 15549, 14853, 13507,  7861, 25940,  9859,\n",
            "         4286,  3720,  8704,  3073, 19184, 13494, 10449,  6832,  4454, 20478,\n",
            "         3001, 10537,  3522,  9849,  6832,  4454, 21331,   102,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  7603,  5038,  7336, 14125,  1999,  7512,  4892,  2529,  6699,\n",
            "         2536,  4216, 16913, 11475,  7368,  2164,  3160, 20589,  2015,  3558,\n",
            "         7755, 19389,  7755,  3728,  3652,  3037,  7603,  5038,  2349,  7289,\n",
            "         5654,  2075,  5097,  7461,  3512,  9798,  9871,  2529,  3217, 18384,\n",
            "        10266,  3006,  2470,  3259,  7534,  7721, 11778,  3319,  7603,  5038,\n",
            "         5461,  2783,  5476,  7995,  3558, 19389,  7755,  3558,  7755,  2421,\n",
            "         4613, 13268, 11423, 19389,  7755, 25281, 16175, 10127, 21890, 24915,\n",
            "        25212,  2290, 16175, 11522,  3695, 13113, 14925,  2290, 14891, 27760,\n",
            "         2278,  3096,  3433, 28177,  2099,  3239,  9651,  3259, 13999,  2536,\n",
            "         7603,  4275, 22239,  2109,  7603, 12005, 26243,  3370,  4281,  4493,\n",
            "        12978,  7603,  5038,  3001,  4472, 16030,  3945,  3319,  2092,  2243,\n",
            "        19779,  2078,  2951, 13462,  2015,  2206,  2640,  9181,  3319, 27427,\n",
            "        23606,  2232,  4106,  6594, 16087,  3485,  4790,   102]), tensor([  101,  3259, 15102, 27891,  7976,  4454,  7603, 10788, 11265, 10976,\n",
            "        20285,  2075, 13659,  6709,  5310,  6699,  4773, 28727,  2478,  9530,\n",
            "         6767,  7630,  3508,  2389, 15756,  6125, 13229,  2015,  3988,  2930,\n",
            "         3640, 19184, 15756,  6125,  2164,  3937,  4127, 25995,  3579,  9530,\n",
            "         6767,  7630,  3508,  2389, 15756,  6125, 13229,  2015, 26398,  6364,\n",
            "         8370, 10359,  2951,  4871,  7603,  5038, 19601,  2224,  2227,  9331,\n",
            "        28418,  2015,  3075, 22164,  4275,  2066,  7020,  2094,  4684,  7159,\n",
            "         1058,  2487,  4714,  2227, 19034, 11047,  2278, 10695,  4714,  2227,\n",
            "        19034,  2944, 12550,  4646,  4107,  2613,  7292,  2227, 10788,  2235,\n",
            "         2946,  3177,  8777,  7692,  8381, 11892,  4773,  4684,  7248,  2117,\n",
            "         2112,  3259,  4751,  2458,  4646, 16911,  2227,  9331, 28418,  2015,\n",
            "         3075,  7603, 10788,  2881,  2490, 11265, 10976, 20285,  2075,  2470,\n",
            "         4646, 12939,  3006,  2545, 17908,  6475,  3430,   102]), tensor([  101,  9932,  2784,  4083, 17547,  5310,  5248,  4719,  3424,  6895,\n",
            "        17585,  4769,  4022, 13500,  2224, 21318,  2640,  3465, 24110,  3775,\n",
            "        10451,  3325, 12046,  2015,  7487,  3471,  5198,  8087,  2478,  8278,\n",
            "        21318,  2191,  9416, 20600,  2051,  7976,  4454,  4235,  2109,  7365,\n",
            "         2166,  2126,  5198, 11835,  3617,  2088,  2036,  3791, 13265,  9414,\n",
            "         3787,  5547,  3465, 20831,  8321,  4106,  3325, 20390,  4117,  9932,\n",
            "         2974, 23569, 27605,  4371,  2640,  6578,  5198,  3617,  2088,  6551,\n",
            "         4359,  2437,  3617,  3688,  7218,  5310,  3791, 10910, 25180,  3238,\n",
            "         9123,  3325,  5335,  5310,  3325,  2036,  5326,  2458, 21318,  2640,\n",
            "         5310, 19699,  9013, 18718,  9414,  3257,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  2396,  2124,  6643,  3726,  2126, 11131, 16636,  2075,  2047,\n",
            "        12020, 13367, 18593,  4249,  7976,  2166,  7976,  4454, 15078,  7366,\n",
            "        12553,  7366,  6233,  8361,  2270,  3193,  4072, 28667,  5644, 18688,\n",
            "         4262,  3430,  2303,  4767,  3019,  2088,  4145,  2166,  5002,  3640,\n",
            "         3906,  3319,  3522,  2573,  7976,  2166,  5107,  2396,  2627,  2871,\n",
            "         2086,  4919, 15078,  4007,  5884,  6614,  3073, 11778, 19184,  3324,\n",
            "         4824,  3267,  4526,  2047,  2166,  2715,  2974,  3818,  2275,  9181,\n",
            "        25274,  4780, 17908,  4387, 22000,  2367,  7236,   102,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  5002,  2236, 22793,  7976,  4454,  9932,  2197,  2301,  6123,\n",
            "         8092,  7976,  2166, 10831,  2089, 11248,  7580,  2529,  5198, 10760,\n",
            "        13507,  2071,  2729,  2625,  2714, 11443,  9038,  2696,  6321,  4895,\n",
            "         2890,  3597, 29076,  5422,  2126,  9932,  3471, 10366,  3732,  3921,\n",
            "         9124,  9849,  2784,  4083, 26137,  9932,  9849,  2156,  2651, 23736,\n",
            "        22373, 14269,  6666,  2036, 23382, 10831,  3058, 24783,  2175,  7011,\n",
            "         6553,  3574,  5906,  4286,  2224,  2764,  4034, 14354,  2015,  5041,\n",
            "         8248, 11443,  4087,  8107, 13729,  9932,  3471,  2048,  7958,  2175,\n",
            "         7011,  6553, 15078,  2135,  4427, 16941,  7159,  2594,  4862,  7959,\n",
            "         4427,  8849, 13494,  5936, 25953,  4818,  3891,  4286, 13507,  2635,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  7976,  4454,  9932,  6208,  4254,  8384,  6964,  9932,  2764,\n",
            "         4007, 11265, 10976, 18078,  3330,  8051,  2147,  2048, 10015,  8107,\n",
            "        12992,  2075, 29080,  2649,  2028, 12362, 12697, 14972, 15756,  7505,\n",
            "        21799,  2015, 10639,  9380,  5072,  7755,  2507,  4125,  6125, 15078,\n",
            "         5682,  4503, 12702,  7229, 14604, 18384,  6558,  3728,  4435,  2638,\n",
            "         2860,  5656,  3818, 27084, 24164,  2094,  5072,  9932, 29080, 20397,\n",
            "         8382, 10514, 18098, 22591,  2571, 15431,  3001,  6370,  4954,  8059,\n",
            "        23150,  2529,  4454,  7832,  3591,  3937,  2504,  3701, 12367, 12368,\n",
            "         4378,  2512, 13102,  8586,  4818,  5130,  7927,  4125,  3037,  8880,\n",
            "         5739,  5094,  4286,  5307,  3795,  7860,  2301,  3921,  5936,  3953,\n",
            "         6279, 12553,  4442, 18516,  5097,  2536, 16820,  2164,  2925, 28991,\n",
            "         7583, 28775,  2638,   102,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  3522, 15463,  2529, 22461,  8360, 11643, 16731, 16715,  6148,\n",
            "         5050,  3019, 13352,  3408, 19287,  2170,  8360,  2110,  7258,  1042,\n",
            "         4757,  8676, 16246,  2163, 15380,  5459, 10266,  4655,  3043,  1998,\n",
            "         2953,  3424, 18900,  3334,  6653,  2028,  2110, 15380,  2178,  8107,\n",
            "         2170,  2529, 22461,  1044, 22571, 14573,  2229,  3550,  2529, 15923,\n",
            "        27570,  4277,  1996, 10867,  7716, 18279, 22924, 23084, 27885,  8043,\n",
            "        12423,  2088,  3408,  1042,  4757,  1042,  4757,  6194,  8676, 10124,\n",
            "         2135,  2417, 21104,  2275,  7065,  2545,  7028,  3136,  4972,  3125,\n",
            "        24039,  8627,  8993,  6177,  8106,  2453, 25705,  8361,  2511,  4045,\n",
            "         8474, 21934, 10924,  3558,  6194,  6194,  5884, 10061, 15380,  3001,\n",
            "         3421,  3408,  1042,  4757,  1044, 22571, 14573,  2229,  3550,  2897,\n",
            "         3896,  3443,  4022,  6022,  2130, 27258,  2135,  3623,  2236,  3471,\n",
            "         4747,  6455,  3754,  2529,  2967, 25613,  1042,   102]), tensor([  101, 15252, 10287,  4973,  7976,  4454,  2224,  2495,  3391,  3078,\n",
            "         2082, 18046,  3579,  2613, 13494,  3145,  4547,  4119,  5525, 13896,\n",
            "        10660, 21865,  3891, 11717, 27788, 29278,  6129,  1999,  2063, 26426,\n",
            "         6447,  2591,  2967,  5020,  3229, 12361,  7976,  4454, 21331, 13382,\n",
            "         2846,  2591, 21877,  2850,  3995, 26715,  6742, 12962,  2036,  2591,\n",
            "         3425,  3314,  7860,  7149,  3431,  4547,  6194, 22267,  2478, 23323,\n",
            "         2458,  4556,  8433,  3752, 18560,  6848,  2342, 16599,  7976,  4454,\n",
            "        21331,  8433,  5352,  5089,  6786,  2109,  4235,  2426,  2367,  2287,\n",
            "         2967,  7022,  2028,  3787,  2469,  2839,  5562,  2925,  2495,  7976,\n",
            "         4454,  2109,  6994,  5335,  4252,  4083,  6194,  2092,  2147,  5089,\n",
            "        15631,  3579,  6061,  3167,  9355,  4083, 16910,  7851,  3078,  2082,\n",
            "        11107,  6461,  6469,  2075,  4621, 12317,  4807,  4813,  2344, 17614,\n",
            "         6709,  2036,  4652,  5876,  4254,  2075,  4083,   102]), tensor([  101,  2028,  2192,  2458,  7976,  4454,  6233,  2590,  4254,  3171,\n",
            "         2291,  2036,  7243,  3268,  3098,  2047, 16820, 16625,  2047, 14679,\n",
            "         3228,  4125,  2047,  6695,  2051,  8361,  4022,  5081,  8438,  7976,\n",
            "         4454,  6994,  2442,  2109,  2729, 14046,  2036,  2635,  4070,  2825,\n",
            "        10831,  2920, 10831,  2468,  3618,  3928, 17208,  5906,  2342, 10824,\n",
            "         3921,  2241, 21931, 18024,  2875,  7976,  4454,  2411,  3591,  6090,\n",
            "        10732,  2050,  4763,  2015, 22794, 12248, 20689, 12863,  5144,  3668,\n",
            "         3471,  8146,  3277,  3698,  9615, 23097,  2992,  4045,  2504,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  3166,  4455,  2561,  7221,  9932,  6083,  2071, 25732,  2128,\n",
            "        13331,  7630,  3370,  9253, 29521, 21673, 16498,  2342,  4769, 25953,\n",
            "         4818,  8767,  3720, 15102,  2536, 10831,  3378,  9932,  2164,  6034,\n",
            "         7403,  3330,  8767,  3361,  2291, 12765,  8392,  4255,  3171, 16440,\n",
            "         4483,  4254, 14173,  2529,  6550,  9932,  4107,  2116,  6666,  9229,\n",
            "         2943,  7300, 23661,  2592,  4997,  8465,  2041, 27204,  2232,  2460,\n",
            "         3334,  2213, 12637,  3166, 11637,  4771,  6695,  2627,  4652,  4997,\n",
            "        14670,  6786,  2066, 19207, 11704, 12141,  3720, 15841,  4022, 16796,\n",
            "         7976,  4454,  9932,  9251,  2442,  3030,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101, 12761, 22334,  4942,  3790,  7976,  4454,  7976,  2166,  3594,\n",
            "         6897,  2135,  4427,  4725,  9611, 20600,  3471,  2478,  2009, 25284,\n",
            "        25416,  3170,  8163,  2275,  7300,  3081,  2689,  4989,  3144,  5097,\n",
            "         8897,  3674, 13100,  2164,  3132, 20600,  3698,  4083, 21331,  2536,\n",
            "         2752,  2817,  2542,  3001,  3921,  2211,  4856, 17367,  3652,  2275,\n",
            "        13792,  5214, 13729,  2898,  2846,  3471,  4055,  2536,  4127, 11234,\n",
            "         4989, 16221,  6630,  4018,  7300,  4310,  4022,  9699, 10866, 15463,\n",
            "         2599, 20680,  5670,  2458,  7976,  4454,  7976,  2166, 12761, 22334,\n",
            "         3728,  2464,  6308,  3391,  2817,  2330, 21945,  6622,  2590, 13494,\n",
            "         2925,  9932,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  3800,  2817,  2817, 12020,  4800,  6914, 16754,  2389, 20600,\n",
            "         5248,  2491,  3001,  6074,  2236,  7976,  4454,  5214,  9174, 13729,\n",
            "         5415,  2846,  8518,  2613,  4044,  4007,  7427, 21934, 10924,  6194,\n",
            "         3031, 21281, 21197,  8625,  4588, 10752,  4800,  4270,  3372, 11265,\n",
            "        10976,  3597, 29076,  6024,  4294,  2015,  2764,  7885,  3344,  3443,\n",
            "         6887, 16515, 13874,  2015,  9414,  6074,  2241,  2364,  6481,  3031,\n",
            "        21281, 21197,  8625,  4588, 10752,  2491,  3001,  6074,  2236,  7976,\n",
            "         4454,  2241,  4800,  4270,  3372, 11265, 10976,  3597, 29076,  6024,\n",
            "         4294,  2015,  2764,  3491,  4800,  6914, 16754,  2389, 20600,  4800,\n",
            "         4270,  3372, 11265, 10976,  3597, 29076,  6024,  4294,  9414,  6074,\n",
            "         9002,  6344, 19293,  5012,  4082,  3785,  2236,  7976,  4454,  4005,\n",
            "         3073, 10752,  4942,  7361,  3775,  9067,  8332,  8360,  5679, 23306,\n",
            "         4083, 13792,  4531,  7300,  5415,  2846,  3471,   102]), tensor([  101,  3720, 10641, 10077, 18001,  7961, 13109,  2177,  3399,  2306,\n",
            "         8391,  7976,  4454,  9932, 26944,  2075, 10938,  8082, 19962, 24395,\n",
            "         5763, 11598, 15581,  8010, 15873,  2791,  9414,  3001,  2927,  3265,\n",
            "         7749, 18001,  7961,  2177,  3399,  3259,  2511,  9373, 10100,  8346,\n",
            "        18001,  7961,  2015,  3977,  5047, 12503, 25546,  3550,  2177,  3399,\n",
            "         2015, 26120,  8669,  8332, 20062,  2877, 10562,  7705,  8346,  9398,\n",
            "         4383,  2186, 17075,  2553,  2913,  7885,  2408,  7578, 13100,  7478,\n",
            "        19293, 21331,  2491,  9871,  3247,  2490,  6742,  5097, 22443,  7268,\n",
            "         4254, 13109,  2177,  3399, 14313,  5301, 15581,  8010, 11718, 24501,\n",
            "        18622, 10127,  3375, 16820,  3463,  2128, 10354, 23141,  9373, 10100,\n",
            "         2036,  3024, 24600,  3350,  6377,  3921,  2015,  4022,  2559,  2646,\n",
            "         2925,  3259, 14801,  3145,  7826,  2470,  2164, 25416,  3170,  3672,\n",
            "         9373, 10100,  8346,  3698,  4083, 12786,  7860,   102]), tensor([  101,  2817,  8849,  8790,  2492, 18001,  7961,  7976,  4454,  9932,\n",
            "         3361,  4106,  2901, 16798,  2509, 16911, 12170, 16558, 18994,  3388,\n",
            "        17682,  7427, 12667,  8525, 20617,  2951,  4773,  2671,  3579, 12151,\n",
            "         8045,  4275, 20607,  2535, 18001,  2592, 12604,  9513,  5884,  2470,\n",
            "        11596, 13661,  2342,  3305,  2458,  4254, 18001,  7961,  9932,  2306,\n",
            "        12368,  9531, 20607, 10660, 17826,  4118, 20792,  3391, 16966,  4646,\n",
            "         3361,  8169, 18046, 12170, 16558, 18994,  3388,  7277,  4106,  9125,\n",
            "         4866,  3319,  3906,  2405,  2558, 11628,  3145, 12046,  2015,  3296,\n",
            "         3930,  3446,  2248,  5792,  2779, 22921,  2566,  6254, 12944,  4249,\n",
            "         4935, 12317,  3267,  3463,  7487,  3278,  3296,  3930,  3446,  2248,\n",
            "         5792,  2779, 11091,  2566,  6254,  2350,  9263, 15368, 11817, 18001,\n",
            "         3001, 18001,  4520,  3001,  3485,  9414, 18001,  3001,  2592,  4163,\n",
            "        12636,  3278, 16884, 25705,  2075,  9999,  2015,   102]), tensor([  101,  3259,  3591,  4118,  4346,  4863,  8010,  8346,  7976,  4454,\n",
            "         9932,  2951,  5471,  5461,  7149, 20557, 17547,  4863,  3085,  7976,\n",
            "         4454,  1060,  4886,  5218, 16987,  9932,  3001,  4346, 17959, 20932,\n",
            "         3247, 12614,  6194, 16605,  9229, 17547, 10640, 20226,  3404,  9932,\n",
            "         3001,  3579,  3259, 13538, 17841,  8010,  7860,  2030, 18979,  2140,\n",
            "         5579,  3471,  2306,  4633, 19939,  2075,  2030, 18979,  2140,  5579,\n",
            "         7336, 29458,  4633, 13352,  3641,  4280,  4860,  8483,  3612,  3177,\n",
            "        13511,  3798,  2500,  4769,  4119,  3117,  2236,  4654, 24759,  5555,\n",
            "         3468, 19939,  2075,  7705,  4117, 27427, 14194,  6024,  3513, 18001,\n",
            "         7961,  3818,  2147, 27427, 14194,  6024,  3513,  5173,  3439,  4633,\n",
            "         2951,  3024, 11177, 17841,  3085,  3978, 19939,  2075, 18001,  7961,\n",
            "         8971, 12503, 17727,  2890, 28472,  4633,  2951,  2291, 10173,  2275,\n",
            "         4013,  3676, 14680, 14932,  7099,  6272,  2641,   102]), tensor([  101, 17841,  3085,  7976,  4454,  9932,  2036,  2124,  4863,  3085,\n",
            "         9932, 27427,  2483, 11837, 19150,  7411,  3404,  3085,  9932,  6847,\n",
            "         3406,  8270,  7363,  5449,  6937, 13494,  2529,  2092, 19205,  3070,\n",
            "         2174,  3484,  4493,  2470,  2181,  2415,  2075, 12697,  3375, 12138,\n",
            "         4725,  7539, 17841,  8010,  8821,  2364,  3653,  2890, 24871, 14972,\n",
            "         3404, 13966,  9932,  2966, 13100,  2777,  6529,  4975,  2536,  7526,\n",
            "         4725, 17841,  3085,  9932,  2426,  4725, 18001,  3513, 11157, 18001,\n",
            "        28937,  2291, 27424,  8361,  3117,  3928,  6994,  2958,  4807,  6578,\n",
            "         4286,  3935,  9932,  6681,  2174,  4391,  2224, 27424,  2015,  2966,\n",
            "        11616,  2804,  4646, 18001,  3513,  2367,  7957,  4800,  5302,  9305,\n",
            "         2966,  2951,  4909, 13990,  3086,  2750,  4022,  2224, 18001,  3513,\n",
            "        12697,  6413,  4118, 20792,  2800,  2951, 13462,  2015,  3319,  3073,\n",
            "         8050,  4824, 17841,  8010, 18001,  3513,  6204,   102]), tensor([  101,  2349, 12607, 11619,  2715, 19207,  6346, 10788,  2908,  3458,\n",
            "         6410,  3979,  7561,  4725,  6346, 10788,  6786, 12945,  3068,  2109,\n",
            "         6709,  4022,  4493, 19399, 19207, 19399, 19207,  2788,  6228,  5992,\n",
            "         2164,  2250, 16078,  2491,  3131, 15451, 11263, 27989,  2015, 10958,\n",
            "         9032,  4263,  3314, 22227,  3471,  6726,  2491,  3131, 10697, 12824,\n",
            "         3778, 28828, 13428, 15428,  2250,  4650,  2121, 15451, 11263, 27989,\n",
            "         2015,  7956, 25864,  3314, 11477, 27413, 19399,  9594, 15451, 11263,\n",
            "        27989,  2015,  4385,  6346,  3563,  3141,  5751,  8030,  2195,  4725,\n",
            "         6346, 10788, 19207, 12441,  7961,  6028, 18001,  7961,  4118,  7976,\n",
            "         4454,  6028,  2367, 13792,  2470,  2147,  4846, 18001,  7961, 15058,\n",
            "         2094,  6028,  3594,  5003, 26876,  7088,  9896,  3591,  2488,  6346,\n",
            "        10788,  7337,  5003, 26876,  7088,  2015,  9896,  3818,  1041, 10024,\n",
            "        14341,  5003, 26876,  7088, 18001, 28937,  4118,   102]), tensor([  101,  9949, 13617,  2897,  1059,  2015,  2078,  5500,  3074,  4714,\n",
            "         2659, 11452,  9949,  5733,  7333,  3558,  4044,  8080,  2536,  4483,\n",
            "         3785,  2951,  5067, 10959, 13617, 14164, 11860,  7688, 14164,  2478,\n",
            "         4800, 18471,  4806,  1059,  2015,  3619,  3749,  3365, 12637,  6125,\n",
            "         2164,  9412, 16991,  2659,  3465, 11038, 10813,  2349,  7692,  8663,\n",
            "        20528, 21280,  3267,  1059,  2015,  3619,  2227,  2536,  7860,  3314,\n",
            "         2342,  8280,  5676, 10539,  5851,  2951,  6726, 14164,  1059,  2015,\n",
            "         3619,  3811,  8211,  2536,  4127,  3036,  4491,  8419,  2304,  4920,\n",
            "         4491, 14920,  2326,  9998,  4491, 13045, 12014,  4491,  2426,  4491,\n",
            "         2304,  4920,  2886, 13382,  3809,  5081, 14164,  2897,  2886,  3344,\n",
            "        24391, 14164, 15734,  4530,  2951, 23730,  2491, 23730,  2302,  2830,\n",
            "         2075,  3832,  7688,  5676,  3036,  2897,  2304,  4920,  4491,  4072,\n",
            "         2640,  8114, 24554, 10788,  6028,  8909,  2102,   102]), tensor([  101,  3720,  3591,  2944, 26404, 14098,  2491,  3439,  3121,  3818,\n",
            "         2291,  2764,  2433, 12379, 22834,  2102,  6502,  3375,  2291, 13907,\n",
            "         2275,  5468,  2503,  3785, 18213, 12826,  3463,  3798, 22761,  2015,\n",
            "         4542,  3612,  3177,  6133, 17462,  2291,  2764,  2491,  2944,  2109,\n",
            "         2828,  2475, 18001,  7961, 13384, 23951, 17296, 14171,  6567,  8015,\n",
            "         2300, 16326,  2126,  3818,  2944,  2081,  9525,  9414,  2291,  9756,\n",
            "         4592,  3785,  3439,  3121,  2764,  2291,  5361,  8920,  2214, 12161,\n",
            "         2311,  4760,  8122,  2139, 28600, 28173, 10803,  7290,  3465,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101, 21641,  2838,  2377, 20369,  2535,  3019,  2653,  6364,  4346,\n",
            "         6748,  4824,  3574,  6123,  2306, 25304,  2951,  8391,  3698,  4083,\n",
            "         7976,  4454, 21641,  3444, 14676,  9125, 22969, 12158,  3787, 15973,\n",
            "        15066,  2411, 16911,  3935,  5461,  2066,  2773,  7861,  8270,  4667,\n",
            "         2015,  2784,  4083,  4275,  8346, 21641,  2838, 11598, 11718,  6123,\n",
            "        10830,  7389,  7971,  2653,  4275, 12067,  5097, 15792,  4106,  6254,\n",
            "         4937, 20265, 26910,  2592, 26384,  5452,  3618, 10640, 21923,  3259,\n",
            "         8970,  3117,  3921, 25835,  2158, 17661,  2072, 23569, 27605,  5422,\n",
            "        21641,  3444, 14676, 20287,  2891,  7959,  2881, 11598, 21641,  3444,\n",
            "        14676,  2394, 11746,  3818, 20287,  2891,  7959,  2944, 15821, 10077,\n",
            "        25835,  9324,  2075, 18001, 15058,  2094,  3444, 14676, 20287,  2891,\n",
            "         7959,  6614,  5425, 17796, 21641,  6550,  2306, 11746,  4346, 16371,\n",
            "         6651,  2094, 20062, 10318,  3574, 25304,  4180,   102]), tensor([  101,  9414,  7497,  2291,  2270,  7497,  2291,  2109,  7976,  4454,\n",
            "         2974, 23569, 27605,  4371,  2943,  2968,  5335,  3737,  7497,  2270,\n",
            "         2752,  3259,  3591,  2224,  2048,  4069,  7976,  4454,  4725,  8419,\n",
            "        18001,  7961, 15756,  6125,  9414,  2373,  2491,  2270,  7497,  6125,\n",
            "         3078,  7863,  2817, 16157,  2836,  8107, 23569, 27605,  6774,  2373,\n",
            "         8381, 10910,  8114,  7497,  2635,  9584,  2048, 11709,  8419,  2346,\n",
            "         4834,  4633,  3785,  6162,  7497,  2291, 14440,  2478,  2110,  4834,\n",
            "         6994, 13523, 20470,  5332, 12274, 13767,  2536, 13792,  2241, 18001,\n",
            "         7961,  7976, 15756,  6125,  3525,  2764,  2613,  2951,  4026,  4834,\n",
            "         6112,  3104, 12550,  3345, 13792,  2588,  4106, 12504,  3463,  5159,\n",
            "         3452,  3463,  3553,  9896,  2241, 18001,  7961, 17544, 13792,  2241,\n",
            "        15756,  6125,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  7398,  2301,  3795,  5949,  7860,  3517,  4788,  2078,  4975,\n",
            "         3741, 11160,  6410, 22210, 24156,  5949, 13148, 13382,  3278,  8767,\n",
            "         2529,  2740,  4044, 26785,  7971, 16518,  9886,  7976,  4454, 15058,\n",
            "         2094,  5024,  5949, 18771,  2974,  9932,  5910,  9333,  2102,  6123,\n",
            "         3935,  3581, 28286,  2953,  2213,  5425, 16371,  6651,  2094,  6550,\n",
            "        18001,  7961, 10232, 16820,  2344, 18001,  4520,  5609,  2311,  6481,\n",
            "         3375,  1053, 15532,  2290,  3861, 18001,  2275,  1039,  4160, 14536,\n",
            "        10343,  2468,  6150,  5052,  3247, 12088, 18394,  2048, 22172,  6132,\n",
            "        19301,  5450, 20226,  8304, 13727,  2592,  2613, 11108, 16820,  9186,\n",
            "         3192,  2389,  6481,  3259,  8970,  9525,  3581,  3136, 16764,  3581,\n",
            "        28286,  2953,  5244,  2306,  6123,  1039,  4160, 14536, 10343, 15929,\n",
            "        16594,  3136,  3259, 16599,  2176, 15873, 28041,  9224, 20118,  2015,\n",
            "         1039,  4160, 14536, 10343,  3375,  1053, 15532,   102]), tensor([  101,  2592,  2058, 11066, 20228, 11031,  6525,  7047,  2716,  3733,\n",
            "         4274,  3229, 10660, 12607,  2015,  2437,  3247, 12614,  5186,  3697,\n",
            "        16755,  2121,  2291, 12667,  2464,  4022,  5576, 13951,  5198,  2437,\n",
            "         6567, 16755,  2075, 29458,  4031,  8599, 12317,  4180, 15058,  2094,\n",
            "         8893, 22910,  2093,  8050,  3596, 12667,  2224, 24655, 13216, 12247,\n",
            "        12832,  8599,  2691,  2433, 12247,  4031, 13271,  4391,  4871,  5746,\n",
            "         2015,  6876,  2036,  2590,  2393,  5335,  2836,  3151, 12667,  3176,\n",
            "        10857,  3278,  4254, 12667,  2015,  2836,  8107,  2241,  7205, 11429,\n",
            "         3698,  4083,  4275,  2109,  3151, 12667,  2015,  3522,  9849,  7976,\n",
            "         4454,  2784,  4083,  2419,  2458, 12667,  2015,  2478,  9530,  6767,\n",
            "         7630,  3508,  2389, 15756,  6125, 13229, 18228, 18077,  9830,  2592,\n",
            "         2804, 13599, 13229, 15058,  2094, 12667,  2015,  2691,  5286,  3720,\n",
            "         3640,  2440,  7749, 13229, 15058,  2094, 12667,   102]), tensor([  101,  3522,  2086,  7142,  5082,  2458,  2671,  2974,  2926,  7142,\n",
            "         2458,  7976,  4454,  3698,  9896,  6786,  3167,  3550,  4180,  5625,\n",
            "         7528,  2495,  2291,  3048,  2185,  3151,  4972,  3151,  2495,  3001,\n",
            "         2411,  7356, 16151,  3924,  4697,  8873, 27110,  3363,  3921,  4252,\n",
            "         5136,  4310,  3791,  4083,  6782,  3076,  2495,  2291,  3167,  3550,\n",
            "        23569, 27605,  5422,  3698,  4083, 13792,  3073, 28749,  4083,  4475,\n",
            "        11433,  2241,  2493,  4083,  2381,  5426,  7590,  5335,  4083, 13105,\n",
            "         2613,  7292, 12247,  3076,  2836,  3024,  3698,  4083, 13792,  4083,\n",
            "         3488, 10426,  2241, 12247,  2437,  4083,  2832,  8790,  3167,  3550,\n",
            "         3568,  4162,  4127,  2495,  2164,  2653,  4083,  5597,  2671,  4385,\n",
            "         2174,  9229,  8122,  3698,  4083, 13792,  9041,  7620, 15973, 20600,\n",
            "        13792,  4072,  7680,  7849,  4697, 20600, 13792,  2312, 15782,  2571,\n",
            "         3698,  4083,  3259,  5363,  2191,  6851, 19184,   102]), tensor([  101,  7721,  3906,  3319,  2470,  4646,  3698,  4083, 19875, 13792,\n",
            "        16755,  2121,  3001, 12667,  3591,  3259,  2817,  8704,  6709,  3522,\n",
            "        12878,  8849,  2613, 15509,  5097,  5009,  6950, 19120,  2470,  3450,\n",
            "         5884,  2405, 16798,  2509,  5553, 19792,  2063,  9556, 20427,  2367,\n",
            "        13100,  2164,  2495,  9871, 19875, 13792,  8285,  2368, 16044,  2869,\n",
            "        23895,  4083, 17338, 15810,  3401,  3617,  8083,  3319, 11637,  9412,\n",
            "        12832, 10640,  3445, 26743,  8553,  3167,  3989,  6123,  7073,  7578,\n",
            "        19875,  5461,  9942,  8304,  3147,  2707,  2951, 12403,  2869,  3012,\n",
            "         3192,  2925, 12607,  2015, 19875, 13792, 12667,  2015,  6195,  4646,\n",
            "         5814,  9926,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101, 19143,  2592,  4807,  6786, 25891,  3923,  2968,  5335,  3737,\n",
            "         2166,  2103, 28857,  2839, 10057,  6047,  3655,  6123, 16755,  2121,\n",
            "         3001,  5906,  3749,  3167,  3550, 15690,  2103, 28857,  6003,  3145,\n",
            "        16884, 19143,  3144,  4646,  2536,  2752,  2103,  2166,  3754,  2832,\n",
            "         5294,  8310,  2951,  7013,  3923, 10058,  4654,  5669, 17572,  3570,\n",
            "        10232,  2974,  6622,  2103,  4041, 16134,  2443, 15252,  4773,  2671,\n",
            "         7809,  4525,  7558,  4790, 21839,  2128, 20414, 11656,  4359,  6564,\n",
            "         2034,  2754,  5031,  4755, 12170, 16558, 18994,  3388,  7277,  4106,\n",
            "         7863, 20253,  8332,  5919, 16596, 18900,  6994, 16378, 12543, 11778,\n",
            "         3906,  3319,  2478, 26113,  2050, 12609,  4861,  3463,  7203,  2367,\n",
            "         6194, 11433, 21839,  2752,  6813,  2740, 12969,  3665,  2470,  2464,\n",
            "         3278, 12687,  3298,  6622,  8122,  6047,  3655,  7411,  5024,  7705,\n",
            "         2925,  2470,  8790,  2492,   102,     0,     0,     0]), tensor([  101,  6556,  9871,  5097,  2241,  4274,  2477, 22834,  2102,  3073,\n",
            "         3435,  4652,  8082,  2966,  2578,  5022,  3891,  2174, 29458,  2540,\n",
            "         4295,  3375,  4708, 11616,  3463,  6524,  8321,  4769,  3277,  3117,\n",
            "        12832,  2291, 22935,  4295, 17547,  2478, 22834,  2102,  2897,  2784,\n",
            "        11522,  3695,  3818,  3073,  3188, 11616,  3949, 23444, 11433, 15050,\n",
            "         7870,  3322, 19389,  2951,  5067,  5022, 19512,  2478,  2176, 16012,\n",
            "         5054, 21748,  2015, 14925,  2290, 13617,  3778, 13617,  8187, 13617,\n",
            "        18423, 13617,  5067,  2951,  2363, 12098,  8566,  5740, 11486, 22834,\n",
            "         2102, 13907, 16014, 22939, 26745,  3366,  4295, 22935,  4295, 17547,\n",
            "         2944,  7528,  2478,  2502,  6820,  7226,  7442,  7542,  2389, 11644,\n",
            "        28667, 29264,  3131,  3086,  2944, 22939, 26745,  8583, 22935,  4295,\n",
            "         2465, 14144,  2274,  2800, 22935,  4280, 12832,  2291,  3640,  3558,\n",
            "        23444, 11433, 15050,  5022,  2241,  6219,  2951,   102]), tensor([  101,  6745,  3947, 12771,  9798,  4219,  2326, 10489, 10390,  5836,\n",
            "         5670,  2185,  9798,  4031,  4156,  9798,  2326,  5359,  5198,  4274,\n",
            "         2312, 15782,  2571,  2951,  6401,  2174, 13896,  6112, 15058,  2094,\n",
            "        22834,  2102,  7976,  4454,  9932, 10787,  8013,  3325, 19309,  2015,\n",
            "         2116,  4646,  2752, 16755,  2121,  3001, 12667,  2342, 13368,  2078,\n",
            "         2536, 12719,  2490, 22834,  2102,  5733,  2415, 19309,  2088,  2164,\n",
            "         3522,  2653,  4275,  2066, 11834, 21600,  2102, 22759,  6786,  2066,\n",
            "        28991, 15007, 21020,  3259, 13999,  5821,  2451,  3522,  9798,  2458,\n",
            "        22834,  2102, 23663,  2078,  9666,  9798,  4429,  2348,  3365,  2470,\n",
            "         2913,  2405,  4429,  6047,  5097,  3904,  2718,  5886,  3406,  4146,\n",
            "         9666, 15058,  2094,  6047,  5821, 13100, 16755,  2121,  3001,  4429,\n",
            "         2641,  3117, 15078,  2291, 10210, 28731,  2397,  9407,  5335, 20235,\n",
            "        27891,  8392,  7325,  5248,  5097,  9034,  2613,   102]), tensor([  101,  3800,  2236,  3800,  2817,  8556, 12353, 16755,  2121,  3001,\n",
            "         3716,  5456, 16134, 15363,  2470, 16134,  4233,  2817,  4624,  2470,\n",
            "         5218,  3905,  2951,  5067,  2302,  2492,  6198,  4624,  2470, 10468,\n",
            "         2920,  9334,  2951,  4493,  4219,  6516,  2411,  2641,  2659, 13186,\n",
            "         2102,  6028,  4102,  2492,  2470,  2364,  3465,  2920, 12706,  2051,\n",
            "         7026,  5571,  2472,  3111,  2947,  2817, 13538,  2525,  2405,  2913,\n",
            "         4311,  6747,  3905,  2951,  4089, 11570,  3784,  9263,  3075,  9556,\n",
            "         3936,  9556,  6526,  6123,  8787,  4118, 10091,  6578,  8800, 16755,\n",
            "         2121,  3001,  3716,  5456,  2817, 12353, 16755,  2121,  3001,  3716,\n",
            "         5456,  2179,  3001,  2209, 20369,  2535, 25505,  5198,  8993,  6565,\n",
            "         2592, 16360, 20049, 29469,  2229, 12067, 26944,  7882,  4219,  7818,\n",
            "         3716,  2179, 16755,  2121,  3001, 15440,  3935, 13792,  3167,  3550,\n",
            "         5461,  7645,  3020, 12353, 11717,  7882, 11433,   102]), tensor([  101,  4646,  7976,  4454,  9932,  6022,  3445,  2116,  2529,  4219,\n",
            "        17850,  4972,  2470,  8704,  3305,  4022,  7976,  4454, 15058,  2094,\n",
            "        16755,  2121,  3001,  2674,  3105, 17879,  7904, 17879,  8690,  7578,\n",
            "         8519,  5664,  8593,  2622, 10489, 10489, 22565,  2529,  7692, 10489,\n",
            "         2817, 13495,  3972, 21850,  2817, 15058,  2094, 16134,  4919, 21317,\n",
            "         6739,  5997,  3640, 10740,  8599,  7928,  2275, 14848,  2015,  2241,\n",
            "         3784,  3972, 21850,  2817,  3463, 13180, 10740,  2470,  8704,  6709,\n",
            "         7860,  3141,  7904,  5558,  2497,  6337,  9844,  7976,  4454,  3698,\n",
            "         4083,  5906,  2433, 16755,  2121,  3001,  2817,  2536,  7860,  9844,\n",
            "         7904, 17879,  3105, 17879,  2783,  3471,  4320, 12706,  2529,  7692,\n",
            "         5073, 22565,  2622, 10489,  5502,  3972,  7178,  2817,  2036, 25999,\n",
            "         2422,  4022, 24010,  7300,  7976,  4454,  2433, 16755,  2121,  3001,\n",
            "         3232, 14848,  2015,  3579,  4022,  7300,  2536,   102]), tensor([  101, 13268,  3670,  5038, 10768,  2099, 12550,  2536,  4249,  2495,\n",
            "        10355, 21331,  9871,  2500, 13268,  3670,  5461,  6013,  9123,  8957,\n",
            "         7976,  4454,  6807,  2529,  5344, 11487,  6699,  2711,  9530, 14028,\n",
            "         2075,  2224,  6699,  5454,  6413,  6998,  2028,  2224,  2553,  2227,\n",
            "         7603, 10788,  2652,  2189,  2241,  5198,  6888,  5198, 13268,  3670,\n",
            "        16578,  2139,  8566,  3401,  5346,  2765,  4812,  3223,  2047,  7603,\n",
            "         4275,  4493,  3924,  5998, 11178,  5468,  2189,  2015,  4434, 13268,\n",
            "         7603,  3259,  2785,  3105,  7528,  2478,  9530,  6767,  7630,  3508,\n",
            "        15756,  2897, 13229,  2241,  2784,  4083,  3921,  2784,  4083,  6464,\n",
            "        17908,  4895,  3367, 26134,  2951,  5691,  3596,  2865,  3698,  4083,\n",
            "         2470,  2613,  7292,  2291,  2580,  6807,  2529,  5344, 14358,  2529,\n",
            "         6699,  2130, 16755,  2189,  5198,  1051,  4430, 29107, 10768,  2099,\n",
            "        11387, 17134,  2951, 13462,  2015, 12550,  6388,   102]), tensor([  101,  2445,  7860,  6970,  9527,  8113,  2592, 10077,  2951, 12403,\n",
            "         2869,  3012, 12317, 22910, 13792,  2892,  9527,  8113,  2592, 10077,\n",
            "         8185, 22511,  9896,  3818,  3259, 11598, 10640,  3167,  3550, 11433,\n",
            "         7976,  4454, 12832,  3001,  2817,  4269,  9334,  2079, 19761,  2078,\n",
            "         3185,  5790,  2951,  2591,  2897,  2592,  5676,  2951, 11109, 23310,\n",
            "         6132, 11039, 12377,  3292, 10788,  4846,  6366, 24473,  7644,  3019,\n",
            "         2653,  6364,  2974, 12550, 14817,  3145, 22104,  8476,  2592,  2591,\n",
            "         6981,  5678, 10629,  9530,  6767,  7630,  3508,  2389,  6125, 12550,\n",
            "        10463,  5310,  6550,  3444, 19019,  4310,  9829, 16861,  4118,  2109,\n",
            "        10463, 16246,  5310,  3185,  2592, 12441, 21520,  4652,  2058,  8873,\n",
            "        13027,  5526,  3180,  3989,  4118,  3107,  6360, 23569, 27605,  4371,\n",
            "         4022,  3444, 19019, 18215,  2779,  3444,  4434,  5461,  4162, 17409,\n",
            "         2838,  2367,  4249,  9308,  8875, 15058,  2094,   102]), tensor([  101, 18804, 16070,  3617,  4044,  5198, 11835,  7484,  5200,  2855,\n",
            "         3352,  4507,  7976,  4454,  9932,  6233, 20300,  2458,  3098,  2047,\n",
            "        10047, 16862,  3512,  6322,  2817, 20798,  9932,  4117,  6786,  2066,\n",
            "         4274,  2477,  3796, 24925,  2078,  3019,  2653,  6364,  7484,  4507,\n",
            "        19335,  4507,  3816,  4507,  3668,  4507,  2306, 18804, 16070,  2028,\n",
            "         5056,  9932, 18804, 16070,  3754, 22701,  6322,  3265,  5198,  2241,\n",
            "         5248, 18394,  5678,  9932,  8285,  8585, 24684,  8518,  4352,  2051,\n",
            "         5541, 28809,  2174,  7860,  9394, 13827,  9147,  2442,  8280, 11131,\n",
            "         5919,  2164, 12962,  5936,  2488,  7374,  2925, 27830,  2817,  3640,\n",
            "        16030, 19184,  9932,  2015,  8346,  8361, 18804, 16070,  6786, 22671,\n",
            "         5197,  6595,  7172,  5901, 20607,  2492,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  8391,  7976,  4454, 17215,  3278,  8651,  2197,  5476,  3391,\n",
            "        14053,  2784,  4083,  2419,  3862, 12607,  2015,  2408,  2536,  6088,\n",
            "         5541,  4249,  2174, 12637,  2907,  2678,  2208,  4753,  2208,  7976,\n",
            "         4454,  9932,  2146, 24911,  9009,  2093,  5109, 12786,  3563,  7860,\n",
            "         6143,  4748, 14028, 12086,  2512, 13068,  2121,  3494, 11247, 15732,\n",
            "        24508,  4180,  4245,  3127, 20618,  8050,  2752,  3151,  3627, 15058,\n",
            "         2094,  9932,  4247, 24970,  3698,  4083,  5378,  3117, 15955,  7511,\n",
            "         4725,  5678, 15102,  2047, 12020, 17707,  9932, 24501,  3270,  4691,\n",
            "         2208,  2458,  2164,  2447,  5248,  4106,  9412,  8389,  7284,  2491,\n",
            "        12978,  3737, 16375,  5604,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  7976,  2236,  4454, 12943,  2072,  4145,  9104,  7976,  4454,\n",
            "         9932, 12607,  2015,  2071,  2599,  4325,  9178, 27097,  2130,  9414,\n",
            "         4286,  4145,  2556,  2144,  2220,  5711,  9932,  2458, 13977,  2536,\n",
            "        10287,  9932,  2453, 11835,  4286,  7214,  2573,  2470,  2913,  3259,\n",
            "        20798,  2783,  5082,  9932, 15841,  7552,  9932,  2971,  5901, 10449,\n",
            "         2047,  8052,  9932,  5461,  5214, 27097,  2529,  2836,  3130,  4895,\n",
            "         9581, 20876,  3468,  8518, 23217,  2075,  3105,  3006, 12607,  2015,\n",
            "         2992,  5936, 12943,  2072,  2453,  2468,  4507, 10076, 11436,  2174,\n",
            "         3259,  9251,  2784, 15756,  6125,  2747,  2433,  3192,  9932,  4725,\n",
            "         9832,  2599, 12943,  2072,  2349, 16112, 12546,  2612,  6083,  8767,\n",
            "        29217,  2783,  9932,  2679,  3141, 12546,  5097,  3768,  7816,  4193,\n",
            "         4493,  4275, 13792,  2738, 14053, 12943,  2072,   102,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101, 29458,  4791,  9686, 25378,  2613,  7292, 25095,  4022, 11598,\n",
            "        13972,  8147,  2350,  2977,  2824,  2174,  4708, 10368,  2349,  2399,\n",
            "        21446, 10857,  7578,  2447,  9942,  3247, 12614,  2470,  8704,  3623,\n",
            "         4378,  8147,  2678,  2208,  8504, 10449,  2613,  7292, 17547,  4118,\n",
            "        12515,  5222, 16462,  2146,  2460,  2744,  3638,  2897,  1048,  3367,\n",
            "         5244,  2241,  3921, 18228, 16014,  2015,  2663, 10483,  2063, 13105,\n",
            "         2478,  2740, 17245,  2447,  2051,  2186, 10580,  3921, 16157,  2836,\n",
            "         4438,  2048, 13068,  2121, 10877,  2208,  3565,  2395,  4959,  2462,\n",
            "        15386,  5678, 12826,  4118,  2110, 15794, 22375,  2051,  2186, 19939,\n",
            "         2075,  4725, 10938,  2121,  4275,  2179,  2312,  2653,  4275,  2222,\n",
            "         5244, 22267,  3073,  2951, 13462,  3642,  7480,  8162,  3401,  4219,\n",
            "         8627,  2458, 16014,  3512,  4106, 10877,  2399,   102,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  2622,  9891,  7780,  2735, 15058,  2094,  5656,  2399,  2066,\n",
            "         2345,  5913,  9887,  1060,  9006,  1016,  3522,  4486,  6907,  8704,\n",
            "        21155,  7976,  4454, 11598, 20957,  5656,  2399,  4919,  2622,  7679,\n",
            "         2478,  9932,  4503,  8795,  4245,  2291, 20957,  5682,  2291, 19421,\n",
            "         2047,  8795,  2015,  8790,  3973, 21935,  9932, 12067,  2867,  9280,\n",
            "         5959,  2412, 10288,  9739,  4667,  2466,  8795,  2015,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  3127, 20798,  3617,  2974, 12550,  5083,  3521, 25820,  2495,\n",
            "         6195,  4022,  6666, 10831, 17146,  3921, 16764,  2529, 13013,  6850,\n",
            "         2640, 16731,  2094,  3188, 25090, 11254,  3791, 15251, 26262,  2093,\n",
            "         2553,  2913,  3127, 27397,  4022,  3617, 20957,  7976,  4454,  9932,\n",
            "        10355,  4637,  3521, 25820,  4073,  2034,  2553,  2817, 24899,  2224,\n",
            "         3617, 20957,  4252, 14052,  2117, 11637,  9932,  2015,  2535, 28805,\n",
            "         2075,  5694,  4808,  2353,  2553,  2817, 15102, 10355,  4846,  5333,\n",
            "         7073,  2162,  6048,  6807,  2974,  7534,  4800, 12172,  3064,  2181,\n",
            "         2817,  6592, 28575, 11110,  4372, 17084, 12020,  5622,  5677, 14049,\n",
            "         2640,  7091,  3127,  2104,  9363,  6072,  7784, 14622,  2974,  2015,\n",
            "         7037,  3267,  3977,  8020,  4736,  6469,  2075,  3521, 25820,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  8790,  7484,  4507, 27830,  8590, 10355,  4024,  5378, 10047,\n",
            "        16862,  3512,  6322,  3665,  5198,  2047, 18814,  2817, 13999,  9525,\n",
            "         4145,  7484,  4507,  5469,  2998, 23293,  5469,  2998, 27830, 16599,\n",
            "        19293,  3921,  4975, 27830,  5469,  2399, 11566,  2447, 11643, 19293,\n",
            "         2965, 15058,  2094,  2291, 10229,  2867, 10069, 14171,  2015,  2208,\n",
            "         4180, 11914,  2470,  7534,  2048,  3145, 12607,  2015,  4310,  4118,\n",
            "        12151,  2447, 10069,  2208,  2951,  3698,  4083, 19293,  2208,  2291,\n",
            "         2478,  6074,  8080,  2447,  7404,  5787,  7524, 12893,  2075,  3787,\n",
            "         3176,  3350,  5310,  2913,  7778,  5604,  6083,  3921,  4578,  6132,\n",
            "         6911, 10089, 27911,  2015, 20226,  3325, 11566, 27830,  5469,  2998,\n",
            "         9005, 17075, 10047, 16862,  3512,  4024,  3325,  2867, 26275,  2166,\n",
            "        10359, 26162,  7484,  4044,  8790, 27830,  5469,  2998,  3325,  9412,\n",
            "         7976,  4454,  9932,  2447, 11643,  4107,  7721,   102]), tensor([  101, 16911, 11721,  4328, 10803,  2678,  2399,  3824,  4118, 20226,\n",
            "        10699,  7590, 24465,  5566, 14767,  3391,  6143,  3241,  4813,  2116,\n",
            "         4411,  6611,  2678,  2399,  2408,  2536, 11105,  2495,  5821,  2449,\n",
            "        20213,  6162,  4515,  2817,  6461,  8849,  4254,  2678,  2399, 20226,\n",
            "         6143,  3241,  2426, 10489,  4022,  4975, 10699,  9859,  2817,  2920,\n",
            "         2382,  2493,  8851,  5117,  8144, 20213, 16927, 14358,  6818,  6143,\n",
            "         3241, 25472, 19312,  2015,  6143,  3241,  3160, 20589, 12550, 10699,\n",
            "         9859,  7594,  2478,  2064,  2696,  2497,  3231, 20390, 12702, 24805,\n",
            "        20511,  4041,  2933,  5038, 20932,  7692,  7215,  7704, 27885,  8043,\n",
            "         3567,  8553,  4053, 24685,  2881,  6709,  3633, 11247,  2075,  6782,\n",
            "         3463,  3662,  5187,  2509,  3867,  6818,  7645, 21346,  3241,  2382,\n",
            "         3867,  8176,  3001,  3241,  6893,  6913, 25416,  6444,  2075,  3241,\n",
            "         2806,  7444,  6143,  3241,  9812,  9308, 16902,   102]), tensor([  101,  2470, 15102,  4022, 22415,  2449, 12504,  2399, 18667,  2290,\n",
            "        12978, 15581,  3085,  4083, 18667,  2290,  2445,  5915,  4935,  2592,\n",
            "        11619,  3824,  2449, 10058,  3151, 18667,  2290,  2495,  4725,  2411,\n",
            "         2991,  2460, 23613,  8225,  2493,  2613, 11108,  7860,  4769,  2817,\n",
            "        17146,  9525,  7705, 10843, 15581,  2015,  4083, 10425, 10960,  5604,\n",
            "        16820,  2241,  3265,  3076,  5082, 18394,  4719,  4646,  2715,  7976,\n",
            "         4454,  5461,  2164,  3698,  4083,  6614, 23569, 27605,  6774,  5198,\n",
            "        20125,  3716,  3247, 12614,  7590,  5541,  3241,  4813,  3167,  6026,\n",
            "         4083,  3325,  7091,  2470, 16605,  7552, 15152,  6840,  9932,  2495,\n",
            "         5971,  9942,  5378, 16746,  9412, 11973,  4547,  8107,  2715,  3690,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  3652,  2193,  2111, 13543,  2678,  2399,  2166, 12098, 15441,\n",
            "         3528,  5346,  2867,  8404,  8277,  7404, 26452,  4525, 13769,  2504,\n",
            "        27013,  9879,  5758, 22945,  2224,  5346,  3495,  2208,  5047,  2801,\n",
            "         4526,  8790, 24508,  4180,  4245,  7473,  2290,  2291,  6832,  2208,\n",
            "        10949,  8290,  3591,  3259,  3921,  2328,  7461,  3512,  9798,  5461,\n",
            "         3259,  2580,  7603,  5038,  2291,  2241, 18001,  7961,  2344, 14570,\n",
            "         3125,  7976, 15756,  6125,  8971,  7473,  2290,  7461,  3512,  9798,\n",
            "         5461,  2164, 21935,  6832,  3670,  2843,  3749,  2678,  2208,  2449,\n",
            "         2447,  6832,  5211, 10232,  5587,  2242,  4840,  3528, 10266,  4286,\n",
            "         7588,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])], 'attention_mask': [tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])]}\n",
            "Construction: {'input_ids': [tensor([  101,  3522,  8973,  7976,  4454,  9932,  7013,  2307, 10908,  2925,\n",
            "         4254,  9932,  2495,  4083,  9932,  2098,  2411, 10908,  2241, 24216,\n",
            "         2783,  4087, 12020,  3768,  3716,  2110, 15794, 22375,  9932,  2495,\n",
            "        17003,  2135,  4867,  5328,  4972,  2495,  2554,  3720,  3073,  3319,\n",
            "         4493,  9932,  3001,  2495, 21877,  2850,  3995, 12863,  4547, 17568,\n",
            "         4503,  5939, 18155, 15707,  9932,  2098,  3001,  6235,  2367,  3971,\n",
            "         2478,  9932,  2495,  4083,  2265, 16764,  2367, 15931,  9932,  2495,\n",
            "         2071,  6848,  4022,  2346, 23467,  2015,  9932,  2098,  3307,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  7976,  4454,  9932,  4975,  4646,  9359,  8598,  2075,  3446,\n",
            "         9932,  2468,  2112,  3679,  3268,  3043,  2755,  9932,  2904,  2126,\n",
            "         2111,  4553,  2174,  9886,  4547,  4753, 12279,  2094,  7860, 12962,\n",
            "         3314,  3800,  2817, 17908,  6695,  6666,  7860,  9932,  2495,  3319,\n",
            "         2800,  7882,  3906,  2589,  2478, 11778,  3319,  4118,  6709,  2783,\n",
            "         2470,  3579,  3073, 27427, 23606,  2232,  4824,  9932,  2974,  2495,\n",
            "        19156,  2925,  2470,  7826,  9556,  3662,  9932,  2015,  9886,  2495,\n",
            "         3935,  2764,  3032,  2470,  2150,  2759,  2306,  3068,  2871,  3690,\n",
            "         7860,  2092, 11433,  6936,  2817,   102,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  2817,  3024,  4180,  4106,  2913, 13659, 26056,  7976,  4454,\n",
            "         9932,  4162,  2495,  4753,  8849,  4022,  2470, 12878,  7860,  9932,\n",
            "         2495,  2561,  2531,  4981,  2164,  6191, 17537,  4981,  6356,  2913,\n",
            "         4261, 23521,  4981,  3479,  2495,  4547,  2470,  4696,  2591,  4163,\n",
            "        11091,  5950,  7809,  2230, 12609,  4180,  4106,  3662,  2470,  3980,\n",
            "         2071,  6219,  2458,  6741,  5579,  9844, 12832,  2784,  4083,  4646,\n",
            "         6741, 12247, 13384, 19293,  4083,  8346,  6741, 12242,  9798,  2535,\n",
            "        13068,  2075, 10047, 16862,  3512,  4083, 11721,  4328, 10803,  9308,\n",
            "         2176,  2470, 12878,  2164,  4274,  2477, 21708,  4454,  2784,  4083,\n",
            "        23700,  2092,  7667,  9932,  2495,  4081,  4812,  2174,  2036,  3818,\n",
            "         7860,  2495,  2089,  3303,  9932,  7634, 15884,  2224,  9932,  5461,\n",
            "         5278,  4395,  5089,  2493,  2092,  2591, 12962,  3314,  3463,  3073,\n",
            "        20062, 19184,  9932,  2109,  2495,  5884,  7126,   102]), tensor([  101, 25682,  2382,  3032,  2207,  2120,  7976,  4454,  9932,  3343,\n",
            "         9942,  5491,  2396, 24153,  3488, 10908,  4953,  9932,  4254,  3343,\n",
            "        11105,  2164,  2495,  4050,  6848,  2591, 12962, 13494,  9932,  3720,\n",
            "        24255, 23539,  4106,  2484,  2120,  9932,  3343,  9942, 15252,  2535,\n",
            "         2495,  3795,  9932,  3343, 15152,  4858,  2224,  9932,  2495,  9932,\n",
            "         2098,  4321,  9962,  3343, 11450,  6150,  3643,  2495,  4637,  2250,\n",
            "        13775,  2100, 14877,  2731,  9932,  8519, 24783,  3188, 25090,  5422,\n",
            "        12962, 13494,  9932,  2098,  4374, 13594,  2102,  3086,  2750, 12144,\n",
            "         9932,  9615,  6594,  3227,  5491,  6083,  9932,  2098, 12368,  3343,\n",
            "        12962, 13494, 24146,  2919,  3270,  3726,  3478,  3362,  7731,  7073,\n",
            "        11376,  2015,  3145,  3247, 12088,  5142,  2445,  4621,  3343,  6176,\n",
            "         9584,  9615,  1999, 10288, 12412,  8231,  5799,  3720,  9251,  2422,\n",
            "         9556,  3720, 12033,  7705,  2274,  9932,  9615,   102]), tensor([  101,  7976,  4454,  9932, 24501,  3270,  4691,  2088, 13769,  3971,\n",
            "        14670,  5121, 15189,  6923,  9879,  7386,  2015,  2765,  2974,  2092,\n",
            "         8346,  9932,  2536,  5919,  2529,  2166, 14128,  3375, 12962,  5936,\n",
            "         8361,  2640, 10813,  2224,  2974,  4240, 14764,  2051,  7065, 17417,\n",
            "         2102,  2925,  9797, 11216,  2247,  8390,  4083,  3310,  9932, 11734,\n",
            "         5197,  3345,  2925,  2372,  9932,  2451, 22859,  2092,  8339,  3971,\n",
            "         9932,  2453,  4254,  7243,  3268,  9979, 10198, 11598,  6666, 10210,\n",
            "        13340,  3436,  4022,  7386,  2015,  2071,  5258,  2112, 12548, 11778,\n",
            "        10502,  9932,  9615,  8882,  3259,  4780,  6235,  2367,  8107,  9932,\n",
            "         9615,  3749,  2275, 11433,  3141,  9932,  9615, 21877,  2850,  3995,\n",
            "         6292,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  7976,  4454,  2495,  9932,  2098,  2470,  4563,  4792,  2490,\n",
            "         3076,  4083,  3325,  9932, 13100,  6592, 12962, 11174,  7182,  2036,\n",
            "         2342,  5136, 12045,  3314, 26935, 17842, 16987, 13827, 12645,  4034,\n",
            "        10502,  2236,  2504,  2036,  2342, 21032, 12962,  2477,  2477, 12962,\n",
            "         2135,  3305,  2191, 21877,  2850,  3995, 26715,  9804, 12962,  4070,\n",
            "         2412, 28994,  4765,  6061,  4895, 18447, 21945,  8465,  2174, 12786,\n",
            "         3141,  3980,  2521, 20610,  2034,  3357,  2875, 12786,  4187,  6578,\n",
            "         4778,  3438,  9932,  2098,  2451,  2015,  2877,  6950,  6869,  5002,\n",
            "         3980,  9615,  4646,  9932,  4547, 18046,  3259,  2034,  8970,  3314,\n",
            "         2105,  9615,  9932,  2495,  2279,  7680,  7849,  5562,  5857,  2459,\n",
            "        25094,  6848,  3375,  3314,  2992,  3563, 13105,  2421,  5038,  9932,\n",
            "         2098,  6950,  4738, 11147,  8361, 12962,  3980,  2092,  6155, 23773,\n",
            "         2098,  7705, 11973,  9615,  9932,  2098,  4117,   102]), tensor([  101,  4547,  5097,  9932,  5257, 19351,  9236, 29371,  5577,  2224,\n",
            "         7076, 21649,  3937,  5760,  4162,  2470,  3720,  3957, 19184,  4556,\n",
            "         8361,  4294,  2015,  9932,  2495,  2220,  6950,  4208,  4526,  3167,\n",
            "         3550,  4252,  3001,  2241, 14348, 26262,  6168,  3522,  2147,  3138,\n",
            "         4070,  2111,  4083,  6123,  2536,  2882,  7860, 19141,  3314,  2145,\n",
            "         5307,  9932,  2495,   102,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  3330,  2495,  7887, 20607,  2562,  6745, 10660,  8973,  3113,\n",
            "         5278,  3791,  3330,  3068,  2028, 10015,  2458,  2492,  2224, 11416,\n",
            "         6024,  7976,  4454,  2974, 11834, 21600,  2102,  4512,  2389,  4005,\n",
            "        11834, 21600,  2102,  4022,  3749,  3167,  3550,  4621,  4083,  6322,\n",
            "         4346,  2493, 28749, 12247, 17959,  2092,  4526, 12689,  7484, 24710,\n",
            "         2398,  2239,  4083,  2174,  2590,  2036,  5136, 12546,  2974, 11834,\n",
            "        21600,  2102, 11416,  6024,  9932,  3001,  2204,  2731,  2951,  2089,\n",
            "         2566, 22327, 20598, 13827,  2229,  2130,  9699,  3659, 28616,  2378,\n",
            "        14192,  3370,  5678,  2224, 11416,  6024,  9932,  2495, 13275, 12962,\n",
            "         5936,  4022, 16655, 23048,  2389,  9841, 21821,  2102,  2224,  2493,\n",
            "         4022, 12163,  4286,  2081, 21707,  2974,  2783,  2110, 11416,  6024,\n",
            "         9932,  2974,  3421, 11834, 21600,  2102,  8052, 25077, 19236,  2272,\n",
            "         2590,  3330, 19156,  3305, 13494,  2974,  2817,   102]), tensor([  101,  3720, 20798,  6666, 10831,  7976,  4454,  9932,  2495,  7189,\n",
            "         8050,  2529,  2916,  3720,  2241,  7327,  8040, 17686,  2817,  2022,\n",
            "         7389, 11927,  1038,  2210,  5558,  7295,  1052, 22762,  1052, 10210,\n",
            "         7352,  1060, 22200,  7878,  6511,  5974,  2418,  2502,  2951,  8822,\n",
            "         4547,  3001, 10765,  5523,  2436,  2647,  2586, 16770, 14289, 16558,\n",
            "        21261,  3366, 10976,  4502, 13765,  2368, 14289, 16558, 21261,  3207,\n",
            "        14162, 14289, 16558, 21261,  2683,  2549, 27421,  2629, 11329,  2620,\n",
            "        22610,  2509,  2063, 14526,  2063,  2581, 21996, 17914,  2487, 11057,\n",
            "        23352,  2098,  2581,  2487, 27717,  2817,  3138,  4070,  4022,  9932,\n",
            "         2502,  2951,  3073,  4621,  8822,  2495,  2291,  2613,  7292,  2036,\n",
            "        10592, 13494,  8050,  2529,  2916, 22467,  5089, 26262,  4106, 11637,\n",
            "         2342,  5703,  6666, 10831,  9932,  5906,  2764, 11625,  7333, 16519,\n",
            "         2655,  7861,  8270,  9584,  6666, 10831,  9932,   102]), tensor([  101, 12854,  7814,  2715,  2287,  2702, 20113,  6772,  2974,  7365,\n",
            "         2166,  2560,  2495,  2071,  5275,  1999, 27753, 14505,  2974, 21416,\n",
            "        21850,  6632,  2495,  2784,  4254,  9823,  5278,  3276,  3836,  3076,\n",
            "         2092,  2493,  4262,  2468,  6233,  2462,  2102,  2009,  6806,  2226,\n",
            "         2241,  3977,  2433,  9547,  2504,  4198,  2791,  3836,  2493,  2493,\n",
            "         2593, 10548,  2468, 18234,  4852, 21416, 21197,  6648,  2495,  2770,\n",
            "         5903,  3383,  4654, 10732, 28483,  3436,  3291, 27084, 24164,  2094,\n",
            "         2832,  4553,  9031, 19821,  5089,  8210,  6904,  6895, 27606,  6591,\n",
            "         4083,  2832,  2738,  2619, 11532,  2242,  6570,  2500,  3720,  2034,\n",
            "        14358,  2783, 21416, 21197,  6648,  2495,  4254,  4262,  2306,  9823,\n",
            "         2117,  2839,  5562, 20934, 17198,  2462,  2102,  2009,  6806,  2226,\n",
            "         4262, 13494,  2495,  2633,  8556,  2245,  7551,  2458,  9932,  2071,\n",
            "         1015,  2154,  5147,  5672,  2529,  5089,  9823,   102]), tensor([  101,  5237,  7209, 23934,  3078,  3120,  4761,  6519, 24014,  4968,\n",
            "         3318,  4800, 14971,  6313,  3032,  4295,  3303,  4264,  2349,  2536,\n",
            "        26835,  2015,  2066, 18191, 15289, 10327, 20090,  6196, 12194,  6409,\n",
            "         5237,  3840,  2408,  2088,  3036,  8765,  7175,  3737, 11712, 10232,\n",
            "         8080,  4295,  4264,  2947,  5038,  3269,  4295,  6827,  3269,  4295,\n",
            "         8715, 17725,  5664,  3033,  4264,  9690,  4141,  8985, 11156,  5664,\n",
            "         3727,  4264,  3274,  4432,  2784,  4083,  2261, 19040,  4083,  3730,\n",
            "         9798,  5461, 12550,  2536, 14766,  8073,  6709,  4295,  4264,  3081,\n",
            "         7053,  4871,  5461,  2036,  5770,  6617, 10910,  4654,  5669, 25090,\n",
            "         3560,  6413,  4506,  4468,  7312,  3737, 11712,  8765,  4646,  5461,\n",
            "         5038,  4295, 13642,  5339, 20502,  4761,  2755,  6313,  4989,  4295,\n",
            "         2838, 14676,  2838, 12992,  3177,  2974,  8122,  2470,  2036,  3056,\n",
            "         8382,  5461,  2511,  4652, 10210, 28731, 26835,   102]), tensor([  101,  2312,  2193,  8360, 13907,  5361,  2715,  9414,  4683,  2116,\n",
            "         7976,  4454,  2241,  3192,  4275,  3818,  6047, 13851,  6807,  2124,\n",
            "         4874,  4280,  2047,  2714, 16820,  2174,  2145, 10368,  3192,  4275,\n",
            "         6047, 13851, 11487,  4874,  4280,  2464, 16100, 16820,  3661,  8704,\n",
            "         6183,  6192,  6047, 13851,  2470,  9414,  4683,  2034,  7680,  7849,\n",
            "         4697,  2783,  4235, 13901,  3192,  4275,  3192,  4454,  2734,  6047,\n",
            "        13851,  9414,  4683,  4863,  2061,  2527, 15058,  2094,  5903,  4432,\n",
            "        12992,  3192,  4275,  6047, 13851,  3937,  4454,  2184,  9412,  4454,\n",
            "         2322,  2345, 18960,  4454,  2382,  2195,  4387,  2553,  2913,  6936,\n",
            "         2265,  4022,  8192,  2015,  2061,  2527, 15058,  2094,  5903,  4432,\n",
            "         2628,  2925,  2470,  3257,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  7976,  4454,  2468,  3278,  6994,  2715,  2974, 12067,  2111,\n",
            "        11835,  6681,  2536,  4725,  3633,  5107, 25172,  2015,  4390,  8518,\n",
            "         2593,  6397,  3532,  4432,  1038,  5737,  4832,  6397, 17453, 18234,\n",
            "         7300,  2442,  2036,  5083,  2974,  5676,  3633,  6464, 22149, 11301,\n",
            "         6509,  2613,  7292,  9163,  2817, 17976, 12265, 17453,  8315,  3633,\n",
            "         2451,  8704,  6509,  4346,  6047, 11721, 28682,  6709,  5344,  8604,\n",
            "         5200,  9308,  2817, 20618,  2367,  6786,  4725,  2109,  3041,  2393,\n",
            "        17453, 18234,  2111,  2154,  3406, 10259,  2166,   102,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  2088,  2350,  4664, 22508,  9015,  3679,  7860, 26290, 13280,\n",
            "         2622, 13999,  7721,  6047,  2490,  2291,  2881,  4681,  3791,  2111,\n",
            "        17453, 18234,  3935,  2291, 13749, 18595, 13453,  6377,  3940,  2132,\n",
            "        19093, 11566,  2536,  2110, 15794, 22375,  6786,  8629, 11087, 18585,\n",
            "        13907,  6276, 24225,  3698,  4083, 13792,  3078,  3289, 25281, 14622,\n",
            "         5200, 14125,  9765, 22835, 12103,  5200,  5198, 11703, 11514, 22658,\n",
            "         4110,  5751, 24936,  5378,  2613,  7292,  3295, 15058,  2094,  9163,\n",
            "         7826,  4800, 11263, 27989,  2389,  6397,  5375,  5080,  2881,  7861,\n",
            "        11452,  5198, 20226, 13589,  7073,  4346,  5906,  2342, 22149,  3604,\n",
            "        28999,  5836,  9487, 11679,  2830, 28596,  3452,  3737,  2166, 12969,\n",
            "         6397,  2111,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101, 24075,  9682,  4683, 25423, 15088,  6296,  5294,  3086,  2116,\n",
            "         3330,  6742,  5097,  2197,  2086,  6459,  3169, 16991, 25423,  2615,\n",
            "         2291,  7218,  2491,  3001,  3223,  5452, 23263, 18228,  8361,  2491,\n",
            "         6028,  5107, 14262,  6767,  2075, 16911, 27120,  4950,  3001, 29508,\n",
            "        25423, 15088,  4044,  8392,  2135,  9756, 25423, 15088,  3169,  7976,\n",
            "         4454,  9932,  5461,  4235,  7333,  5107, 14262,  6767,  2075,  8392,\n",
            "        25423,  2615,  5097,  2750,  4852,  2470,  2492,  9932, 15058,  2094,\n",
            "         5107,  2491, 25423,  2615,  3001,  7721,  3319,  4790, 13398,  2236,\n",
            "        12878,  2925,  7826,  2492,  2470,  3132,  2147,  7721,  2135, 20798,\n",
            "         4646, 12607,  2015,  9932,  2368,  4819, 11788,  5107, 14262,  6767,\n",
            "         2075,  8392, 25423,  2615,  3001,  5266,  4187,  2491,  8518,  5378,\n",
            "        20062,  2925,  2470,  7826, 20226,  2836, 10439, 19341,  8553,  3132,\n",
            "         2783,  3906,  3259,  2034,  4391,  4646,  9414,   102]), tensor([  101,  4329,  3617,  3274,  2974,  2081,  2825,  2047, 12138, 12126,\n",
            "         5461,  2089,  2279,  3747,  7613,  2557, 27179,  4871,  5003,  7382,\n",
            "         9888,  3274,  4432,  7976,  4454,  5461,  2109,  5147, 11487,  2839,\n",
            "         4697, 28828,  3617,  4871,  2557, 18738,  8127,  2592,  2411,  4685,\n",
            "         2488,  5003,  7382, 13705, 10788, 23191,  8518,  9718,  2913, 14477,\n",
            "        14097,  2557, 18738,  2974,  3568,  2071,  9885, 10697,  5003,  7382,\n",
            "        13705,  7613,  3613, 11629,  2529, 14009,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  8982,  2537,  3248,  2590,  2535,  3795,  4610,  3168,  5157,\n",
            "         8114,  3647,  4725,  2833,  2537,  4852,  2592,  2974,  2028,  5906,\n",
            "         2203,  2426,  2800,  5906, 12944,  3274,  4432,  7300,  4117,  7976,\n",
            "         4454, 13792,  4719,  2590,  3463, 10788,  7060,  4871,  6123,  2147,\n",
            "         7534, 11778,  3319,  8704,  6709, 10439, 19341,  8553,  3274,  4432,\n",
            "        11718,  5237,  2537,  2274,  2550, 17588,  2088, 21154,  5785, 10500,\n",
            "        25176,  4783,  2319, 21569,  3168,  2556,  2423,  4981,  3479,  2197,\n",
            "         2274,  2086,  2367,  8107,  7438,  5919,  3141,  4295, 10788,  8982,\n",
            "         3737,  6887, 16515,  3723,  4691,  3463, 11778,  3319,  2825,  6709,\n",
            "         2307,  6695, 14427, 14246,  2226,  8389,  6364,  3131,  3935,  7976,\n",
            "         4454,  5461, 16962,  2078,  2784,  6772,  6125,  2810, 15873,  4725,\n",
            "         3274,  4432,  4162, 11718,  5237,   102,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  2974,  3935,  5970,  2926, 10124,  2135, 17503,  5970, 28616,\n",
            "         2164,  5001, 10464, 24895,  5970, 20478,  5970,  2419,  3623,  2193,\n",
            "         6786,  4082,  2282,  3073,  2592, 11707,  7709,  1041,  2290,  6602,\n",
            "         8192, 19817, 13006, 22471, 18909,  2426,  5970, 16570,  4383,  6786,\n",
            "         3815,  2592, 15901, 11707,  2678,  4110,  2203,  2891, 16186,  2926,\n",
            "         2307,  3568, 19309,  2951,  4106,  6827,  5970,  5547, 11619,  2951,\n",
            "        20446,  6026,  9710,  9585,  2047,  6695,  2470,  2458,  3274,  4432,\n",
            "        26226,  2492,  2817,  9144,  7588,  3305,  3617,  4871,  6876, 11014,\n",
            "         8285,  8585,  8518,  2864,  2529,  5107,  2291,  2492,  9144,  6194,\n",
            "         2613, 11108,  2592,  7654,  7588, 18444, 26226,  4866,  8483,  8051,\n",
            "         3746, 13851,  9932, 15058,  2094,  3746,  5038,  9932, 15058,  2094,\n",
            "         3746,  5038,  3722,  8518, 14622, 20057, 12326,  2015,  3935, 12435,\n",
            "         4286,  3522,  2086,  2348, 11707,  2678,  5038,   102]), tensor([  101,  4955,  4102,  6140, 13122, 28084,  2818,  5144,  2529,  2836,\n",
            "         6459,  2048,  7976,  4454,  4432,  8387,  2030, 28727,  2026, 17683,\n",
            "         1015, 12109,  5080,  3773,  9932, 18059, 25249,  4646,  4725,  2698,\n",
            "         6818,  5107, 25172,  2015,  3325,  2048,  3752,  8387,  2176,  6818,\n",
            "         2422, 10617,  2048,  3633,  2033, 28329,  9353, 18518,  2028,  2422,\n",
            "        10617,  7718,  6397, 10371,  2098,  2036,  7718,  2836,  3793,  9671,\n",
            "         3311,  9671, 10523,  3785, 16157,  2529,  2836,  2356,  6818,  2224,\n",
            "         5733,  3535,  2260,  3752,  8518,  2714,  3450,  3679,  2542, 14155,\n",
            "         8483,  3793, 12332,  3752,  2825,  6140,  2946,  5688,  2422,  2504,\n",
            "         2036, 14155,  3633,  2071,  3143,  8518,  5733,  7594, 10640,  6503,\n",
            "         2051,  6818,  2036,  2949,  5002,  7175,  2048,  8387,  3463,  8387,\n",
            "         4719,  3618,  5345, 10640,  3793,  5038,  4257,  5810,  2773,  5491,\n",
            "        15844,  2410,  5401, 10640,  4289,  3064,  3793,   102]), tensor([  101,  2028,  5628,  3698,  4083,  2784,  4083,  2944,  4117,  7976,\n",
            "         4454,  4235,  2109,  2492,  3274,  4432,  2974,  3746,  5038,  2492,\n",
            "         3421,  2966,  3746,  4106,  2036,  4975,  5056, 11160,  2529,  5754,\n",
            "        17287,  3508,  3274,  6807,  2832,  3444,  2592, 16647,  2529,  9552,\n",
            "         2944,  2731,  2832,  6162,  2130, 13467, 10640,  2529,  6364,  2241,\n",
            "         2236,  3768,  4863,  3754,  3303,  4242,  2951,  6364,  2832,  2784,\n",
            "         2944,  4493,  7300,  3701,  2421,  5069,  4722,  4863,  3754,  3086,\n",
            "         7337,  7613,  3563,  4275,  7613,  4895,  2243, 19779,  3085,  4275,\n",
            "         3421, 14123,  2126, 20155,  2135, 14358, 17841,  8010,  2145, 10641,\n",
            "         2926, 17841,  8082,  7667,  7435,  5022,  2966,  3247, 16570,  4383,\n",
            "         4275,  2195,  9539,  3818,  4431,  2783,  2470,  4646,  7976,  4454,\n",
            "         2784,  4083,  4275,  2966, 12126,  3227, 12778,  3086, 10640,  2738,\n",
            "         4863,  3754,  4525,  3768,  4863,  3754,  2947,   102]), tensor([  101,  3259,  3701, 15841,  2004, 24335, 12589,  2227,  5038,  3291,\n",
            "         2193,  3415,  2171,  2862,  2193,  5344,  6302,  2453,  5020,  2227,\n",
            "         8073, 12599,  2171, 14354,  3277,  2116,  6295,  2627,  3116, 13180,\n",
            "         2165,  2177,  7760,  3116,  3024,  7978,  2171,  2862,  6818,  2302,\n",
            "         2028,  3406,  5643, 10873,  5409,  2553,  2177,  6302,  2453,  4666,\n",
            "         5344,  8019,  3116,  2178,  3114,  2004, 24335, 12589,  2227,  5038,\n",
            "         3116,  5073,  3711,  7760,  7197,  2635,  4620,  3259, 17146,  2004,\n",
            "        24335, 12589,  2227,  5038,  7337,  2170, 21358, 10867,  2460,  3322,\n",
            "         3818, 21358, 10867, 11092,  2015,  2010,  3406, 13113,  8048, 17978,\n",
            "         2015, 27589,  2490,  9207,  3698, 17917,  2213, 11487, 14817,  5344,\n",
            "         7760,  2279, 21358, 10867, 27059,  2838,  2227,  2478,  9530,  6767,\n",
            "         7630,  3508,  3444,  4949,  9530,  2615,  1035, 21461, 11092,  2015,\n",
            "         2838, 13571,  5344,  2367,  4280, 21358, 10867,   102]), tensor([  101,  2227,  6827,  2112,  2529,  2303,  8200, 12955, 10232, 14622,\n",
            "         2111, 13268,  5038,  2974, 10424,  2102,  2028,  3144, 17160,  6786,\n",
            "         2715,  2335,  2088,  3048,  2875,  3967,  3238, 10424,  2102,  2522,\n",
            "        17258, 16147,  6090,  3207,  7712,  2349,  3967,  3238, 16012, 12589,\n",
            "         6459, 10424,  2102,  3352,  3243,  2759,  4969,  5661,  6419,  7511,\n",
            "         4344, 16550, 26221,  2015,  7976,  4454, 15058,  2094, 10424,  2102,\n",
            "         3098,  8216,  3293, 16746,  3036,  9867, 27280,  6305,  9623,  2015,\n",
            "         2491,  3001,  3617,  9871,  6302, 26384,  4385, 11105,  2224,  2468,\n",
            "         6827,  2556,  4807,  3591,  3795,  9886, 10424,  2102,  4803,  9874,\n",
            "         3006, 27891,  2974,  2536, 11105,  7860,  4803,  5936,  2569,  4431,\n",
            "         2634,  4969,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  5761,  3112, 13268, 10768, 25300,  9276,  5970, 21461,  2015,\n",
            "         3130,  2443,  5301,  6165,  6327,  5907, 10617,  2931,  5776,  2890,\n",
            "         6442,  2098,  9560,  5761,  2817,  2109,  7976,  4454, 13268,  5038,\n",
            "         4007,  7863,  2135, 16157,  3896, 21461,  2015,  8690,  5907,  2287,\n",
            "         2426,  3287,  3406,  7959,  9067,  2063, 16824,  5022,  2092,  3276,\n",
            "         5776, 13268,  9967, 16367, 19124,  3653, 25918,  8082,  2695, 25918,\n",
            "         8082,  4871,  2676, 16824,  2308, 14996, 21461,  2015, 16578,  9733,\n",
            "         2015,  9932, 13268,  5038,  4007,  5646,  5907, 10768, 25300, 22758,\n",
            "         7023,  3556,  8690,  2287,  2931,  5907,  3723,  4691,  7620,  5907,\n",
            "         3723,  4691,  3653, 25918,  8082,  2135,  2695, 25918,  8082,  2135,\n",
            "        10768, 25300, 22758,  7023,  7644, 16578, 14358,  5776,  9967,  2227,\n",
            "         4160, 14184,  2949,  2695, 25918,  8082,  2135,  3653, 25918,  8082,\n",
            "         2135, 21461,  2015,  4871,  8690,  2931,  4466,   102]), tensor([  101, 10889,  2152, 16222,  4648,  9243,  3130,  2988, 17003,  5345,\n",
            "         3333,  6022,  4320,  9694,  3785, 15359, 11967, 22088, 11368,  2075,\n",
            "         2659,  3515, 11305, 13268,  5038,  3001,  3491,  8052,  2836,  7812,\n",
            "         3785,  2817,  7127,  6937,  9885, 10640,  4320,  3375,  6447,  7860,\n",
            "         5171,  2613, 11108, 15359, 16820, 20655,  2342, 12607,  2015,  2958,\n",
            "         6578,  3522, 12607,  2015,  3698,  4083,  3274,  4432,  3491, 13268,\n",
            "         5038,  3001, 10910, 16222,  4648,  9243,  7505, 15194,  2529,  2836,\n",
            "         4758, 10906,  4344, 16550,  4106,  4928,  8321,  5919,  8556,  2580,\n",
            "         2312, 15782,  2571, 12553, 13268,  2951, 13462,  2881,  4758, 13268,\n",
            "        10515, 23150,  2015,  3785,  8567,  2613, 15359,  8146,  3921,  3039,\n",
            "         2149, 23087, 14358, 13268,  5038,  2536, 10368,  2613, 11108,  3785,\n",
            "         2478, 12553,  2951, 13462,  2092,  2243, 19779,  2078,  2951, 13462,\n",
            "         5025,  5344,  7718, 10640,  2048,  4235,  2109,   102]), tensor([  101, 13268,  5038, 23447, 28146,  2759,  2492,  3274,  4432,  2926,\n",
            "        12607,  2015,  2784,  4083,  2951,  4520,  2784, 13268,  5038,  2081,\n",
            "         3278,  5082,  4235,  4162,  2613, 11108, 16820,  3143, 13268,  5038,\n",
            "         2291,  7336,  2093,  2364,  6177, 13268,  5038, 10296,  6630,  2291,\n",
            "        11487,  2015,  5344, 25705,  2015,  3115,  3193, 27059,  2838,  5038,\n",
            "         2478,  2784,  9530,  6767,  7630,  3508,  2389, 15756,  6125,  3720,\n",
            "         3640,  6851, 19184,  6745, 12607,  2015,  2752,  4760,  2784,  4083,\n",
            "         6551,  9412,  7590,  4874, 10788,  3698,  4432, 10368,  2181,  5942,\n",
            "         3278,  8377,  3746,  5579, 10640, 23454, 14993, 27097,  2529,  2836,\n",
            "         4874, 10788, 13792,  2145,  2220,  5711,  2783, 13792,  6162,  2871,\n",
            "         2620,  7341,  2715,  5200,  6176,  2951, 13462,  4989, 10232, 15502,\n",
            "         3463,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  2227,  5038,  3728,  4227,  3278,  3086,  2028,  6179,  3746,\n",
            "         4106,  5097, 15929, 16594,  4310,  9788,  8720,  4813,  3001,  5214,\n",
            "        14622,  5198,  2227,  5038,  3001,  8077,  3273,  2291,  2174,  2193,\n",
            "         4009, 12221,  4493,  2227,  5038,  4725,  2089,  2765,  2936,  2010,\n",
            "         3406, 13113,  4030,  2015,  2312, 15782,  2571,  7809,  4769,  7860,\n",
            "         2227,  5038,  3818,  8893,  4078, 23235,  2953,  2478,  4800, 23467,\n",
            "         2334, 28774, 24041,  5418,  8318, 26952,  9447,  2504,  2522, 14404,\n",
            "         8185,  1043, 15472,  2213,  2817,  4846,  8318,  2361,  1043, 15472,\n",
            "         2213,  3177,  2098, 15873,  2838, 14175,  4725, 14817, 21203,  9963,\n",
            "         4094,  2378, 10755,  2937,  2102,  2838,  2227,  7809,  4871,  2838,\n",
            "         4738,  2478,  7976, 15756,  2897,  6741, 15698, 15502,  2135,  3479,\n",
            "        11465,  3945, 20600, 20116,  2080,  4118, 17544, 10640,  5345,  3818,\n",
            "         3921,  7528, 13523, 20470,  4007,  6388,  2951,   102]), tensor([  101,  4125,  2784, 15756,  6125,  2836, 16012, 12589,  3001,  3445,\n",
            "        14388,  2135, 16012, 12589,  3001,  2227,  5038,  2109, 10126,  2166,\n",
            "         1041,  2290,  3675,  2491,  4126,  9740,  3167,  5080,  3229,  2491,\n",
            "         2348, 10640,  2227,  5038,  3001,  3227,  2152,  2302, 21407,  2116,\n",
            "        16012, 12589,  3001,  2179,  8327, 15982, 13827,  4525,  2367, 15982,\n",
            "         2967,  3858, 10640,  2926,  2995, 13268,  5038,  2349, 15982,  5876,\n",
            "         1041,  2290,  5907,  3096,  3609,  2116,  3025,  2573,  2525,  2988,\n",
            "        15982, 13827,  2147,  8704,  5547, 15982, 13827, 16012, 12589,  2227,\n",
            "         5038,  5097,  7634,  2260,  2227,  5038,  3001,  6847, 10665,  2098,\n",
            "         4953, 16012, 12589,  5038,  2836,  2092, 15982, 11658,  2015, 29464,\n",
            "        26935,  3525,  3674, 10077,  5461,  4162,  3125,  5335, 26935,  5688,\n",
            "         2309,  3001,  6388,  3463,  2265,  2825,  5335, 26935,  4953,  2309,\n",
            "        28321,  1041,  2290,  3096,  3609,  5907,  9229,   102]), tensor([  101,  7387,  2116,  2367,  3036,  5936,  2947,  6997,  3445,  2750,\n",
            "         2755,  5164,  4765,  4277, 29115,  2173, 28283,  2437,  3711,  2295,\n",
            "         4614,  4039,  2644,  2344,  6709, 12290,  6204,  9751, 23934, 13268,\n",
            "         5038,  2291,  4198,  7887,  7172,  3617,  3075,  3579,  3259,  4503,\n",
            "         6882,  4735,  4812,  2291,  6709, 12290,  2241,  5344,  3965,  2613,\n",
            "         7292,  3617,  8264,  2174,  4874, 10788,  4118, 13268,  5038,  2944,\n",
            "         2047,  2291,  2328,  5292,  2906, 16690,  2015,  2465, 18095,  6028,\n",
            "         2330,  2278,  2615,  7427,  5678,  6413,  4730,  4155,  2089,  3073,\n",
            "         2734,  3463, 10847, 18750,  4029,  2109,  6520, 23422,  4413,  7705,\n",
            "         2330,  2278,  2615,  7685,  2705,  2239, 21469, 12322,  2653,  7781,\n",
            "         2349,  6520, 23422,  2015,  2030,  2213,  2490,  3365, 17881,  8192,\n",
            "        29296,  4221,  2509,  7809, 19647,  7809,  4846, 12038,  5097,  2260,\n",
            "         5387, 10439,  2801,  2109,  9570,  4487,  3540,   102]), tensor([  101, 13268,  3670,  5038, 10768,  2099, 12550,  2536,  4249,  2495,\n",
            "        10355, 21331,  9871,  2500, 13268,  3670,  5461,  6013,  9123,  8957,\n",
            "         7976,  4454,  6807,  2529,  5344, 11487,  6699,  2711,  9530, 14028,\n",
            "         2075,  2224,  6699,  5454,  6413,  6998,  2028,  2224,  2553,  2227,\n",
            "         7603, 10788,  2652,  2189,  2241,  5198,  6888, 17908,  5198, 13268,\n",
            "         3670,  2139,  8566,  3401,  5346,  2765,  2047,  7603,  4275,  5478,\n",
            "         4812,  4493,  3924,  5998, 11178,  5468,  2189,  2015,  4434, 13268,\n",
            "         7603,  3259, 10408,  2785,  3105,  2478,  9530,  6767,  7630,  3508,\n",
            "        15756,  2897, 13229,  2241,  2784,  4083,  3921,  2784,  4083,  6464,\n",
            "        17908,  4895,  3367, 26134,  2951,  5691,  3596,  2865,  3698,  4083,\n",
            "         2470,  2580,  2613,  7292,  2291,  6807,  2529,  5344, 14358,  2529,\n",
            "         6699,  2130, 16755,  2189,  5198,  1051,  4430, 29107, 10768,  2099,\n",
            "        11387, 17134,  2951, 13462,  2015, 12550,  6388,   102]), tensor([  101, 13268,  3670,  5038, 10768,  2099, 12550,  2536,  4249,  2495,\n",
            "        10355, 21331,  9871,  2500, 13268,  3670,  5461,  6013,  9123,  8957,\n",
            "         7976,  4454,  6807,  2529,  5344, 11487,  6699,  2711,  9530, 14028,\n",
            "         2075,  2224,  6699,  5454,  6413,  6998,  2028,  2224,  2553,  2227,\n",
            "         7603, 10788,  2652,  2189,  2241,  5198,  6888, 17908,  5198, 13268,\n",
            "         3670,  2139,  8566,  3401,  5346,  2765,  2047,  7603,  4275,  5478,\n",
            "         4812,  4493,  3924,  5998, 11178,  5468,  2189,  2015,  4434, 13268,\n",
            "         7603,  3259, 10408,  2785,  3105,  2478,  9530,  6767,  7630,  3508,\n",
            "        15756,  2897, 13229,  2241,  2784,  4083,  3921,  2784,  4083,  6464,\n",
            "        17908,  4895,  3367, 26134,  2951,  5691,  3596,  2865,  3698,  4083,\n",
            "         2470,  2580,  2613,  7292,  2291,  6807,  2529,  5344, 14358,  2529,\n",
            "         6699,  2130, 16755,  2189,  5198,  1051,  4430, 29107, 10768,  2099,\n",
            "        11387, 17134,  2951, 13462,  2015, 12550,  6388,   102]), tensor([  101,  8392,  4683, 20704,  2015,  3517, 24501,  3270,  5051,  2925,\n",
            "         5193,  3001,  3247,  2437,  2028,  4187, 14184,  2646,  2152, 20414,\n",
            "         2884, 12978,  4439,  9462,  8552, 16820,  3627, 15058,  2094,  4725,\n",
            "         2071, 11997,  2092,  2951, 23663,  2078,  3247, 12614,  8107, 18391,\n",
            "         3579,  2951, 13462,  2015,  2109,  4975,  2951, 23663,  2078,  4725,\n",
            "        12099,  3747,  2836,  3247,  2437,  6516,  4072,  7721, 12369,  4493,\n",
            "         2951, 13462,  2015,  5919,  3074,  4216,  4439,  2951,  4055,  4316,\n",
            "         4044,  4062, 16570,  4383,  2951,  2817, 22963,  2110, 15794, 22375,\n",
            "         2951, 13462,  2015,  2093,  7236,  7680,  7849, 10057,  2838,  2164,\n",
            "        13907,  2109,  5754, 17287,  3508,  4439, 16820,  2241,  6459,  2951,\n",
            "        13462,  2015,  5002,  2036, 15841,  4022,  5097,  2951, 13462,  2015,\n",
            "         2536,  5919, 20704,  3247,  2437, 13951,  6950,  4531,  6413,  3924,\n",
            "         2490,  2470,  2925, 12878, 20704,  2951, 13462,   102]), tensor([  101,  8321, 22793,  9651,  4895, 22852,  6553,  2613, 11108, 16820,\n",
            "         2174,  4141,  5071, 10956,  4367,  4041,  9896,  2640,  3259,  3647,\n",
            "        10539,  4367,  4041,  2491,  7705,  3818,  5047,  9651, 10697,  3303,\n",
            "        24949,  9651, 19795,  4367,  4041,  6741, 11486,  4919,  4367,  2686,\n",
            "         4055,  3647,  4655, 19188,  4655, 12697,  2929, 19355,  2946,  7790,\n",
            "         9651,  7561,  9570, 16360, 23004,  4022,  2492, 12365, 23301,  2126,\n",
            "         8400,  2275,  4663, 11566,  3795,  3945,  3818,  2126,  8400,  2275,\n",
            "        22910,  4118,  3740, 22793,  7130, 20600, 15058,  2094,  3921, 18478,\n",
            "         2015, 16264,  4431, 22793,  3740, 22793,  7039,  6310,  2881,  3424,\n",
            "        26895, 19969, 14080,  5676,  3808,  2478,  1999, 16874,  7028,  8651,\n",
            "        19293,  9430,  4473, 25354, 22793,  9651, 10697,  3132,  2306,  2881,\n",
            "         2555,  2130,  2552,  6692,  4263, 19399,  9651,  7561,  2641,  7785,\n",
            "         2098,  4041,  2504,  3808, 15258, 12361, 12016,   102]), tensor([  101,  2052,  2111, 16062, 10831,  8392,  4683, 20704,  2015, 10126,\n",
            "         2346,  4026,  4138,  3906,  9615,  8392,  4683, 20704,  2015, 19223,\n",
            "         2105,  7191, 26186, 14477,  6767,  8524,  3468, 12365, 16820,  7475,\n",
            "         8402,  5981,  4439, 15592, 10126,  2346,  4026, 28498, 12962,  3980,\n",
            "        13368,  2349,  4568, 25707,  3891,  2426,  2346,  5198,  4353, 10831,\n",
            "        13275, 12962,  2135,  7882,  3980,  3685, 26399,  2094,  3722,  2002,\n",
            "         9496, 10074,  2015,  7294, 13627,  2478,  9123, 20477,  6630,  2367,\n",
            "         4026,  8146,  7594,  6818, 18394,  4439, 23802, 20704,  2015,  4387,\n",
            "         5002,  2762,  6818, 18394, 14386,  4383,  6022,  8210, 12365, 24685,\n",
            "         5875,  2135,  6818,  5627,  2202, 10831,  5770,  2346,  5198,  9104,\n",
            "         2591, 21883, 20704,  2015,  2089, 10210, 28731,  2094, 19188, 10058,\n",
            "         2470,  2453,  3857,  2958,  6145, 17586,  6848,  9615, 20704,  2015,\n",
            "        26157,  2135,   102,     0,     0,     0,     0,     0]), tensor([  101,  7976,  4454,  2028,  8361,  6786, 26633,  2529,  4454,  6681,\n",
            "         4730,  2228,  2066,  2529,  9552, 23150,  4506,  8392,  4316,  3853,\n",
            "         4287,  4072,  4972,  2302,  2529,  6624,  9525,  2974,  2089,  3073,\n",
            "         3445,  4628,  3808,  2625, 26478, 17944,  4925, 20176,  7312, 23569,\n",
            "        28591,  4026,  2896,  4762,  8381,  2625, 10796,  2488,  3604,  6322,\n",
            "         8392,  4683,  2377,  8995,  2535,  3068,  5237,  5193,  2510,  5097,\n",
            "         8392,  4683,  3450,  3569, 13617,  2951,  7976,  4454,  3001,  7976,\n",
            "         4454,  3074,  2951,  4130,  4041,  7781,  8392,  4683,  5478,  3698,\n",
            "         4083,  5461,  2112,  7976,  4454,  3310,  9394,  3314,  3036,  5936,\n",
            "         3036,  2590,  5142,  8392,  4683,  3314, 16941,  3366, 10841, 15780,\n",
            "        13543,  7976,  4454,  8392,  4683,  3139,  3720,  2247,  3652,  2974,\n",
            "         2969, 13626, 14966, 19207,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  2802,  2197,  5109,  2193,  4683,  2346, 11328,  3445,  2349,\n",
            "         4803,  5157,  3923, 12969,  3824, 12708,  2048,  2116, 29172,  3896,\n",
            "         4683,  2346,  2036, 17727, 14728,  3171,  2458,  3445,  4026, 20176,\n",
            "         4026, 13436,  3314,  3855,  6022, 10395,  2437,  4683, 25670,  8161,\n",
            "        17975,  4286,  2627,  2301,  2536,  3741,  4146,  4866,  2470, 17999,\n",
            "        19309,  2346,  4683,  2458,  8392,  4316, 20704,  6786,  2747,  9505,\n",
            "         3278,  5013,  8712,  4969, 17319,  6923,  2224,  8392,  3765, 17566,\n",
            "         5382,  2445,  2458,  7976,  4454,  9932,  2344, 20704,  2015, 23084,\n",
            "        11301,  2191,  2157,  6567,  2613,  2051,  9932,  6003, 10232,  6922,\n",
            "         2458,  9932,  5533,  3930,  2502,  2951,  3365, 13851,  5733,  6276,\n",
            "        24225,  9798,  4219,  2442,  2034, 11628,  9932,  2015,  2458,  2381,\n",
            "         2344, 22346,  4972, 20704,  3001,   102,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  2925, 15169,  3795, 12945,  3068,  6551,  5360,  2959,  3919,\n",
            "         4329,  6622,  7976,  4454,  9932,  2047,  3671, 11310,  5533,  2047,\n",
            "         3068,  4781,  2164,  6233,  8392,  2969, 13626, 14966,  2974, 13266,\n",
            "         3808,  4781,  3375,  5427,  7040, 19293,  2591,  5012, 10660,  2689,\n",
            "         2103,  6502,  5918,  3617, 11443, 23217,  3512,  2449,  8144,  2241,\n",
            "         6143,  7953,  4425, 13797,  7480,  8162,  3401,  9932,  3127,  3145,\n",
            "         5876,  8392,  4683, 20704,  2015, 16578,  2478,  9932,  8973,  7217,\n",
            "         9138,  2974,  3293,  3891,  5876,  2969, 13626, 14966,  7325,  5248,\n",
            "         2103,  6502, 14679,  2591, 17241,  2047,  2974,  2925, 22793, 20704,\n",
            "         3068,  3517,  6970, 13068,  3293,  2591,  3891,  6502, 10738, 10595,\n",
            "         2536, 14670,  3068,  2015, 22859,  2817, 16014,  2015,  3497,  9084,\n",
            "        11967, 20704,  3068,  5533,  1015,  9932,  2015, 24107,  9138, 11876,\n",
            "         2906,  2422, 10788,  7478,  7182,  7077,  6075,   102]), tensor([  101,  2925,  8392,  4683,  3658, 19143,  2529, 22461,  2640,  3935,\n",
            "         9932,  9859,  8392,  4683,  2925,  3665,  5467,  2036, 11835, 15581,\n",
            "        14714,  2437,  4990,  6625,  8114,  8242,  3259,  2556,  3117,  7705,\n",
            "        21155,  2015,  2312,  2653,  4275,  2222,  5244, 11598,  8392,  4683,\n",
            "         3247, 12614,  6194, 22380,  2222,  5244,  3019,  2653,  9859,  6123,\n",
            "         8787,  4824,  7772,  5906,  8192, 19962,  2121, 28660, 13384,  3772,\n",
            "         2536, 14184,  8392,  4683,  7705,  8704, 25180, 10895, 17409,  3935,\n",
            "         2653, 13384,  9859,  2222,  5244,  8392,  4683,  3818,  7705,  4324,\n",
            "         4022,  4329,  4697,  2126,  8392,  4683,  5452,  5378,  3167,  3550,\n",
            "         5375,  7142,  4083, 13338,  3247, 12614,  4821,  8020, 13726,  8114,\n",
            "         8392,  4439,  6786,   102,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  4022,  4198, 12978,  4683,  4800, 12172,  3064, 12978, 12607,\n",
            "         9144,  4274,  2477, 22834,  3215,  2458, 12067,  7976,  4454,  9932,\n",
            "         2220, 12607,  2015,  3330,  8139,  2116,  4249,  4427,  9932,  2195,\n",
            "        10340,  6786,  2109, 12978,  4683, 12978,  4683,  9002,  6551,  2646,\n",
            "         4026, 20600, 19844,  7312,  5702,  4316, 12645,  2048,  7236,  2458,\n",
            "         2800,  2152, 20414,  2884,  2291,  8346,  2015,  2066,  2047, 24454,\n",
            "         6292,  4683,  9414,  5193,  3001,  7336,  8848,  4942,  6508, 13473,\n",
            "         2213, 12607,  2066, 13617,  2592,  6364,  3001,  3935,  4062,  5375,\n",
            "         2291,  3065,  3463,  3113, 10908,  2613, 11108,  3471,  4316, 12645,\n",
            "         3663,  2389,  4454, 17427,  8216,  8310,  2951,  2641,  2152,  3207,\n",
            "        16294, 22753,  4325,  2103,  7341,  2455, 19654,  3737,  9361,  4925,\n",
            "         2092, 18558, 18249,  3672,  2291,  3665,  4472,  6853,  9218,  5038,\n",
            "         2653, 12598, 10617, 11301,  5375,  4950,  2422,   102]), tensor([  101,  7976,  4454,  4072,  6922,  2537,  2326,  3001,  3522,  2086,\n",
            "         2974,  2468,  8995,  7814,  3679,  2166, 12978,  4439,  4683,  5452,\n",
            "         8392,  2135,  2036,  2124,  4062,  3238,  3765,  5452,  2302,  2529,\n",
            "         4062,  2470,  8392,  4683, 12381,  3935,  3522,  2086,  7976,  2135,\n",
            "         9414,  8392,  4683,  2783,  2342,  2554,  2348,  2111,  2453, 10439,\n",
            "         2890, 10222, 12742,  2507,  3274,  2491,  4316, 12978,  4439,  6786,\n",
            "         4022,  2191,  4925, 13726,  2969, 13626, 14966, 19207,  4769,  4483,\n",
            "         3314,  2092,  3808, 16570,  4383,  3924,  4406,  4286,  7588,  2428,\n",
            "         7669,  4363,  3086,  4439,  5678, 14120, 23263, 12978,  2482,  4652,\n",
            "        13436,  9280,  4795,  2824,  2346,  2969, 13626, 14966,  2974,  2116,\n",
            "        12637,  2028,  2191,  4089,  7801,  2965,  3665,  2111,  4039,  3298,\n",
            "         3528,  4436,  1999, 10288,  4842, 13684, 27523, 19498,  3012,  2287,\n",
            "         2116,  2111,  4039,  5452,  4316,  3633,  3604,   102]), tensor([  101, 13896,  8392,  4683,  9536,  2098, 10938,  8082,  3690,  5193,\n",
            "        24501,  3270,  4691,  5957, 12969,  6276, 24225,  6786,  2430,  6622,\n",
            "         8346,  7976,  4454,  9932,  4083, 13792, 17678, 23918,  4683, 18814,\n",
            "        15741, 12645,  3259,  3640,  7721,  8993, 12761, 22793,  9932,  2306,\n",
            "         8392,  4683, 16907,  4990,  3192,  2389,  6481,  3522, 12607,  2015,\n",
            "        25819,  2783,  5957, 19184,  3259,  3972,  6961,  8050,  2535,  9932,\n",
            "        20300,  8392,  3247, 12614,  9859,  4683,  3449, 14194,  8524,  4570,\n",
            "         4084,  2920,  9932, 27267,  2458,  2166,  5402,  4683, 12786, 12962,\n",
            "        16852, 13827,  4681,  3089,  8159,  4007,  2458,  8392,  4683,  2817,\n",
            "         7534,  7778, 20062,  8192,  4127,  9932, 19738,  6826,  2075, 13792,\n",
            "         2086, 27696, 20607,  2470,  5957,  2306, 12945,  3068,  7297,  3259,\n",
            "        11637, 20369,  2535, 11709, 28596, 13792,  9322,  3765, 25505,  4683,\n",
            "        15581,  4553,  5335,  2836,  2051, 14730,  2041,   102]), tensor([  101,  7976,  4454,  9932,  2326, 15428, 13418, 15961,  3316,  2947,\n",
            "         9932,  2326,  7233, 14567,  6304,  3277,  3685,  6439,  3720,  7679,\n",
            "         9932,  2326,  7233, 19816,  3151,  4454, 22035,  9515,  3372,  3241,\n",
            "        11131,  7233,  3466, 26452,  3433,  7339,  6832,  4454,  2478,  2176,\n",
            "         6388, 16820,  3463,  5769,  2326,  7233,  2152,  6633, 20166,  9932,\n",
            "         3433,  3623,  6304,  7142,  8192,  6808,  8317,  3292,  3404, 25582,\n",
            "         2865,  6591,  2832,  4102, 18847,  5054, 21748,  2100, 19220, 10266,\n",
            "         3793,  2152,  6633, 20166,  3433, 11092,  2015,  4800,  5054, 21748,\n",
            "         2100, 19220, 10266,  3793,  2376,  2071, 12919,  7233,  3466, 26452,\n",
            "        10960,  3259,  8908,  2492,  9932,  2326,  2470,  3579,  2051,  4403,\n",
            "         5719,  2224,  9932,  2326,  4945,  2036,  5829,  3458,  3151,  4454,\n",
            "        22035,  9515,  3372,  7620,  3241,  7657,  5197,  2478,  9932,  6832,\n",
            "         4454, 20544,  8013,  6832,  3433,  9932,  2326,   102]), tensor([  101, 11128,  4411, 13417,  3795,  4450, 15843,  7976,  4454,  9932,\n",
            "        11834, 27014,  4846,  2393,  4337, 15843,  2174,  9531,  6537,  9932,\n",
            "        28536,  2015,  2145, 10599,  4214,  4812,  5335,  4824,  9932, 28536,\n",
            "         2015,  2817,  8733,  3515,  2549,  6001,  3784, 12783,  8162,  6129,\n",
            "         4132,  2764,  2416, 11834, 18384,  6074,  6832,  5443, 25854,  3746,\n",
            "         5443,  3698, 10359,  3746,  5443,  2529,  3746,  2034,  4846,  2981,\n",
            "         8168, 23746,  4355, 11628,  3466, 11834, 27014,  4512,  2389,  2806,\n",
            "        19732, 21357,  5924,  2162,  5694,  2817,  2036,  7718,  2865,  3436,\n",
            "         4395,  2981,  7642,  8690,  2529,  2791, 26452,  2646,  5694,  3276,\n",
            "        11834, 27014,  6832,  3670, 19732, 21357,  9283,  7642,  3674, 26435,\n",
            "         4106,  2633,  2817,  7718,  5549, 15172,  2535,  5107, 23391,  3746,\n",
            "         5443,  3698, 10359,  3746,  5443,  2529,  3746,  9283,  8777,  2094,\n",
            "         7642,  3674, 26435,  4106,  3463,  3936,  6832,   102]), tensor([  101, 14972, 26452,  9871, 11834, 27014,  2641, 10015,  3443,  3168,\n",
            "         2529,  8251,  2174,  4493,  2470,  4703, 27590,  2015,  4800, 22172,\n",
            "         6132, 19301,  3012, 26452,  2877, 13990,  4824,  7976, 26452,  8690,\n",
            "         6660,  6970, 28823, 26452,  3259,  9251, 14972,  4654,  4842, 11638,\n",
            "         4818, 11423, 26452,  2089,  4895, 18447, 21945,  4997,  8465,  2453,\n",
            "         2514, 27118, 14317,  4765,  2594,  2612,  4346,  6150,  2490,  2071,\n",
            "         7218, 11643,  7976, 26452, 25705,  2015,  2488,  3274, 10359,  8040,\n",
            "        28433,  2015,  2875, 11834, 27014,  2048,  6388,  2913,  2478,  9871,\n",
            "        11834, 27014, 11628,  3466,  7861, 15069, 16530,  3110, 13026,  3110,\n",
            "        14260,  6633, 15069, 16530,  7861, 15069, 16530,  5094,  5443,  3904,\n",
            "         8737,  8988, 16530, 10960,  8690,  8251,  8690, 21452,  8465,  3404,\n",
            "         2478, 11174,  3463,  7487,  2785, 26452,  5443, 26452, 11598,  2015,\n",
            "         8690,  8251,  4525,  3020,  3404,  2478, 11174,   102]), tensor([  101,  9123,  4007,  6074, 11834, 27014, 20519,  2109,  2181,  2740,\n",
            "         2092, 19205,  3070,  5097,  6074,  8526,  5198,  6970, 28823, 11450,\n",
            "         1041,  2290,  7748,  7216,  5248, 22305,  2063, 19388,  3445,  2342,\n",
            "         4824,  6074,  7861, 25940,  9859,  2783,  2110, 15794, 22375,  5906,\n",
            "         2344,  3305,  7861, 25940,  9859,  9123,  4007,  6074,  2342, 10480,\n",
            "         9366, 26452,  3906, 15841,  3528, 15182, 26452, 10465,  5337,  6210,\n",
            "         2241, 11778,  3906,  3319, 24209, 11475, 27453,  4106,  3522,  8107,\n",
            "        26452,  9123,  6074,  2740,  2092, 19205,  3070,  5337,  6210,  2319,\n",
            "         3031,  6483, 11253, 26452,  2764,  2556,  4022,  5337,  6210,  4758,\n",
            "         5198,  8525,  5149, 11243,  6994, 20077, 26452,  2048,  2110, 15794,\n",
            "        22375,  2740,  2092, 19205,  3070, 11834, 27014, 16360, 25421,  1059,\n",
            "         7274,  2050,  9556,  6592,  6210, 19566,  4072,  3785, 20077, 26452,\n",
            "         9123,  6074, 26944,  4863, 12878,  5278, 23271,   102]), tensor([  101, 20607,  5957,  2529,  9006, 18780,  2121,  8290,  3259, 13999,\n",
            "         9525,  7705, 22303,  4329,  4697, 11834, 18384,  3001,  7705,  2777,\n",
            "         2594, 21227,  2881, 14868,  5204,  4800,  5302,  9305, 11834, 27014,\n",
            "        25180, 10895, 17409,  2015,  2613,  7292,  2227,  7603,  5038,  3019,\n",
            "         2653,  6364,  2747, 13908,  4403,  7705, 10637,  8200, 26293, 23448,\n",
            "         7578,  9140,  2529,  8128,  8128,  8487,  8518, 11717,  6851, 14408,\n",
            "         8496,  4874, 10320, 14120,  2236, 10861,  5134, 15929, 16594, 16381,\n",
            "        12879,  8873, 23402,  3372,  2986,  8525,  5582,  2330, 10258, 10631,\n",
            "        16656, 19335, 10502,  2659, 26763, 15581,  2121,  8840,  2527,  7705,\n",
            "        23972,  3188, 25090, 11254, 18601, 18724,  6515,  8122,  4563,  3921,\n",
            "         3658,  5069,  7899, 23561,  2015, 17796,  2135, 13590,  4432,  2653,\n",
            "         2951,  6143,  8346,  3596, 21505,  4800,  5302,  9305,  3012,  7899,\n",
            "        17372, 16134, 20226, 15581,  8010, 11834, 18384,   102]), tensor([  101,  4281,  6203,  2705, 24010, 20794,  4953,  2478,  2312,  2653,\n",
            "         4275,  2222,  5244, 14120, 27050,  8740, 16774,  2594,  5022,  2306,\n",
            "         2822, 25023,  6692,  3351,  6123,  2750,  2822,  2028,  4235,  5287,\n",
            "         4155, 16452, 21047,  2470,  3579, 11243,  4275,  2966,  2492,  2394,\n",
            "        13102, 25508,  2075,  7080,  7863,  2817,  8704, 14358, 12353,  2222,\n",
            "         2213, 11834, 27014,  4919, 11834, 21600,  2102,  2549,  2330,  4886,\n",
            "        14637, 28516,  2544, 20802, 21790,  8566,  4297,  2028,  3935,  2222,\n",
            "         5244,  2859, 12786, 27050,  8740, 16774,  2594,  3633,  2822,  4292,\n",
            "         4725,  2817,  5935,  2951,  1040, 18037,  2050,  4235,  8969, 10923,\n",
            "        11022,  2094,  2966, 16053,  4132,  2859,  5310,  2918,  2531,  2454,\n",
            "         3633,  2561,  2531,  5776, 16053,  8168, 20001,  2135,  3479,  2254,\n",
            "         2760,  2257, 16798,  2509,  3815,  2075, 23688,  3980, 15901,  7271,\n",
            "         2800, 19465, 16570,  4383,  5491,  4132,  5441,   102]), tensor([  101,  2034,  2186,  7976,  4454,  4456,  6612,  2470,  2590,  3535,\n",
            "         9375,  4145,  4454,  2590,  2838,  5482,  2529,  4454,  4454,  9570,\n",
            "         5482,  5546,  2529,  9552,  4824,  2529,  4454,  2164, 10617, 26497,\n",
            "         2245, 17158,  3989,  5418,  5038, 12613,  6364, 14842,  3291, 13729,\n",
            "        13399,  6835,  3787,  4454,  2542,  2427,  4141,  2228,  4454, 24491,\n",
            "         9715,  7073,  3754,  2433,  8474,  2247,  3977, 12613,  6364,  2458,\n",
            "         2653,  4821,  3754,  3114,  2191,  6567,  2224, 16646, 22149,  2088,\n",
            "        11091, 16932,  2051,  8298,  2969, 10830,  7389,  7971,  4025,  8050,\n",
            "         4310,  2529,  3325,  8474,  3961, 13769, 26475, 15572,  3375,  9140,\n",
            "        13353, 10737,  4821, 16582,  3558,  4277,  4367,  2247, 17796,  2897,\n",
            "        15698,  2430,  6091,  2291,  2507,  4125,  4722,  9715,  3325,  3754,\n",
            "         2228,  3114,  2247,  6322,  6569, 12039,  2293,  5053, 17158,  6194,\n",
            "         2089,  2572,  8189,  3468,  3698,  4083, 19875,   102]), tensor([  101,  2529,  4886,  8290,  2468,  2590,  3579,  2458, 26651, 23369,\n",
            "         2974,  6123,  2224,  7976, 26452,  9942,  3327,  3037,  2349,  4022,\n",
            "         9229,  8013,  6322,  7461, 14547, 14286,  2470,  8704,  8849, 20600,\n",
            "         2529,  4886, 10266,  4646,  7976, 26452,  9942,  9229,  7461,  3512,\n",
            "         2591,  8013,  6322,  2470,  3921,  2109, 24209, 11475, 27453, 15252,\n",
            "         2536,  2913,  3141,  3906,  2951,  4216,  2109,  9263,  4790,  2808,\n",
            "         7882,  2470,  8476,  2470,  3463,  2179,  7375,  7976, 26452,  9942,\n",
            "         2529,  4886, 10266,  2307,  4022,  5335,  3737, 10266,  8013,  6322,\n",
            "         2224,  6786,  3019,  2653,  6364,  7603,  5038, 15792,  4106,  9585,\n",
            "         9932,  6869, 10785,  7591,  2135,  5310,  3791,  6699,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101, 13234, 24969,  4512,  2389,  6074, 25222,  9969,  2881, 12005,\n",
            "        26243,  2622, 26452,  2348, 26452,  2393,  2974,  2488,  3710,  2529,\n",
            "         3791,  2036, 11703, 22048,  9280, 18077,  8082,  2147,  2839,  4697,\n",
            "        26452, 10266, 25222, 20655,  5197, 20852, 23408, 23909,  2015, 26452,\n",
            "         2048,  4286,  3924,  2529,  6187,  2203, 23087, 25732, 25222,  6153,\n",
            "         2312,  2653,  4275,  2222,  5244,  4653, 26452,  9530, 14028,  2075,\n",
            "         3515,  5664,  2529, 15702,  2036, 12826,  2367,  2222,  5244,  4653,\n",
            "         2944, 26452,  2424, 25222,  2191,  3643, 26186,  3056, 15702, 11434,\n",
            "        15702,  3141, 17631,  8909,  8780, 21615,  1041,  2290, 13157,  2213,\n",
            "         1060, 16515, 24920,  9308, 15078,  3921,  4824, 26452,  7657,  2750,\n",
            "         3754,  4653, 26452, 25222,  9996, 25455, 11131,  5198,  3325, 22133,\n",
            "         2529, 14562,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101, 26452,  9798,  8361,  2470,  2492, 17409,  2015,  7976,  4454,\n",
            "         9932,  2502,  2951,  2974, 16014,  6709, 26633,  9699,  2529, 26452,\n",
            "         2492, 16473,  2588,  8317,  2913,  3408,  8474, 11702, 15756, 10100,\n",
            "         5097, 26452, 13495,  9525,  9798,  8107, 20253, 21934, 10924, 26452,\n",
            "         3720, 11321,  4391,  2783,  2470, 26452,  9798, 15841,  2925,  7826,\n",
            "         8317,  7339,  6614, 25505,  3192,  2389,  2470,  6742,  5097,  2492,\n",
            "         2783,  2470, 26452,  9798, 20427,  2176,  6991,  2241,  2367,  5682,\n",
            "         4725,  2028,  2192, 26452,  9798,  3952,  8704, 17908, 22346, 26452,\n",
            "         2478,  7588, 23855,  4055,  2048,  7236,  1015,  3265, 26452,  7667,\n",
            "         7679, 20253,  3265,  7861, 15069, 16530, 12955,  1016,  7861, 15069,\n",
            "        16530,  4180,  5579,  7679, 20253,  7861, 15069, 16530,  2838,  6981,\n",
            "         2738,  3633,  2192,  2470,  2036,  7679, 21934, 10924, 14026, 26452,\n",
            "         9798,  2950,  1017,  2640,  7861, 15069, 16530,   102]), tensor([  101,  7976,  4454,  9932,  5461,  1041,  2290,  6739,  2291,  9686,\n",
            "        18001,  7961, 13109,  7976, 15756,  2897,  5754,  7403,  9896, 11721,\n",
            "        10811, 21708, 20600,  8827,  2080,  6897,  2135,  4427, 12170,  3728,\n",
            "         4162,  4235,  2373,  8139,  5013,  9297,  5243,  2818,  9932,  4118,\n",
            "         4310,  2791,  6459,  3728,  6950,  2764, 15078,  2944,  6832,  4083,\n",
            "        26524,  4167,  8419,  4167,  6832,  4083,  2241,  9414, 11486, 19337,\n",
            "        13592,  3463,  5769,  3754, 19337, 13592,  2491,  4242, 27400,  8790,\n",
            "         3001,  3568, 19337, 13592,  4089,  4233, 18111,  2033,  7507, 15312,\n",
            "         6558,  3919,  5097,   102,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  3800,  3319,  7603,  7976,  4454,  9932,  2974,  7603, 10788,\n",
            "         5038,  7603,  9932,  9186,  5901,  3293,  2231, 10906,  2648,  4200,\n",
            "         6233,  2468,  9410,  2112,  3679,  2166,  3125,  7984,  3319,  3623,\n",
            "         7073,  6923,  2224,  7603,  9932,  5936,  3293,  2224,  7603,  9932,\n",
            "         7189,  2111,  5177,  7355,  3522,  9556,  3259, 15841,  7603,  9932,\n",
            "         8050,  2015,  2236, 19184,  3293,  7603,  9932,  2648,  4200,  4973,\n",
            "         2224,  7603,  9932,  7904, 14763, 16165,  8822, 12654,  3144, 27788,\n",
            "         2618, 29397,  5022,  5177,  7355,  2554,  2442,  6807,  4852,  3293,\n",
            "         2224,  7603,  9932,  5936,  3293,  2224,  7603,  9932,  3623, 26453,\n",
            "         9147,  4997,  8465,  3679,  2166,  2111,  5177,  7355,  3293,  7603,\n",
            "         9932,  9896, 20932,  5177,  7355,  5845,  2966,  2755,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  4167,  9006, 18780,  2121,  8290,  4647,  2072,  2291,  4454,\n",
            "         2468,  7790, 16175, 10127, 21890, 24915, 25212, 18259, 11022,  2094,\n",
            "         7603,  5038,  3365,  5097,  7603,  5579, 16755,  2121,  3001, 10699,\n",
            "         7170, 10788,  4385,  7603,  5579,  4567,  3522, 12610,  7976,  4454,\n",
            "         9932, 27267,  2470,  3720,  3591, 11778,  3319, 12978,  7603,  5038,\n",
            "        25212,  2290,  7755,  2478,  9932,  3319,  2832,  3344,  2241,  6871,\n",
            "         7316,  5167, 11778,  4391, 18804, 27953, 23274, 13102,  6935,  2863,\n",
            "        25212,  2290, 17881, 25212,  2290, 17463,  3217,  9623,  7741,  4725,\n",
            "         2443,  2817,  2036,  2443,  3444, 14676,  3444,  4989,  4725,  2804,\n",
            "         2443,  2913,  4055,  2048,  4127,  8909,  4402,  2361,  4083, 19422,\n",
            "        15058,  2094,  7603,  8720,  3001,  2462,  3698,  4083, 19968, 15058,\n",
            "         2094,  7603,  5579,  4275,  8920,  3001, 16578,  2241,  2838,  5579,\n",
            "         4118, 20792,  2465, 28295,  4127,  6219,  6699,   102]), tensor([  101,  4286,  3056,  2591,  6832,  9859,  2393, 11835,  2529,  9552,\n",
            "         2028, 10673,  6807,  4286,  6699, 10673, 11598,  2015,  2529, 10266,\n",
            "         2307,  6698,  2693,  2875,  2287,  4852,  2529, 22911, 14014,  8290,\n",
            "         3001,  2442, 29453,  2565,  6681,  6162, 27084, 24164,  2094,  2591,\n",
            "         6832,  9859,  9896, 15004,  3078,  2470,  8880,  7603, 10788, 14622,\n",
            "         2478, 13268,  4871,  2583,  6807,  6699,  2529,  7126,  3698, 14171,\n",
            "         8694,  4286,  3791,  7216,  7603, 10788,  2864,  2478,  2536, 16913,\n",
            "        11475,  7368,  2678,  5746,  4871,  3793, 16012, 12589,  2592,  4385,\n",
            "         2817, 15102,  8361, 12878,  7603,  5038, 13268,  4871, 12978,  5038,\n",
            "         6699,  2111,  4022, 16014, 13691,  7355,  2397,  3372,  5177,  2740,\n",
            "         3314,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  7976,  4454, 11834, 27014, 10836,  6813,  3068, 11427,  2659,\n",
            "         3465,  2152,  8122,  2174,  3747,  6832, 11423, 11834, 27014,  2326,\n",
            "        13105,  2363,  2172,  3086,  6950,  5059,  2588,  5987, 11656, 13302,\n",
            "         3399, 10641,  6832, 11423, 11834, 27014,  7461,  8013,  9967,  2478,\n",
            "         2093,  7885,  6123,  7538,  8432, 11433, 11834, 27014, 11423,  5142,\n",
            "         6304,  5335,  8013,  9967,  8161,  5987, 11656, 13302,  3327,  6304,\n",
            "         3125, 10296,  2529, 10359,  2791, 11834, 27014, 22128,  2015,  3276,\n",
            "         2828,  6304, 11834, 27014,  8777,  4997,  3276,  6832,  3670,  5987,\n",
            "        11656, 11371,  9556,  5083,  2470,  6832, 11423, 11834, 27014,  3073,\n",
            "         4187, 20062, 21296,  2075, 11834, 27014,  8013,  2326,  6813,  3068,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  3259, 15847, 27338,  2394,  3793,  7603,  3670,  2592,  4807,\n",
            "         2465, 14144,  2394,  3793,  7603,  3670,  2592,  4807,  2429,  2529,\n",
            "         7603, 10175,  5657,  3276,  7680,  7849, 10057,  6459,  2394,  7603,\n",
            "         3670,  2592,  4807, 16378,  2478,  7976,  4454,  2974,  3818,  9570,\n",
            "         4106,  2944,  2394,  3793,  7603,  2592,  4807,  2478, 12170,  4877,\n",
            "        21246, 15756,  2897,  3066,  6459,  2394,  3793,  2855, 18228,  4072,\n",
            "         4372, 16044,  6832,  2592,  2394,  3793,  2241, 17181, 12170,  4877,\n",
            "        21246, 15756,  2897,  4162, 14817,  6832,  2838,  2394,  3793,  9611,\n",
            "         3291,  3279,  6832,  2838,  3279,  3853, 13529,  2121,  6994,  2109,\n",
            "         6855,  2951, 13462,  2822,  2394, 11336,  9587, 10085,  2822,  5534,\n",
            "         9312,  5950,  2229,  2275,  2429,  4275,  2836,  2628,  6388,  4106,\n",
            "         2394,  3793,  7603,  3670,  2592, 16636,  6651,  3463,  2265,  4102,\n",
            "         2434, 13229,  1048,  3367,  2213,  1056,  4877,   102]), tensor([  101, 12978,  7982,  3001,  2590,  5097,  7976,  4454,  3151,  3001,\n",
            "         5998,  3305,  5310,  6699,  3073,  7861, 15069, 16530, 12247,  2817,\n",
            "        17409,  2015,  6832,  4454,  2974, 12978,  7982,  3001,  9005,  7982,\n",
            "         4245,  2944,  6832,  4454,  2784,  4083,  3019,  2653,  6364,  5461,\n",
            "         2944, 11487,  3305,  2898,  2846,  6699,  3563,  3255,  7755,  2613,\n",
            "         2051, 12067,  2291,  3073,  7861, 15069, 16530,  8290, 22380,  3463,\n",
            "         2817,  7976,  4454, 11487,  3255,  4671,  3255, 26452,  4275,  3754,\n",
            "         3305, 11259,  3787,  3255, 26452,  9412,  4292,  3020,  4781,  6832,\n",
            "         4454,  7982,  3001,  2622,  8704,  3073,  9373,  4824,  6742, 15690,\n",
            "        17409,  3935,  6832,  4454,  9859,  7982,  3001,  8558,  9229,  5310,\n",
            "         3325,  8290,  3737,   102,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  2470,  6083, 14868, 26651,  6681, 26633, 26452,  3623,  2139,\n",
            "         9920,  5198,  2875,  3110, 16730,  2875,  3698, 13416,  4997,  2566,\n",
            "         3401, 13876,  8787, 12247,  2344,  2203,  5004,  8957,  6832,  4454,\n",
            "         2442,  6055, 13907,  5214, 11847,  5198,  6699,  3168, 10439, 14995,\n",
            "        12002,  4110,  6699, 15176,  4722,  2110, 24134,  2633,  4685,  8518,\n",
            "         4506, 12222, 24806,  6832,  2110,  2552,  2174,  2750,  8052,  5082,\n",
            "         2081,  3522,  2086,  3408,  7976,  4454,  4613,  5038, 10752,  3274,\n",
            "         4432,  2116, 12736,  3495, 17351,  3141,  7976,  6832,  5038,  5248,\n",
            "         2145,  2521,  2583,  2203,  5004, 13507,  7861, 25940,  9859,  2529,\n",
            "         3720,  8704,  2507, 19184, 13494, 10449,  6832,  4454, 20478, 21913,\n",
            "        10537,  3522,  9849,  6832,  4454, 21331,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  7603,  5038,  3754, 10785,  1999,  7512,  2529,  6699,  3365,\n",
            "         4216, 16913, 11475,  7368,  2478,  3160, 20589,  2015,  3558,  7755,\n",
            "        19389,  7755,  3728,  7603,  5038,  4227,  3086,  7578,  4646,  2752,\n",
            "         2066,  7461,  3512,  9798,  9871,  2529,  3217, 18384, 10266,  3006,\n",
            "         2470,  3259,  3640,  7721, 11778,  3319,  7603,  5038,  5461,  2783,\n",
            "         5476,  3259,  2950,  7603,  5038,  2478,  3558, 19389,  7755,  3558,\n",
            "         7755,  9125,  4613, 13268,  3670, 19389,  7755,  2421, 16175, 10127,\n",
            "        21890, 24915, 16175, 11522,  3695, 13113, 14891, 27760,  2278,  3096,\n",
            "         3433,  3239,  9651,  3259,  3640,  4955,  2536,  7603,  4275, 22239,\n",
            "         2109,  7603, 12005, 26243,  3370,  4281,  4493, 12978,  7603,  5038,\n",
            "         3001,  3259,  4472,  7721,  6575, 13722,  2092,  2243, 19779,  2078,\n",
            "         2951, 13462,  2015,  2628,  2640,  9181,  3319, 16030,  4106,  6594,\n",
            "         3479, 16087,  3485,  4790,  2478, 26113,  2050,   102]), tensor([  101,  3395,  3259,  4646,  7976,  4454, 25952,  6699, 11265, 10976,\n",
            "        20285,  2075,  3125,  9585,  8720,  5310,  6699,  4773, 28727,  2478,\n",
            "         9530,  6767,  7630,  3508,  2389, 15756,  6125,  2034,  2112,  3259,\n",
            "         5577, 15756,  6125,  3937,  4127,  5966,  4602,  3086,  2445,  6412,\n",
            "         4646,  9530,  6767,  7630,  3508,  2389, 15756,  6125,  9530,  6767,\n",
            "         7630,  3508,  2389, 15756,  2897,  2036,  2124, 13229,  7772,  6364,\n",
            "         2951,  8370, 10359, 19587,  3746,  5310,  7603,  5038,  9124,  2478,\n",
            "         2227,  9331, 28418,  2015,  3075, 22164,  2206,  4275,  7020,  2094,\n",
            "         4684,  7159,  1058,  2487,  4714,  2227, 19034, 11047,  2278, 10695,\n",
            "         4714,  2227, 19034,  2109,  4646,  2944,  2613,  7292,  2227, 10788,\n",
            "         2235,  2946,  3177,  8777,  7692,  8381,  2944, 11892,  4773,  4684,\n",
            "         7248,  2117,  2112,  3259,  4646,  2764,  3594,  2227,  9331, 28418,\n",
            "         2015,  3075, 11487,  6699,  2764,  6994,  2490,   102]), tensor([  101,  2051,  7976,  4454,  4235,  2109,  7365,  2166,  2126,  5198,\n",
            "        11835,  3617,  2088,  2036,  3791, 13265,  9414,  3787,  5547,  3465,\n",
            "        20831,  3465, 24110,  3775, 10451,  3325, 12046,  2015,  7487,  3471,\n",
            "         5198,  8087,  2478,  8278, 21318,  2191,  9416, 20600,  9932,  2784,\n",
            "         4083, 17547,  5310,  5248,  4719,  3424,  6895, 17585,  4769,  4022,\n",
            "        13500,  2224, 21318,  2640,  5335,  5310,  3325,  2036,  5326,  2458,\n",
            "        21318,  2640,  5310, 19699,  9013, 18718,  9414,  3257,  8321,  4106,\n",
            "         3325, 20390,  4117,  9932,  2974, 23569, 27605,  4371,  2640,  6578,\n",
            "         5198,  3617,  2088,  6551,  4359,  2437,  3617,  3688,  7218,  5310,\n",
            "         3791, 10910, 25180,  3238,  9123,  3325,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101, 13367, 18593,  4249,  7976,  2166,  7976,  4454, 15078,  7366,\n",
            "        12553,  7366,  6233,  8361,  2270,  3193,  4072, 28667,  5644, 18688,\n",
            "         4262,  3430,  2303,  4767,  3019,  2088,  4145,  2166,  2396,  2124,\n",
            "         6643,  3726,  2126, 11131, 16636,  2075,  2047, 12020,  5002,  3640,\n",
            "         3906,  3319,  3522,  2573,  7976,  2166,  5107,  2396,  2627,  2871,\n",
            "         2086,  4919, 15078,  4007,  5884,  3818,  2275,  9181, 25274,  4780,\n",
            "        17908,  4387, 22000,  2367,  7236,  6614,  3073, 11778, 19184,  3324,\n",
            "         4824,  3267,  4526,  2047,  2166,  2715,  2974,   102,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  5002,  2236, 22793,  7976,  4454,  9932,  2197,  2301,  6123,\n",
            "         8092,  7976,  2166,  5041,  8248, 11443,  4087,  8107, 13729,  9932,\n",
            "         3471,  2048,  7958,  2175,  7011,  6553, 15078,  2135,  4427, 16941,\n",
            "         7159,  2594,  4862,  7959,  4427,  3732,  3921,  9124,  9849,  2784,\n",
            "         4083, 26137,  9932,  9849,  2156,  2651, 23736, 22373, 14269,  6666,\n",
            "         2036, 23382, 10831,  2714, 11443,  9038,  2696,  6321,  4895,  2890,\n",
            "         3597, 29076,  5422,  2126,  9932,  3471, 10366,  3058, 24783,  2175,\n",
            "         7011,  6553,  3574,  5906,  4286,  2224,  2764,  4034, 14354,  2015,\n",
            "         8849, 13494,  5936, 25953,  4818,  3891,  4286, 13507,  2635, 10831,\n",
            "         2089, 11248,  7580,  2529,  5198, 10760, 13507,  2071,  2729,  2625,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  7976,  4454,  9932,  6208,  4254,  8384,  5094,  4286,  5307,\n",
            "         3795,  7860,  2301,  6964,  9932,  2764,  4007, 11265, 10976, 18078,\n",
            "         3330,  8051,  3728,  4435,  2638,  2860,  5656,  3818, 27084, 24164,\n",
            "         2094,  5072,  9932, 29080, 20397,  8382, 10514, 18098, 22591,  2571,\n",
            "        15431,  3001,  6370,  4954,  8059, 23150,  2529,  4454,  2147,  2048,\n",
            "        10015,  8107, 12992,  2075, 29080,  2649,  2028, 12362, 12697, 14972,\n",
            "        15756,  7505, 21799,  2015, 10639,  9380,  5072,  7755,  2507,  4125,\n",
            "         6125, 15078,  5682,  4503, 12702,  7229, 14604, 18384,  6558,  3921,\n",
            "         5936,  3953,  6279, 12553,  4442, 18516,  5097,  2536, 16820,  2164,\n",
            "         2925, 28991,  7583, 28775,  2638,  7832,  3591,  3937,  2504,  3701,\n",
            "        12367, 12368,  4378,  2512, 13102,  8586,  4818,  5130,  7927,  4125,\n",
            "         3037,  8880,  5739,   102,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  3522, 15463,  2529, 22461,  8360, 11643, 16731, 16715,  6148,\n",
            "         5050,  3019, 13352,  3408, 19287,  2170,  8360,  2110,  7258,  1042,\n",
            "         4757,  8676, 16246,  2163, 15380,  5459, 10266,  4655,  3043,  1998,\n",
            "         2953,  3424, 18900,  3334,  6653,  2028,  2110, 15380,  2178,  8107,\n",
            "         2170,  2529, 22461,  1044, 22571, 14573,  2229,  3550,  2529, 15923,\n",
            "        27570,  4277,  1996, 10867,  7716, 18279, 22924, 23084, 27885,  8043,\n",
            "        12423,  2088,  3408,  1042,  4757,  1042,  4757,  6194,  8676, 10124,\n",
            "         2135,  2417, 21104,  2275,  7065,  2545,  7028,  3136,  4972, 25613,\n",
            "         1042,  4757,  6125, 21934, 10924,  3558,  6194,  6194,  5884, 10061,\n",
            "        15380,  3001,  3421,  3408,  1042,  4757,  1044, 22571, 14573,  2229,\n",
            "         3550,  2897,  3896,  3443,  4022,  6022,  2130, 27258,  2135,  3623,\n",
            "         2236,  3471,  4747,  6455,  3754,  2529,  2967,  3125, 24039,  8627,\n",
            "         8993,  6177,  8106,  2453, 25705,  8361,  2511,   102]), tensor([  101,  2028,  3787,  2469,  2839,  5562,  2925,  2495,  7976,  4454,\n",
            "         2109,  6994,  5335,  4252,  4083,  6194,  2092,  2147,  5089, 15631,\n",
            "         7976,  4454, 21331, 13382,  2846,  2591, 21877,  2850,  3995, 26715,\n",
            "         6742, 12962,  2036,  2591,  3425,  3314,  7860,  7149,  3431,  4547,\n",
            "         6194, 15252, 10287,  4973,  7976,  4454,  2224,  2495,  3391,  3078,\n",
            "         2082, 18046,  3579,  2613, 13494,  3145,  4547,  4119,  5525, 13896,\n",
            "        10660, 21865,  3891, 11717, 27788, 29278,  6129,  1999,  2063, 26426,\n",
            "         6447,  2591,  2967,  5020,  3229, 12361,  3579,  6061,  3167,  9355,\n",
            "         4083, 16910,  7851,  3078,  2082, 11107,  6461,  6469,  2075,  4621,\n",
            "        12317,  4807,  4813,  2344, 17614,  6709,  2036,  4652,  5876,  4254,\n",
            "         2075,  4083, 10840, 22267,  2478, 23323,  2458,  4556,  8433,  3752,\n",
            "        18560,  6848,  2342, 16599,  7976,  4454, 21331,  8433,  5352,  5089,\n",
            "         6786,  2109,  4235,  2426,  2367,  2287,  2967,   102]), tensor([  101,  2028,  2192,  2458,  7976,  4454,  6233,  2590,  4254,  3171,\n",
            "         2291,  2036,  7243,  3268,  3098,  2047, 16820, 16625,  2047, 14679,\n",
            "         3228,  4125,  2047,  6695,  2051,  8361,  4022,  5081,  8438,  2342,\n",
            "        10824,  3921,  2241, 21931, 18024,  2875,  7976,  4454,  2411,  3591,\n",
            "         6090, 10732,  2050,  4763,  2015, 22794, 12248, 20689, 12863,  5144,\n",
            "         3668,  3471,  8146,  7976,  4454,  6994,  2442,  2109,  2729, 14046,\n",
            "         2036,  2635,  4070,  2825, 10831,  2920, 10831,  2468,  3618,  3928,\n",
            "        17208,  5906,  3277,  3698,  9615, 23097,  2992,  4045,  2504,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  3720, 15841,  4022, 16796,  7976,  4454,  9932,  9251,  2442,\n",
            "         3030,  9932,  4107,  2116,  6666,  9229,  2943,  7300, 23661,  2592,\n",
            "         4997,  8465,  2041, 27204,  2232,  2460,  3334,  2213, 12637,  3166,\n",
            "        11637,  4771,  6695,  2627,  4652,  4997, 14670,  6786,  2066, 19207,\n",
            "        11704, 12141,  3720, 15102,  2536, 10831,  3378,  9932,  2164,  6034,\n",
            "         7403,  3330,  8767,  3361,  2291, 12765,  8392,  4255,  3171, 16440,\n",
            "         4483,  4254, 14173,  2529,  6550,  3166,  4455,  2561,  7221,  9932,\n",
            "         6083,  2071, 25732,  2128, 13331,  7630,  3370,  9253, 29521, 21673,\n",
            "        16498,  2342,  4769, 25953,  4818,  8767,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101, 12761, 22334,  4942,  3790,  7976,  4454,  7976,  2166,  3594,\n",
            "         6897,  2135,  4427,  4725,  9611, 20600,  3471,  2478,  2009, 25284,\n",
            "        25416,  3170,  8163,  2275,  7300,  3081,  2689,  4989,  3921,  2211,\n",
            "         4856, 17367,  3652,  2275, 13792,  5214, 13729,  2898,  2846,  3471,\n",
            "         4055,  2536,  4127, 11234,  4989, 16221,  6630,  4018,  7300,  3144,\n",
            "         5097,  8897,  3674, 13100,  2164,  3132, 20600,  3698,  4083, 21331,\n",
            "         2536,  2752,  2817,  2542,  3001, 12761, 22334,  3728,  2464,  6308,\n",
            "         3391,  2817,  2330, 21945,  6622,  2590, 13494,  2925,  9932,  4310,\n",
            "         4022,  9699, 10866, 15463,  2599, 20680,  5670,  2458,  7976,  4454,\n",
            "         7976,  4454,  2166,   102,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  3800,  2817,  2817, 12020,  4800,  6914, 16754,  2389, 20600,\n",
            "         5248,  2491,  3001,  6074,  2236,  7976,  4454,  5214,  9174, 13729,\n",
            "         5415,  2846,  8518,  2613,  4044,  2364,  6481,  3031, 21281, 21197,\n",
            "         8625,  4588, 10752,  2491,  3001,  6074,  2236,  7976,  4454,  2241,\n",
            "         4800,  4270,  3372, 11265, 10976,  3597, 29076,  6024,  4294,  2015,\n",
            "         2764,  4725, 13792, 24203,  2229,  6026,  6887, 16515, 13874,  2015,\n",
            "         2491,  3001,  9414,  6074,  2429,  8991, 26305,  2015,  3818,  4007,\n",
            "         7427, 21934, 10924,  6194,  3031, 21281, 21197,  8625,  4588, 10752,\n",
            "         4800,  4270,  3372, 11265, 10976,  3597, 29076,  6024,  4294,  2015,\n",
            "         2764,  7885,  3344,  3443,  6887, 16515, 13874,  2015,  9414,  6074,\n",
            "         2241,  3375, 13458,  9414,  4005,  2764,  2838,  4800,  2818, 21716,\n",
            "        19137,  4168,  7403,  9896, 10863, 16268, 20680,  4800,  6914, 16754,\n",
            "         2389, 20600,  4800,  4270,  3372, 11265, 10976,   102]), tensor([  101,  3720, 15102, 10077, 18001,  7961, 13109,  2177,  3399,  2306,\n",
            "         8391,  7976,  4454,  9932, 26944,  2075, 10938,  8082, 19962, 24395,\n",
            "        10659, 11598, 15581,  8010, 15873,  2791,  9414,  3001,  2927,  3265,\n",
            "         7749, 18001,  7961,  2177,  3399,  3259, 21009,  9373, 10100,  8346,\n",
            "        18001,  7961,  2015,  3977,  5047, 12503, 25546, 10057,  2177,  3399,\n",
            "         2015, 26120,  8669,  8332, 20062,  2877, 10562,  7705,  8346,  9398,\n",
            "         4383,  2186, 17075,  2553,  2913,  7885,  2408,  7578, 13100,  7478,\n",
            "        19293, 21331,  2491,  9871,  3247,  2490,  6742,  5097, 13398,  7268,\n",
            "         4254, 13109,  2177,  3399, 14313,  5301, 15581,  8010, 11718, 24501,\n",
            "        18622, 10127,  3375, 16820,  3463,  2128, 10354, 27972,  9373, 10100,\n",
            "         2036,  3073, 24600,  3350,  6377,  3921,  2015,  4022,  2559,  2646,\n",
            "         2925,  3259, 22106,  3145,  7826,  2470,  2164, 25416,  3170,  3672,\n",
            "         9373, 10100,  8346,  3698,  4083, 12786,  7860,   102]), tensor([  101,  2817, 10641,  8790,  2492, 18001,  7961,  7976,  4454,  9932,\n",
            "         3361,  4106,  2901, 16798,  2509, 16911, 12170, 16558, 18994,  3388,\n",
            "        17682,  7427, 12667,  8525, 20617,  2951,  4773,  2671,  4208, 12151,\n",
            "         8045,  4275, 20607,  2535, 18001,  2592, 12604,  9513,  5884,  2470,\n",
            "        11596, 13661,  2342,  3305,  2458,  4254, 18001,  7961,  9932,  2306,\n",
            "        12368,  9531, 20607, 10660, 17826,  4118, 20792,  3391, 16966,  4646,\n",
            "         3361,  8169, 18046, 12170, 16558, 18994,  3388,  7277,  4106,  2920,\n",
            "         4866,  3319,  3906,  2405,  2558,  8920,  3145, 12046,  2015,  3296,\n",
            "         3930,  3446,  2248,  5792,  2779, 22921,  2566,  6254, 11548,  4249,\n",
            "         4935, 12317,  3267,  3463,  3936,  3278,  3296,  3930,  3446,  4051,\n",
            "         2248,  5792, 19235,  2575,  2779, 11091,  2566,  6254, 20637,  2475,\n",
            "         2350,  9263, 15368, 11817, 18001,  3001, 18001,  4520,  3001,  3485,\n",
            "         9414, 18001,  3001,  2592,  4163,  6003,  3278,   102]), tensor([  101,  3259,  7534,  4118,  4346,  4863,  8010,  8346,  7976,  4454,\n",
            "         9932,  2951,  5471,  5461,  7149, 20557, 17547,  4863,  3085,  7976,\n",
            "         4454,  1060,  4886,  5218, 16987,  9932,  3001,  4346, 17959, 20932,\n",
            "         3247, 12614,  6194,  9002,  5335, 17547, 10640, 11598,  3404,  9932,\n",
            "         3001,  3579,  3259, 16803, 17841,  8010,  7860,  2030, 18979,  2140,\n",
            "         5579,  3471,  2306,  4633, 19939,  2075,  2030, 18979,  2140,  5579,\n",
            "         7336, 29458,  4633, 13352,  3641,  4280,  4860,  8483,  3612,  3177,\n",
            "        13511,  3798,  2500,  4769,  4119,  3117,  2236,  4654, 24759,  5555,\n",
            "         3468, 19939,  2075,  7705, 13585, 27427, 14194,  6024,  3513, 18001,\n",
            "         7961,  3818,  2147, 27427, 14194,  6024,  3513,  5173,  3439,  4633,\n",
            "         2951,  3073, 11177, 17841,  3085,  3978, 19939,  2075, 18001,  7961,\n",
            "        16024, 12503, 17727,  2890, 28472,  4633,  2951,  2291, 16014,  2015,\n",
            "         2275,  4013,  3676, 14680, 14932,  7099,  7460,   102]), tensor([  101, 17841,  3085,  7976,  4454,  9932,  2036,  2124,  4863,  3085,\n",
            "         9932, 27427,  2483, 11837, 19150,  7411,  3404,  3085,  9932,  6847,\n",
            "         3406,  8270,  7363,  5449,  6937, 13494,  2529,  2092, 19205,  3070,\n",
            "         2174,  3484,  4493,  2470,  2181,  8857, 12697,  3375, 12138,  4725,\n",
            "         7539, 17841,  8010,  8821,  2364,  3653,  2890, 24871, 14972,  3404,\n",
            "        13966,  9932,  2966, 13100,  2777,  6529,  2764,  2536,  7526,  4725,\n",
            "        17841,  3085,  9932,  2426,  4725, 18001,  3513, 11157, 18001, 28937,\n",
            "         2291, 27424,  6003,  3117,  3928,  6994,  2958,  4807,  6578,  4286,\n",
            "         3935,  9932,  6681,  2174,  4391,  2224, 27424,  2015,  2966, 11616,\n",
            "         2804,  4646, 18001,  3513,  2367,  7957,  4800,  5302,  9305,  2966,\n",
            "         2951,  2363, 13990,  3086,  2750,  4022,  2224, 18001,  3513, 12697,\n",
            "         6413,  4118, 20792,  2800,  2951, 13462,  2015,  3319,  3640,  8050,\n",
            "         4824, 17841,  8010, 18001,  3513, 17976, 12596,   102]), tensor([  101,  2349, 12607, 11619,  2715, 19207,  6346, 10788,  2908,  3458,\n",
            "         6410,  3979,  7561,  4725,  6346, 10788,  6786, 12945,  3068,  2109,\n",
            "         6709,  4022,  2525,  4493,  6346, 19207, 19399, 19207,  2788,  6228,\n",
            "         5992, 19399,  2089,  2421,  2250, 16078,  2491,  3131, 10958,  9032,\n",
            "         4263, 22227,  6726,  2491,  3131, 21904,  3778, 13627,  2250,  4650,\n",
            "         2121,  7956, 25864, 11477, 27413,  9594,  2015, 15451, 11263, 27989,\n",
            "         2015,  4385,  6346,  3563,  3141,  3696,  8030,  2195,  4725,  6346,\n",
            "        10788,  2015, 19207,  2066, 12441,  7961,  6028, 18001,  7961,  4118,\n",
            "         6028,  7976,  4454,  6028,  2367, 13792,  2470,  2147,  4846, 18001,\n",
            "         7961,  2241,  6028,  3594,  5003, 26876,  7088,  9896,  3591,  2488,\n",
            "         6346, 10788,  7337,  5003, 26876,  7088,  2015,  9896,  3818,  1041,\n",
            "        10024, 14341,  5003, 26876,  7088, 18001, 28937,  4118,  3627, 15058,\n",
            "         2015, 29202,  6082, 20302, 23274, 10408,  5003,   102]), tensor([  101,  9949, 13617,  2897,  1059,  2015,  2078,  5500,  3074,  4714,\n",
            "         2659, 11452,  9949,  5733,  7333,  3558,  4044,  8080,  2536,  4483,\n",
            "         3785,  2951,  5067, 10959, 13617, 14164, 11860,  7688, 14164,  2478,\n",
            "         4800,  6154,  4806,  1059,  2015,  3619,  3749,  3365, 12637,  2060,\n",
            "         7159,  9316,  2164,  9412, 16991,  2659,  3465, 11038, 10813,  2349,\n",
            "         7692, 27142,  3267,  1059,  2015,  2078,  5344,  2536,  7860,  3314,\n",
            "         2342,  8280,  2344,  5676, 10539,  5851,  2951,  6726, 14164,  1059,\n",
            "         2015,  2078,  3811,  8211,  2536,  4127,  3036,  4491,  8419,  2304,\n",
            "         4920,  2886, 14920,  2326,  9998, 13045, 12014,  2886,  2426,  4491,\n",
            "         2304,  4920,  2886,  5320,  3809,  5081, 14164,  2897,  2886,  3344,\n",
            "        24391, 14164, 15734,  4530,  2951, 23730,  2491, 23730,  2302,  2830,\n",
            "         2075,  3832,  7688,  5676,  3036,  2897,  2304,  4920,  2886,  4072,\n",
            "         2640,  8114, 24554, 10788,  6028, 25952, 24391,   102]), tensor([  101,  3720,  2556,  2944, 26404, 14098,  2491,  3439,  3121,  3818,\n",
            "         2291,  2764,  2433, 12379, 22834,  2102,  6502,  3375,  2291, 13907,\n",
            "         2275,  5468,  2503,  3785, 18213, 12826,  2765,  3798, 22761,  2015,\n",
            "         4542,  3612,  3177,  6133, 17462,  2291,  2764,  2491,  2944,  2478,\n",
            "         2828,  2475, 18001,  7961, 13384, 23951, 17296, 14171,  6567,  8015,\n",
            "         2300, 16326,  2126,  3818,  2944,  3084,  9525,  9414,  2291,  2491,\n",
            "         4592,  3785,  3439,  3121,  2764,  2291,  5361,  8920,  2214, 12161,\n",
            "         2311,  2470,  3463,  2265,  8122,  2139, 28600, 28173, 10803,  7290,\n",
            "         3465,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101, 21641,  2838,  2377, 20369,  2535,  3019,  2653,  6364,  4346,\n",
            "         6748,  4824,  3574,  6123,  2306, 25304,  2951,  8391,  3698,  4083,\n",
            "         7976,  4454, 21641,  3444, 14676,  7336, 22969, 12158,  3787, 15973,\n",
            "        15066,  2411, 16911,  3935,  5461,  2066,  2773,  7861,  8270,  4667,\n",
            "         2015,  2784,  4083,  4275,  8346, 21641,  2838, 11598,  2015, 11718,\n",
            "         6123, 10830,  7389,  7971,  2653,  4275, 12067,  5097, 15792,  4106,\n",
            "         6254,  4937, 20265, 26910,  2592, 26384,  5452,  3618, 10640, 21923,\n",
            "         3259, 13999,  3117,  3921, 25835,  2158, 17661,  2072, 23569, 27605,\n",
            "         5422, 21641,  3444, 14676, 20287,  2891,  7959,  2881, 11598, 21641,\n",
            "         3444, 14676,  2394, 11746,  3818, 20287,  2891,  7959,  2944,  8681,\n",
            "        10077, 25835,  9324,  2075, 18001, 15058,  2094,  3444, 14676, 20287,\n",
            "         2891,  7959,  8704,  5425, 17796, 21641,  6550,  2306, 11746,  4346,\n",
            "        16371,  6651,  2094, 20062, 10318,  3574, 25304,   102]), tensor([  101,  9414,  7497,  2291,  2270,  7497,  2291,  3594,  7976,  4454,\n",
            "         2974, 23569, 27605,  4371,  2943,  2968,  5335,  3737,  7497,  2270,\n",
            "         2752,  3259,  7534,  2224,  2048,  4069,  7976,  4454,  4725,  8419,\n",
            "        18001,  7961, 15756,  6125,  9414,  2373,  2491,  2270,  7497,  6125,\n",
            "         3078,  7863,  2817, 16157,  2836,  8107, 23569, 27605,  6774,  2373,\n",
            "         8381, 10910,  8114,  7497,  2635,  9584,  2048, 11709,  8419,  2346,\n",
            "         4834,  4633,  3785,  6162,  7497,  2291, 14440,  2478,  2110,  4834,\n",
            "         6994, 13523, 20470,  5332, 12274, 13767,  2536, 13792,  2241, 18001,\n",
            "         7961,  7976, 15756,  6125,  3525,  2764,  2613,  2951,  4026,  4834,\n",
            "         6112,  3104, 12550,  3345, 13792,  2588,  4106, 12504,  3463,  5159,\n",
            "         3452,  3463,  3553,  9896,  2241, 18001,  7961, 17544, 13792,  2241,\n",
            "        15756,  6125,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  7398,  2301,  3795,  5949,  7860,  4788,  2078,  4975,  3741,\n",
            "        18345,  6410, 22210, 24156,  5949, 13148, 22382,  3278,  8767,  2529,\n",
            "         2740,  4044, 26785,  7971, 16518,  9886,  7976,  4454, 15058,  2094,\n",
            "         5024,  5949, 18771,  2974,  9932,  5910,  9333,  2102,  6123,  3935,\n",
            "         3581, 28286,  2953,  2213, 19566, 16371,  6651,  2094,  6550, 18001,\n",
            "         7961, 10232, 16820, 18001,  2275,  2344,  5609,  2311,  6481,  3375,\n",
            "         1053, 15532,  2290,  3861, 18001,  2275,  1039,  4160, 14536, 10343,\n",
            "         4150,  6150,  5052,  3247, 12088, 18394,  2048, 22172,  6132, 19301,\n",
            "         5450, 20226,  8304, 13727,  2592,  2613, 11108, 16820,  9186,  3192,\n",
            "         2389,  6481,  3259, 13999,  9525,  3581,  3136, 16764,  3581, 28286,\n",
            "         2953,  5244,  2306,  6123,  1039,  4160, 14536, 10343, 15929, 16594,\n",
            "         3136,  3259, 17146,  2176, 15873, 28041,  9224, 20118,  2015,  1039,\n",
            "         4160, 14536, 10343,  3375,  1053, 15532,  2290,   102]), tensor([  101,  3733,  4274,  3229, 10660, 12607,  2015,  4504,  2592,  2058,\n",
            "        11066, 20228, 11031,  6525,  7047,  2437,  3247, 12614,  5186,  3697,\n",
            "        16755,  2121,  2291, 12667,  4022,  5576, 13951,  5198,  2437,  6567,\n",
            "        16755,  2075, 29458,  4031,  8599,  2093,  8050,  3596, 12667,  2224,\n",
            "        24655, 13216, 12247, 12832, 12317,  4180, 15058,  2094,  8893, 22910,\n",
            "         8599,  2691,  2433, 12247,  4031, 13271,  4391,  4871,  5746,  2015,\n",
            "         6876,  2036,  2590,  2393,  5335,  2836,  3151, 12667,  3176, 10857,\n",
            "         3278,  4254, 12667,  2015,  2836,  3151, 12667,  2015,  2109,  8107,\n",
            "         2241,  7205, 11429,  3698,  4083,  4275,  4283,  3522,  9849,  7976,\n",
            "         4454,  2784,  4083, 12667,  2015,  2764,  2478,  9530,  6767,  7630,\n",
            "         3508,  2389, 15756,  6125, 13229, 18228, 18077,  9830,  2592,  2804,\n",
            "        13599, 13229, 15058,  2094, 12667,  2015,  2691,  5286,  3720,  3640,\n",
            "         2440,  7749, 13229, 15058,  2094, 12667,  2015,   102]), tensor([  101,  3522,  2086,  7142,  5082,  2458,  2671,  2974,  2926,  7142,\n",
            "         2458,  7976,  4454,  3698,  9896,  6786,  2495,  2291,  2036,  5625,\n",
            "         4287,  3167,  3550,  4180,  3151,  4972,  3151,  2495,  3001,  2411,\n",
            "        11092,  3924,  4697,  8873, 27110,  3363,  3921,  4252,  2202,  4070,\n",
            "         4310,  3791,  4083,  6782,  3076,  2495,  2291,  3167,  3550, 23569,\n",
            "        27605,  5422,  3698,  4083, 13792,  3073, 28749,  4083,  4475, 11433,\n",
            "         2241,  2493,  4083,  2381,  5426,  7590,  5335,  4083, 13105,  3698,\n",
            "         4083, 13792,  3073,  2613,  7292, 12247,  3076,  2836, 14171,  4083,\n",
            "         3488,  2241, 12247,  3084,  4083,  2832,  8790,  3167,  3550,  3568,\n",
            "         4162,  4127,  2495,  2164,  2653,  4083,  5597,  2671,  4385,  2174,\n",
            "         9229,  8122,  3698,  4083, 13792,  9041,  7620, 15973, 20600, 13792,\n",
            "         4072,  7680,  7849,  4697, 20600, 13792,  2312, 15782,  2571,  3698,\n",
            "         4083,  3259,  5363,  2191,  6851, 19184,  4493,   102]), tensor([  101,  3259,  7534,  7721,  3906,  3319,  2470,  4646,  3698,  4083,\n",
            "        19875, 13792, 16755,  2121,  3001, 12667,  2817,  8704,  6709,  3522,\n",
            "        12878,  8849,  2613, 15509,  5097,  5009,  6950, 19120,  2470,  3450,\n",
            "         5884,  2405, 16798,  2509,  5553, 19792,  2063,  9556, 20427,  2367,\n",
            "        13100,  2164,  2495,  9871, 19875, 13792,  8285,  2368, 16044,  2869,\n",
            "        23895,  4083, 17338, 15810,  3401,  3617,  8083,  3319, 11637,  9412,\n",
            "        12832, 10640,  3445, 26743,  8553,  3167,  3989,  6123,  7073,  7578,\n",
            "        19875,  5461,  9942,  8304,  3147,  2707,  2951, 12403,  2869,  3012,\n",
            "         3192,  2925, 12607,  2015, 19875, 13792, 12667,  2015,  6195,  4646,\n",
            "         5814,  9926,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  6047,  3655,  5050, 19143,  2592,  4807,  6786, 25891,  3923,\n",
            "         2968,  5335,  3737,  2166,  2103, 28857,  6123, 16755,  2121,  3001,\n",
            "         5906,  3749,  3167,  5084, 15690,  2103, 28857,  6003,  3145, 16884,\n",
            "        19143,  3144,  4646,  2536,  2752,  2103,  2166,  3754,  2832,  5294,\n",
            "         8310,  2951,  7013,  3923, 10058,  4654,  5669, 17572,  3570, 10232,\n",
            "         2974,  6622,  2103,  4041, 16134,  2443, 15252,  4773,  2671,  7809,\n",
            "         4525,  7558,  4790, 21839,  2128, 20414, 11656,  4359,  6564,  2034,\n",
            "         2754,  5031,  4755, 12170, 16558, 18994,  3388,  7277,  4106,  7863,\n",
            "        20302,  7274,  2075,  8332,  5919, 16596, 18900,  6994, 16378, 11778,\n",
            "         3906,  3319, 10607,  2478, 26113,  2050, 12609,  4861,  3463,  7203,\n",
            "         2367,  6194, 11433, 21839,  2752,  6813,  2740, 12969,  3665,  2470,\n",
            "         2464,  3278, 12687,  3298,  6622,  8122,  6047,  3655,  7411,  5024,\n",
            "         7705,  2925,  2470,  8790,  2492,   102,     0,     0]), tensor([  101,  4274,  2477, 22834,  2102,  2241,  6556,  9871,  5097,  3073,\n",
            "         3435,  4652,  8082,  2966,  2578,  5022,  3891,  2174, 29458,  2540,\n",
            "         4295,  3375,  4708, 11616,  3463,  6524,  8321,  4769,  3277,  3117,\n",
            "        12832,  2291, 22935,  4295, 17547,  2478, 22834,  2102,  2897,  2784,\n",
            "        11522,  3695,  3818,  4346,  3188, 11616,  3949, 23444, 11433, 15050,\n",
            "         7870,  3322, 19389,  2951,  5067,  5022, 19512,  2478,  2176, 16012,\n",
            "        13907, 14925,  2290, 13617,  3778, 13617,  8187, 13617, 18423, 13617,\n",
            "        12098,  8566,  5740, 11486,  8267,  5067,  2951, 22834,  2102, 13907,\n",
            "        16014, 22939, 26745,  3366,  4295, 22935,  4295, 17547,  2944,  7528,\n",
            "         2478,  2502,  6820,  7226,  7442,  7542,  2389, 11644, 28667, 29264,\n",
            "         3131,  3086,  2944, 22939, 26745,  3366, 22935,  4295, 26268,  2274,\n",
            "         2800, 22935,  4280, 12832,  2291,  3640,  3558, 23444, 11433, 15050,\n",
            "         5022,  2241,  6219,  2951,  3081,  5310,  4684,   102]), tensor([  101,  6745,  3947, 12771,  9798,  4219,  2326, 10489, 10390,  5836,\n",
            "         5670,  2185,  9798,  4031,  4156,  9798,  2326,  5359,  5198,  4274,\n",
            "         2312, 15782,  2571,  2951,  6401,  2174, 13896,  6112, 15058,  2094,\n",
            "        22834,  2102,  7976,  4454,  9932, 10787,  8013,  3325, 19309,  2015,\n",
            "         2116,  4646,  2752, 16755,  2121,  3001, 12667,  2342, 13368,  2078,\n",
            "         2536, 12719,  2490, 22834,  2102,  5733,  2415, 19309,  2088,  2164,\n",
            "         3522,  2653,  4275,  2066, 11834, 21600,  2102, 22759,  6786,  2066,\n",
            "        28991, 15007, 21020,  3259, 13999,  5821,  2451,  3522,  9798,  2458,\n",
            "        22834,  2102, 23663,  2078,  9666,  9798,  4429,  2348,  3365,  2470,\n",
            "         2913,  2405,  4429,  6047,  5097,  3904,  2718,  5886,  3406,  4146,\n",
            "         9666, 15058,  2094,  6047,  5821, 13100, 16755,  2121,  3001,  4429,\n",
            "         2641,  3117, 15078,  2291, 10210, 28731,  2397,  9407,  5335, 20235,\n",
            "        27891,  8392,  7325,  5248,  5097,  9034,  2613,   102]), tensor([  101,  3800,  2236,  3800,  2817,  8556, 12353, 16755,  2121,  3001,\n",
            "         3716,  5456, 16134,  2817,  4233, 15363,  2470, 16134,  4624,  2470,\n",
            "         5218,  3905,  2951,  5067,  2302,  2492,  6198,  4624,  2470, 10468,\n",
            "         2920,  9334,  2951,  4493,  4219,  6516,  2411,  2641,  2659,  3465,\n",
            "         6028,  4102,  2492,  2470,  2364,  3465,  2920, 12706,  2051,  7026,\n",
            "         5571,  2472,  3111,  2947,  2817, 13538,  2525,  2405,  2913,  4311,\n",
            "         6747,  3905,  2951,  4089, 11570,  3784,  9263,  3075,  9556,  9556,\n",
            "         7487,  6526,  6123,  8787,  4118, 10091,  6578,  8800, 16755,  2121,\n",
            "         3001,  3716,  5456,  2817, 12353, 16755,  2121,  3001,  3716,  5456,\n",
            "         2179,  3001,  2209, 20369,  2535, 25505,  5198,  8993,  6565,  2592,\n",
            "        16360, 20049, 29469,  2229, 12067, 26944,  7882,  4219,  7818,  3716,\n",
            "         2179, 16755,  2121,  3001, 15440,  3935, 13792,  3167,  3550,  5461,\n",
            "         7645,  3020, 12353, 11717,  7882, 11433, 21727,   102]), tensor([  101,  4646,  7976,  4454,  9932,  6022,  4852,  2116,  2529,  4219,\n",
            "        17850,  4972,  2470,  8704,  3305,  7578,  8519,  5664,  8593,  2622,\n",
            "        10489, 10489, 22565,  2529,  7692, 10489, 23084,  4022,  7976,  4454,\n",
            "        15058,  2094, 16755,  2121,  3001,  2674,  3105, 17879,  7904, 17879,\n",
            "         2817, 13495,  3972, 21850,  2817, 15058,  2094, 16134,  4919, 21317,\n",
            "         6739,  5997,  3640, 10740,  8599,  7928,  2275, 14848,  2015,  2241,\n",
            "         3784,  3972, 21850,  2817,  3463, 13180, 10740,  2470,  8704,  6709,\n",
            "         7860,  3141,  7904,  5558,  2497,  6337,  9844,  7976,  4454,  3698,\n",
            "         4083,  5906,  2433, 16755,  2121,  3001,  2817,  3972,  7178,  2536,\n",
            "         7860,  9844,  7904, 17879,  3105, 17879,  2783,  3471,  4320, 12706,\n",
            "         2529,  7692,  5073, 22565,  2622, 10489,  5502,  2817,  2036, 25999,\n",
            "         2422,  4022, 24010,  7300,  7976,  4454,  2433, 16755,  2121,  3001,\n",
            "         2036,  3231,  3232, 14848,  2015,  3579,  4022,   102]), tensor([  101, 13268,  3670,  5038, 10768,  2099, 12550,  2536,  4249,  2495,\n",
            "        10355, 21331,  9871,  2500, 13268,  3670,  5461,  6013,  9123,  8957,\n",
            "         7976,  4454,  6807,  2529,  5344, 11487,  6699,  2711,  9530, 14028,\n",
            "         2075,  2224,  6699,  5454,  6413,  6998,  2028,  2224,  2553,  2227,\n",
            "         7603, 10788,  2652,  2189,  2241,  5198,  6888, 17908,  5198, 13268,\n",
            "         3670,  2139,  8566,  3401,  5346,  2765,  2047,  7603,  4275,  5478,\n",
            "         4812,  4493,  3924,  5998, 11178,  5468,  2189,  2015,  4434, 13268,\n",
            "         7603,  3259, 10408,  2785,  3105,  2478,  9530,  6767,  7630,  3508,\n",
            "        15756,  2897, 13229,  2241,  2784,  4083,  3921,  2784,  4083,  6464,\n",
            "        17908,  4895,  3367, 26134,  2951,  5691,  3596,  2865,  3698,  4083,\n",
            "         2470,  2580,  2613,  7292,  2291,  6807,  2529,  5344, 14358,  2529,\n",
            "         6699,  2130, 16755,  2189,  5198,  1051,  4430, 29107, 10768,  2099,\n",
            "        11387, 17134,  2951, 13462,  2015, 12550,  6388,   102]), tensor([  101,  2445,  7860,  6970,  9527,  8113,  2592, 10077,  2951, 12403,\n",
            "         2869,  3012, 12317, 22910, 13792,  3259, 17146,  2892,  9527,  8113,\n",
            "         2592, 10077,  8185, 22511,  9896, 11598, 10640,  3167,  3550, 11433,\n",
            "         7976,  4454, 12832,  3001,  2817,  4269,  9334,  2079, 19761,  2078,\n",
            "         3185,  5790,  2951,  2591,  2897,  2592,  5676,  2951, 11109, 23310,\n",
            "         6132, 11039, 12377,  3292, 10788,  4846,  6366, 24473,  7644,  3019,\n",
            "         2653,  6364,  2974, 12550, 14817,  3145, 22104,  8476,  2592,  2591,\n",
            "         6981,  5678, 10629,  9530,  6767,  7630,  3508,  2389,  6125, 12550,\n",
            "        10463,  5310,  6550,  3444, 19019,  4310,  9829, 16861,  4118,  2109,\n",
            "        10463, 16246,  5310,  3185,  2592, 12441, 21520,  4652,  2058,  8873,\n",
            "        13027,  5526,  3180,  3989,  4118,  3107,  6360, 23569, 27605,  4371,\n",
            "         4022,  3444, 19019, 18215,  2779,  3444,  4434,  5461,  4162, 17409,\n",
            "         2838,  2367,  4249,  9308,  3259, 13585,  8875,   102]), tensor([  101, 18804, 16070,  7484,  4507, 27830,  2686,  5198, 11835,  3617,\n",
            "         5200,  5901,  3352,  4507,  2047,  2088, 19852,  2015,  7976,  4454,\n",
            "         9932,  2652,  6233,  2590,  2535, 20300,  2458, 22380,  9932,  8361,\n",
            "         6786, 18804, 16070,  9005,  2047, 12020, 10047, 16862,  3512,  6322,\n",
            "         3130,  5263,  3259, 15102,  9932,  6377,  6786,  4274,  2477,  3796,\n",
            "        24925,  2078,  3019,  2653,  6364,  7484,  4507, 19335,  4507,  3816,\n",
            "         4507,  3668,  4507,  2028,  4022,  5770,  2478,  9932, 18804, 16070,\n",
            "         3754,  3443,  3167,  3550,  6322,  3265,  5198,  2241,  5248, 18394,\n",
            "         2178,  4022,  5770,  2478,  9932, 18804, 16070,  3754,  8285,  8585,\n",
            "        23563,  8518, 22198,  2051,  4219,  3375,  5541, 28809,  2174,  2036,\n",
            "         7860,  3378,  2478,  9932, 18804, 16070, 12725,  5310,  9394, 12786,\n",
            "         3314, 13827,  9147, 12843,  4022,  6666,  7860,  2478,  9932, 18804,\n",
            "        16070,  2164, 12962, 16852,  2488,  7374, 10990,   102]), tensor([  101,  2088,  7976,  4454,  2904, 21040,  2627,  2184,  2086,  4125,\n",
            "         2784,  4083,  5026,  3278, 12154, 25028,  3919,  5541, 11105,  5770,\n",
            "         3073,  2678,  2399,  3068,  2208,  9932,  2511,  2492,  2382,  2086,\n",
            "        18640,  4310,  3471,  2492,  6143,  7892,  2512, 13068,  2121,  3494,\n",
            "        11247, 15732, 24508,  4180,  4245,  3127, 11637,  4563,  2752,  4556,\n",
            "        12613,  9932,  4247, 25220,  2306,  3698,  4083,  4346,  2047, 15955,\n",
            "         2511,  6078,  4606,  2047,  6695,  8361, 14571,  9932,  5278,  2399,\n",
            "         2081,  2164,  2447, 19518, 20477, 11139,  9289,  2075,  7284, 21257,\n",
            "        12978,  5604,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  7976,  2236,  4454,  2801, 13834, 25613,  4005, 13368,  7976,\n",
            "         4454,  9932, 22901,  7505, 15194,  2521, 26849, 12785,  2529,  9273,\n",
            "         2801,  2105,  2144,  2220,  2458,  9932,  2144, 16820,  9932,  2089,\n",
            "        16582,  2875,  4286,  3395,  2116,  7214,  2470,  2573,  3259, 17908,\n",
            "         2015,  2783,  2110,  7976,  4454, 22901,  2783,  9932,  2679,  2412,\n",
            "         5514,  2713,  8052,  2047,  9932,  4725, 11703,  7416,  3726,  4286,\n",
            "         2041,  4842, 14192,  8518,  2245,  5263, 11147,  9932,  8210,  5476,\n",
            "         3283, 23217,  3105,  3006,  2992,  5936,  7976,  2236,  4454, 12943,\n",
            "         2072,  2453,  2746,  5514,  2245,  3327,  3579,  1017,  3563,  2945,\n",
            "         2715,  9932,  2015,  4503,  2801,  2784, 15756,  6125,  2783, 21505,\n",
            "         3053,  7976,  4454,  4725,  3532,  5347, 12943,  2072, 13368,  2349,\n",
            "         2116, 12546,  3568,  5081,  2746,  3522,  9932,  2679,  4682, 12943,\n",
            "         2072, 12546,  3594,  3768,  7040,  2783,  4275,   102]), tensor([  101, 10848, 10526,  2075,  4791,  9686, 25378,  2613,  7292, 25095,\n",
            "         4022,  8526,  9501,  3666,  2350,  2977,  2824,  2174,  2437,  2613,\n",
            "         7292, 20932, 10368,  2349, 21446, 10857,  2306,  2208,  5994,  7578,\n",
            "         2447,  9942,  3247, 12614,  2147,  4740, 11598,  4378,  8147,  2306,\n",
            "         2678,  2208,  8504, 10449,  2613,  7292,  4118, 29458,  5222,  2146,\n",
            "         2460,  2744,  3638,  2897,  1048,  3367,  5244,  2241,  3921, 12939,\n",
            "         8114, 20932,  2663, 10483,  2063, 13105,  2478,  2740, 17245,  2447,\n",
            "         2051,  2186,  6947,  4145, 16157,  4275,  2836,  2306,  4438,  2048,\n",
            "        13068,  2121, 10877,  2208,  3565,  2395,  4959,  2462, 15386,  2036,\n",
            "         6847, 10665,  4118,  2110,  2396,  4725,  2051,  2186, 19939,  2075,\n",
            "        29464, 10938,  2121,  4275,  2179,  2312,  2653,  4275,  2222,  5244,\n",
            "         2633,  7480,  8162,  3401,  2951,  2275,  3642,  8069,  2582,  2075,\n",
            "         2147, 16014,  3512,  4106, 10877,  2399,   102,     0]), tensor([  101,  2622,  4427,  2735, 15058,  2094,  5656,  2399,  2345,  5913,\n",
            "         9887,  1060,  9006,  1016,  2715,  2735, 15058,  2094,  5656,  2399,\n",
            "         2622, 14336,  2105,  2224,  7976,  4454, 20957,  2306,  5656,  2399,\n",
            "         3579,  2622, 21852,  7976,  4454,  4526,  8795,  4245,  2291, 20957,\n",
            "         4525,  8795,  2291,  9005,  2047,  8795,  2015,  8790,  3973, 20888,\n",
            "         7976,  4454,  4352,  2867,  9280,  3325,  2412, 10288,  9739,  4667,\n",
            "         2466,  8795,  2015,   102,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  3127, 15841,  4022,  3617,  2974,  5326,  3521, 25820,  2495,\n",
            "        21894,  4022,  6666, 10831,  3378,  2224,  6048, 16599,  3921,  2241,\n",
            "         2529, 13013,  6850,  2640, 16731,  2094,  3188, 25090, 11254,  3791,\n",
            "        15251, 26262,  3127,  7534,  2093,  2553,  2913, 10580,  4022,  3617,\n",
            "        20957,  7976,  4454,  9932, 10355,  2490,  3521, 25820,  2034,  2553,\n",
            "         2817, 15102,  2224,  3617, 20957,  6570, 14052,  2117,  7679,  2224,\n",
            "         9932,  4047,  5694,  4808,  2353,  2553,  2817, 15841,  2224, 10355,\n",
            "         5333,  7073,  2162,  6048, 13399,  2974,  5836,  3375,  2492,  9934,\n",
            "         3749, 11110,  9647,  8849, 12020,  5622,  5677, 14049,  2640,  3127,\n",
            "        14730, 20655,  5197,  4824,  2572,  5638, 24879,  3267,  2974,  4022,\n",
            "         4736,  3521, 25820,   102,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  8790,  7484,  4507, 27830,  4329,  3550, 10355,  4024,  6088,\n",
            "         4346, 10047, 16862,  3512,  6322,  2202,  5198,  2047,  5269,  2817,\n",
            "         7534,  3117, 10990,  2801,  2170,  7484,  4507,  5469,  2998, 13585,\n",
            "         5919,  5469,  2998, 27830,  5396,  3073,  3117,  3921,  4975, 19293,\n",
            "        27830,  5469,  2399, 11566,  2447, 11643,  8107, 19293,  2965, 15058,\n",
            "         2094,  2291,  4553,  2867,  3265, 10069, 14171,  2399,  4180, 11914,\n",
            "         2147,  7534,  2048,  3278,  9849,  4310,  4118, 12515,  2867,  3563,\n",
            "        10069,  3081,  2208,  2951,  3698,  4083,  4725, 19293,  2208,  2291,\n",
            "        13495,  6074,  8080,  2867,  7404,  6322, 21573,  7524,  6177,  2424,\n",
            "         6314,  3436,  3176,  3350,  5310,  2913,  7778,  7784,  5604,  6083,\n",
            "         4118,  2089, 12992,  6911, 10089,  2371, 27911,  2015,  4525, 10377,\n",
            "         2075, 10355,  3325, 27830,  5469,  2998,  2716,  2362,  9560,  2089,\n",
            "         4012, 11880, 20998,  4024,  3325,  2867, 26275,   102]), tensor([  101,  2478, 11721,  4328, 10803,  2678,  2399,  2028,  2715,  8107,\n",
            "        10699, 22415,  9229,  7590,  5566, 14767, 10489,  2164,  6143,  3241,\n",
            "         4813,  2116,  4411,  2224,  2678,  2399,  4249,  2495,  5821,  2449,\n",
            "        20213,  2470,  6461,  8556,  2535,  2678,  2399, 20226, 10489,  6143,\n",
            "         3241,  4022,  6691,  4975, 10699,  9859,  7099,  2443,  2382,  2493,\n",
            "         8851,  2920,  8144, 20213, 16927,  5468,  6143,  3241,  6818, 25472,\n",
            "        19312,  2015,  6143,  3241,  3160, 20589,  2109,  2064,  2696,  2497,\n",
            "         3231,  4846,  5468, 10699,  9859,  6709,  3633, 11247,  2075,  6782,\n",
            "        20390, 12702, 24805, 20511,  4041,  2933,  5038, 20932,  7215,  4219,\n",
            "         7704, 27885,  8043,  3567,  8553,  4053, 24685,  2881,  9556,  5393,\n",
            "         5187,  2509,  3867,  6818, 21346,  3241,  2382,  3867,  3001,  3241,\n",
            "         2717, 25416,  6444,  2075,  3241,  2806,  6143,  3241,  7444,  9812,\n",
            "         2192,  2445,  4453, 16902,  4053, 24685,  9181,   102]), tensor([  101,  2817, 28062, 12978, 15581,  3085,  4083, 18667,  2290,  2089,\n",
            "         5335,  2449, 21934, 10924,  2399, 18667,  2290,  8651, 12020,  5915,\n",
            "         3623,  2592,  4117, 17796,  3267,  2651,  2015,  2194, 18046,  2965,\n",
            "         4438, 18667,  2290,  2495,  5461,  4703,  8246, 23613,  7374,  2493,\n",
            "         8190,  2227, 10126,  2166,  2817,  3640,  6208,  4294, 14678, 19852,\n",
            "         2015,  4083, 10425, 10960,  5604,  8146,  2241,  3563,  3076,  5082,\n",
            "        14714, 16911,  2715,  7976,  4454,  4725,  2164,  3698,  4083,  6028,\n",
            "        11014, 25845,  5198,  8347, 11532,  3754,  2191,  6567,  3977,  5541,\n",
            "         3241, 22701,  2075,  2495, 12654,  2817, 13275, 12020,  2488,  5875,\n",
            "         4547,  6695,  2802,  2715,  2287,  5815,  5719,  4512,  3276,  9932,\n",
            "         2731,  5971,  9942,   102,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  2678,  2399,  3352,  2112,  3268,  2116,  2116,  2111,  2583,\n",
            "        23408, 11045,  2898,  2846,  6699,  6569,  8277,  3571, 26452,  4526,\n",
            "         2784, 27013, 13432, 19221,  2867,  6133,  2825,  2224,  6699,  2208,\n",
            "         3720,  7534,  4145,  4975,  2291,  8790, 24508,  4180,  4245,  7473,\n",
            "         2290,  2208,  9760,  8290,  2478,  6699,  2241,  4725,  7461,  3512,\n",
            "         9798,  6162,  3125,  3720,  2764,  7603,  5038,  2291,  2241, 18001,\n",
            "         7961,  7473,  2290,  2864,  7976, 15756,  6125,  2678,  2208,  3068,\n",
            "         7461,  3512,  9798,  4725,  8290,  3670,  6699,  3288,  2307,  6666,\n",
            "         2144,  6832,  6624,  2447,  2590,  2191,  2047,  6691,  8906,  2529,\n",
            "         9006, 18780,  2121,  8290,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])], 'attention_mask': [tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])]}\n",
            "Test: {'input_ids': [tensor([  101,  6882,  4007, 20228, 22974, 23061,  2213, 10788,  5906,  4235,\n",
            "         2109,  4547, 10906,  5676,  7864,  2147, 15826,  5906,  4961,  2224,\n",
            "         2362,  4125, 10316,  2015,  3274,  2671,  3454,  6923, 11343,  3642,\n",
            "         3784, 19156, 11160, 15873,  2791, 20228, 22974, 23061,  2213, 10788,\n",
            "         5906,  2551, 11213,  3947,  3223, 26399, 10788,  2152,  3223,  2941,\n",
            "         4137,  2147,  3259,  3065,  2553,  7534,  4498,  6882,  2565,  8651,\n",
            "         3921, 10636,  4215, 14222,  2759,  4007, 20228, 22974, 23061,  2213,\n",
            "        10788,  5906, 10636,  4215,  8681,  7705,  6062,  5461,  4427,  7403,\n",
            "         4730, 13100,  5051,  6895,  8873,  2278,  3716,  6464, 25174, 20228,\n",
            "        22974, 23061,  2213, 25971, 10636,  4215,  4621,  6324,  2176, 20228,\n",
            "        22974, 23061,  2213, 25971,  2164, 10636, 16545, 17802, 10636,  4215,\n",
            "         3435,  4621,  2781,  9699,  6310,  4617,  3454,  3497,  4019, 10788,\n",
            "        16021, 28173, 13453,  2512,  3207,  3334, 25300,   102]), tensor([  101,  2048, 29100,  2817,  3757,  2470,  2974,  2495,  6239,  3591,\n",
            "         9312,  5534,  6239,  9556,  9312, 14099,  6447,  2536, 14481,  3730,\n",
            "         3597, 13046, 11316,  2493,  2714,  6981,  2800,  4274,  6878, 20228,\n",
            "        22974, 23061,  2213,  5248,  4997,  3466,  2493,  4513,  2372,  2364,\n",
            "         3114,  2369,  5248,  3768, 16367,  7073,  2426,  4513,  2372,  7634,\n",
            "        20228, 22974, 23061,  2213,  3568,  2817, 17146,  3274,  3550,  2291,\n",
            "         2583, 11487, 20228, 22974, 23061,  2213,  2592,  2478,  2463, 11219,\n",
            "         2015,  2522, 11493,  2063,  3292,  9896,  2832,  4627, 17463,  3217,\n",
            "         9623,  7741,  2832,  2950,  3117,  3357,  9361,  9003,  2502,  9206,\n",
            "         9207,  2686,  2944,  2640,  4117, 17208,  2463, 11219,  2015,  2522,\n",
            "        11493,  2063,  3292,  2459,  5491,  3231,  2951,  2765,  2817,  3227,\n",
            "         3065,  5491, 10788, 10640,  6109, 22394,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  4372, 28517,  2396,  2594, 18845,  7367, 16258,  2638,  3449,\n",
            "        20302, 17417,  2015,  4487,  5054,  2080, 10408, 21736, 10975,  5657,\n",
            "        22083,  2139,  4895, 16913, 18845, 11498,  2474, 20010,  8586, 10446,\n",
            "         2139,  8962, 27742,  2140, 20228, 22974,  2080,  2139,  5869, 16985,\n",
            "         5243,  2015,  4372,  9035,  8883,  4895, 24761, 18532,  2050,  2139,\n",
            "         4748, 25300, 20528, 10446,  2139, 12731, 25301,  2015, 21183, 18622,\n",
            "        13471,  3527,  2474, 19534, 14192,  2050,  2139,  4013,  9623, 10631,\n",
            "         4765,  2080,  4487,  3367,  3089,  8569, 13820,  2018, 18589,  4372,\n",
            "         3449,  2556,  2063, 19817, 19736,  5558,  7367, 20302, 21335,  2474,\n",
            "        18636,  2050,  3972, 20228, 22974,  2080, 10861,  1051, 10841, 14343,\n",
            "         4372,  5869, 16985,  5243,  2015,  3449,  7875,  6525,  8883,  3617,\n",
            "         3672,  2063, 18499,  3050,  9765, 21041, 24985, 10861,  2365, 28667,\n",
            "        23606,  8447,  2015, 18499,  3050, 24761, 18532,   102]), tensor([  101,  2028,  3145,  5876,  2369, 20228, 22974, 23061,  2213, 11343,\n",
            "         2312,  3815,  2951,  2592,  4274, 11570,  5901,  7457,  3891,  3834,\n",
            "         9861,  7789,  3200, 11933,  4852, 10089, 20228, 22974, 23061,  2213,\n",
            "         4982,  8089,  4567,  2875,  6882, 20228, 22974, 23061,  2213, 10788,\n",
            "         8893, 13792,  5240,  2028, 17464,  3971, 11487, 14402, 10126,  2653,\n",
            "         3120,  3642,  2517,  3076,  2817, 28062, 10439, 19341,  8553,  3112,\n",
            "        11566, 23310,  6132, 11039, 12377, 10086,  3292, 15796,  5164,  9844,\n",
            "         9896,  2744,  6075, 19262,  6254,  6075,  1056,  8873, 20952,  8558,\n",
            "        12992,  2075,  3446, 14402,  7594,  2478,  2522, 11493,  2063, 14402,\n",
            "         3818,  8893,  9896,  2036,  2583, 11487, 20228, 22974, 23061,  2213,\n",
            "         4158,  3019,  2653,  3120,  9537,  6635, 17330,  2616,  2764,  9896,\n",
            "        11487,  4373, 24388,  2098,  2616,  6970, 18209,  8787, 14402, 23851,\n",
            "         3972, 20624,  2239, 24402,  3431,  2470,  2093,   102]), tensor([  101,  5761,  3112, 13268, 10768, 25300,  9276,  5970, 21461,  2015,\n",
            "         3130,  2443,  5301,  6165,  6327,  5907, 10617,  2931,  5776,  2890,\n",
            "         6442,  2098,  9560,  5761,  7603,  5038,  3754, 10785,  1999,  7512,\n",
            "         2529,  6699,  3365,  4216, 16913, 11475,  7368,  2478,  3160, 20589,\n",
            "         2015,  3558,  7755, 19389,  7755,  2817,  2109,  7976,  4454, 13268,\n",
            "         5038,  4007,  7863,  2135, 16157,  3896, 21461,  2015,  8690,  5907,\n",
            "         2287,  2426,  3287,  3406,  7959,  9067,  2063, 16824,  5022,  2092,\n",
            "         3276,  5776, 13268,  9967, 21461,  2015,  3378,  9885,  8690,  2287,\n",
            "         5816,  5022,  2995,  2287,  2484,  1052,  8889, 24096,  3080,  5022,\n",
            "        13417,  3618, 25006, 12874, 16902,  8185,  2179,  3278,  3276,  5301,\n",
            "         2931,  5907, 22868,  5776, 13268,  9967,  9099,  7959, 25300,  2638,\n",
            "         5022,  5281,  8377,  9967, 13268,  3311,  8690,  5907, 17913,  8690,\n",
            "         2287,  2206, 21461,  2015,  5546,  5776,  9967,   102]), tensor([  101,  2470,  3218,  2147,  5082,  3259,  7534, 19204, 15058,  2094,\n",
            "         3921, 25952, 20228, 22974, 23061,  2213,  2118,  5352,  8051,  4730,\n",
            "        14799, 25952, 20228, 22974, 23061,  2213, 21118,  3697,  2051,  8663,\n",
            "        17421,  2075,  2147,  2197,  2048,  5109,  2536, 20228, 22974, 23061,\n",
            "         2213, 10788,  5906,  2764,  5461,  2071,  3701,  4055,  2206,  7236,\n",
            "        25304,  2674,  2565, 18642, 10629,  7831, 10061, 20231,  3392,  4106,\n",
            "         2659, 20414,  2884,  2433,  3642,  7831,  2348,  2843, 27338, 25952,\n",
            "         3642, 24418,  4007,  4730,  4155,  1041,  2290,  3937, 10507,  9262,\n",
            "        18750,  4385,  2470,  4208,  8051,  6412,  4155,  2145, 11158,  2241,\n",
            "         4621, 10246,  7591, 23325,  3853, 21934, 14949,  2232,  2788,  2109,\n",
            "        25952,  2379,  8566, 24759, 24695,  2015,  4773, 15927,  3818,  5301,\n",
            "         2613,  7292, 20228, 22974, 23061,  2213, 10788,  3921,  2310, 15928,\n",
            "         8649, 10751,  2140,  8051,  6412,  2653,  4730,   102]), tensor([  101, 11778,  3319,  3640,  4310,  9556,  2039,  3406, 13701,  7749,\n",
            "         7976,  4454,  9932,  3020,  2495,  2355, 16798,  2475,  2478, 26113,\n",
            "         2050,  6481,  8778, 15028,  4790,  4453,  2440,  7749,  2478,  3188,\n",
            "         2072, 16764, 16861,  2951, 15028,  4790, 15901, 16578, 22402,  9556,\n",
            "         2817,  2265, 25682, 16798,  2475,  5523,  3123,  3053,  2048,  2093,\n",
            "         2335,  2193,  3025,  2086,  5915,  4125,  2193,  9932,  2098,  5523,\n",
            "         2047, 12878,  6003,  9556,  2265,  2470,  4146,  2416,  2698, 17846,\n",
            "         2088,  9874,  5429,  2149,  2859,  2877,  2193,  5523,  2178,  2047,\n",
            "         9874, 10753, 12912,  3188,  2913,  3662,  3768,  6950,  7640,  2495,\n",
            "         2904,  7444,  2533,  8324,  2493,  3273,  2493,  5824,  2714,  9556,\n",
            "         2913,  2653,  4083,  2691,  3395,  5884,  2443,  3015,  3752, 16188,\n",
            "         7654,  7749,  9932,  2098,  3832,  5824,  2913,  4208,  2493,  2459,\n",
            "        19922,  2340, 10489, 10739,  2058,  2906,  8450,   102]), tensor([  101, 15756,  2897, 15058,  2094, 10629,  7861,  8270,  4667,  2892,\n",
            "        24759,  4017, 14192, 12441,  3642, 14402, 10788,  3291,  2892, 24759,\n",
            "         4017, 14192, 12441,  3642, 14402, 10788,  8704, 25952,  3251,  2048,\n",
            "        12441,  4972,  2746,  2367,  7248,  2714,  2116,  3036,  5097,  2164,\n",
            "        20228, 22974, 23061,  2213, 10788, 15451,  8059, 10788, 18130,  3945,\n",
            "         4385,  4493,  8107, 11160, 15796, 10629, 18900,  8450, 13792, 21268,\n",
            "         4030,  2823, 24949,  2524, 15581,  2047,  4708,  4769,  3314,  2147,\n",
            "        16599,  3117, 15756,  2897, 15058,  2094,  3921, 24134,  7861,  8270,\n",
            "         4667, 29464, 16371, 25531,  9207,  2241,  2491,  4834, 10629, 12441,\n",
            "         3853, 14402, 10788,  2589, 18228,  9854,  3292,  7861,  8270,  4667,\n",
            "         2015,  2048,  4972, 10408,  8773,  2170, 21424,  4866,  9312,  3065,\n",
            "        21424,  2041,  4842, 22694,  2110, 15794, 22375,  8107,  2312, 17034,\n",
            "         4847, 14402, 10788, 10640, 21424,  3177,  3188,   102]), tensor([  101,  3120, 16044, 14402, 10788, 10788,  5906,  2109, 16926, 11778,\n",
            "         3319,  5089,  3066, 20228, 22974, 23061,  2213,  3180,  3978,  3046,\n",
            "         4652, 11487, 20228, 22974, 23061,  2213,  4708,  8552,  2312,  2946,\n",
            "         4280,  2493, 21910,  2411,  3046,  5342, 20228, 22974, 23061,  2213,\n",
            "        27885, 25608, 16280,  2116,  2367, 14402, 10788,  5209,  2411,  2170,\n",
            "        20228, 22974, 23061,  2213, 10788,  5906,  2328,  2393,  5089,  3720,\n",
            "         7679, 20228, 22974, 23061,  2213, 10788,  7534,  6851, 11778,  3319,\n",
            "         2492,  3120, 16044, 20228, 22974, 23061,  2213, 10788, 16926,  3319,\n",
            "         3957, 19184, 15182, 20228, 22974, 23061,  2213, 20228, 22974, 23061,\n",
            "         2213, 10788,  5906,  7831, 12046,  2015, 27885, 25608, 10719,  4725,\n",
            "         2951, 13462,  2015,  2109,  7831,  9896,  4127, 15251,  3574,  3120,\n",
            "        16044, 20228, 22974, 23061,  2213, 10788, 16926,  3591,  2362,  4937,\n",
            "        20265,  6935, 10708,  2800, 10788,  5906, 16478,   102]), tensor([  101, 18804, 16070,  7484,  4507, 27830,  2686,  5198, 11835,  3617,\n",
            "         5200,  5901,  3352,  4507,  2047,  2088, 19852,  2015,  7976,  4454,\n",
            "         9932,  2652,  6233,  2590,  2535, 20300,  2458, 11566,  9932,  8361,\n",
            "         6786, 18804, 16070,  7480,  2047, 12020, 10047, 16862,  3512,  6322,\n",
            "         4895,  9581, 20876,  3468,  3259, 20798,  8346,  9932,  2536,  6786,\n",
            "         2164,  4274,  2477,  3796, 24925,  2078,  3019,  2653,  6364,  7484,\n",
            "         4507, 19335,  4507,  3816,  4507,  3668,  4507,  2028,  4022,  5770,\n",
            "         2478,  9932, 18804, 16070,  3754,  3443,  3167,  3550,  6322,  3265,\n",
            "         5198,  2241,  5248, 18394,  2178,  4022,  5770,  2478,  9932, 18804,\n",
            "        16070,  3754,  8285,  8585, 23563,  8518, 22198,  2051,  4219,  3375,\n",
            "         5541, 28809,  2174,  2036,  7860,  3378,  2478,  9932, 18804, 16070,\n",
            "        12725,  5310,  9394, 12786,  3314, 13827,  9147, 11131,  4022,  6666,\n",
            "         7860, 13543,  9932, 18804, 16070,  2164, 12962,   102]), tensor([  101,  4372, 28517, 19817, 19736,  5558,  7367,  9530,  3367,  6820,\n",
            "         7677,  4895,  2632, 20255,  4183,  5302,  4012, 18780, 21736,  2389,\n",
            "        11498,  2474,  4862, 22084, 10446,  2139,  3793,  2891,  4372,  2474,\n",
            "        16985,  5243,  2139, 20010,  8586, 10446,  2139, 20228, 22974,  2080,\n",
            "        12170,  2989,  5657,  3449,  2777,  7716,  2080,  2139, 20010,  8586,\n",
            "        10446,  2139, 20228, 22974,  2080, 12170,  2989,  5657,  5292,  3401,\n",
            "         2149,  2080,  3972, 14262,  7903,  3695,  2139, 19817,  4215, 14194,\n",
            "        19277,  2015,  6882,  2891,  9530,  2474,  2345, 27893,  2139,  2702,\n",
            "         2121,  3050,  6254,  2891,  4372, 23391,  3508,  4372,  4895,  8909,\n",
            "        18994,  2050,  2918, 11498,  4078, 14289,  2229,  9706, 19341,  2099,\n",
            "         8915,  2278, 12782,  2015,  2139, 20228, 22974,  2080, 18847,  2989,\n",
            "         5657,  3449,  2632, 20255,  4183,  5302, 11865,  2063,  4013,  9024,\n",
            "         2080,  9530,  3449, 13931,  2566,  6528,  8586,   102]), tensor([  101,  3019,  2653,  6364,  9009, 15685, 15397,  3274,  2671, 12374,\n",
            "        19962,  2696, 13306,  3471, 24402,  4696,  2773,  6903,  3370,  2171,\n",
            "         9178,  5038,  4385, 28081, 23541,  4106,  6981,  4937, 20265, 26910,\n",
            "         5449,  3980, 10739,  4385,  5554,  7755,  4245,  6981,  6981,  4245,\n",
            "         5554,  7755,  4385,  2197,  2086,  6529,  3316,  2583,  3443, 13792,\n",
            "         5214, 10910,  2152,  3798,  2836,  8518,  5449, 15792,  5579,  2112,\n",
            "         2478,  2502,  2951,  2755, 13792,  4685,  2092,  2312,  3815,  2951,\n",
            "         3957,  3278,  2449,  5056,  2312,  3316,  2312, 17881,  3760,  5661,\n",
            "        22752,  2015,  3800,  9459,  2424, 13792,  4725,  4621, 13729,  3019,\n",
            "         2653,  6364,  3471,  2235, 17881,  2470,  2328,  4180, 15058,  2094,\n",
            "        12832,  2291,  7718, 14402,  5761,  2397,  3372, 16101,  7033,  7485,\n",
            "        16169,  2522, 11493,  2063, 14402,  2146, 22231,  5339,  2744,  3638,\n",
            "        15756,  2897, 27634, 19064,  2036,  4102,  8122,   102]), tensor([  101,  3120, 16044, 14402, 10788, 10788,  5906,  2109, 16926, 11778,\n",
            "         3319,  5089,  3066, 20228, 22974, 23061,  2213,  3180,  3978,  3046,\n",
            "         4652, 11487, 20228, 22974, 23061,  2213,  4708,  8552,  2312,  2946,\n",
            "         4280,  2493, 21910,  2411,  3046,  5342, 20228, 22974, 23061,  2213,\n",
            "        27885, 25608, 16280,  2116,  2367, 14402, 10788,  5209,  2411,  2170,\n",
            "        20228, 22974, 23061,  2213, 10788,  5906,  2328,  2393,  5089,  3720,\n",
            "         7679, 20228, 22974, 23061,  2213, 10788,  7534,  6851, 11778,  3319,\n",
            "         2492,  3120, 16044, 20228, 22974, 23061,  2213, 10788, 16926,  3319,\n",
            "         3957, 19184, 15182, 20228, 22974, 23061,  2213, 20228, 22974, 23061,\n",
            "         2213, 10788,  5906,  7831, 12046,  2015, 27885, 25608, 10719,  4725,\n",
            "         2951, 13462,  2015,  2109,  7831,  9896,  4127, 16021, 28173, 13453,\n",
            "         2512,  3207,  3334, 25300, 10074,  3921, 10636,  4215,  2309,  2565,\n",
            "         9699,  9877, 10176,  6219, 10027, 11476, 14799,   102]), tensor([  101,  4102,  6140, 13122, 28084,  2818,  5144,  2529,  2836,  6459,\n",
            "         2048,  7976,  4454,  4432,  8387,  2030, 28727,  2026, 17683,  1015,\n",
            "        12109,  5080,  3773,  9932, 18059, 25249,  4646,  3036,  8765,  7175,\n",
            "         3737, 11712, 10232,  8080,  4295,  4264,  2947,  5038,  3269,  4295,\n",
            "         6827,  3269,  4295,  8715, 17725,  5664,  3033,  4264,  2048,  3633,\n",
            "         2033, 28329,  9353, 18518,  2028,  2422, 10617,  7718,  6397, 10371,\n",
            "         2098,  2036,  7718,  2836,  3793,  9671,  3311,  9671, 10523,  3785,\n",
            "        16157,  2529,  2836,  2356,  6818,  2224,  5733,  3535,  2260,  3752,\n",
            "         8518,  2714,  3450,  3679,  2542, 14155,  8483,  3793, 12332,  3752,\n",
            "         2825,  6140,  2946,  5688,  2422,  2504,  2036, 14155,  3633,  2071,\n",
            "         3143,  8518,  5733,  7594, 10640,  6503,  2051,  6818,  2036,  2949,\n",
            "         5002,  7175,  2048,  8387,  3463,  8387,  4719,  3618,  5345, 10640,\n",
            "         3793,  5038,  4257,  5810,  2773,  5491, 15844,   102]), tensor([  101,  7976,  4454,  2028,  8361,  6786, 23599,  2529,  4454,  6681,\n",
            "         4730,  2228,  2066,  2529,  9552, 23150,  4506,  8392,  4316,  2071,\n",
            "         3853,  4287,  4072,  4972,  2302,  2529,  6624,  9525,  2974,  3024,\n",
            "         3445,  4628,  3808,  2625, 26478, 17944,  4925, 20176,  7312, 23569,\n",
            "        28591,  4026,  4834,  2896,  4762,  8381,  2625, 10796,  2488,  3604,\n",
            "         6322,  8392,  4683,  2209,  8995,  2535,  3068,  5237,  5193,  2510,\n",
            "         5097,  8392,  4683,  3450,  3569, 13617,  2951,  7976,  4454,  3001,\n",
            "         7976,  4454,  3074,  2951,  4130,  4041,  7781,  8392,  4683,  3223,\n",
            "         3698,  4083,  5461,  2112,  7976,  4454,  2234,  9394,  3314,  3036,\n",
            "         5936,  3036,  2590,  5142,  8392,  4683,  3314, 16941,  3366, 10841,\n",
            "        15780, 13543,  7976,  4454,  8392,  4683,  3139,  3720,  2247,  3652,\n",
            "         2974,  2969, 13626, 14966, 19207,   102,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  6203,  2705, 24010, 20794,  4953,  2224,  2312,  2653,  4275,\n",
            "         2222,  5244, 14120, 27050,  8740, 16774,  2594,  5022,  2306,  2822,\n",
            "        25023,  6692,  3351,  6123,  2750,  2822,  2028,  4235,  5287,  4155,\n",
            "        16452, 21047,  2470,  3579,  4646,  4275,  2966,  2492,  2394, 13102,\n",
            "        25508,  2075,  7080, 12353,  2222,  2213, 11834, 27014,  4919, 11834,\n",
            "        21600,  2102,  2549,  2330,  4886, 14637, 28516,  2544, 20802, 21790,\n",
            "         8566,  4297,  2028,  3935,  2222,  5244,  2859, 12786, 27050,  8740,\n",
            "        16774,  2594,  3633,  2822,  4292,  6461, 14155,  2817,  2951,  5935,\n",
            "         1040, 18037,  2050,  4235,  8969, 10923, 11022,  2094,  2966, 16053,\n",
            "         4132,  2859,  5310,  2918,  2531,  2454,  3633,  2561,  2531,  5776,\n",
            "        16053,  8168, 20001,  2135,  3479,  2254,  2760,  2257, 16798,  2509,\n",
            "         3815,  2075, 23688,  3980, 15901,  7271,  2800, 19465, 16570,  4383,\n",
            "         5491,  4132,  5441,  4874,  7730,  2434,  3980,   102]), tensor([  101,  5002,  3640,  3906,  3319,  3522,  2573,  7976,  2166,  5107,\n",
            "         2396,  2627,  2871,  2086,  4919, 15078,  4007,  5884,  4072, 28667,\n",
            "         5644, 18688,  4262,  3430,  2303,  4767,  3019,  2088,  4145,  2166,\n",
            "         2396,  2124,  6643,  3726,  2126, 11131, 16636,  2075,  2047, 12020,\n",
            "         3818,  2275,  9181, 25274,  4780, 17908,  4387, 22000,  2367,  7236,\n",
            "         6614,  3073, 11778, 19184,  3324,  4824,  3267,  4526,  2047,  2166,\n",
            "         2715,  2974, 13367, 18593,  4249,  7976,  2166,  7976,  4454, 15078,\n",
            "         7366, 12553,  7366,  6233,  8361,  2270,  3193,   102,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101, 12978,  7982,  3001,  2590,  5097,  7976,  4454,  6915,  3151,\n",
            "         3001,  3305,  5310,  6699,  3073,  7861, 15069, 16530, 12247,  6832,\n",
            "         4454,  2974,  6377, 12978,  7982,  3001,  2817,  7982,  4245,  2944,\n",
            "         6832,  4454,  2580,  2784,  4083,  3019,  2653,  6364,  5461,  2898,\n",
            "         2846,  6699,  3563,  3255,  7755, 11156,  5319,  2944,  2613,  2051,\n",
            "        12067,  7861, 15069, 16530,  8290,  3024,  2291, 22380,  3463,  2817,\n",
            "         7976,  4454, 11487,  3255,  4671,  3255, 26452,  3754,  2944,  3305,\n",
            "        11259,  3787,  3255, 26452,  9412,  4292,  3020,  4781,  6832,  4454,\n",
            "         7982,  3001,  2622,  8704,  3073,  9373,  4824,  6742, 15690, 17409,\n",
            "         3935,  6832,  4454,  9859,  7982,  3001,  8558,  9229,  5310,  3325,\n",
            "         8290,  3737,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  2028,  3145,  3787,  3517,  9375,  2925,  2495,  2224,  7976,\n",
            "         4454,  6994, 11598,  4252,  4083,  6194,  2092,  2147,  5089, 15631,\n",
            "         7976,  4454, 21331,  2556,  3528,  2591, 21877,  2850,  3995, 26715,\n",
            "         6742, 12962,  2591,  3425,  3314,  7860,  3288,  3431,  4547,  6194,\n",
            "        12843, 10287,  4973,  9932,  2224,  2495,  2926,  3078,  2082, 10906,\n",
            "         3579,  5025, 13494,  3278,  4547,  4119, 10660, 12607,  2015,  3154,\n",
            "         3891,  4526,  4654, 10732, 28483,  3436,  1999,  2063, 26426,  6447,\n",
            "         2426,  2591,  2967,  5020,  3229, 16316,  8849,  4022,  3167,  6026,\n",
            "         4083, 16910,  7851,  3078,  2082, 11107,  2881,  5326,  4621, 12317,\n",
            "         4807,  4813,  6614, 14622, 12151, 10723,  5876,  4254,  4083, 10840,\n",
            "         2633,  5059,  5903,  2458,  4556,  8433,  3752, 18560,  6848, 13185,\n",
            "        10449,  7976,  4454, 21331,  8433,  5352,  5089, 12067,  6786,  4235,\n",
            "         2109,  2408,  2367,  2287,  2967,  7022,   102,     0]), tensor([  101,  2028,  3145,  3787,  3517,  9375,  2925,  2495,  2224,  7976,\n",
            "         4454,  6994, 11598,  4252,  4083,  6194,  2092,  2147,  5089, 15631,\n",
            "         7976,  4454, 21331,  2556,  3528,  2591, 21877,  2850,  3995, 26715,\n",
            "         6742, 12962,  2591,  3425,  3314,  7860,  3288,  3431,  4547,  6194,\n",
            "        12843, 10287,  4973,  9932,  2224,  2495,  2926,  3078,  2082, 10906,\n",
            "         3579,  5025, 13494,  3278,  4547,  4119, 10660, 12607,  2015,  3154,\n",
            "         3891,  4526,  4654, 10732, 28483,  3436,  1999,  2063, 26426,  6447,\n",
            "         2426,  2591,  2967,  5020,  3229, 16316,  8849,  4022,  3167,  6026,\n",
            "         4083, 16910,  7851,  3078,  2082, 11107,  2881,  5326,  4621, 12317,\n",
            "         4807,  4813,  6614, 14622, 12151, 10723,  5876,  4254,  4083, 10840,\n",
            "         2633,  5059,  5903,  2458,  4556,  8433,  3752, 18560,  6848, 13185,\n",
            "        10449,  7976,  4454, 21331,  8433,  5352,  5089, 12067,  6786,  4235,\n",
            "         2109,  2408,  2367,  2287,  2967,  7022,   102,     0]), tensor([  101, 20228, 22974, 23061,  2213,  2470,  5258,  2349,  4926, 21249,\n",
            "        20228, 22974, 23061,  2213,  2552, 23640,  2015,  9385,  2950,  4506,\n",
            "         7386,  2500, 12040,  3436,  2516,  2470,  2742,  2345,  8775,  2470,\n",
            "         2493,  8385,  7864,  4486,  5837,  2641, 20228, 22974, 23061,  2213,\n",
            "         2516,  3818,  2525,  5839,  2342,  2291, 11487, 14402,  4486,  7864,\n",
            "         4493,  4486,  3517,  5547, 14404, 20228, 22974, 23061,  2213,  2817,\n",
            "         3594,  2663, 19779,  2075,  9896,  2424,  7017, 14402,  4486,  8224,\n",
            "         6288,  2109,  6855,  2951,  2470,  4486,  3130,  2800,  7831,  4486,\n",
            "         4773, 23704, 15390,  7396, 24471,  4877,  3722, 16129, 14383, 11968,\n",
            "         8043,  2109, 12850,  2516,  2951,  8224,  6288,  3463,  2817,  4646,\n",
            "         2663, 19779,  2075,  9896,  2424,  7017, 14402,  2951,  8224,  6288,\n",
            "         2583,  2556,  7017, 12319,  3867,  4696, 10256,  8777,  5729, 20228,\n",
            "        22974, 23061,  2213,  2036,  5094,  2220, 10788,   102]), tensor([  101,  2445,  2454,  8620, 14389,  3962,  2379,  8566, 24759, 24695,\n",
            "         2015, 12702, 20464, 19966,  2545, 14997,  2788,  7755,  2529, 11626,\n",
            "         1044,  2102,  7680,  7849,  4697,  8054,  2375,  7285,  2552, 27963,\n",
            "        12702, 20464, 19966,  2545,  2379,  8566, 24759, 24695,  5491,  6179,\n",
            "         3674,  3176, 10906,  2164, 12403, 13344,  2102, 10788, 10474, 14997,\n",
            "        20228, 22974, 23061,  2213,  2556, 18558,  6182, 14273,  3084,  2206,\n",
            "         5857,  6742, 26743,  3468,  4621,  2613,  2951, 16381, 23301,  6958,\n",
            "         2094,  9034,  5310,  3207, 23460,  2094, 11709, 17841,  3085,  4531,\n",
            "         6254,  9324,  4387, 20655,  2691, 15672,  8073, 25952, 19832, 29464,\n",
            "        15672, 11234,  2296,  6254,  2236, 21335,  3468,  6012,  9844, 13100,\n",
            "         5051,  6895,  8873,  2278,  4725, 10474, 28516, 10788,  1044,  2102,\n",
            "        10788,  4414,  2092,  2653,  2981, 17841,  8010,  3391,  2590,  3424,\n",
            "        11039,  5884,  2375,  7285,  2442, 17453, 22459,   102]), tensor([  101,  4773,  2951,  5471,  4773,  2951,  5471,  2291,  2478, 12604,\n",
            "         7934,  9798,  2004,  2361,  4730,  3818,  4773,  2241,  4646,  4473,\n",
            "         4773,  5198, 12040,  5002,  2951,  2116,  2367,  3316,  5002,  3074,\n",
            "         3980,  2393,  3316,  4503,  5335,  2449,  8013,  2326,  7846, 20253,\n",
            "         5002,  2951,  4773,  4646,  4473,  5198, 12040,  2951,  5973,  5002,\n",
            "         2951,  5067,  7809,  4106,  8911,  4773,  4646,  8833,  2378,  2291,\n",
            "         3193,  2951,  7864,  4773,  4646, 11665,  4773,  8241,  7809, 11665,\n",
            "         5796, 29296,  8241,   102,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  5577,  7551,  2311,  4007,  5214, 11717,  5260,  3780,  4486,\n",
            "        12978,  4827,  2592,  4663,  4274,  9373,  6061,  2474,  3351,  2525,\n",
            "         3024,  2203,  2197,  2301,  2241,  4659, 11841,  3722,  3252,  2828,\n",
            "         2466,  2810, 27777,  6630,  5449, 20231,  3408,  8128,  3274, 15389,\n",
            "         3259,  2036, 15841,  3276,  2554,  6028,  2974,  2437,  4766,  2381,\n",
            "         4955,  3617,  7300,  2739, 29020, 14670,  2458,  2589, 18750,  4730,\n",
            "         2653, 17953,  2102,  2243,  3019,  2653,  6994, 23615,  3075,  2109,\n",
            "         3463,  6142,  4715,  2528,  2286,  2405,  4274,  9445,  2951,  3120,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  9123,  4007,  6074, 11834, 27014, 20519,  2109,  2181,  2740,\n",
            "         2092, 19205,  3070,  5097,  6074,  8526,  5198,  6970, 28823, 11450,\n",
            "         1041,  2290,  7748,  7216,  5248, 22305,  2063, 19388,  3445,  2342,\n",
            "         4824,  6074,  7861, 25940,  9859,  2783,  2110, 15794, 22375,  5906,\n",
            "         2344,  3305,  7861, 25940,  9859,  9123,  4007,  6074,  2342, 10480,\n",
            "         9366, 26452,  3906, 15841,  3528, 15182, 26452, 10465,  5337,  6210,\n",
            "         2241, 11778,  3906,  3319, 24209, 11475, 27453,  4106,  3522,  8107,\n",
            "        26452,  9123,  6074,  2740,  2092, 19205,  3070,  5337,  6210,  2319,\n",
            "         3031,  6483, 11253, 26452,  2764,  2556,  4022,  5337,  6210,  4758,\n",
            "         5198,  8525,  5149, 11243,  6994, 20077, 26452,  2048,  2110, 15794,\n",
            "        22375,  2740,  2092, 19205,  3070, 11834, 27014, 16360, 25421,  1059,\n",
            "         7274,  2050,  9123,  4007,  6074, 11834, 27014, 20519,  2109,  2181,\n",
            "         2740,  2092, 19205,  3070,  5097,  6074,  8526,   102]), tensor([  101,  4207,  2592,  2565, 20228, 22974, 23061,  2213, 10788,  8050,\n",
            "         3160,  2592,  3399,  3274,  2671,  5468, 14402,  3815,  4207,  2592,\n",
            "         2048, 10071,  3818, 12046,  2241, 12849, 13728, 22844, 12298, 11619,\n",
            "         3437,  3160, 10003,  5415,  6611, 12046,  9854,  3815,  4207,  2592,\n",
            "         2048,  3274,  3454,  9585, 20228, 22974, 23061,  2213, 10788,  2881,\n",
            "         7528,  6742,  2291, 15765,  4007, 11109, 11616,  2291, 15796,  2015,\n",
            "        12046,  2002,  9496, 10074, 13379,  9896,  6388,  3463, 10580, 15765,\n",
            "         3154, 12637, 20228, 22974, 23061,  2213, 10788,  3001, 15765,  2291,\n",
            "         8241,  3784, 16770, 15794,  8059, 26282,  2378, 14192, 17592, 25974,\n",
            "        24932,  4135, 24755,  5332,  2094,   102,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  3623,  2193,  8013, 10821,  2419,  3623,  2193,  2373,  8013,\n",
            "         2326,  2147,  4449,  4525,  4945,  9611,  9608,  7670,  6304,  2051,\n",
            "        12473,  8013,  2326,  3737,  2373,  4425,  4879,  9611,  3471,  3793,\n",
            "        14402, 10788,  4118,  2373,  8013,  2326,  2147,  2344,  2241,  1056,\n",
            "         8873, 20952,  9896,  3818,  4118,  3594,  4773, 26988,  2099,  2974,\n",
            "         6855,  2373,  8013,  2326,  2147,  2344,  3793, 17463,  3217,  9623,\n",
            "         8583,  3793,  2164,  2822,  2773,  6903,  3370, 15363,  2616,  3793,\n",
            "         6630,  1056,  8873, 20952,  9896,  2109, 14817, 17463,  3217,  9623,\n",
            "         6924,  3793,  3145, 22104,  6855,  3145, 18351,  3635,  2241,  3635,\n",
            "         2522, 11493,  2063,  3292,  4118,  2109, 18422,  3793, 14402,  3793,\n",
            "         3145, 22104,  2367,  2373,  8013,  2326,  2147,  4449,  3463,  2265,\n",
            "         4102, 10788,  4118,  2241, 18215,  2773,  6251,  9207, 10788,  4118,\n",
            "         2241,  8893,  2944, 10788,  4118,  2241, 19780,   102]), tensor([  101,  6882, 20228, 22974, 23061,  2213, 10788,  3344,  6195,  4431,\n",
            "        13931, 10027,  3793,  4102,  2275,  2434,  5491,  2344, 14396, 20228,\n",
            "        22974, 23061,  2098,  3793, 10341,  4022,  3120,  2028,  5221,  8190,\n",
            "         4708, 12453, 20228, 22974, 23061,  2098, 10341,  6310,  2128, 18351,\n",
            "         2075, 23851,  3972, 20624,  2239,  2742,  3120,  3793,  6210,  5372,\n",
            "         3793, 24839,  7831,  3197, 10027,  2434,  6981, 10232,  3112,  2785,\n",
            "         5097,  7885,  8316, 13931,  2265,  2190,  3463,  4663,  6195,  2659,\n",
            "         2504,  2773, 12835,  6444,  2015, 18539,  1050,  2603,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101, 11910,  2047, 22921,  3811,  2714, 22921,  3130,  2405, 10485,\n",
            "         3711,  2095, 20906,  3906, 19960,  4179,  2894,  2104,  9363,  6072,\n",
            "         5197,  4495, 10195, 15814, 10788,  2291,  6709,  3811,  2714,  3793,\n",
            "         7864, 10485,  3319, 21160,  2047,  4007, 15058,  2094,  2578,  3293,\n",
            "         2489,  3073, 10673, 11343,  5906,  3640,  2126, 19115,  8343, 10485,\n",
            "         3710, 28283, 22787,  6854,  9859,  2578,  8137,  9839,  3701,  9509,\n",
            "        11343,  3143,  2791,  3906,  7888,  2047, 10861,  5134,  4102,  3293,\n",
            "         4007,  2881, 10788, 20228, 22974, 23061,  2213,  2152,  2082,  2267,\n",
            "         4981,  2174,  2560,  7408, 15058,  2094,  2326,  2892,  2890,  2546,\n",
            "         1015,  2489,  2326,  3802, 28522, 23809,  2290,  2881,  4539,  3791,\n",
            "        20906,  4772,  3068,  2592,  2536,  2578,  4973,  2828,  3850,  8553,\n",
            "         6434,  2477,  2342,  2641,  8544, 10195, 15814, 17739,  2478,  2578,\n",
            "         3024,  1039,  2249,  2842, 14356,  4297,  2916,   102]), tensor([  101,  7976,  4454, 11834, 27014, 10836,  6813,  3068, 11427,  2659,\n",
            "         3465,  2152,  8122,  2174,  3747,  6832, 11423, 11834, 27014,  2326,\n",
            "        13105,  2363,  2172,  3086,  6950,  5059,  2588,  5987, 11656, 13302,\n",
            "         3399, 10641,  6832, 11423, 11834, 27014,  7461,  8013,  9967,  2478,\n",
            "         2093,  7885,  6123,  7538,  8432, 11433, 11834, 27014, 11423,  5142,\n",
            "         6304,  5335,  8013,  9967,  8161,  5987, 11656, 13302,  3327,  6304,\n",
            "         3125, 10296,  2529, 10359,  2791, 11834, 27014, 22128,  2015,  3276,\n",
            "         2828,  6304, 11834, 27014,  8777,  4997,  3276,  6832,  3670,  5987,\n",
            "        11656, 11371,  7297,  2817, 11637, 13185,  6813,  3316,  5362,  2640,\n",
            "        11834, 18384, 10266, 25705,  6304, 10908, 12725,  5703,  8122,  7861,\n",
            "        15069, 16530,  4807, 13543,  6832,  4454, 11834, 18384,  2640,  6813,\n",
            "         5661, 11598,  8013,  9967,  2036,  6469,  6428,  3167,  3550,  7264,\n",
            "         7396, 12260,  2470,  6083,  2925,  2913,  3972,   102]), tensor([  101, 20228, 22974, 23061,  2213,  2116,  2367,  3267,  2015,  7478,\n",
            "        24731,  6981, 16151,  4784,  2302,  3228,  4923,  4761,  8844,  3259,\n",
            "         7534,  2047, 25274, 20228, 22974, 23061,  2213, 11637,  5966, 18204,\n",
            "        20228, 22974, 23061,  2213,  9414, 20228, 22974, 23061,  2213, 20228,\n",
            "        22974, 23061,  3215, 14260,  2391,  3193, 25274,  6753,  2784,  4824,\n",
            "         2367, 12158,  7060, 16873, 20228, 22974, 23061,  2213,  2742,  5278,\n",
            "         6981, 21641,  3973,  5662,  2367,  2616,  3029,  2460,  7406,  6981,\n",
            "         4145,  2236,  3989, 12827, 16151,  4784,  2590,  5857,  2500,  2367,\n",
            "        25304,  2838,  2839,  4697,  2367, 20228, 22974, 23061,  2213,  4127,\n",
            "         6936, 11778,  7705,  2015,  4725, 18847,  2989,  8787,  4654, 18886,\n",
            "         3619,  2594, 23807,  2892,  2989,  8787, 20228, 22974, 23061,  2213,\n",
            "        10788, 12876, 23900, 20228, 22974, 23061,  2213,  4127,  3205, 25274,\n",
            "         6204,  4866,  2817,  2110, 15794, 22375,  5461,   102]), tensor([  101, 20228, 22974, 23061,  2213,  2028,  3596,  3834, 23337,  2015,\n",
            "        18636,  3463, 12532,  4648,  4726,  8144,  3974,  3404,  3834,  2451,\n",
            "        14440, 20228, 22974, 23061,  2213,  3834,  5523,  2965, 14402, 25304,\n",
            "         8417, 11091,  4262,  7297,  4233,  2944,  3818,  4118, 20228, 22974,\n",
            "        23061,  2213, 10788, 16157,  4118,  2478,  2048,  4127,  2951, 13462,\n",
            "         8419,  8285,  5332, 12274, 13776,  1998,  2386, 28488, 13224,  2951,\n",
            "        13462,  7551,  3065,  4118,  2041,  4842, 22694, 26163,  3594, 14402,\n",
            "        25304,  8417,  8285,  5332, 12274, 13776,  2951, 13462, 21118, 13224,\n",
            "         2028,  9353,  2140,  4942,  2850, 18260,  2102,   102,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  7976,  2236,  4454,  2801, 13834, 25613,  4005, 13368,  7976,\n",
            "         4454,  9932, 22901,  7505, 15194,  2521, 26849, 12785,  2529,  9273,\n",
            "         2801,  2105,  2144,  2220,  2458,  9932,  2144, 16820,  9932,  2089,\n",
            "        16582,  2875,  4286,  3395,  2116,  7214,  2470,  2573,  2147,  7534,\n",
            "         2048,  3278,  9849,  4310,  4118, 12515,  2867,  3563, 10069,  3081,\n",
            "         2208,  2951,  3698,  4083,  4725, 19293,  2208,  2291, 13495,  6074,\n",
            "         8080,  2867,  7404,  6322, 21573,  7524,  6177,  2424,  6314,  3436,\n",
            "         3176,  3350,  5310,  2913,  7778,  7784,  5604,  6083,  4118,  2089,\n",
            "        12992,  6911, 10089,  2371, 27911,  2015,  4525, 10377,  2075, 10355,\n",
            "         3325,  3327,  3579,  1017,  3563,  2945,  2715,  9932,  2015,  4503,\n",
            "         2801,  2784, 15756,  6125,  2783, 21505,  3053,  7976,  4454,  4725,\n",
            "         3532,  5347, 12943,  2072, 13368,  2349,  2116, 12546,  3568,  5081,\n",
            "         2746,  3522,  9932,  2679,  4682, 12943,  2072,   102]), tensor([  101,  3720,  8970,  2944, 26404, 14098,  2491,  4919,  2881,  3439,\n",
            "         3121,  3818,  2291,  2764, 12379, 22834,  2102,  6502,  6055,  3375,\n",
            "         2897, 13907,  8080,  7169, 18213,  3798, 12826, 22761,  3798, 10101,\n",
            "         3612,  3177,  6133, 17462,  2291,  2491,  2944, 13495,  2828,  2475,\n",
            "        18001,  7961, 13384, 12067, 15581,  6567,  2241,  8015,  2300, 16326,\n",
            "         9525,  2944,  2947,  3640,  9414,  2291,  6605,  4592,  3785,  3439,\n",
            "         3121,  2291,  5361,  7718,  2214, 12161,  2311,  2470,  3463, 10580,\n",
            "         8122,  2139, 28600, 28173, 10803, 10124,  3465,   102,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  7976,  4454,  2495,  9932,  2098,  2470,  6461,  2490,  3076,\n",
            "         4083,  6322,  9932, 13100,  6592, 12962, 11174,  2894, 13990,  4072,\n",
            "        12045,  5136,  3314,  2066, 26935, 17842, 16987, 13827, 12645,  4034,\n",
            "        10502,  3227,  2590, 10782, 12962,  2477,  2477, 12962,  2135,  4824,\n",
            "         2437, 21877,  2850,  3995, 26715,  9804, 12962,  9529,  6061,  4895,\n",
            "        18447, 21945,  8465,  2174, 12786,  3141,  3980,  2521,  3722,  2034,\n",
            "         3357,  2875, 12786,  4187,  6578,  4778,  3438,  9932,  2098,  2451,\n",
            "         2015,  2877,  6950,  6869,  5002,  9615,  4646,  9932,  4547, 18046,\n",
            "         3259,  2034,  8970,  3314,  4193,  9615,  9932,  2495,  2279,  7680,\n",
            "         7849,  4697,  5857,  2459, 25094,  6848,  3375,  3314,  2992,  3563,\n",
            "        13105,  2421,  5038,  9932,  2098,  6950,  4738, 11147,  8361, 12962,\n",
            "         3980,  2092,  6155, 23773,  2098,  7705, 11973,  9615,  9932,  2098,\n",
            "        11566,  4800, 10521,  6895, 28296,  5649,  3921,   102]), tensor([  101,  3720, 20798,  6666, 10831,  7976,  4454,  9932,  2495,  7189,\n",
            "         8050,  2529,  2916,  3720,  2241,  7327,  8040, 17686,  2817,  2022,\n",
            "         7389, 11927,  1038,  2210,  5558,  7295,  1052, 22762,  1052, 10210,\n",
            "         7352,  1060, 22200,  7878,  6511,  5974,  2418,  2502,  2951,  8822,\n",
            "         4547,  3001, 10765,  5523,  2436,  2647,  2586, 16770, 14289, 16558,\n",
            "        21261,  3366, 10976,  4502, 13765,  2368, 14289, 16558, 21261,  3207,\n",
            "        14162, 14289, 16558, 21261,  2683,  2549, 27421,  2629, 11329,  2620,\n",
            "        22610,  2509,  2063, 14526,  2063,  2581, 21996, 17914,  2487, 11057,\n",
            "        23352,  2098,  2581,  2487, 27717,  2817,  3138,  4070,  4022,  9932,\n",
            "         2502,  2951,  3073,  4621,  8822,  2495,  2291,  2613,  7292,  2036,\n",
            "        10592, 13494,  8050,  2529,  2916, 22467,  5089, 26262,  4106, 11637,\n",
            "         2342,  5703,  6666, 10831,  9932,  5906,  2764, 11625,  7333,  7091,\n",
            "         4567,  2655,  7861,  8270,  9584,  6666, 10831,   102]), tensor([  101,  2028,  5628,  3698,  4083,  2784,  4083,  2944,  4117,  7976,\n",
            "         4454,  4235,  2109,  2492,  3274,  4432,  2974,  3746,  5038,  2492,\n",
            "         3421,  2966,  3746,  4106,  2036,  4975,  5056, 11160,  2529,  5754,\n",
            "        17287,  3508,  4352,  3274,  6807,  2832,  3444,  2592, 16647,  4286,\n",
            "         2944,  2731,  2832, 10910,  2130, 17003, 10640,  2529,  6364,  2241,\n",
            "         2236,  3768,  4863,  8010,  3303,  4242,  2951,  6364,  2832,  2784,\n",
            "         2944,  4493,  7300,  3701,  2421,  5069,  4722,  4863,  8010,  3086,\n",
            "         7337,  7613,  3563,  4275,  7613,  4895,  2243, 19779,  3085,  4275,\n",
            "         3421, 14123,  2126, 20155,  2135, 14358, 17841,  8010,  2145, 10641,\n",
            "         2926, 17841,  8082,  7667,  7435,  5022,  2966,  3247, 16570,  4383,\n",
            "         4275,  2195,  9539,  3818,  4431,  2783,  2470,  4646,  7976,  4454,\n",
            "         2784,  4083,  4275,  2966, 12126,  3227, 12778,  3086, 10640,  2738,\n",
            "         4863,  8010,  4525,  3768,  4863,  8010,  2947,   102]), tensor([  101, 12761, 22334,  4942,  3790,  7976,  4454,  7976,  2166,  7356,\n",
            "         2224,  6897,  2135,  4427,  4725,  9611, 20600,  3471,  2009, 25284,\n",
            "        25416,  3170,  8163,  2275,  7300,  3081,  2689,  4989,  3921,  2211,\n",
            "         4856,  8681,  3652,  2275, 13792,  5214, 13729,  2898,  2846,  3471,\n",
            "         4055,  2536,  4127, 16965,  4989, 16221,  6630,  4018,  7300,  3144,\n",
            "         5097,  2680,  3674, 13100,  2164, 20600,  3698,  4083, 21331,  2536,\n",
            "         2752,  2817,  2542,  3001, 12761, 22334,  3728,  5281,  6308,  3391,\n",
            "         2817,  2330, 21945,  6622,  3278, 13494,  2925,  9932,  4310,  4022,\n",
            "         9699, 10866, 15463,  2599, 20680,  5670,  2458,  7976,  4454,  7976,\n",
            "         2166,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  2627,  5109,  2193,  4683,  2346, 10862,  3445,  2349,  3652,\n",
            "         5157,  3923, 12969,  2715, 12708, 12058,  4683,  2419,  3278,  3314,\n",
            "        21106,  4026, 20176,  3445,  4026, 13436, 17666,  2121,  3171,  2458,\n",
            "         7860,  6464,  8280,  2437,  4683, 25670,  8161, 18642,  2529,  6853,\n",
            "         2627,  2301,  4866,  2470,  4146,  2536,  3741, 15801, 19309,  2346,\n",
            "         4683,  2651,  2350,  5013,  8712,  4969,  8851,  4975,  8392,  4316,\n",
            "        20704,  6786, 12607,  2015,  7976,  4454,  9932,  6923,  9886,  8392,\n",
            "         3765,  3553,  2453,  5987,  9932,  2468,  4187,  5783, 20704,  2015,\n",
            "        12067, 23084,  4044,  2191,  2613,  7292,  6567, 14125,  5082,  9932,\n",
            "        17999, 20250,  2502,  2951,  3365, 13851,  5733,  3935,  9798,  4219,\n",
            "         3929,  3305,  9932,  2015,  2535, 20704,  3001,  6827,  8849,  2458,\n",
            "         3439,  6123,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  3259,  3640,  7721,  3906,  3319,  2470,  4646,  3698,  4083,\n",
            "        19875, 13792, 16755,  2121,  3001, 12667,  2817,  8704,  6709,  3522,\n",
            "        12878,  8849,  2613, 15509,  5097,  5009,  6950, 19120,  2470,  3450,\n",
            "         5884,  5266,  5523,  2254,  2238, 16798,  2509,  9556, 20427,  2536,\n",
            "        13100,  2164,  2495,  9871, 19875, 13792,  8285,  2368, 16044,  2869,\n",
            "        23895,  4083, 17338, 15810,  3401,  3617,  8083,  3319, 20618,  5301,\n",
            "        12832, 10640,  3445, 26743,  8553,  3167,  3989,  6123,  7073,  2092,\n",
            "         7578, 19875,  5461,  9942,  8304,  3147,  2707,  2951, 12403,  2869,\n",
            "         3012,  5678, 19764,  2598,  6198,  2925, 12607,  2015, 19875, 13792,\n",
            "        12667,  2015,  3391,  6123,  5814,  9926,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])], 'attention_mask': [tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reformateo de tensores de tokens"
      ],
      "metadata": {
        "id": "-d_zR4R1Bg5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para reformatear los tensores de tokens\n",
        "def reformat_tesnsors(token):\n",
        "  # Reformatear lista de tensores a un solo tensor\n",
        "  token['input_ids'] = torch.stack(token['input_ids'])\n",
        "  token['attention_mask'] = torch.stack(token['attention_mask'])\n",
        "  # Procesar tokens a través del modelo\n",
        "  output = model(**token)\n",
        "  output.keys()\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "id": "8jBrooC-A91D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener salidas del modelo para los tokens de plagio, construcción y prueba\n",
        "plag_output = reformat_tesnsors(plagiarism_token)\n",
        "cons_output = reformat_tesnsors(construction_token)\n",
        "test_output = reformat_tesnsors(test_token)"
      ],
      "metadata": {
        "id": "3ZGq1IVKBqMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Los vectores densos de las representaciones de texto están en el tensor 'last_hidden_state'\n",
        "plag_embeddings = plag_output.last_hidden_state\n",
        "cons_embeddings = cons_output.last_hidden_state\n",
        "test_embeddings = test_output.last_hidden_state\n",
        "\n",
        "# Impresion de los embeddings\n",
        "print(f'Plagiarism: {plag_embeddings}')\n",
        "print(f'Construction: {cons_embeddings}')\n",
        "print(f'Test: {test_embeddings}')"
      ],
      "metadata": {
        "id": "fVDJM6lECKI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aplicación de máscaras a los embeddings"
      ],
      "metadata": {
        "id": "-mz-OgTmEdTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para aplicar máscaras a los embeddings\n",
        "def apply_masks(token_dict, embeddings):\n",
        "    att_mask = token_dict['attention_mask']\n",
        "    mask = att_mask.unsqueeze(-1).expand(embeddings.size()).float()\n",
        "    mask_embeddings = embeddings * mask\n",
        "    return mask_embeddings, mask"
      ],
      "metadata": {
        "id": "UGdjN4kiEeQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener máscaras para los tokens de plagio, construcción y prueba\n",
        "mask_plag_embeddings, mask_plag = apply_masks(plagiarism_token, plag_embeddings)\n",
        "mask_cons_embeddings, mask_cons = apply_masks(construction_token, cons_embeddings)\n",
        "mask_test_embeddings, mask_test = apply_masks(test_token, test_embeddings)\n",
        "\n",
        "# Impresion de los tamaños de las máscaras\n",
        "print(f'Plagiarism: {mask_plag_embeddings.shape}')\n",
        "print(f'Construction: {mask_cons_embeddings.shape}')\n",
        "print(f'Test: {mask_test_embeddings.shape}')"
      ],
      "metadata": {
        "id": "pyYBhPC1FkM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Promedio de los embeddings"
      ],
      "metadata": {
        "id": "4X25EU6VGjpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para promediar los embeddings\n",
        "def mean_pool_embeddings(masked_embeddings, mask):\n",
        "    summed_embeddings = torch.sum(masked_embeddings, 1)\n",
        "    summed_mask = torch.clamp(mask.sum(1), min=1e-9)\n",
        "    mean_pooled = summed_embeddings / summed_mask\n",
        "    return mean_pooled"
      ],
      "metadata": {
        "id": "Q8wiNYFsGnG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener los promedios de los embeddings de plagio, construcción y prueba\n",
        "plag_mean_pooled = mean_pool_embeddings(mask_plag_embeddings, mask_plag)\n",
        "cons_mean_pooled = mean_pool_embeddings(mask_cons_embeddings, mask_cons)\n",
        "test_mean_pooled = mean_pool_embeddings(mask_test_embeddings, mask_test)\n",
        "\n",
        "# Impresion de los promedios de los embeddings\n",
        "print(f'Plagiarism: {plag_mean_pooled}')\n",
        "print(f'Construction: {cons_mean_pooled}')\n",
        "print(f'Test: {test_mean_pooled}')"
      ],
      "metadata": {
        "id": "j9BN1ItRHBIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cálculo final de similitud de coseno"
      ],
      "metadata": {
        "id": "wmRFdzBRHdXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir del tensor de PyTorch a una matriz numpy\n",
        "plag_mean_pooled = plag_mean_pooled.detach().numpy()\n",
        "cons_mean_pooled = cons_mean_pooled.detach().numpy()\n",
        "test_mean_pooled = test_mean_pooled.detach().numpy()"
      ],
      "metadata": {
        "id": "UIfiSLlSH_fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para calcular similitud de coseno\n",
        "def calculate_cosine_similarity(embeddings1, embeddings2):\n",
        "  for i in range(len(embeddings1)):\n",
        "    similarities = cosine_similarity(\n",
        "        [embeddings1[i]],\n",
        "        embeddings2\n",
        "    )\n",
        "    print(f'Array de similitudes: {similarities}')\n",
        "\n",
        "    # Operaciones para encontrar la similitud más alta y su índice\n",
        "    max_similarity_index = similarities.argmax()\n",
        "    max_similarity_value = similarities[0, max_similarity_index]\n",
        "    print(f\"Archivo {i} es más similar a archivo {max_similarity_index} con una similitud de {max_similarity_value}\")\n",
        "    print('---------------------------------------------------------------------')\n",
        "\n",
        "  return similarities"
      ],
      "metadata": {
        "id": "_jALDAx_JRMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para calcular similitud de coseno y determinar plagio\n",
        "def calculate_plagiarism(test_files, test_embeddings, construction_files, construction_embeddings, threshold=0.9):\n",
        "    similarity_scores_list = []\n",
        "    plagiarism_results = []\n",
        "\n",
        "    for test_file, test_embedding in zip(test_files, test_embeddings):\n",
        "        similarity_scores = cosine_similarity([test_embedding], construction_embeddings)[0]\n",
        "        max_similarity = max(similarity_scores)\n",
        "        percentage_plagiarism = round(max_similarity * 100, 2)\n",
        "\n",
        "        plagiarized_files = [(os.path.basename(construction_file), score) for score, construction_file in zip(similarity_scores, construction_files) if score >= threshold]\n",
        "\n",
        "        plagiarism_detected = len(plagiarized_files) > 0\n",
        "        plagiarism_results.append({\n",
        "            'Documento sospechoso': os.path.basename(test_file),\n",
        "            'Copia': 'Sí' if plagiarism_detected else 'No',\n",
        "            'Documento Plagiado': ', '.join([file for file, score in plagiarized_files]) if plagiarized_files else 'Ninguno',\n",
        "            '% de Plagio': f'{percentage_plagiarism} %' if plagiarized_files else ''\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(plagiarism_results)"
      ],
      "metadata": {
        "id": "quTPHfjBjQbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la similitud de coseno entre los archivos de prueba y de construcción\n",
        "cosine_similarity_result_tc = calculate_cosine_similarity(test_mean_pooled, cons_mean_pooled)"
      ],
      "metadata": {
        "id": "3u3FRt45KMSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular Plagio entre los archivos de prueba y de construcción\n",
        "plagiarism_df_tc = calculate_plagiarism(test_files, test_mean_pooled, construction_files, cons_mean_pooled)\n",
        "print(plagiarism_df_tc)"
      ],
      "metadata": {
        "id": "HjLl0VURiwDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la similitud de coseno entre los archivos de plagio y de construcción\n",
        "cosine_similarity_result_pc = calculate_cosine_similarity(plag_mean_pooled, cons_mean_pooled)"
      ],
      "metadata": {
        "id": "edAPHfGYLslx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular Plagio entre los archivos de plagio y de construcción\n",
        "plagiarism_df_pc = calculate_plagiarism(plagiarism_files, plag_mean_pooled, construction_files, cons_mean_pooled)\n",
        "print(plagiarism_df_pc)"
      ],
      "metadata": {
        "id": "riQu3aJfl7CY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluación del rendimiento"
      ],
      "metadata": {
        "id": "ZJMqIXGVouGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para calcular TPR, FPR y AUC\n",
        "def calculate_metrics(y_true, y_pred, threshold=0.9):\n",
        "    y_pred_labels = [1 if score >= threshold else 0 for score in y_pred]\n",
        "\n",
        "    tp = sum((yt == 1 and yp == 1) for yt, yp in zip(y_true, y_pred_labels))\n",
        "    tn = sum((yt == 0 and yp == 0) for yt, yp in zip(y_true, y_pred_labels))\n",
        "    fp = sum((yt == 0 and yp == 1) for yt, yp in zip(y_true, y_pred_labels))\n",
        "    fn = sum((yt == 1 and yp == 0) for yt, yp in zip(y_true, y_pred_labels))\n",
        "\n",
        "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "\n",
        "    auc = roc_auc_score(y_true, y_pred)\n",
        "\n",
        "    return tpr, fpr, auc"
      ],
      "metadata": {
        "id": "97iaH8HRdIQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluación del rendimiento con los dataset del profesor\n",
        "y_true_tc = [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
        "y_pred_tc = [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
        "\n",
        "# Calcular métricas\n",
        "tpr, fpr, auc = calculate_metrics(y_true_tc, y_pred_tc)\n",
        "print(f'TPR: {tpr}, FPR: {fpr}, AUC: {auc}')"
      ],
      "metadata": {
        "id": "PdHevFC_sfkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parte 2: Clasificación de \"Tipo de Plagio\""
      ],
      "metadata": {
        "id": "VgSnkXn0s68d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Clasificación de archivos"
      ],
      "metadata": {
        "id": "JK4f3HdlKnXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para obtener la clasificación de un archivo basado en su nombre\n",
        "def obtener_clasificacion(nombre_archivo):\n",
        "    numero = int(nombre_archivo.split('-')[-1].split('.')[0])\n",
        "    if numero >= 1 and numero <= 10:\n",
        "        return 'Reemplazar frases'\n",
        "    elif numero >= 11 and numero <= 20:\n",
        "        return 'Desordenar las frases'\n",
        "    elif numero >= 21 and numero <= 30:\n",
        "        return 'Cambio de tiempo'\n",
        "    elif numero >= 31 and numero <= 40:\n",
        "        return 'Cambio de voz'\n",
        "    elif numero >= 41 and numero <= 50:\n",
        "        return 'Parafraseo'\n",
        "    elif numero >= 51 and numero <= 60:\n",
        "        return 'Reemplazar frases'\n",
        "    elif numero >= 61 and numero <= 70:\n",
        "        return 'Desordenar las frases'\n",
        "    elif numero >= 71 and numero <= 80:\n",
        "        return 'Cambio de tiempo'\n",
        "    elif numero >= 81 and numero <= 90:\n",
        "        return 'Cambio de voz'\n",
        "    elif numero >= 91 and numero <= 100:\n",
        "        return 'Parafraseo'\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "1w6uoIaCs6Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directorios de los archivos\n",
        "directorio_original = '/content/drive/MyDrive/RetoDesarrollo/dataset/train'\n",
        "directorio_plagio = '/content/drive/MyDrive/RetoDesarrollo/dataset/plagiarism'\n",
        "\n",
        "# Función para leer archivos de un directorio\n",
        "def leer_archivos(directorio):\n",
        "    archivos = {}\n",
        "    for archivo in sorted(os.listdir(directorio)):\n",
        "        if archivo.endswith('.txt'):\n",
        "            ruta_archivo = os.path.join(directorio, archivo)\n",
        "            with open(ruta_archivo, 'r', encoding='utf-8') as f:\n",
        "                contenido = f.read()\n",
        "            archivos[archivo] = contenido\n",
        "    return archivos\n",
        "\n",
        "# Leer archivos de ambos directorios\n",
        "archivos_originales = leer_archivos(directorio_original)\n",
        "archivos_plagio = leer_archivos(directorio_plagio)\n",
        "\n",
        "# Lista para almacenar los datos\n",
        "datos = []\n",
        "\n",
        "# Emparejar archivos según el patrón de nombre\n",
        "for nombre_archivo_plagio in archivos_plagio:\n",
        "    # Eliminar el prefijo 'not-' del nombre del archivo de plagio para obtener el nombre correspondiente del archivo original\n",
        "    nombre_archivo_original = nombre_archivo_plagio.replace('not-', '', 1)\n",
        "\n",
        "    if nombre_archivo_original in archivos_originales:\n",
        "        contenido_original = archivos_originales[nombre_archivo_original]\n",
        "        contenido_plagio = archivos_plagio[nombre_archivo_plagio]\n",
        "        # Obtener el tipo de plagio usando la función obtener_clasificacion\n",
        "        tipo = obtener_clasificacion(nombre_archivo_plagio)\n",
        "        datos.append({\n",
        "            'Contenido_Original': contenido_original,\n",
        "            'Contenido_Plagio': contenido_plagio,\n",
        "            'Clasificacion': tipo\n",
        "        })\n",
        "\n",
        "# Crear DataFrame\n",
        "df = pd.DataFrame(datos)\n",
        "\n",
        "# Mostrar DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "id": "CqJN5j-jJs8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir el DataFrame en características y etiquetas\n",
        "X = df.drop(columns=['Clasificacion'])\n",
        "y = df['Clasificacion']\n",
        "\n",
        "# Usar train_test_split para dividir el DataFrame en conjuntos de entrenamiento y prueba, asegurando el balanceo de clases\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Combinar de nuevo las características y etiquetas para obtener los DataFrames finales\n",
        "train_df = pd.concat([X_train, y_train], axis=1)\n",
        "test_df = pd.concat([X_test, y_test], axis=1)\n",
        "\n",
        "# Mostrar los tamaños de los conjuntos de datos resultantes para verificación\n",
        "print(f\"Tamaño del conjunto de entrenamiento: {train_df.shape}\")\n",
        "print(f\"Tamaño del conjunto de prueba: {test_df.shape}\")\n"
      ],
      "metadata": {
        "id": "N47G4VD8JwCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Seleccionar etiquetas únicas dentro de la columna clasificación\n",
        "print(train_df['Clasificacion'].unique())"
      ],
      "metadata": {
        "id": "Xw9B2WXmJyVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "ONE HOT ENCODING PARA TRAIN\n",
        "'''\n",
        "# Aplicar One-Hot Encoding a la columna 'Clasificacion'\n",
        "one_hot_encoded = pd.get_dummies(train_df['Clasificacion'], dtype=int)\n",
        "\n",
        "# Concatenar el DataFrame original con las columnas One-Hot Encoding\n",
        "train_df_encoded = pd.concat([train_df, one_hot_encoded], axis=1)\n",
        "\n",
        "# Eliminar la columna original 'Clasificacion'\n",
        "train_df_encoded.drop('Clasificacion', axis=1, inplace=True)\n",
        "\n",
        "# Mostrar el DataFrame resultante con One-Hot Encoding\n",
        "print(train_df_encoded)"
      ],
      "metadata": {
        "id": "SAGfoUTFJ5_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "ONE HOT ENCODING PARA TEST\n",
        "'''\n",
        "# Aplicar One-Hot Encoding a la columna 'Clasificacion'\n",
        "one_hot_encoded = pd.get_dummies(test_df['Clasificacion'], dtype=int)\n",
        "\n",
        "# Concatenar el DataFrame original con las columnas One-Hot Encoding\n",
        "test_df_encoded = pd.concat([test_df, one_hot_encoded], axis=1)\n",
        "\n",
        "# Eliminar la columna original 'Clasificacion'\n",
        "test_df_encoded.drop('Clasificacion', axis=1, inplace=True)\n",
        "\n",
        "# Mostrar el DataFrame resultante con One-Hot Encoding\n",
        "print(test_df_encoded)"
      ],
      "metadata": {
        "id": "0py2mhCPJ8fN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_labels = train_df_encoded.columns.tolist()[2:]\n",
        "label_counts = train_df_encoded[column_labels].sum().sort_values()\n",
        "\n",
        "# Crear un fondo para la gráfica\n",
        "plt.figure(figsize=(7, 5))\n",
        "\n",
        "# Crear un gráfico de barras horizontal usando Seaborn\n",
        "ax = sns.barplot(x=label_counts.values,\n",
        "                 y=label_counts.index, palette='viridis')\n",
        "\n",
        "# Añadir etiquetas y título a la gráfica\n",
        "plt.xlabel('Número de Ocurrencias')\n",
        "plt.ylabel('Etiquetas')\n",
        "plt.title('Distribución de las Ocurrencias de Etiquetas')\n",
        "\n",
        "# Mostrar la gráfica\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "87ggCkT9KOqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_encoded[column_labels].sum().sort_values()"
      ],
      "metadata": {
        "id": "2RoqsOVaKfYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Embedding"
      ],
      "metadata": {
        "id": "c27xEVrzKjvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para obtener el embedding de BERT de un texto\n",
        "def get_bert_embedding(text):\n",
        "    # Obtener el embedding de BERT\n",
        "    embedding = model.encode(text)\n",
        "    return embedding"
      ],
      "metadata": {
        "id": "iEJnP1YINpas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el modelo SentenceTransformer pre-entrenado\n",
        "model = SentenceTransformer('bert-base-nli-mean-tokens')"
      ],
      "metadata": {
        "id": "STd3mE6yNupe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar la función de limpieza de texto a cada fila del DataFrame\n",
        "train_df_encoded['Contenido_Original_Limpio'] = clean_text(train_df_encoded['Contenido_Original'])\n",
        "train_df_encoded['Contenido_Plagio_Limpio'] = clean_text(train_df_encoded['Contenido_Plagio'])\n",
        "\n",
        "# Aplicar la función de embedding de BERT a cada fila del DataFrame limpio\n",
        "train_df_encoded['Embedding_Original'] = train_df_encoded['Contenido_Original_Limpio'].apply(lambda x: get_bert_embedding(x))\n",
        "train_df_encoded['Embedding_Plagiado'] = train_df_encoded['Contenido_Plagio_Limpio'].apply(lambda x: get_bert_embedding(x))"
      ],
      "metadata": {
        "id": "qEjl76GCKhbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un nuevo DataFrame con los embeddings y las otras características\n",
        "embedding_train_df = train_df_encoded[['Embedding_Original', 'Embedding_Plagiado', 'Cambio de tiempo', 'Cambio de voz', 'Desordenar las frases', 'Parafraseo', 'Reemplazar frases']]\n",
        "\n",
        "# Mostrar el nuevo DataFrame\n",
        "print(embedding_train_df.head())"
      ],
      "metadata": {
        "id": "Jkcxfh_VKsbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar la función de limpieza de texto a cada fila del DataFrame\n",
        "test_df_encoded['Contenido_Original_Limpio'] = clean_text(test_df_encoded['Contenido_Original'])\n",
        "test_df_encoded['Contenido_Plagio_Limpio'] = clean_text(test_df_encoded['Contenido_Plagio'])\n",
        "\n",
        "# Aplicar la función de embedding de BERT a cada fila del DataFrame limpio\n",
        "test_df_encoded['Embedding_Original'] = test_df_encoded['Contenido_Original_Limpio'].apply(lambda x: get_bert_embedding(x))\n",
        "test_df_encoded['Embedding_Plagiado'] = test_df_encoded['Contenido_Plagio_Limpio'].apply(lambda x: get_bert_embedding(x))"
      ],
      "metadata": {
        "id": "cS871LszK1ME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un nuevo DataFrame con los embeddings y las otras características\n",
        "embedding_test_df = test_df_encoded[['Embedding_Original', 'Embedding_Plagiado', 'Cambio de tiempo', 'Cambio de voz', 'Desordenar las frases', 'Parafraseo', 'Reemplazar frases']]\n",
        "\n",
        "# Mostrar el nuevo DataFrame\n",
        "print(embedding_test_df.head())"
      ],
      "metadata": {
        "id": "fRXYR8AbK29v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asignar el DataFrame de entrenamiento codificado a la variable 'train_data'\n",
        "train_data = embedding_train_df\n",
        "\n",
        "# Asignar el DataFrame de prueba codificado a la variable 'test_data'\n",
        "test_data = embedding_test_df\n",
        "\n",
        "# Obtener las etiquetas (nombres de columnas) a partir de la tercera columna del DataFrame de entrenamiento\n",
        "train_labels = train_data.columns[2:]\n",
        "\n",
        "# Obtener las etiquetas (nombres de columnas) a partir de la tercera columna del DataFrame de prueba\n",
        "test_labels = train_data.columns[2:]\n",
        "\n",
        "# Imprimir las etiquetas de entrenamiento\n",
        "print(train_labels)\n",
        "\n",
        "# Imprimir las etiquetas de prueba\n",
        "print(test_labels)\n"
      ],
      "metadata": {
        "id": "cacHfeYcNwAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.shape)\n",
        "print(train_labels.shape)\n",
        "print('----------------------------')\n",
        "print(test_data.shape)\n",
        "print(test_labels.shape)"
      ],
      "metadata": {
        "id": "bPr8pmEyOTrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tokenizar"
      ],
      "metadata": {
        "id": "USU7O8QVOWbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para tokenizar y codificar\n",
        "def tokenize_and_encode(tokenizer, plagiarized, original, labels, max_length=128):\n",
        "\t# Inicializar listas vacías para almacenar las entradas tokenizadas y las máscaras de atención\n",
        "\tinput_ids = []\n",
        "\tattention_masks = []\n",
        "\n",
        "\t# Iterar a través de cada comentario en las listas 'plagiarized' y 'original'\n",
        "\tfor plagiarized, original in zip(plagiarized, original):\n",
        "\n",
        "\t\t# Tokenizar y codificar el comentario utilizando el tokenizador de BERT\n",
        "\t\tencoded_dict = tokenizer.encode_plus(\n",
        "\t\t\tplagiarized,\n",
        "\t\t\ttext_pair=original,\n",
        "\t\t\t# Añadir tokens especiales como [CLS] y [SEP]\n",
        "\t\t\tadd_special_tokens=True,\n",
        "\n",
        "\t\t\t# Truncar o rellenar el comentario a 'max_length'\n",
        "\t\t\tmax_length=max_length,\n",
        "\n",
        "\t\t\ttruncation=True,\n",
        "\n",
        "\t\t\t# Rellenar el comentario hasta 'max_length' con ceros si es necesario\n",
        "\t\t\tpad_to_max_length=True,\n",
        "\n",
        "\t\t\t# Devolver la máscara de atención para enmascarar los tokens rellenados\n",
        "\t\t\treturn_attention_mask=True,\n",
        "\n",
        "\t\t\t# Devolver tensores de PyTorch\n",
        "\t\t\treturn_tensors='pt'\n",
        "\t\t)\n",
        "\n",
        "\t\t# Añadir la entrada tokenizada y la máscara de atención a sus respectivas listas\n",
        "\t\tinput_ids.append(encoded_dict['input_ids'])\n",
        "\t\tattention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "\t# Concatenar las entradas tokenizadas y las máscaras de atención en tensores\n",
        "\tinput_ids = torch.cat(input_ids, dim=0)\n",
        "\tattention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "\t# Convertir las etiquetas a un tensor de PyTorch con el tipo de dato float32\n",
        "\tlabels = torch.tensor(labels, dtype=torch.float32)\n",
        "\n",
        "\t# Devolver las entradas tokenizadas, las máscaras de atención y las etiquetas como tensores de PyTorch\n",
        "\treturn input_ids, attention_masks, labels\n"
      ],
      "metadata": {
        "id": "T8Q-Ct-6OVdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicialización del Tokenizador\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',\n",
        "\t\t\t\t\t\t\t\t\t\tdo_lower_case=True)"
      ],
      "metadata": {
        "id": "Jnp9O0TNOjNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicialización del Modelo\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\tnum_labels=5)\n"
      ],
      "metadata": {
        "id": "Mz7Dl-bLOocE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mover el modelo a GPU si está disponible\n",
        "device = torch.device(\n",
        "\t'cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "KTRJZlO5OsXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_df_encoded\n",
        "test_data = test_df_encoded"
      ],
      "metadata": {
        "id": "rzx5MiT7OxBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifica las columnas de los DataFrames\n",
        "print(\"Train Data Columns: \", train_data.columns)\n",
        "print(\"Test Data Columns: \", test_data.columns)"
      ],
      "metadata": {
        "id": "WtsSNiPXOya4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data)\n",
        "print(test_data)"
      ],
      "metadata": {
        "id": "vKhp0pvlOzq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraer comentarios y etiquetas del DataFrame de datos de entrenamiento\n",
        "plagiarized = train_data['Contenido_Plagio_Limpio'].tolist()\n",
        "original = train_data['Contenido_Original_Limpio'].tolist()\n",
        "plagiarized_test = test_data['Contenido_Plagio_Limpio'].tolist()\n",
        "original_test = test_data['Contenido_Original_Limpio'].tolist()\n",
        "train_labels = train_data[['Cambio de tiempo', 'Cambio de voz', 'Desordenar las frases', 'Parafraseo', 'Reemplazar frases']].values\n",
        "test_labels = test_data[['Cambio de tiempo', 'Cambio de voz', 'Desordenar las frases', 'Parafraseo', 'Reemplazar frases']].values"
      ],
      "metadata": {
        "id": "r0SoTeu3O1Ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizar y codificar los comentarios y etiquetas para el conjunto de entrenamiento\n",
        "input_ids, attention_masks, train_labels = tokenize_and_encode(\n",
        "\ttokenizer,\n",
        "\tplagiarized,\n",
        "\toriginal,\n",
        "\ttrain_labels,\n",
        "\tmax_length=128\n",
        ")\n",
        "\n",
        "# Tokenizar y codificar los comentarios y etiquetas para el conjunto de prueba\n",
        "test_input_ids, test_attention_masks, test_labels = tokenize_and_encode(\n",
        "\ttokenizer,\n",
        "\tplagiarized_test,\n",
        "\toriginal_test,\n",
        "\ttest_labels,\n",
        "\tmax_length=128\n",
        ")\n",
        "\n",
        "# Revisar dimensiones de los tensores\n",
        "print('Textos de Entrenamiento:', train_data.shape)\n",
        "print('ID de Entrada:', input_ids.shape)\n",
        "print('Máscara de Atención:', attention_masks.shape)\n",
        "print('Etiquetas de Entrenamiento:', train_labels.shape)\n",
        "print('---------------------------------------------------------')\n",
        "print('Textos de Prueba:', test_data.shape)\n",
        "print('ID de Entrada de Prueba:', test_input_ids.shape)\n",
        "print('Máscara de Atención de Prueba:', test_attention_masks.shape)\n",
        "print('Etiquetas de Prueba:', test_labels.shape)"
      ],
      "metadata": {
        "id": "8G8COuWuO912"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Entrenamiento del Modelo"
      ],
      "metadata": {
        "id": "iX-_DloWPGDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 6\n",
        "print('Textos de Entrenamiento -->>', train_data.values[k])\n",
        "print('\\nID de Entrada -->>\\n', input_ids[k])\n",
        "print('\\nID Decodificado -->>\\n', tokenizer.decode(input_ids[k]))\n",
        "print('\\nMáscara de Atención -->>\\n', attention_masks[k])\n",
        "print('\\nEtiquetas -->>', train_labels[[k]])"
      ],
      "metadata": {
        "id": "6WP6d7gtPD35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifica las columnas de los DataFrames\n",
        "print(train_data.columns)\n",
        "print(test_data.columns)"
      ],
      "metadata": {
        "id": "bj7g5iB4Pkhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df=train_data[['Embedding_Original', 'Embedding_Plagiado', 'Cambio de tiempo', 'Cambio de voz', 'Desordenar las frases', 'Parafraseo', 'Reemplazar frases']]\n",
        "test_df=test_data[['Embedding_Original', 'Embedding_Plagiado', 'Cambio de tiempo', 'Cambio de voz', 'Desordenar las frases', 'Parafraseo', 'Reemplazar frases']]"
      ],
      "metadata": {
        "id": "x-LLj_7tPoo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifica los DataFrames\n",
        "print(train_df)\n",
        "print(test_df)"
      ],
      "metadata": {
        "id": "GjKTCoG3PrcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"train_labels: {train_labels}\")\n",
        "print(f\"Length of train_labels: {len(train_labels)}\")"
      ],
      "metadata": {
        "id": "9mzzBjZtPr4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creación de DataLoader para el conjunto de datos de entrenamiento balanceado\n",
        "batch_size = 32\n",
        "train_dataset = TensorDataset(input_ids, attention_masks, train_labels)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Conjunto de prueba\n",
        "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "fW83KiwwPwp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Tamaño del Lote:', train_loader.batch_size)\n",
        "batch = next(iter(train_loader))\n",
        "print('Forma de cada ID de Entrada:', batch[0].shape)\n",
        "print('IDs de Entrada:\\n', batch[0][0])\n",
        "print('Texto Decodificado Correspondiente:\\n', tokenizer.decode(batch[0][0]))\n",
        "print('Máscara de Atención Correspondiente:\\n', batch[1][0])\n",
        "print('Etiqueta Correspondiente:', batch[2][0])"
      ],
      "metadata": {
        "id": "-_3i2FPYP4ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuración del Optimizador\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)"
      ],
      "metadata": {
        "id": "NPMbD3E5QOH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicialización del Modelo\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\tnum_labels=5)"
      ],
      "metadata": {
        "id": "zNoNgZu7QSa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, optimizer, device, num_epochs):\n",
        "    # Iterar a través del número especificado de épocas\n",
        "    for epoch in range(num_epochs):\n",
        "        # Establecer el modelo en modo de entrenamiento\n",
        "        model.train()\n",
        "        # Inicializar la pérdida total para la época actual\n",
        "        total_loss = 0\n",
        "\n",
        "        # Iterar a través de los lotes en los datos de entrenamiento\n",
        "        for batch in train_loader:\n",
        "          # Imprimir el lote actual para depuración\n",
        "          print(batch)\n",
        "          # Mover los tensores del lote al dispositivo especificado (CPU o GPU)\n",
        "          input_ids, attention_mask, labels = [t.to(device) for t in batch]\n",
        "\n",
        "          # Reiniciar los gradientes acumulados en el optimizador\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # Propagar hacia adelante: calcular la salida y la pérdida del modelo\n",
        "          outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "          loss = outputs.loss\n",
        "          total_loss += loss.item()\n",
        "\n",
        "          # Propagar hacia atrás: calcular los gradientes de la pérdida con respecto a los parámetros del modelo\n",
        "          loss.backward()\n",
        "          # Actualizar los parámetros del modelo utilizando el optimizador\n",
        "          optimizer.step()\n",
        "\n",
        "        # Imprimir la pérdida promedio para la época actual\n",
        "        print(f'Época {epoch+1}, Pérdida de Entrenamiento: {total_loss/len(train_loader)}')\n",
        "\n",
        "# Crear DataLoader para el conjunto de datos balanceado\n",
        "tamaño_lote = 32\n",
        "conjunto_datos_entrenamiento = TensorDataset(input_ids, attention_masks, train_labels)\n",
        "cargador_entrenamiento = DataLoader(conjunto_datos_entrenamiento, batch_size=tamaño_lote, shuffle=True)\n",
        "\n",
        "# Conjunto de prueba\n",
        "conjunto_datos_prueba = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
        "cargador_prueba = DataLoader(conjunto_datos_prueba, batch_size=tamaño_lote, shuffle=False)\n",
        "\n",
        "# Llamar a la función para entrenar el modelo\n",
        "train_model(model, train_loader, optimizer, device, num_epochs=3)\n"
      ],
      "metadata": {
        "id": "A2Qr-T82QUiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluar Modelo"
      ],
      "metadata": {
        "id": "_IA9vybPQkX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar el Modelo\n",
        "def evaluate_model(model, test_loader, device):\n",
        "\tmodel.eval() # Establecer el modelo en modo de evaluación\n",
        "\n",
        "\ttrue_labels = []\n",
        "\tpredicted_probs = []\n",
        "\n",
        "\twith torch.no_grad():\n",
        "\t\tfor batch in test_loader:\n",
        "\t\t\tinput_ids, attention_mask, labels = [t.to(device) for t in batch]\n",
        "\n",
        "\t\t\t# Obtener las predicciones del modelo\n",
        "\t\t\toutputs = model(input_ids, attention_mask=attention_mask)\n",
        "\t\t\t# Utilizar la función sigmoide para clasificación multietiqueta\n",
        "\t\t\tpredicted_probs_batch = torch.sigmoid(outputs.logits)\n",
        "\t\t\tpredicted_probs.append(predicted_probs_batch.cpu().numpy())\n",
        "\n",
        "\t\t\ttrue_labels_batch = labels.cpu().numpy()\n",
        "\t\t\ttrue_labels.append(true_labels_batch)\n",
        "\n",
        "\t# Combinar predicciones y etiquetas para evaluación\n",
        "\ttrue_labels = np.concatenate(true_labels, axis=0)\n",
        "\tpredicted_probs = np.concatenate(predicted_probs, axis=0)\n",
        "\tpredicted_labels = (predicted_probs > 0.5).astype(\n",
        "\t\tint) # Aplicar umbral para clasificación binaria\n",
        "\n",
        "\t# Calcular métricas de evaluación\n",
        "\taccuracy = accuracy_score(true_labels, predicted_labels)\n",
        "\tprecision = precision_score(true_labels, predicted_labels, average='micro')\n",
        "\trecall = recall_score(true_labels, predicted_labels, average='micro')\n",
        "\n",
        "\t# Imprimir las métricas de evaluación\n",
        "\tprint(f'Precisión: {accuracy:.4f}')\n",
        "\tprint(f'Precision: {precision:.4f}')\n",
        "\tprint(f'Recall: {recall:.4f}')\n",
        "\n",
        "\n",
        "# Llamar a la función para evaluar el modelo en los datos de prueba\n",
        "evaluate_model(model, test_loader, device)"
      ],
      "metadata": {
        "id": "ZVWm0Dt-Qgtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directorio de salida para guardar el modelo y el tokenizer\n",
        "output_dir = \"Saved_model\"\n",
        "# Guardar el diccionario de estado y la configuración del modelo\n",
        "model.save_pretrained(output_dir)\n",
        "# Guardar la configuración y el vocabulario del tokenizer\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "metadata": {
        "id": "qdKt2xJQQq2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nombre del directorio donde se guardaron el modelo y el tokenizer\n",
        "model_name = \"Saved_model\"\n",
        "# Cargar el tokenizer desde el directorio guardado\n",
        "Bert_Tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "# Cargar el modelo desde el directorio guardado y moverlo al dispositivo adecuado (CPU o GPU)\n",
        "Bert_Model = BertForSequenceClassification.from_pretrained(\n",
        "\tmodel_name).to(device)"
      ],
      "metadata": {
        "id": "xMQd5WT7QvUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_input(input_text, model=Bert_Model, tokenizer=Bert_Tokenizer, device=device):\n",
        "    # Convertir el texto de entrada en una lista\n",
        "    input = [input_text]\n",
        "\n",
        "    # Codificar el texto de entrada utilizando el tokenizer\n",
        "    encodings = tokenizer(\n",
        "        input, truncation=True, padding=True, return_tensors=\"pt\")\n",
        "\n",
        "    # Crear un conjunto de datos TensorDataset para el texto de entrada\n",
        "    dataset = TensorDataset(\n",
        "        encodings['input_ids'], encodings['attention_mask'])\n",
        "\n",
        "    # Crear un DataLoader para el conjunto de datos\n",
        "    loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    # Establecer el modelo en modo de evaluación\n",
        "    model.eval()\n",
        "\n",
        "    # Realizar la clasificación del texto de entrada\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            input_ids, attention_mask = [t.to(device) for t in batch]\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            predictions = torch.sigmoid(logits)\n",
        "\n",
        "    # Convertir las predicciones en etiquetas binarias utilizando un umbral de 0.5\n",
        "    predicted_labels = (predictions.cpu().numpy() > 0.5).astype(int)\n",
        "    labels_list = ['Time Change', 'Voice Change',\n",
        "                   'Sentence Rearrangement', 'Paraphrasing', 'Phrase Replacement']\n",
        "    result = dict(zip(labels_list, predicted_labels[0]))\n",
        "    return result\n",
        "\n",
        "\n",
        "# Texto de entrada para clasificar\n",
        "text = 'Interactive software agents, such as chatbots, are progressively being used in the area of health and well-being. In such applications, where agents engage with users in interpersonal conversations for, e.g., coaching, comfort or behavior-change interventions, there is an increased need for understanding agents’ empathic capabilities. In the current state-of-the-art, there are no tools to do that. In order to understand empathic capabilities in interactive software agents, we need a precise notion of empathy. The literature discusses a variety of definitions of empathy, but there is no consensus of a formal definition. Based on a systematic literature review and a qualitative analysis of recent approaches to empathy in interactive agents for health and well-being, a formal definition—an ontology—of empathy is developed. We present the potential of the formal definition in a controlled user-study by applying it as a tool for assessing empathy in two state-of-the-art health and well-being chatbots; Replika and Wysa. Interactive software agents, such as chatbots, are progressively being used in the area of health and well-being. In such applications, where agents engage with users in interpersonal conversations for, e.g., coaching, comfort or behavior-change interventions, there is an increased need for understanding agents’ empathic capabilities. In the current state-of-the-art, there are no tools to do that. In order to understand empathic capabilities in interactive software agents, we need a precise notion of empathy. The literature discusses a variety of definitions of empathy, but there is no consensus of a formal definition. We present the potential of the formal definition in a controlled user-study by applying it as a tool for assessing empathy in two state-of-the-art health and well-being chatbots; Replika and Wysa. Our findings suggest that our definition captures necessary conditions for assessing empathy in interactive agents, and how it can uncover and explain trends in changing perceptions of empathy over time. The definition, implemented in Web Ontology Language (OWL), may serve as an automated tool, enabling systems to recognize empathy in interactions—be it an interactive agent evaluating its own empathic performance or an intelligent system assessing the empathic capability of its interlocutors.'\n",
        "classify_input(input_text=tex\n"
      ],
      "metadata": {
        "id": "xcvNqKl-QzKi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}